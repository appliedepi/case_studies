[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Epi cases studies",
    "section": "",
    "text": "Here, you can practice technical and analytical skills using real-life scenarios. The case studies, contributed by FETPs and health ministries worldwide, feature data that is either generated or anonymized for training purposes.\nFind a case study of interest with the table below, and click on the link to open it in the appropriate language for you."
  },
  {
    "objectID": "index.html#welcome-to-our-case-study-repository",
    "href": "index.html#welcome-to-our-case-study-repository",
    "title": "Applied Epi cases studies",
    "section": "",
    "text": "Here, you can practice technical and analytical skills using real-life scenarios. The case studies, contributed by FETPs and health ministries worldwide, feature data that is either generated or anonymized for training purposes.\nFind a case study of interest with the table below, and click on the link to open it in the appropriate language for you."
  },
  {
    "objectID": "index.html#about-us",
    "href": "index.html#about-us",
    "title": "Applied Epi cases studies",
    "section": "About us",
    "text": "About us\nApplied Epi is a nonprofit organisation and grassroots movement of frontline epis from around the world. We write in our spare time to offer this resource to the community. Your encouragement and feedback is most welcome:\n\nVisit our website and join our contact list\ncontact@appliedepi.org, tweet @appliedepi, or LinkedIn\nSubmit issues to our Github repository"
  },
  {
    "objectID": "pages/r_practical.html",
    "href": "pages/r_practical.html",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "Tool: R | Technical complexity: Basic | Methodological complexity: Basic\nSource: ECDC EI Group (simulated data)\nPrior knowledge required: R basics (Using Rstudio; R packages, functions and arguments)\n\n\n\nFor instructions on how to use our case studies, [see here.] We welcome feedback and suggestions via contact@appliedepi.org. Discuss the case study at [community].\n\n\n\nIt is May 2022 and Mpox has just been reported for the first time across 5 countries in Europe. You have been requested to provide a basic descriptive analysis to the European Centre for Disease Prevention and Control (ECDC).\nYou are given access to:\n\nLinelists with cases collated by the five countries\nDatasets with aggregate cases from open sources\n\nLet’s go!\n\n\n\nIn this case study you will:\n\nExplore different types of files and how they can be imported in R.\nPerform basic data cleaning, e.g., changing the variable type, recode variables, aggregate and filter.\nPerform a basic descriptive analysis using tables and graphs\n\n\n\n\n\n\nStart by setting up a reproducible and well-organized workflow. This will make it easy to rerun your analysis whenever needed.\nTasks:\n\nSet up a R Studio project\nSet up clear sub-folders where your code, data, and outputs will go\nCreate an R script, or an Rmarkdown file if you prefer. Make sure the script purpose, date, and author are written as comments at the top.\nExtra: Ensure your working language in RStudio is appropriate (e.g. English for this exercise)\n\n\n\n Click to read a hint\n\n\n\nCreate a folder where all the work in this case study will go. For example, create ‘mpox_analysis’ on your computer desktop. Create your R Studio project to be based in this folder.\nWe suggest creating the following sub-folders: scripts (for your code), data (for your data), and outputs (for your analytical outputs).\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nTo create an Rstudio project in your new folder, clicking New Project… in the top left of your R Studio, then “Existing Directory” (because your folder area already exists), then Browse to select your new folder. For more information, look at the [R projects] section of the Epi R Handbook (https://epirhandbook.com/new_pages/r_projects.html)\nStart a new R script by clicking New File… in the top left of your R Studio, then “R Script”. Save it immediately in the appropriate place, e.g. in a ‘scripts’ subfolder of your R Project.\nAt the top of your new R scipt, write some essential information like your name, the purpose of the file, and the date.\nYour R locale determines the language and regional settings used for things like date formats and translations. If your locale is different from the language you want for your report (e.g., a French locale vs. an English report), you can change it to English by running Sys.setlocale(“LC_ALL”, “English”). Include this in your script if needed, or skip it if your locale is usually appropriate. More information on this is available in the [instructions] page.\n\n\n\n\nNext in your R script, you need to install and load the necessary R packages. This ensures that the functions you need are available for your analysis.\nYou will need the following packages: rio (for importing data), janitor (for cleaning data), lubridate (for cleaning dates), skimr (for reviewing data), epikit (for epi-related tasks), gtsummary (for presentation-ready tables), apyramid (for age-sex pyramids), and tidyverse (for general data manipulation/science tasks).\nAs you start, your trusted colleague nudges you and whispers “I’ve heard that a great way to manage your packages is with the {pacman} package”.\nOver to you!\n\n\nClick to see a solution (try it yourself first!)\n\n\nUse the function p_load() from {pacman} for this task. You provide the function with a list of packages that you want to use. It will take two steps per package: 1) Check if the package is installed on your computer, and install it if necessary, then 2) Load the package so it can be used during this R session.\nIf you don’t already have pacman installed, you will need to install it the “traditional way” first, with install.packages().\nNote that the order of packages in your p_load function can be important. If two packages have the same function names (e.g. select() in tidyverse and select() in MASS, which do different things), then R will use the function from the most recently loaded package. To prioritize functions from tidyverse, which are commonly used for data manipulation and visualization, load tidyverse last.\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\n\n\n\n\n\n\nECDC provides you with two files for your analysis:\n\nA case-level linelist (“mpox_linelist.xlsx”) with case information from five countries (countries A - E)\nAn aggregate table (“mpox_aggregate_table.csv”) for those countries with cumulative case counts per day.\n\nThey provide it to you via AppliedEpi’s very useful data repository, which you can access using the {appliedepidata} package. So first you need to download these two files to your own computer, as follows:\n\nInstall the {appliedepidata} package from GitHub using the install_github functions in the remotes package. Install {remotes} if you need to first.\n\n\n# Install remotes if you need to (so you can install a package from GitHub)\npacman::p_load(\"remotes\")\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nSave the two datasets into a specific folder using the save_data() function from {appliedepidata}, by running the code below. The example below saves the data into a ‘data’ subfolder within the R project. Note that if you do not specify a location within the ‘path’ argument of the function, a window will pop up asking you to manually select a folder.\n\n\n# Save down the two mpox files using the save_data() function from appliedepidata\nappliedepidata::save_data(\"mpox_linelist\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"mpox_aggregate_table\",\n                          path = \"data\")\n\n\n\n\nGreat! Thanks ECDC and Applied Epi! Now it’s time to import the data into R Studio so you can analyse it.\nTask: Import the downloaded case-based and aggregated data into your R environment. Ideally you want to use one function for both datasets, despite one being a csv and the other an xlsx file.\n\n\n Click to read a hint\n\n\nUse the import function from the {rio} package, which can recognise and import different file types. It replaces importing functions that are specific to the file type, such as read.csv() from {base} for .csv files and read_excel() from {readxl} to import .xlsx files.\nIf you feel you need to know more about importing functions, read the Import and export chapter of the EpiRhandbook.\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n# Import data  --------------\n\n# Case-based data\nmpox_linelist_raw &lt;- import(\"data/mpox_linelist.xlsx\")\n\n# Aggregated data\nmpox_agg_raw &lt;- import(\"data/mpox_aggregate_table.csv\")\n\n\n\n\n\n\nYou need to understand what the data looks like as a first step, to inform your analysis.\nTasks: Take a look at the different data frames and determine:\n\nThe number of columns and observations (e.g. their dimensions)\nThe class of their columns and whether it matches its nature (e.g., are “dates” considered “dates” by R?)\nIf the contents of columns are clean and standardized in the mpox linelist (e.g. gender, clinical symptoms, outcome, hiv status and sexual orientation). Do you need to recode any of them?\nHow unknown or missing data is categorised in these columns. Do these values need to be standardized?\n\n\n\n Click to read a hint\n\n\nAn efficient function for initial data exploring is skim() from the {skimr} package, as it gives you a lot of information on data structure and content.\nYou can also use the function tabyl() from {janitor}, to get counts and percentages of every category in the data column, one by one. These get printed to your RStudio console.\nFinally, you can use the tbl_summary() function from gtsummary to get see the distribution of values within multiple variables at once. The output from tbl_summary() is seen in the Viewer of your RStudio.\nDecide which one you prefer!\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Explore the dimensions of the two data objects\nskim(mpox_linelist_raw)\nskim(mpox_agg_raw)\n\n# Explore the values of different categorical columns in the mpox linelist: with tabyl\ntabyl(mpox_linelist_raw, Gender)\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms)\n\ntabyl(mpox_linelist_raw, Outcome)\n\ntabyl(mpox_linelist_raw, HIVStatus)\n\ntabyl(mpox_linelist_raw, SexualOrientation)\n\n# Explore the values of different categorical columns in the mpox linelist: with tbl_summary\nmpox_linelist_raw %&gt;% \n  select(Gender, ClinicalSymptoms, Outcome, HIVStatus, SexualOrientation) %&gt;% \n  tbl_summary()\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nHow many columns does the aggregated data frame have?\n\n 2000 13 3 101\n\n\n\nWhat is the class of the column DateOfNotification in the case-based data?\n\n Date Character Numeric Factor\n\n\n\nFor how many cases is the HIV status Unknown or missing?\n\n 1168 722 900 446\n\n\n\n\n\n\n\n\n\n\nWhen exploring the case-based data, you may have noticed that there are a few things that we need to take care of before we can start doing further analysis. Firstly, names contain a mixture of upper and lower case letters. Whilst this isn’t in itself a problem, R is case-sensitive, so having all names in lower case may make our life easier. Also, date columns are not consider “Dates” by R, but instead they are being consider as “Character”, which means they are being considered as nominal data. This would give us problems when plotting by Dates. Another issue is that some columns have categories that may not be intuitive for all. For example, Gender is categorised with “F”, “M”, “O” and “UNK”. The column Outcome as “A” and “UNK”. We should give them more appropriate categories. Finally, it is important that missing data is considered as “missing” in R. That means that R treats it as “NA”. In the column clinical symptoms, for example, missing data is an empty cell, not “NA”. R is considering this as another nominal category instead of missing, and will consider it this way in any analysis or output you produce.\nTasks:\n\nCreate a clean version of your case-based data making all cleaning changes in a single piping command\nChange all column names to lower case.\nConvert all date columns to class “Date”.\nUse the column “DateOfNotification” to create a column called “week_date” which has the week of notification, starting on Mondays.\nTransform all empty cells into “NA”\nRecode “Gender” categories into: “Female”, “Male”, “Other” and “Unknown”\nRecode “Outcome” categories into: “Alive” and “Unknown”\nRecode HIV status into: “Positive”, “Negative” and “Unknown/Missing”\nRecode Sexual orientation into: “Bisexual”, “Heterosexual”, “MSM/homo or bisexual male” and “Unknown/missing”.\nCreate a column called “age_group” with ten year age groups and the oldest group being 70+\nCheck that all changes have been made correctly\n\n\n\n Click to read a hint\n\n\nTo convert all names to lower case, rather than renaming each column you may use the function clean_names() from the {janitor} package, which will do it automatically for all columns. Use lubridate functions to transform date columns into “Date” class, you can do this one by one, or you could do all at the same time using the across() function from {dplyr}. If you feel you need to know more about transforming dates read the chapter Working with Dates from the EpiRhandbook. If you are not sure how to use the across() function, you can also read the section on Transform multiple columns.\nOne simple way to create the “week_date” column would be to use the function floor_date() from {lubridate}. Take a look at the documentation to understand how it works and how to make Monday the starting day of the week.\nThere are different functions that we can use to recode. We propose three: The function recode() from {dplyr}, the function ifelse() from {base} and the function case_when() from {dplyr}. If you want to know more about these functions, look that the section on Re-code values from the EpiRhandbook.\nTo create the age groups, explore the function called age_categories() from the {epikit} package.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Create a new object called mpox_linelist which is the clean version of the raw data, applying the cleaning functions\n\n\nmpox_linelist &lt;- mpox_linelist_raw %&gt;% \n  \n  clean_names() %&gt;% # standardises names and puts all into lower case \n  \n  #(Note: after this point all column names have changed)\n  \n  mutate(date_of_notification = ymd(date_of_notification)) %&gt;%  #transform ONE column into date\n\n  mutate(across(starts_with(\"date\"), \n                .fns = ~ ymd(.x))) %&gt;%  #transforms ALL columns starting with \"date\" into dates\n  \n  mutate(week_date = floor_date(date_of_notification, # create week column with Monday start\n                              unit = \"week\",\n                              week_start = \"Monday\")) %&gt;% \n  \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x == \"\", NA, .x)))  %&gt;% #transforms empty cells into NA across all character columns\n  \n  mutate(gender = recode(gender,\n                         \"F\" = \"Female\",\n                         \"M\" = \"Male\",\n                         \"O\" = \"Other\",\n                         \"UNK\" = \"Unknown\")) %&gt;%\n  \n    \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x == \"UNK\", \"Unknown\", .x)))  %&gt;% #transforms UNK to Unknown across all character columns\n  \n  mutate(outcome = ifelse(outcome == \"A\", \"Alive\", outcome)) %&gt;%   #we can recode as well with ifelse if we want to change only one or two categories\n  \n  mutate(hiv_status = case_when(hiv_status == \"NEG\" ~ \"Negative\",    #for more complex recoding better case_when\n                                hiv_status == \"POS\" ~ \"Positive\",\n                                TRUE                ~ \"Unknown/missing\")) %&gt;% \n  \n  mutate(sexual_orientation = case_when(sexual_orientation == \"BISEXUAL\" ~ \"Bisexual\",\n                                        sexual_orientation == \"HETERO\" ~ \"Heterosexual\",\n                                        sexual_orientation == \"MSM\" ~ \"MSM/homo or bisexual male\",\n                                        TRUE                        ~  \"Unknown/missing\")) %&gt;% \n  \n  mutate(age_group = age_categories(age, \n                                    lower = 0,      #set up the lower age\n                                    upper = 70,     #set up the upper age\n                                    by = 10))       #set up the age breaks\n\n\n\n\n# Check that all changes have been made correctly\n\nskim(mpox_linelist)\n\ntabyl(mpox_linelist, gender)\n\ntabyl(mpox_linelist, clinical_symptoms)\n\ntabyl(mpox_linelist, outcome)\n\ntabyl(mpox_linelist, hiv_status)\n\ntabyl(mpox_linelist, sexual_orientation)\n\ntabyl(mpox_linelist, week_date)\n\ntabyl(mpox_linelist, age_group)\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nHow many male cases we have in the data frame?\n\n 36 1960 65 1523\n\n\n\nWhich week has the largest number of cases?\n\n 2022-04-11 2022-07-25 2022-02-28 2022-05-09\n\n\n\nHow many cases with missing age are present?\n\n 1 3 None 396\n\n\n\n\n\n\n\n\nIn a similar way, clean the aggregated data by:\n\nStandardising names to lower case\nEnsure that date of reporting is of class “Date”\nCreate a column called “week_date” with the week of reporting starting on Monday\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Check class of date of reporting column\n\nclass(mpox_agg_raw$DateRep) #It is a date, so we do not need to change its class\n\n# Create a new object called mpox_agg which is the clean version of the raw data, applying the cleaning functions\n\nmpox_agg &lt;- mpox_agg_raw %&gt;% \n  \n  clean_names() %&gt;% # standardises names and puts all into lower case \n  \n  #(Note: after this point all column names have changed)\n  \n  mutate(week_date = floor_date(date_rep, # create week column with Monday start\n                              unit = \"week\",\n                              week_start = \"Monday\")) \n\n\n\n\n\n\n\nYou’re now aware that you have information on region of residence, dates of notification, age, and sex of cases. You can use this to build a picture of how the outbreak is progressing in Europe.\n\n\nTask: Using the case-based data, create a table with the number of cases by country\n\n\n Click to read a hint\n\n\nAn easy way to produce tables is using the function tbl_summary() from {gtsummary} package\n\n\n\n\n\n\n\n\nTest yourself!\n\nWhat’s the country with the largest percentage of cases?\n\n C D B A\n\n\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Create an object with the table\ncb_country_table &lt;- mpox_linelist %&gt;%\n\n  select(country) %&gt;% #select the column that we want to use in the table\n  \n  gtsummary::tbl_summary() # create the table\n\n# Ask R to print the table\ncb_country_table\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 2,0001\n    \n  \n  \n    country\n\n        CountryA\n816 (41%)\n        CountryB\n391 (20%)\n        CountryC\n474 (24%)\n        CountryD\n217 (11%)\n        CountryE\n102 (5.1%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\n\n\n\nTasks:\n\nUsing the case-based data, create an epicurve by week of notification\nUsing the case-based data, create an epicurve by week of notification in which the colour of the bins represents the number of cases by country\nUsing the case-based data, create a heat plot with the number of cases by country and week of notification.\n\n\n\n Click to read a hint\n\n\nTo do the epicurve, you can use ggplot() and geom_histogram(), which will automatically aggregate your data. If you are unsure on how ggplot() works, read the EpiRhandbook chapter on Epidemic curves.\nAn alternative approach is to first aggregate the number of cases by week of notification. You can do this using the functions group_by() and summarise() from {dplyr}. If you are unsure on how to do this, review the Grouping data chapter of the EpiRhandbook.\nOnce you have an object with aggregated cases by week of notification, create the epicurve using ggplot(). If want a dynamic colour inside the bins, you need to assign the fill to the column you want to use (country) and place it inside the aesthetics\nHeat plots can be useful to understand how the epidemic evolved in different countries. You will need to aggregate your data by country and week of notification. You can do this using the functions group_by() and summarise() from {dplyr}. If you are unsure on how to do this, review the Grouping data chapter of the EpiRhandbook. Then, use the geom geom_tile() to create a heat plot. If you’re unsure on how to do this, read the EpiRhanbook section on Heat Plots\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Epicurve by notification\n\nepicurve_epox &lt;- ggplot(data = mpox_linelist,          #data to be used\n                        aes(x = week_date)) +    #with geom_histogram() you only need to assign the x axis\n  \n  geom_histogram(binwidth = 7,                   #binwidth 7 ensures that the width represents 7 days\n                 fill=\"darkgreen\",               #colour inside the bins\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  \n  labs(title=\"Mpox cases reported in 2022\") +  #add a title\n  \n  theme_bw() +                                  #assign a predefined theme\n  \n  theme(axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n           \n  \nepicurve_epox\n\n\n\n# Epicurve by notification and country \n\nepicurve_epox_country &lt;- ggplot(data = mpox_linelist,  #data to be used\n                        aes(x = week_date,       \n                            fill = country)) +   #now the fill needs to be inside aes()  \n  \n  geom_histogram(binwidth = 7,                   #binwidth 7 ensures that the width represents 7 days\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_fill_viridis_d() +                       #we change the predefined colours\n\n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  \n  labs(title=\"Mpox cases reported by country in 2022\") +  #add a title\n  \n  theme_bw() +                                  #assign a predefined theme\n  \n  theme(legend.position = \"bottom\",             #legend position to the bottom\n        axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90),   #rotate the x axis text\n        legend.title = element_blank())         #remove title of legend\n           \n  \nepicurve_epox_country\n\n\n\n# Heatmap of cases by country over time\n\nhp_epox &lt;- mpox_linelist %&gt;% #we first group the data by country and week of notification\n  \n  group_by(country, week_date) %&gt;% \n  \n  summarise(n_cases = n(), .groups = \"drop\") %&gt;% \n\n  #now we can use the pipe to directly plot the resulting data from the grouping\n  \n  ggplot(aes(x = week_date,\n           y = country,           #we want the countries to be in the y axis\n           fill = n_cases)) +     #the colour of the tiles should depend on the number of cases\n  \n  geom_tile(colour = \"black\") +   #this is the outline colour of each tile\n  \n  scale_fill_gradient(            #here we define the colours we want to use in the gradient\n    low = \"lightgreen\",\n    high = \"red\") +\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n  \n  labs(\n    title= \"Mpox cases by country and week of notification\",\n    fill = \"Number of cases\"                               \n  ) +\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\",             #legend position to the bottom\n        axis.text = element_text(size=9),       #define the font size of the axis\n        axis.title = element_blank(),           #remove the titles of the x and y \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n    \nhp_epox \n\n\n\n\n\n\n\n\n\nNow that we have created some outputs by time and place, we should focus on the “person” element. The two most important demographic characteristics are usually age and gender. In the case we are seeing, we may also want to explore the sexual orientation of cases.\nTask:\n\nExplore the number of cases by age group and gender.\nCreate a table with number and percentages of cases by sexual orientation\n\n\n\n Click to read a hint\n\n\nThe easiest way to explore both columns (age_group and gender) would be to use the tabyl() function from {janitor}. Then, to create the age pyramid explore the function age_pyramid() from the {apyramid} package. You can find more about this function in the EpiRhandbook chapter Demographic pyramids and Likert-scales\nTo create the table by sexual orientation, consider using the function tbl_summary() from {gtsummary}\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Explore gender and age group columns\ntabyl(mpox_linelist, gender)\n\n  gender    n percent\n  Female   36  0.0180\n    Male 1960  0.9800\n   Other    1  0.0005\n Unknown    3  0.0015\n\ntabyl(mpox_linelist, age_group)\n\n age_group   n percent valid_percent\n       0-9   1  0.0005  0.0005007511\n     10-19  33  0.0165  0.0165247872\n     20-29 396  0.1980  0.1982974462\n     30-39 766  0.3830  0.3835753630\n     40-49 524  0.2620  0.2623935904\n     50-59 204  0.1020  0.1021532298\n     60-69  64  0.0320  0.0320480721\n       70+   9  0.0045  0.0045067601\n      &lt;NA&gt;   3  0.0015            NA\n\n# Table with sexual orientation \n\ntab_sor &lt;- mpox_linelist %&gt;% \n  \n  select(sexual_orientation) %&gt;% \n  \n  tbl_summary(label = list(sexual_orientation ~ \"Sexual Orientation\")) \n\ntab_sor\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 2,0001\n    \n  \n  \n    Sexual Orientation\n\n        Bisexual\n7 (0.4%)\n        Heterosexual\n46 (2.3%)\n        MSM/homo or bisexual male\n833 (42%)\n        Unknown/missing\n1,114 (56%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nWhich demographic group is more affected by Mpox?\n\n Females 60-69 Males 40-49 Females 10-19 Males 30-39\n\n\n\n\n\n\n\n\nNow, let’s summarise the main clinical information that we have in our case-based data frame.\nTasks:\n\nCreate a bar plot with the proportion of each type clinical symptoms\nCreate a table with the number and percentage of cases by outcome\n\n\n\n Click to read a hint\n\n\nTo create bar plots we can use geom_bar() or geom_col() depending on the nature of our data. If we aggregate first, we can use geom_col(), otherwise we should use geom_bar(). There is a function of the {gtsummary} package called add_p() which enables you to easy calculate a statistical test across groups. If you want to know more read the section on gtsummary package of the EpiRhandbook.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Bar plot with clinical symptoms\n\nbar_clinical &lt;- mpox_linelist %&gt;% \n  \n  drop_na(clinical_symptoms) %&gt;%   # we remove those with missing clinical symptoms\n  \n  group_by(clinical_symptoms) %&gt;% \n  \n  summarise(n_cases = n(), .groups = \"drop\") %&gt;%\n  \n  mutate(prop=(n_cases/sum(n_cases))*100) %&gt;%  # we create a column with proportions\n  \n  ggplot(aes(y = reorder(clinical_symptoms, prop), x = prop)) +  # the reorder function ensures that categories are ordered by proportion in the graph\n  \n  geom_col(fill = \"darkgreen\") + \n  \n  labs(\n    title= \"Frequency of clinical symptoms in Mpox cases\",\n    y = \"\",\n    x = \"Number of cases\"\n  ) +\n  \n  theme_bw() +\n  \n  theme(axis.text = element_text(size=9))       #define the font size of the axis\n\nbar_clinical  \n\n\n\n# Table with number and percentage of cases by outcome\n\ntab_outcome &lt;- mpox_linelist %&gt;% \n  \n  select(outcome) %&gt;% \n  \n  tbl_summary(label = list(outcome = \"Reported outcome\")) # with the argument \"label\" we can change how the column name is displayed\n\ntab_outcome\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 2,0001\n    \n  \n  \n    Reported outcome\n\n        Alive\n1,405 (70%)\n        Unknown\n595 (30%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\n\n\n\n\nIt is important to understand how timely, complete, and valid your data is, if it will be the basis of understanding an outbreak and making decisions. For example - you will need to be mindful of reporting delays when interpreting epicurves, and be aware of how complete different sources of data are compared to each other.\n\n\nTasks\n\nCalculate median time from symptom onset to diagnosis and from diagnosis to notification, both overall and by country\nAssess visually the number of cases by calendar period and type of date (onset, diagnosis and notification)\n\n\n\n Click to read a hint\n\n\nTo plot together the different dates you may need to transform your data from “wide” to “long” form. What we call “pivoting” in R. The objective is to have a column with the different date categories (onset, diagnosis and notification) and another column with their date value. If you are unsure on how to do this, have a look at the Pivoting data chapter of the EpiRhandbook. Then, try to plot with the daily values, but if that’s not easy to interpret you may want to aggregate cases by week.\n\n\n\n\n\n\n\n\nTest yourself!\n\nIs there a difference in the delay from diagnosis to notification by country?\n\n Yes No\n\n\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Estimate delay between onset and diagnosis, and between diagnosis and notification\n\ndelay_db &lt;- mpox_linelist %&gt;% \n  \n  mutate(delay_diag = as.numeric(date_of_diagnosis - date_of_onset)) %&gt;%   #we create variables with difference between dates, we transform them in numeric to be able to then calculate measures of central tendency\n  \n  mutate(delay_not = as.numeric(date_of_notification - date_of_diagnosis))\n\nsummary(delay_db$delay_diag) #the summary will give us measures of central tendency and dispersion\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n -2.000   4.000   7.000   7.758  10.000  66.000     897 \n\nsummary(delay_db$delay_not)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-46.0000  -2.0000   0.0000  -0.6078   1.0000  23.0000      715 \n\ndelay_country &lt;- delay_db %&gt;% #here, we group by country and summarise the median to compare across countries\n  \n  group_by(country) %&gt;% \n  \n  summarise(median_delay_diag = median(delay_diag, na.rm = T),\n            median_delay_not = median(delay_not, na.rm = T))\n\ndelay_country\n\n# A tibble: 5 × 3\n  country  median_delay_diag median_delay_not\n  &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt;\n1 CountryA                 7                0\n2 CountryB                 7                0\n3 CountryC                 6                0\n4 CountryD                 7                0\n5 CountryE                 6                0\n\n# Line graph with the different dates \n\ndates_longer &lt;- mpox_linelist %&gt;% # use the variables of the dates and make a longer dataset. In the pivot_longer() command we select the columns which we want to expand in long format and transform the dataset\n   \n  pivot_longer(\n    \n    cols=starts_with(\"date_\"),         # all columns starting with \"date_\" will be taken \n\n    names_to = \"indicator\",            #the names of the columns will be placed in a single column called \"indicator\"\n\n    values_to = \"date\")                # the values (which are dates in this case) will be placed in a column called \"date\"\n  \n\ndates_longer_week &lt;- dates_longer  %&gt;% \n\n  mutate(week_date = floor_date(date, unit = \"week\", week_start = \"Monday\")) %&gt;%  # we create a week column\n    \n  group_by(indicator, week_date) %&gt;% \n    \n  summarise(n=n(), .groups=\"drop\") %&gt;%   # we group and summarise to have the number of cases by date type and week\n    \n  drop_na(week_date)                     # we drop the cases with no data on dates\n\n\n\n\nplot_date_delay &lt;-   ggplot(data = dates_longer_week,\n                            aes(x = week_date, \n                                y = n, \n                                color=indicator)) +\n  \n  geom_line(linewidth = 1.5) +\n  \n  scale_x_date(breaks = \"2 weeks\")+\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\", \n        axis.text = element_text(size=9),\n        axis.title = element_blank(),\n        axis.text.x = element_text(angle=90),\n        legend.title = element_blank()) +\n  labs(title=\"Mpox cases reported in 2022, by date of onset, diagnosis and notification.\")\n\nplot_date_delay\n\n\n\n\n\n\n\n\n\nTask: Create a plot comparing the number of cases reported to through the case-based flow and through the aggregated flow in each country.\nNOTE: Take into consideration that the column on cases in the aggregated data frame reports the cumulative number of cases.\n\n\n\n\n\n\nTest yourself!\n\nWhich country is not reporting aggregated data?\n\n A B C D E\n\n\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Create a data frame with the overall number of cases reported through the aggregated flux\n\nmpox_agg_country &lt;- mpox_agg %&gt;% \n  \n  group_by(country) %&gt;% \n  \n  filter(date_rep == max(date_rep)) %&gt;% # as we have cumulative data, we keep only the last week (after grouping by country)\n  \n  select(-date_rep, -week_date) %&gt;%     # remove unnecessary columns\n\n  mutate(source = \"aggregated\")         # we create this column to distinguish the numbers from the case-based flux\n\n\n# Create a data frame with the overall number of cases reported through the case-based flux\n\nmpox_linelist_country &lt;- mpox_linelist %&gt;%\n  \n  group_by(country) %&gt;% \n  \n  summarise(cases = n(), .groups = \"drop\") %&gt;% \n  \n  mutate(source = \"case_based\")       # we create this column to distinguish the numbers from the\n  \n\n# We append both data frames. Remember this is different from merging\n\ntotal_data &lt;- bind_rows(mpox_linelist_country, mpox_agg_country)\n\n\n# We create a graph to compare the cases reported in both sources\n\ngraph_comp &lt;- ggplot(data = total_data,\n                     aes(x = source, \n                         y = cases, \n                         fill = source)) +\n  \n  geom_col(position = \"dodge\") +            #position dodge puts bars one next to each other, instead of \"stacked\"\n  \n  facet_wrap(~ country, scales = \"free_y\") +  # this command gives us one graph per country. The argument scales is used to allow each y axis scales to adjust to the data\n\n  scale_fill_viridis_d(\n    labels = c(\"Aggregated\", \"Case-based\")  # this function changes the colours, but with the argument \"labels\" we can change the text of each fill.\n     ) +\n  \n  \n  labs(\n    title = \"Number of cases of Mpox reported in 2022 according to source of data\",\n    fill = \"Source\",\n    x = \"\",\n    y = \"Total number of cases\"\n  ) + \n  \n  theme_bw() +\n  \n  theme(axis.text.x = element_blank(),      # we remove the text of the x axis because it is already present in the legend\n        axis.ticks.x = element_blank())     # we also remove the ticks for aesthetic purposes\n\ngraph_comp\n\n\n\n\n\n\n\n\n\n\nWell done! Through your analysis you now understand the magnitude of the outbreak so far, where and when it spread, which demographic groups are most affected, and how the disease actually manifests in terms of symptoms and severity. ECDC is very happy with your work.\nBy coding this up in R, this analysis should be reproducible, meaning you can quickly update it with new data and keep monitoring the outbreak. To further practise reproducible reports, [link to RMarkdown].\n\n\n\nAuthorship\nOriginal authors: Xanthi Andrianou, Gianfranco Spiteri (ECDC EI Group)\nData source: Fictional data provided by ECDC EI Group for training purposes\n\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nOctober 2021\nFirst draft\n1\nXanthi Andrianou\n\n\nJune 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales\n\n\n\nTerms of Use"
  },
  {
    "objectID": "pages/r_practical.html#scenario",
    "href": "pages/r_practical.html#scenario",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "It is May 2022 and Mpox has just been reported for the first time across 5 countries in Europe. You have been requested to provide a basic descriptive analysis to the European Centre for Disease Prevention and Control (ECDC).\nYou are given access to:\n\nLinelists with cases collated by the five countries\nDatasets with aggregate cases from open sources\n\nLet’s go!"
  },
  {
    "objectID": "pages/r_practical.html#objectives",
    "href": "pages/r_practical.html#objectives",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "In this case study you will:\n\nExplore different types of files and how they can be imported in R.\nPerform basic data cleaning, e.g., changing the variable type, recode variables, aggregate and filter.\nPerform a basic descriptive analysis using tables and graphs"
  },
  {
    "objectID": "pages/r_practical.html#step-1.-set-up",
    "href": "pages/r_practical.html#step-1.-set-up",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "Start by setting up a reproducible and well-organized workflow. This will make it easy to rerun your analysis whenever needed.\nTasks:\n\nSet up a R Studio project\nSet up clear sub-folders where your code, data, and outputs will go\nCreate an R script, or an Rmarkdown file if you prefer. Make sure the script purpose, date, and author are written as comments at the top.\nExtra: Ensure your working language in RStudio is appropriate (e.g. English for this exercise)\n\n\n\n Click to read a hint\n\n\n\nCreate a folder where all the work in this case study will go. For example, create ‘mpox_analysis’ on your computer desktop. Create your R Studio project to be based in this folder.\nWe suggest creating the following sub-folders: scripts (for your code), data (for your data), and outputs (for your analytical outputs).\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nTo create an Rstudio project in your new folder, clicking New Project… in the top left of your R Studio, then “Existing Directory” (because your folder area already exists), then Browse to select your new folder. For more information, look at the [R projects] section of the Epi R Handbook (https://epirhandbook.com/new_pages/r_projects.html)\nStart a new R script by clicking New File… in the top left of your R Studio, then “R Script”. Save it immediately in the appropriate place, e.g. in a ‘scripts’ subfolder of your R Project.\nAt the top of your new R scipt, write some essential information like your name, the purpose of the file, and the date.\nYour R locale determines the language and regional settings used for things like date formats and translations. If your locale is different from the language you want for your report (e.g., a French locale vs. an English report), you can change it to English by running Sys.setlocale(“LC_ALL”, “English”). Include this in your script if needed, or skip it if your locale is usually appropriate. More information on this is available in the [instructions] page.\n\n\n\n\nNext in your R script, you need to install and load the necessary R packages. This ensures that the functions you need are available for your analysis.\nYou will need the following packages: rio (for importing data), janitor (for cleaning data), lubridate (for cleaning dates), skimr (for reviewing data), epikit (for epi-related tasks), gtsummary (for presentation-ready tables), apyramid (for age-sex pyramids), and tidyverse (for general data manipulation/science tasks).\nAs you start, your trusted colleague nudges you and whispers “I’ve heard that a great way to manage your packages is with the {pacman} package”.\nOver to you!\n\n\nClick to see a solution (try it yourself first!)\n\n\nUse the function p_load() from {pacman} for this task. You provide the function with a list of packages that you want to use. It will take two steps per package: 1) Check if the package is installed on your computer, and install it if necessary, then 2) Load the package so it can be used during this R session.\nIf you don’t already have pacman installed, you will need to install it the “traditional way” first, with install.packages().\nNote that the order of packages in your p_load function can be important. If two packages have the same function names (e.g. select() in tidyverse and select() in MASS, which do different things), then R will use the function from the most recently loaded package. To prioritize functions from tidyverse, which are commonly used for data manipulation and visualization, load tidyverse last.\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)"
  },
  {
    "objectID": "pages/r_practical.html#step-2-download-and-import-the-data",
    "href": "pages/r_practical.html#step-2-download-and-import-the-data",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "ECDC provides you with two files for your analysis:\n\nA case-level linelist (“mpox_linelist.xlsx”) with case information from five countries (countries A - E)\nAn aggregate table (“mpox_aggregate_table.csv”) for those countries with cumulative case counts per day.\n\nThey provide it to you via AppliedEpi’s very useful data repository, which you can access using the {appliedepidata} package. So first you need to download these two files to your own computer, as follows:\n\nInstall the {appliedepidata} package from GitHub using the install_github functions in the remotes package. Install {remotes} if you need to first.\n\n\n# Install remotes if you need to (so you can install a package from GitHub)\npacman::p_load(\"remotes\")\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nSave the two datasets into a specific folder using the save_data() function from {appliedepidata}, by running the code below. The example below saves the data into a ‘data’ subfolder within the R project. Note that if you do not specify a location within the ‘path’ argument of the function, a window will pop up asking you to manually select a folder.\n\n\n# Save down the two mpox files using the save_data() function from appliedepidata\nappliedepidata::save_data(\"mpox_linelist\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"mpox_aggregate_table\",\n                          path = \"data\")\n\n\n\n\nGreat! Thanks ECDC and Applied Epi! Now it’s time to import the data into R Studio so you can analyse it.\nTask: Import the downloaded case-based and aggregated data into your R environment. Ideally you want to use one function for both datasets, despite one being a csv and the other an xlsx file.\n\n\n Click to read a hint\n\n\nUse the import function from the {rio} package, which can recognise and import different file types. It replaces importing functions that are specific to the file type, such as read.csv() from {base} for .csv files and read_excel() from {readxl} to import .xlsx files.\nIf you feel you need to know more about importing functions, read the Import and export chapter of the EpiRhandbook.\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n# Import data  --------------\n\n# Case-based data\nmpox_linelist_raw &lt;- import(\"data/mpox_linelist.xlsx\")\n\n# Aggregated data\nmpox_agg_raw &lt;- import(\"data/mpox_aggregate_table.csv\")"
  },
  {
    "objectID": "pages/r_practical.html#step-3-explore-the-data",
    "href": "pages/r_practical.html#step-3-explore-the-data",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "You need to understand what the data looks like as a first step, to inform your analysis.\nTasks: Take a look at the different data frames and determine:\n\nThe number of columns and observations (e.g. their dimensions)\nThe class of their columns and whether it matches its nature (e.g., are “dates” considered “dates” by R?)\nIf the contents of columns are clean and standardized in the mpox linelist (e.g. gender, clinical symptoms, outcome, hiv status and sexual orientation). Do you need to recode any of them?\nHow unknown or missing data is categorised in these columns. Do these values need to be standardized?\n\n\n\n Click to read a hint\n\n\nAn efficient function for initial data exploring is skim() from the {skimr} package, as it gives you a lot of information on data structure and content.\nYou can also use the function tabyl() from {janitor}, to get counts and percentages of every category in the data column, one by one. These get printed to your RStudio console.\nFinally, you can use the tbl_summary() function from gtsummary to get see the distribution of values within multiple variables at once. The output from tbl_summary() is seen in the Viewer of your RStudio.\nDecide which one you prefer!\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Explore the dimensions of the two data objects\nskim(mpox_linelist_raw)\nskim(mpox_agg_raw)\n\n# Explore the values of different categorical columns in the mpox linelist: with tabyl\ntabyl(mpox_linelist_raw, Gender)\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms)\n\ntabyl(mpox_linelist_raw, Outcome)\n\ntabyl(mpox_linelist_raw, HIVStatus)\n\ntabyl(mpox_linelist_raw, SexualOrientation)\n\n# Explore the values of different categorical columns in the mpox linelist: with tbl_summary\nmpox_linelist_raw %&gt;% \n  select(Gender, ClinicalSymptoms, Outcome, HIVStatus, SexualOrientation) %&gt;% \n  tbl_summary()\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nHow many columns does the aggregated data frame have?\n\n 2000 13 3 101\n\n\n\nWhat is the class of the column DateOfNotification in the case-based data?\n\n Date Character Numeric Factor\n\n\n\nFor how many cases is the HIV status Unknown or missing?\n\n 1168 722 900 446"
  },
  {
    "objectID": "pages/r_practical.html#step-4-clean-the-data",
    "href": "pages/r_practical.html#step-4-clean-the-data",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "When exploring the case-based data, you may have noticed that there are a few things that we need to take care of before we can start doing further analysis. Firstly, names contain a mixture of upper and lower case letters. Whilst this isn’t in itself a problem, R is case-sensitive, so having all names in lower case may make our life easier. Also, date columns are not consider “Dates” by R, but instead they are being consider as “Character”, which means they are being considered as nominal data. This would give us problems when plotting by Dates. Another issue is that some columns have categories that may not be intuitive for all. For example, Gender is categorised with “F”, “M”, “O” and “UNK”. The column Outcome as “A” and “UNK”. We should give them more appropriate categories. Finally, it is important that missing data is considered as “missing” in R. That means that R treats it as “NA”. In the column clinical symptoms, for example, missing data is an empty cell, not “NA”. R is considering this as another nominal category instead of missing, and will consider it this way in any analysis or output you produce.\nTasks:\n\nCreate a clean version of your case-based data making all cleaning changes in a single piping command\nChange all column names to lower case.\nConvert all date columns to class “Date”.\nUse the column “DateOfNotification” to create a column called “week_date” which has the week of notification, starting on Mondays.\nTransform all empty cells into “NA”\nRecode “Gender” categories into: “Female”, “Male”, “Other” and “Unknown”\nRecode “Outcome” categories into: “Alive” and “Unknown”\nRecode HIV status into: “Positive”, “Negative” and “Unknown/Missing”\nRecode Sexual orientation into: “Bisexual”, “Heterosexual”, “MSM/homo or bisexual male” and “Unknown/missing”.\nCreate a column called “age_group” with ten year age groups and the oldest group being 70+\nCheck that all changes have been made correctly\n\n\n\n Click to read a hint\n\n\nTo convert all names to lower case, rather than renaming each column you may use the function clean_names() from the {janitor} package, which will do it automatically for all columns. Use lubridate functions to transform date columns into “Date” class, you can do this one by one, or you could do all at the same time using the across() function from {dplyr}. If you feel you need to know more about transforming dates read the chapter Working with Dates from the EpiRhandbook. If you are not sure how to use the across() function, you can also read the section on Transform multiple columns.\nOne simple way to create the “week_date” column would be to use the function floor_date() from {lubridate}. Take a look at the documentation to understand how it works and how to make Monday the starting day of the week.\nThere are different functions that we can use to recode. We propose three: The function recode() from {dplyr}, the function ifelse() from {base} and the function case_when() from {dplyr}. If you want to know more about these functions, look that the section on Re-code values from the EpiRhandbook.\nTo create the age groups, explore the function called age_categories() from the {epikit} package.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Create a new object called mpox_linelist which is the clean version of the raw data, applying the cleaning functions\n\n\nmpox_linelist &lt;- mpox_linelist_raw %&gt;% \n  \n  clean_names() %&gt;% # standardises names and puts all into lower case \n  \n  #(Note: after this point all column names have changed)\n  \n  mutate(date_of_notification = ymd(date_of_notification)) %&gt;%  #transform ONE column into date\n\n  mutate(across(starts_with(\"date\"), \n                .fns = ~ ymd(.x))) %&gt;%  #transforms ALL columns starting with \"date\" into dates\n  \n  mutate(week_date = floor_date(date_of_notification, # create week column with Monday start\n                              unit = \"week\",\n                              week_start = \"Monday\")) %&gt;% \n  \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x == \"\", NA, .x)))  %&gt;% #transforms empty cells into NA across all character columns\n  \n  mutate(gender = recode(gender,\n                         \"F\" = \"Female\",\n                         \"M\" = \"Male\",\n                         \"O\" = \"Other\",\n                         \"UNK\" = \"Unknown\")) %&gt;%\n  \n    \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x == \"UNK\", \"Unknown\", .x)))  %&gt;% #transforms UNK to Unknown across all character columns\n  \n  mutate(outcome = ifelse(outcome == \"A\", \"Alive\", outcome)) %&gt;%   #we can recode as well with ifelse if we want to change only one or two categories\n  \n  mutate(hiv_status = case_when(hiv_status == \"NEG\" ~ \"Negative\",    #for more complex recoding better case_when\n                                hiv_status == \"POS\" ~ \"Positive\",\n                                TRUE                ~ \"Unknown/missing\")) %&gt;% \n  \n  mutate(sexual_orientation = case_when(sexual_orientation == \"BISEXUAL\" ~ \"Bisexual\",\n                                        sexual_orientation == \"HETERO\" ~ \"Heterosexual\",\n                                        sexual_orientation == \"MSM\" ~ \"MSM/homo or bisexual male\",\n                                        TRUE                        ~  \"Unknown/missing\")) %&gt;% \n  \n  mutate(age_group = age_categories(age, \n                                    lower = 0,      #set up the lower age\n                                    upper = 70,     #set up the upper age\n                                    by = 10))       #set up the age breaks\n\n\n\n\n# Check that all changes have been made correctly\n\nskim(mpox_linelist)\n\ntabyl(mpox_linelist, gender)\n\ntabyl(mpox_linelist, clinical_symptoms)\n\ntabyl(mpox_linelist, outcome)\n\ntabyl(mpox_linelist, hiv_status)\n\ntabyl(mpox_linelist, sexual_orientation)\n\ntabyl(mpox_linelist, week_date)\n\ntabyl(mpox_linelist, age_group)\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nHow many male cases we have in the data frame?\n\n 36 1960 65 1523\n\n\n\nWhich week has the largest number of cases?\n\n 2022-04-11 2022-07-25 2022-02-28 2022-05-09\n\n\n\nHow many cases with missing age are present?\n\n 1 3 None 396\n\n\n\n\n\n\n\n\nIn a similar way, clean the aggregated data by:\n\nStandardising names to lower case\nEnsure that date of reporting is of class “Date”\nCreate a column called “week_date” with the week of reporting starting on Monday\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Check class of date of reporting column\n\nclass(mpox_agg_raw$DateRep) #It is a date, so we do not need to change its class\n\n# Create a new object called mpox_agg which is the clean version of the raw data, applying the cleaning functions\n\nmpox_agg &lt;- mpox_agg_raw %&gt;% \n  \n  clean_names() %&gt;% # standardises names and puts all into lower case \n  \n  #(Note: after this point all column names have changed)\n  \n  mutate(week_date = floor_date(date_rep, # create week column with Monday start\n                              unit = \"week\",\n                              week_start = \"Monday\"))"
  },
  {
    "objectID": "pages/r_practical.html#step-5-describe-outbreak-by-person-place-and-time",
    "href": "pages/r_practical.html#step-5-describe-outbreak-by-person-place-and-time",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "You’re now aware that you have information on region of residence, dates of notification, age, and sex of cases. You can use this to build a picture of how the outbreak is progressing in Europe.\n\n\nTask: Using the case-based data, create a table with the number of cases by country\n\n\n Click to read a hint\n\n\nAn easy way to produce tables is using the function tbl_summary() from {gtsummary} package\n\n\n\n\n\n\n\n\nTest yourself!\n\nWhat’s the country with the largest percentage of cases?\n\n C D B A\n\n\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Create an object with the table\ncb_country_table &lt;- mpox_linelist %&gt;%\n\n  select(country) %&gt;% #select the column that we want to use in the table\n  \n  gtsummary::tbl_summary() # create the table\n\n# Ask R to print the table\ncb_country_table\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 2,0001\n    \n  \n  \n    country\n\n        CountryA\n816 (41%)\n        CountryB\n391 (20%)\n        CountryC\n474 (24%)\n        CountryD\n217 (11%)\n        CountryE\n102 (5.1%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\n\n\n\nTasks:\n\nUsing the case-based data, create an epicurve by week of notification\nUsing the case-based data, create an epicurve by week of notification in which the colour of the bins represents the number of cases by country\nUsing the case-based data, create a heat plot with the number of cases by country and week of notification.\n\n\n\n Click to read a hint\n\n\nTo do the epicurve, you can use ggplot() and geom_histogram(), which will automatically aggregate your data. If you are unsure on how ggplot() works, read the EpiRhandbook chapter on Epidemic curves.\nAn alternative approach is to first aggregate the number of cases by week of notification. You can do this using the functions group_by() and summarise() from {dplyr}. If you are unsure on how to do this, review the Grouping data chapter of the EpiRhandbook.\nOnce you have an object with aggregated cases by week of notification, create the epicurve using ggplot(). If want a dynamic colour inside the bins, you need to assign the fill to the column you want to use (country) and place it inside the aesthetics\nHeat plots can be useful to understand how the epidemic evolved in different countries. You will need to aggregate your data by country and week of notification. You can do this using the functions group_by() and summarise() from {dplyr}. If you are unsure on how to do this, review the Grouping data chapter of the EpiRhandbook. Then, use the geom geom_tile() to create a heat plot. If you’re unsure on how to do this, read the EpiRhanbook section on Heat Plots\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Epicurve by notification\n\nepicurve_epox &lt;- ggplot(data = mpox_linelist,          #data to be used\n                        aes(x = week_date)) +    #with geom_histogram() you only need to assign the x axis\n  \n  geom_histogram(binwidth = 7,                   #binwidth 7 ensures that the width represents 7 days\n                 fill=\"darkgreen\",               #colour inside the bins\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  \n  labs(title=\"Mpox cases reported in 2022\") +  #add a title\n  \n  theme_bw() +                                  #assign a predefined theme\n  \n  theme(axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n           \n  \nepicurve_epox\n\n\n\n# Epicurve by notification and country \n\nepicurve_epox_country &lt;- ggplot(data = mpox_linelist,  #data to be used\n                        aes(x = week_date,       \n                            fill = country)) +   #now the fill needs to be inside aes()  \n  \n  geom_histogram(binwidth = 7,                   #binwidth 7 ensures that the width represents 7 days\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_fill_viridis_d() +                       #we change the predefined colours\n\n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  \n  labs(title=\"Mpox cases reported by country in 2022\") +  #add a title\n  \n  theme_bw() +                                  #assign a predefined theme\n  \n  theme(legend.position = \"bottom\",             #legend position to the bottom\n        axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90),   #rotate the x axis text\n        legend.title = element_blank())         #remove title of legend\n           \n  \nepicurve_epox_country\n\n\n\n# Heatmap of cases by country over time\n\nhp_epox &lt;- mpox_linelist %&gt;% #we first group the data by country and week of notification\n  \n  group_by(country, week_date) %&gt;% \n  \n  summarise(n_cases = n(), .groups = \"drop\") %&gt;% \n\n  #now we can use the pipe to directly plot the resulting data from the grouping\n  \n  ggplot(aes(x = week_date,\n           y = country,           #we want the countries to be in the y axis\n           fill = n_cases)) +     #the colour of the tiles should depend on the number of cases\n  \n  geom_tile(colour = \"black\") +   #this is the outline colour of each tile\n  \n  scale_fill_gradient(            #here we define the colours we want to use in the gradient\n    low = \"lightgreen\",\n    high = \"red\") +\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n  \n  labs(\n    title= \"Mpox cases by country and week of notification\",\n    fill = \"Number of cases\"                               \n  ) +\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\",             #legend position to the bottom\n        axis.text = element_text(size=9),       #define the font size of the axis\n        axis.title = element_blank(),           #remove the titles of the x and y \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n    \nhp_epox \n\n\n\n\n\n\n\n\n\nNow that we have created some outputs by time and place, we should focus on the “person” element. The two most important demographic characteristics are usually age and gender. In the case we are seeing, we may also want to explore the sexual orientation of cases.\nTask:\n\nExplore the number of cases by age group and gender.\nCreate a table with number and percentages of cases by sexual orientation\n\n\n\n Click to read a hint\n\n\nThe easiest way to explore both columns (age_group and gender) would be to use the tabyl() function from {janitor}. Then, to create the age pyramid explore the function age_pyramid() from the {apyramid} package. You can find more about this function in the EpiRhandbook chapter Demographic pyramids and Likert-scales\nTo create the table by sexual orientation, consider using the function tbl_summary() from {gtsummary}\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Explore gender and age group columns\ntabyl(mpox_linelist, gender)\n\n  gender    n percent\n  Female   36  0.0180\n    Male 1960  0.9800\n   Other    1  0.0005\n Unknown    3  0.0015\n\ntabyl(mpox_linelist, age_group)\n\n age_group   n percent valid_percent\n       0-9   1  0.0005  0.0005007511\n     10-19  33  0.0165  0.0165247872\n     20-29 396  0.1980  0.1982974462\n     30-39 766  0.3830  0.3835753630\n     40-49 524  0.2620  0.2623935904\n     50-59 204  0.1020  0.1021532298\n     60-69  64  0.0320  0.0320480721\n       70+   9  0.0045  0.0045067601\n      &lt;NA&gt;   3  0.0015            NA\n\n# Table with sexual orientation \n\ntab_sor &lt;- mpox_linelist %&gt;% \n  \n  select(sexual_orientation) %&gt;% \n  \n  tbl_summary(label = list(sexual_orientation ~ \"Sexual Orientation\")) \n\ntab_sor\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 2,0001\n    \n  \n  \n    Sexual Orientation\n\n        Bisexual\n7 (0.4%)\n        Heterosexual\n46 (2.3%)\n        MSM/homo or bisexual male\n833 (42%)\n        Unknown/missing\n1,114 (56%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nWhich demographic group is more affected by Mpox?\n\n Females 60-69 Males 40-49 Females 10-19 Males 30-39\n\n\n\n\n\n\n\n\nNow, let’s summarise the main clinical information that we have in our case-based data frame.\nTasks:\n\nCreate a bar plot with the proportion of each type clinical symptoms\nCreate a table with the number and percentage of cases by outcome\n\n\n\n Click to read a hint\n\n\nTo create bar plots we can use geom_bar() or geom_col() depending on the nature of our data. If we aggregate first, we can use geom_col(), otherwise we should use geom_bar(). There is a function of the {gtsummary} package called add_p() which enables you to easy calculate a statistical test across groups. If you want to know more read the section on gtsummary package of the EpiRhandbook.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Bar plot with clinical symptoms\n\nbar_clinical &lt;- mpox_linelist %&gt;% \n  \n  drop_na(clinical_symptoms) %&gt;%   # we remove those with missing clinical symptoms\n  \n  group_by(clinical_symptoms) %&gt;% \n  \n  summarise(n_cases = n(), .groups = \"drop\") %&gt;%\n  \n  mutate(prop=(n_cases/sum(n_cases))*100) %&gt;%  # we create a column with proportions\n  \n  ggplot(aes(y = reorder(clinical_symptoms, prop), x = prop)) +  # the reorder function ensures that categories are ordered by proportion in the graph\n  \n  geom_col(fill = \"darkgreen\") + \n  \n  labs(\n    title= \"Frequency of clinical symptoms in Mpox cases\",\n    y = \"\",\n    x = \"Number of cases\"\n  ) +\n  \n  theme_bw() +\n  \n  theme(axis.text = element_text(size=9))       #define the font size of the axis\n\nbar_clinical  \n\n\n\n# Table with number and percentage of cases by outcome\n\ntab_outcome &lt;- mpox_linelist %&gt;% \n  \n  select(outcome) %&gt;% \n  \n  tbl_summary(label = list(outcome = \"Reported outcome\")) # with the argument \"label\" we can change how the column name is displayed\n\ntab_outcome\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 2,0001\n    \n  \n  \n    Reported outcome\n\n        Alive\n1,405 (70%)\n        Unknown\n595 (30%)\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "pages/r_practical.html#step-6-reviewing-data-quality",
    "href": "pages/r_practical.html#step-6-reviewing-data-quality",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "It is important to understand how timely, complete, and valid your data is, if it will be the basis of understanding an outbreak and making decisions. For example - you will need to be mindful of reporting delays when interpreting epicurves, and be aware of how complete different sources of data are compared to each other.\n\n\nTasks\n\nCalculate median time from symptom onset to diagnosis and from diagnosis to notification, both overall and by country\nAssess visually the number of cases by calendar period and type of date (onset, diagnosis and notification)\n\n\n\n Click to read a hint\n\n\nTo plot together the different dates you may need to transform your data from “wide” to “long” form. What we call “pivoting” in R. The objective is to have a column with the different date categories (onset, diagnosis and notification) and another column with their date value. If you are unsure on how to do this, have a look at the Pivoting data chapter of the EpiRhandbook. Then, try to plot with the daily values, but if that’s not easy to interpret you may want to aggregate cases by week.\n\n\n\n\n\n\n\n\nTest yourself!\n\nIs there a difference in the delay from diagnosis to notification by country?\n\n Yes No\n\n\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Estimate delay between onset and diagnosis, and between diagnosis and notification\n\ndelay_db &lt;- mpox_linelist %&gt;% \n  \n  mutate(delay_diag = as.numeric(date_of_diagnosis - date_of_onset)) %&gt;%   #we create variables with difference between dates, we transform them in numeric to be able to then calculate measures of central tendency\n  \n  mutate(delay_not = as.numeric(date_of_notification - date_of_diagnosis))\n\nsummary(delay_db$delay_diag) #the summary will give us measures of central tendency and dispersion\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n -2.000   4.000   7.000   7.758  10.000  66.000     897 \n\nsummary(delay_db$delay_not)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-46.0000  -2.0000   0.0000  -0.6078   1.0000  23.0000      715 \n\ndelay_country &lt;- delay_db %&gt;% #here, we group by country and summarise the median to compare across countries\n  \n  group_by(country) %&gt;% \n  \n  summarise(median_delay_diag = median(delay_diag, na.rm = T),\n            median_delay_not = median(delay_not, na.rm = T))\n\ndelay_country\n\n# A tibble: 5 × 3\n  country  median_delay_diag median_delay_not\n  &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt;\n1 CountryA                 7                0\n2 CountryB                 7                0\n3 CountryC                 6                0\n4 CountryD                 7                0\n5 CountryE                 6                0\n\n# Line graph with the different dates \n\ndates_longer &lt;- mpox_linelist %&gt;% # use the variables of the dates and make a longer dataset. In the pivot_longer() command we select the columns which we want to expand in long format and transform the dataset\n   \n  pivot_longer(\n    \n    cols=starts_with(\"date_\"),         # all columns starting with \"date_\" will be taken \n\n    names_to = \"indicator\",            #the names of the columns will be placed in a single column called \"indicator\"\n\n    values_to = \"date\")                # the values (which are dates in this case) will be placed in a column called \"date\"\n  \n\ndates_longer_week &lt;- dates_longer  %&gt;% \n\n  mutate(week_date = floor_date(date, unit = \"week\", week_start = \"Monday\")) %&gt;%  # we create a week column\n    \n  group_by(indicator, week_date) %&gt;% \n    \n  summarise(n=n(), .groups=\"drop\") %&gt;%   # we group and summarise to have the number of cases by date type and week\n    \n  drop_na(week_date)                     # we drop the cases with no data on dates\n\n\n\n\nplot_date_delay &lt;-   ggplot(data = dates_longer_week,\n                            aes(x = week_date, \n                                y = n, \n                                color=indicator)) +\n  \n  geom_line(linewidth = 1.5) +\n  \n  scale_x_date(breaks = \"2 weeks\")+\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\", \n        axis.text = element_text(size=9),\n        axis.title = element_blank(),\n        axis.text.x = element_text(angle=90),\n        legend.title = element_blank()) +\n  labs(title=\"Mpox cases reported in 2022, by date of onset, diagnosis and notification.\")\n\nplot_date_delay\n\n\n\n\n\n\n\n\n\nTask: Create a plot comparing the number of cases reported to through the case-based flow and through the aggregated flow in each country.\nNOTE: Take into consideration that the column on cases in the aggregated data frame reports the cumulative number of cases.\n\n\n\n\n\n\nTest yourself!\n\nWhich country is not reporting aggregated data?\n\n A B C D E\n\n\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Create a data frame with the overall number of cases reported through the aggregated flux\n\nmpox_agg_country &lt;- mpox_agg %&gt;% \n  \n  group_by(country) %&gt;% \n  \n  filter(date_rep == max(date_rep)) %&gt;% # as we have cumulative data, we keep only the last week (after grouping by country)\n  \n  select(-date_rep, -week_date) %&gt;%     # remove unnecessary columns\n\n  mutate(source = \"aggregated\")         # we create this column to distinguish the numbers from the case-based flux\n\n\n# Create a data frame with the overall number of cases reported through the case-based flux\n\nmpox_linelist_country &lt;- mpox_linelist %&gt;%\n  \n  group_by(country) %&gt;% \n  \n  summarise(cases = n(), .groups = \"drop\") %&gt;% \n  \n  mutate(source = \"case_based\")       # we create this column to distinguish the numbers from the\n  \n\n# We append both data frames. Remember this is different from merging\n\ntotal_data &lt;- bind_rows(mpox_linelist_country, mpox_agg_country)\n\n\n# We create a graph to compare the cases reported in both sources\n\ngraph_comp &lt;- ggplot(data = total_data,\n                     aes(x = source, \n                         y = cases, \n                         fill = source)) +\n  \n  geom_col(position = \"dodge\") +            #position dodge puts bars one next to each other, instead of \"stacked\"\n  \n  facet_wrap(~ country, scales = \"free_y\") +  # this command gives us one graph per country. The argument scales is used to allow each y axis scales to adjust to the data\n\n  scale_fill_viridis_d(\n    labels = c(\"Aggregated\", \"Case-based\")  # this function changes the colours, but with the argument \"labels\" we can change the text of each fill.\n     ) +\n  \n  \n  labs(\n    title = \"Number of cases of Mpox reported in 2022 according to source of data\",\n    fill = \"Source\",\n    x = \"\",\n    y = \"Total number of cases\"\n  ) + \n  \n  theme_bw() +\n  \n  theme(axis.text.x = element_blank(),      # we remove the text of the x axis because it is already present in the legend\n        axis.ticks.x = element_blank())     # we also remove the ticks for aesthetic purposes\n\ngraph_comp"
  },
  {
    "objectID": "pages/r_practical.html#final-thoughts",
    "href": "pages/r_practical.html#final-thoughts",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "Well done! Through your analysis you now understand the magnitude of the outbreak so far, where and when it spread, which demographic groups are most affected, and how the disease actually manifests in terms of symptoms and severity. ECDC is very happy with your work.\nBy coding this up in R, this analysis should be reproducible, meaning you can quickly update it with new data and keep monitoring the outbreak. To further practise reproducible reports, [link to RMarkdown]."
  },
  {
    "objectID": "pages/r_practical.html#case-study-information",
    "href": "pages/r_practical.html#case-study-information",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "Authorship\nOriginal authors: Xanthi Andrianou, Gianfranco Spiteri (ECDC EI Group)\nData source: Fictional data provided by ECDC EI Group for training purposes\n\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nOctober 2021\nFirst draft\n1\nXanthi Andrianou\n\n\nJune 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales\n\n\n\nTerms of Use"
  },
  {
    "objectID": "pages/instructions.html",
    "href": "pages/instructions.html",
    "title": "Instructions",
    "section": "",
    "text": "There are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\nHere is what the “helpers” look like:\n\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see the solution\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\n\nInstall (and update!) R and RStudio Instructions and links go here. Define R Language Depending on where you are and how you carried out R installation, your language “locale” might be different from the language of the report that you want to produce. For example, a French person might have a French “locale”. If that is the case, when creating a graph by day of the week, Monday will be displayed as “lundi”. If that French person wants to create an English report, as for this case study, the language “locale” should be changed.\nTo ensure your “locale” is set to English, use the following code:\n\n# To see your language locale\nSys.getlocale()\n\n# To change it into English\nSys.setlocale(\"LC_ALL\", \"English\")\n\nSet-up a RStudio Project and R script for the case study Download the case study folder which can be found at the top of the case study page and extract the contents somewhere on your computer.\nIn your case study folder, you should have a subfolder “scripts” should be used to save any scripts related to the analysis. Inside scripts there is another subfolder called “backup” subfolder “data” which will contain the raw data you will use subfolder “outputs” can be used to store any outputs (tables, graphs, documents) that are the result of the analysis.\nMake sure your folders/subfolders are well-organised as this will save you a headache later!\nCreate an Rstudio project in the case study folder. If you are unsure on how to do that, read the EpiRhandbook on R projects. Once you have created an Rproject, create a new script with an appropriate name (example mpox_rpractical) and save it in the subfolder “scripts”.\nIf you are familiar with Rmarkdown, you may decide to use this type of file instead of a standard R script. See Using Rmarkdown below for more instructions.\nMake sure the purpose, date last updated, and author are written as comments at the top.\n\n\n\nSome of our case studies use Rmarkdown and the code goes within “chunks”, which is different from a standard R script. If you want to create a reproducible workflow, you need a place to save your code so you can run it again if you need to. You want all your files easily organised so you don’t get lost later on. You need to begin by setting the default chunk options.\nTypically, you want to change the default chunk options of your Rmarkdown script to: hide all code chunks in the report do not show messages or warnings show errors if they appear, but to not stop the rendering set up the default figure width to 7 and the figure height to 6 to show the figure titles on top of the plots by default\n\n# hide all code chunks in the output, but show errors \nknitr::opts_chunk$set(echo = FALSE,  # hide all code chunks in output\n                      error = TRUE,  # show errors if they appear, but don't stop (produce the word doc)\n                      warning = FALSE, # do not show warnings in the output word doc \n                      message = FALSE, # do not show  messages in the output word doc\n                      fig.width = 7,         # Figure width\n                      fig.height = 6,        # Figure height\n                      fig.topcaption = TRUE  # show figure titles on top of plot\n                     )\n\n\n\nSeveral packages are required for different aspects of analysis with R. You will need to install these before starting. We install and load packages using the {pacman} package. Its p_load() command will install packages if necessary and load them for use in the current session. If a listed package has already been installed, it will just load it. Each case study specifies at the beginning what packages you need to have installed. You can find more about installing/loading packages in the Packages section of the EpiRhandbook.\nNote you may end up using a long list of packages. Unfortunately different packages have functions with the same name. For example, the package {dplyr} (already installed with {tidyverse}) has a function called select() which we frequently use to subset columns of a data frame. Other packages such as {MASS} also have a function called select(). This could create headaches if you want to subset columns using dplyr’s select() but R thinks you’re calling MASS’s select() (we call this masking - dplyr’s select() is masked by MASS’s select()). Given that you are more likely to use functions from {tidyverse}, ensure that this is the last package in your p_load() list so that functions from {tidyverse} (including {dplyr} functions) will always “prevail”.\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\nIf this step is not working, you may have limited administrative rights for your computer. Making sure your IT-department gives you the correct access can save a lot of headache. See this handbook pages on the basics of installing packages and running R from network drives (company computers) for more detail. https://epirhandbook.com/r-basics.html#installation https://epirhandbook.com/r-on-network-drives.html#r-on-network-drives\nTerms of Use Disclaimer: The information presented in this exercise and the associated data files have been deliberately changed so as to facilitate the acquisition of the learning objectives for fellows of EPIET, EUPHEM and EPIET-associated programmes. This case study was first introduced in 2022 (see Copyright and Licence agreement for more information). You are free: to Share: to copy and distribute the work to Remix: to adapt and build upon the material Under the following conditions: Attribution: You must attribute the work in the manner specified by the author or licensor (but not in any way that suggests that they endorse you or your use of the work). The best way to do this is to keep as it is the list of contributors: sources, authors and reviewers. Share Alike: If you alter, transform, or build upon this work, you may distribute the resulting work only under the same or similar license to this one. Your changes must be documented. Under that condition, you are allowed to add your name to the list of contributors. Notification: If you use the work in the manner specified by the author or licensor, Walter@rki.de You cannot sell this work alone but you can use it as part of a teaching. With the understanding that: Waiver: Any of the above conditions can be waived if you get permission from the copyright holder. Public Domain: Where the work or any of its elements is in the public domain under applicable law, that status is in no way affected by the license. Other Rights: In no way are any of the following rights affected by the license: Your fair dealing or fair use rights, or other applicable copyright exceptions and limitations; The author’s moral rights; Rights other persons may have either in the work itself or in how the work is used, such as publicity or privacy rights. Notice: For any reuse or distribution, you must make clear to others the license terms of this work by keeping together this work and the current license. This licence is based on http://creativecommons.org/licenses/by-sa/3.0/"
  },
  {
    "objectID": "pages/instructions.html#getting-help",
    "href": "pages/instructions.html#getting-help",
    "title": "Instructions",
    "section": "",
    "text": "There are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\nHere is what the “helpers” look like:\n\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see the solution\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works."
  },
  {
    "objectID": "pages/instructions.html#r-studio-set-up",
    "href": "pages/instructions.html#r-studio-set-up",
    "title": "Instructions",
    "section": "",
    "text": "Install (and update!) R and RStudio Instructions and links go here. Define R Language Depending on where you are and how you carried out R installation, your language “locale” might be different from the language of the report that you want to produce. For example, a French person might have a French “locale”. If that is the case, when creating a graph by day of the week, Monday will be displayed as “lundi”. If that French person wants to create an English report, as for this case study, the language “locale” should be changed.\nTo ensure your “locale” is set to English, use the following code:\n\n# To see your language locale\nSys.getlocale()\n\n# To change it into English\nSys.setlocale(\"LC_ALL\", \"English\")\n\nSet-up a RStudio Project and R script for the case study Download the case study folder which can be found at the top of the case study page and extract the contents somewhere on your computer.\nIn your case study folder, you should have a subfolder “scripts” should be used to save any scripts related to the analysis. Inside scripts there is another subfolder called “backup” subfolder “data” which will contain the raw data you will use subfolder “outputs” can be used to store any outputs (tables, graphs, documents) that are the result of the analysis.\nMake sure your folders/subfolders are well-organised as this will save you a headache later!\nCreate an Rstudio project in the case study folder. If you are unsure on how to do that, read the EpiRhandbook on R projects. Once you have created an Rproject, create a new script with an appropriate name (example mpox_rpractical) and save it in the subfolder “scripts”.\nIf you are familiar with Rmarkdown, you may decide to use this type of file instead of a standard R script. See Using Rmarkdown below for more instructions.\nMake sure the purpose, date last updated, and author are written as comments at the top."
  },
  {
    "objectID": "pages/instructions.html#using-rmarkdown",
    "href": "pages/instructions.html#using-rmarkdown",
    "title": "Instructions",
    "section": "",
    "text": "Some of our case studies use Rmarkdown and the code goes within “chunks”, which is different from a standard R script. If you want to create a reproducible workflow, you need a place to save your code so you can run it again if you need to. You want all your files easily organised so you don’t get lost later on. You need to begin by setting the default chunk options.\nTypically, you want to change the default chunk options of your Rmarkdown script to: hide all code chunks in the report do not show messages or warnings show errors if they appear, but to not stop the rendering set up the default figure width to 7 and the figure height to 6 to show the figure titles on top of the plots by default\n\n# hide all code chunks in the output, but show errors \nknitr::opts_chunk$set(echo = FALSE,  # hide all code chunks in output\n                      error = TRUE,  # show errors if they appear, but don't stop (produce the word doc)\n                      warning = FALSE, # do not show warnings in the output word doc \n                      message = FALSE, # do not show  messages in the output word doc\n                      fig.width = 7,         # Figure width\n                      fig.height = 6,        # Figure height\n                      fig.topcaption = TRUE  # show figure titles on top of plot\n                     )\n\n\n\nSeveral packages are required for different aspects of analysis with R. You will need to install these before starting. We install and load packages using the {pacman} package. Its p_load() command will install packages if necessary and load them for use in the current session. If a listed package has already been installed, it will just load it. Each case study specifies at the beginning what packages you need to have installed. You can find more about installing/loading packages in the Packages section of the EpiRhandbook.\nNote you may end up using a long list of packages. Unfortunately different packages have functions with the same name. For example, the package {dplyr} (already installed with {tidyverse}) has a function called select() which we frequently use to subset columns of a data frame. Other packages such as {MASS} also have a function called select(). This could create headaches if you want to subset columns using dplyr’s select() but R thinks you’re calling MASS’s select() (we call this masking - dplyr’s select() is masked by MASS’s select()). Given that you are more likely to use functions from {tidyverse}, ensure that this is the last package in your p_load() list so that functions from {tidyverse} (including {dplyr} functions) will always “prevail”.\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\nIf this step is not working, you may have limited administrative rights for your computer. Making sure your IT-department gives you the correct access can save a lot of headache. See this handbook pages on the basics of installing packages and running R from network drives (company computers) for more detail. https://epirhandbook.com/r-basics.html#installation https://epirhandbook.com/r-on-network-drives.html#r-on-network-drives\nTerms of Use Disclaimer: The information presented in this exercise and the associated data files have been deliberately changed so as to facilitate the acquisition of the learning objectives for fellows of EPIET, EUPHEM and EPIET-associated programmes. This case study was first introduced in 2022 (see Copyright and Licence agreement for more information). You are free: to Share: to copy and distribute the work to Remix: to adapt and build upon the material Under the following conditions: Attribution: You must attribute the work in the manner specified by the author or licensor (but not in any way that suggests that they endorse you or your use of the work). The best way to do this is to keep as it is the list of contributors: sources, authors and reviewers. Share Alike: If you alter, transform, or build upon this work, you may distribute the resulting work only under the same or similar license to this one. Your changes must be documented. Under that condition, you are allowed to add your name to the list of contributors. Notification: If you use the work in the manner specified by the author or licensor, Walter@rki.de You cannot sell this work alone but you can use it as part of a teaching. With the understanding that: Waiver: Any of the above conditions can be waived if you get permission from the copyright holder. Public Domain: Where the work or any of its elements is in the public domain under applicable law, that status is in no way affected by the license. Other Rights: In no way are any of the following rights affected by the license: Your fair dealing or fair use rights, or other applicable copyright exceptions and limitations; The author’s moral rights; Rights other persons may have either in the work itself or in how the work is used, such as publicity or privacy rights. Notice: For any reuse or distribution, you must make clear to others the license terms of this work by keeping together this work and the current license. This licence is based on http://creativecommons.org/licenses/by-sa/3.0/"
  },
  {
    "objectID": "pages/fulton.html",
    "href": "pages/fulton.html",
    "title": "Fulton (EN)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\nName\nFulton County\n\n\nLanguage\nEnglish\n\n\nTool\nR\n\n\nLocation\nUnited States\n\n\nScale\nLocal\n\n\nDiseases\nCOVID-19\n\n\nKeywords\nCOVID-19; SARS-COV-2; Outbreak\n\n\nTechnical complexity\nIntermediate\n\n\nMethodological complexity\nBasic\n\n\n\nAuthorship\nOriginal authors: Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer\nData source: Anonymised and jittered data provided by Fulton County for training purposes\nAdapted by: Alberto Mateo Urdiales to the case study template\n\n\n\n\n\n\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\nHere is what the “helpers” look like:\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\n\n… description here about posting in Community…\n\n\n\nXXXXXXXXXXXXXXXXXXXXX\n\n\n\n\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\n\nThe first version was written by Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer in August 2021.\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nMar 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is a an example R-markdown script which demonstrates how to create an automated outbreak situation report for COVID-19 in Fulton county, USA. The data used comes from an anonymised and fake (scrambled) linelist of COVID-19 cases in Fulton county from the beginning of the pandemic (early 2020) until July 2021.\nThe overall objective is to create an automatic and dynamic report that shows the COVID-19 epidemiological situation in Fulton County.\nIn this case study you will learn:\n\nHow to import, clean and analyse your data.\n\nCarry out descrptive analysis by time, place and person.\n\nUse the above to create an automatic and dynamic report in word using Rmarkdown.\n\n\nFor the purpose of the case study we separate this by descriptive analysis and visualisation (normally this would be mixed together of course). The visualisation section is organised in to place, time and person. This is to simplify flow for didactic delivery.\nAnalysis is loosely based off the monthly epidemiology reports for Fulton county\n\n\n\n\nUsers should have some prior experience with R, including:\n\nR basics: Several packages are required for different aspects of analysis with R. You will need to install these before starting. We install and load packages using the {pacman} package. Its p_load() command will install packages if necessary and load them for use in the current session. This might prove difficult if you have limited administrative rights for your computer. Making sure your IT-department gives you the correct access can save a lot of headache. See this handbook pages on the basics of installing packages and running R from network drives (company computers) for more detail. https://epirhandbook.com/r-basics.html#installation https://epirhandbook.com/r-on-network-drives.html#r-on-network-drives\nR projects: See Chapter 6 R Projects from the EpiRhandbook\nImport and export of data: See Chapter7 Import and export\n\n\n\n\n\nDownload folder fulton_en and extract contents in the local laptop\nOpen the Rstudio project inside the folder called fulton_en.Rproj\nInside the folder you can find the Rmd and the word output (weekly report). You can also find a word template that will be used as the template for the report. The Rmd and the output are there to help you if you struggle, but you should try to recreate these yourself following this case study.\nSubfolder data contains fulton COVID-19 data needed for the analysis\nSubfolder solution_materials has a copy of the Rmd document with the solution and a copy Word document with the output requested\nOpen a new Rmarkdown file in RStudio and save it in the root folder fulton_en. If you have any doubts about how to create an Rmarkdown follow the EpiRhandbook instructors here\nThis Rmarkdown file will be the file used throughout the case study and, rendering it will produce the weekly report in word format"
  },
  {
    "objectID": "pages/fulton.html#overview",
    "href": "pages/fulton.html#overview",
    "title": "Fulton (EN)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\nName\nFulton County\n\n\nLanguage\nEnglish\n\n\nTool\nR\n\n\nLocation\nUnited States\n\n\nScale\nLocal\n\n\nDiseases\nCOVID-19\n\n\nKeywords\nCOVID-19; SARS-COV-2; Outbreak\n\n\nTechnical complexity\nIntermediate\n\n\nMethodological complexity\nBasic\n\n\n\nAuthorship\nOriginal authors: Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer\nData source: Anonymised and jittered data provided by Fulton County for training purposes\nAdapted by: Alberto Mateo Urdiales to the case study template"
  },
  {
    "objectID": "pages/fulton.html#instructions",
    "href": "pages/fulton.html#instructions",
    "title": "Fulton (EN)",
    "section": "",
    "text": "There are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\nHere is what the “helpers” look like:\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\n\n… description here about posting in Community…\n\n\n\nXXXXXXXXXXXXXXXXXXXXX\n\n\n\n\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\n\nThe first version was written by Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer in August 2021.\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nMar 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is a an example R-markdown script which demonstrates how to create an automated outbreak situation report for COVID-19 in Fulton county, USA. The data used comes from an anonymised and fake (scrambled) linelist of COVID-19 cases in Fulton county from the beginning of the pandemic (early 2020) until July 2021.\nThe overall objective is to create an automatic and dynamic report that shows the COVID-19 epidemiological situation in Fulton County.\nIn this case study you will learn:\n\nHow to import, clean and analyse your data.\n\nCarry out descrptive analysis by time, place and person.\n\nUse the above to create an automatic and dynamic report in word using Rmarkdown.\n\n\nFor the purpose of the case study we separate this by descriptive analysis and visualisation (normally this would be mixed together of course). The visualisation section is organised in to place, time and person. This is to simplify flow for didactic delivery.\nAnalysis is loosely based off the monthly epidemiology reports for Fulton county\n\n\n\n\nUsers should have some prior experience with R, including:\n\nR basics: Several packages are required for different aspects of analysis with R. You will need to install these before starting. We install and load packages using the {pacman} package. Its p_load() command will install packages if necessary and load them for use in the current session. This might prove difficult if you have limited administrative rights for your computer. Making sure your IT-department gives you the correct access can save a lot of headache. See this handbook pages on the basics of installing packages and running R from network drives (company computers) for more detail. https://epirhandbook.com/r-basics.html#installation https://epirhandbook.com/r-on-network-drives.html#r-on-network-drives\nR projects: See Chapter 6 R Projects from the EpiRhandbook\nImport and export of data: See Chapter7 Import and export\n\n\n\n\n\nDownload folder fulton_en and extract contents in the local laptop\nOpen the Rstudio project inside the folder called fulton_en.Rproj\nInside the folder you can find the Rmd and the word output (weekly report). You can also find a word template that will be used as the template for the report. The Rmd and the output are there to help you if you struggle, but you should try to recreate these yourself following this case study.\nSubfolder data contains fulton COVID-19 data needed for the analysis\nSubfolder solution_materials has a copy of the Rmd document with the solution and a copy Word document with the output requested\nOpen a new Rmarkdown file in RStudio and save it in the root folder fulton_en. If you have any doubts about how to create an Rmarkdown follow the EpiRhandbook instructors here\nThis Rmarkdown file will be the file used throughout the case study and, rendering it will produce the weekly report in word format"
  },
  {
    "objectID": "pages/fulton.html#step-1-rmarkdown-set-up",
    "href": "pages/fulton.html#step-1-rmarkdown-set-up",
    "title": "Fulton (EN)",
    "section": "Step 1: Rmarkdown set up",
    "text": "Step 1: Rmarkdown set up\nRemember that this case study is created in Rmarkdown and that code goes within “chunks”, which is different from a standard R script. The first steps will be to define the language in which you want the report, the default chunk options and to install/load the necessary packages.\n\nStep 1.1: Define R language\nDepending on where you are and how to carried out R installation, your language “locale” might be different from the language of the report that you want to produce. For example, a french person might have a french “locale”. If that is the case, when creating a graph by day of the week, Monday will be displayed as “lundi”. If that french person wants to create an English report, as for this case study, the language “locale” should be changed.\nTask: Ensure your “locale” is in English and change it into English if it is not.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# To see your language locale\nSys.getlocale()\n\n# To change it into English\nSys.setlocale(\"LC_ALL\", \"English\")\n\n\n\n\n\nStep 1.2: Default chunk options\nChange the default chunk options of your Rmarkdown script to:\n\nhide all code chunks in the report\ndo not show messages or warnings\nshow errors if they appear, but to not stop the rendering\nset up the default figure width to 7 and the figure height to 6\nto show the figure titles on top of the plots by default\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# hide all code chunks in the output, but show errors \nknitr::opts_chunk$set(echo = FALSE,  # hide all code chunks in output\n                      error = TRUE,  # show errors if they appear, but don't stop (produce the word doc)\n                      warning = FALSE, # do not show warnings in the output word doc \n                      message = FALSE, # do not show  messages in the output word doc\n                      fig.width = 7,         # Figure width\n                      fig.height = 6,        # Figure height\n                      fig.topcaption = TRUE  # show figure titles on top of plot\n                     )\n\n\n\n\n\nStep 1.3: Install/load packages\nInstall the following packages that will be needed to carry out the analysis: officedown, officer, rio, here, skimr, janitor, lubridate, epikit, tidyverse, flextable, sf, scales, gtsummary, labelled, ggspatial, patchwork, apyramid and incidence2.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  officedown, # format MS word document output\n  officer,    # add table of contents to output\n  rio,        # importing data  \n  here,       # relative file pathways \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # age_categories() function\n  flextable,  # converting tables to pretty images\n  sf,         # manage spatial data using a Simple Feature format\n  scales,     # define colour schemes for flextables \n  gtsummary,  # summary statistics, tests and regressions \n  labelled,   # create variable labels to be displayed in table outputs\n  ggspatial,  # basemaps and scalebars \n  patchwork,  # combining multiple ggplots \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n\n)"
  },
  {
    "objectID": "pages/fulton.html#step-2-data-import-and-exploration",
    "href": "pages/fulton.html#step-2-data-import-and-exploration",
    "title": "Fulton (EN)",
    "section": "Step 2: Data import and exploration",
    "text": "Step 2: Data import and exploration\n\nStep 2.1: Data import\n\nImport the COVID-19 linelist called covid_example_data.xlsx that can be found in the following path: data/covid_example_data/.\nImport also the csv files named fulton_population.csv found in data/covid_example_data needed to retrieve the population in Fulton County.\n\n\n\nClick to see a solution code (try it yourself first!)\n\n\n\nlinelist_raw &lt;- rio::import(\n  file = here::here(\"data\", \"covid_example_data\", \"covid_example_data.xlsx\"),\n  which = \"in\"\n)\n\n# import population data by zipcode to calculate incidence\npop &lt;- import(\n     here(\"data\", \"covid_example_data\", \"fulton_population.csv\")\n)\n\n\n\n\n\nStep 2.2: Data exploration\nExplore the linelist to understand better the data.\n\nQuestion 2.1: How many rows are present in linelist_raw?\n\n 48 31 82101 5\n\nQuestion 2.2: How many columns are of class numeric?\n\n 8 4 19 31\n\n\n\n\nClick to see a solution code (try it yourself first!)\n\n\n\n# view your whole dataset interactively (in an excel style format)\nView(linelist_raw)\n\n# get mean, median and max values of numeric variables; counts for categorical variables and NAs with summary\nsummary(linelist_raw)\n\n# get information about each variable in a dataset \nskim(linelist_raw)\n\n# view unique values contained in variables - useful for categorical variables\nunique(linelist_raw$case_gender)"
  },
  {
    "objectID": "pages/fulton.html#step-3-data-cleaning",
    "href": "pages/fulton.html#step-3-data-cleaning",
    "title": "Fulton (EN)",
    "section": "Step 3: Data cleaning",
    "text": "Step 3: Data cleaning\n\nStep 3.1: Create date objects\nCreate an object called surveillance_date defined as 7 days prior to the reporting date (30 June 2021). Then, create another object rounding it to the closest Wednesday. Create two daily sequences of dates, one as the 14 days prior to the surveillance_date and another as 14-28 days prior to the same date. We will use these throughout the case study\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# create a date object for the surveillance\n# Minus 7 days from the date of report (see YAML) to account for lag in reporting lab results\nsurveillance_date &lt;- as.Date(\"2021-06-30\") - 7\n\n# create an epiweek object from the date \n# floor_date() rounds down to the closest week here\nsurveillance_week &lt;- floor_date(surveillance_date,\n                          # round by weeks\n                          unit = \"week\", \n                          # define week to start on Wednesday\n                          week_start = 3)\n\n# define recent (past 14 days) and previous (28 to 14 days prior)\nrecent_period   &lt;- seq(surveillance_week  - 13, surveillance_week, by = 1)\nprevious_period &lt;- seq(surveillance_week  - 27, surveillance_week - 14, by = 1)\n\n# define a text label of date range for the recent period (for table headers)\nrecent_period_labels &lt;- str_glue(\n  format(min(recent_period), format = \"%m/%d\"), \n  \"-\", \n  format(max(recent_period), format = \"%m/%d\")\n)\n\n# define text label of date range for previous period (for table headers) \nprevious_period_labels &lt;- str_glue(\n  format(min(previous_period), format = \"%m/%d\"), \n  \"-\", \n  format(max(previous_period), format = \"%m/%d\")\n)\n\n\n# define a label for past 28 days (for table captions)\nfull_period_labels &lt;- str_glue(\n  format(min(previous_period), format = \"%B %d\"), \n  \"-\", \n  format(surveillance_week, format = \"%B %d, %Y\")\n)\n\n\n\n\n\nStep 3.2: Clean column names\nClean the column names ensuring that names do not contain special characters. Rename the following columns from the raw data:\n\nDate of report (reprt_creationdt_FALSE) to date_report\nDate of birth (case_dob_FALSE) to date_dob\nDate of symptom onset (sym_startdt_FALSE) to date_onset\nDate of positive testing (pos_sampledt_FALSE) to date_positive\nDate of recovery (sym_resolveddt_FALSE) to date_recovery\nDate of hospitalisation (hosp_admidt_FALSE) to date_hospitalized\nDate of discharge (hosp_dischdt_FALSE) to date_discharge\nDate of death (died_dt_FALSE) to date_died\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist_raw %&gt;% \n     clean_names() %&gt;% \n     # NEW name = OLD name\n  rename( \n    date_report         = reprt_creationdt_false,      \n    date_dob            = case_dob_false,              \n    date_onset          = sym_startdt_false,\n    date_recovery       = sym_resolveddt_false, \n    date_hospitalized   = hosp_admidt_false,\n    date_discharge      = hosp_dischdt_false,\n    date_died           = died_dt_false,\n    date_positive       = pos_sampledt_false\n    )\n\n\n\n\n\nStep 3.3: Remove duplicated rows\nRemove rows that have duplicated information on: patient id, gender and date of birth. Keep duplicates in a separate dataframe.\n\n\n Click to read a hint\n\n\nTo store duplicates in a new dataframe you can use the function get_dupes() from the {janitor} package\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# get a data frame of all the duplicates. This is mostly to inspect manually, but can be used for analysing those dropped\nduplicates &lt;- linelist %&gt;% \n     get_dupes(pid, case_gender, date_dob)\n\n# find duplicates based on unique ID, gender and date of birth. Only keep the first occurrence \nlinelist &lt;- linelist %&gt;% \n  distinct(pid, case_gender, date_dob, .keep_all = TRUE)\n\n\n\n\nQuestion 3.2: How many duplicated rows were present in the raw data?\n\n 28 31 38 124\n\n\n\n\nStep 3.4: Change column class and remove data inconsistencies\nUsing the across() function from {dplyr} make the following:\n\nEnsure that dates are considered dates by R\nClean date columns dealing with values that are not compatible with the period under analysis (early 2020 to July 2021)\nMake the column age of numeric class\nSet us NA those with negative ages and missing Date of birth\nMake the zip code column a factor class column\n\n\n\n Click to read a hint\n\n\nThe across() allows to apply the same modification to multiple columns in an easy way. So, these two options are equivalent:\n\n# Without across()\n\nlinelist &lt;- linelist %&gt;% \n  mutate(date_report = as.Date(date_report)) %&gt;% \n  mutate(date_dob = as.Date(date_dob)) %&gt;% \n  mutate(date_onset = as.Date(date_onset)) %&gt;% \n  mutate(date_hospitalized = as.Date(date_hospitalized)) %&gt;% \n  mutate(date_discharge = as.Date(date_discharge)) %&gt;% \n  mutate(date_died = as.Date(date_died)) %&gt;% \n  mutate(date_positive = as.Date(date_positive))\n\n\n# With across()\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = contains(\"date\"), .fns = ~as.Date(.x)))\n\nYou can read more about across() in the EpiRhandbook section\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(\n    .cols = contains(\"date\"),\n    .fns = ~as.Date(.x)\n  )) %&gt;%\n  \n  # mark as missing onset dates prior to 2020\n  mutate(across(\n    .cols = c(date_report, date_onset, date_hospitalized, date_discharge, date_died),\n    .fns  = ~replace(.x, .x &lt; as.Date(\"2020-01-01\"), NA)\n    )) %&gt;% \n\n  # mark as missing dates after the surveillance_date (for this report) from all date columns\n  mutate(across(\n    .cols = contains(\"date\"),\n    .fns  =  ~replace(.x, .x &gt; surveillance_date, NA)\n    )) %&gt;%\n     \n  # transform age into numeric class\n  mutate(\n    # ensure that age is a numeric variable\n    case_age = as.numeric(case_age),\n    # set those with negative ages and missing DOB to missing \n    # otherwise just leave the age value as is\n          # nb. NA_real_ just ensures the variable class is not changed\n    case_age = if_else(case_age &lt; 0 & is.na(date_dob), NA_real_, case_age)\n  ) %&gt;% \n     \n  # create a factor from a default numeric class\n  mutate(case_zip = as_factor(case_zip)) \n\n\n\n\nQuestion 3.3: Which one of the following could NOT be used to transform the column sym_startdt_FALSE from the raw data frame into a date object?\n\n base::as.Date() lubridate::as_date() lubridate::ymd() lubridate::dmy()\n\n\n\n\nStep 3.5: Create a column for weeks\nCreate a column named “epiweek” using the function floor_date() from the {lubridate} package rounding the report date to the nearest week, taking “Wednesday” as the start of the week.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n  # create an \"epiweek\" column from the report date. Use floor_date() to round down to the closest week\n  mutate(epiweek = floor_date(date_report,\n                          # round by weeks\n                          unit = \"week\", \n                          # define week to start on Wednesday\n                          week_start = 3)\n  )\n\n\n\n\n\nStep 3.6: Create time difference columns\nIn this step we ask you to create columns with various time differences that will be used later on in the case study. Please, try to create:\n\nA column with the number (numeric) of days from date of symptom onset to the date of hospitalization\nIn this new column, set as missing those cases where the difference is longer than 30 days (interval is too long for the hospitalization to be due to the infection), and those less than 0 (cannot be hospitalized before the symptom onset)\nUsing the function coalesce() from {dplyr} create a new column for the date of outcome among hospitalized cases, using date of death or date of discharge, depending on whether cases died or not\nCreate a new column with the length of hospitalization in days, calculated as the time difference between date of hospitalization and the recently created date of outcome.\nIn this newly created column mark as missing cases in which the difference between the date of hospitalization and the date of death/discharge was longer than 60 days or lower than 0 days\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;%\n     \n  # delay from onset to hospitalization\n  mutate(\n    # calculate time differences\n    days_onset_hosp = as.numeric(date_hospitalized - date_onset),\n    # set those under 0 or over 30 to missing\n    days_onset_hosp = replace(days_onset_hosp, days_onset_hosp &lt; 0, NA),\n    days_onset_hosp = replace(days_onset_hosp, days_onset_hosp &gt; 30, NA)\n  ) %&gt;%\n     \n  # length of hospitalization\n  mutate(\n    # create outcome date based on whether died or was discharged\n    date_outcome = coalesce(date_died, date_discharge),\n    # calculate time difference\n    days_hosp = as.numeric(date_outcome - date_hospitalized),\n    # set those under 0 or over 60 to missing\n    days_hosp = replace(days_hosp, days_hosp &lt; 0, NA),\n    days_hosp = replace(days_hosp, days_hosp &gt; 60, NA)\n  )\n\n\n\n\n\nStep 3.7: Create age groups\nCreate a column with 10 year age groups up until 70 (and 70+ afterwards) using the age_group() function from the package {epikit}. You can also use any other alternative\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;%\n     # create age group variable\n     mutate(\n       age_group = age_categories(case_age,\n        # define break points\n        c(0, 10, 20, 30, 40, 50, 60, 70),\n        # whether last break should be highest category\n        ceiling = FALSE\n     ))\n\n\n\n\n\nStep 3.8: Recode character/categorical columns\nRecode the following columns:\n\nIn the column named died_covid recode the category “Under Review” to “Unknown”\nIn the column named confirmed_case recode the category “Pending” to “Unknown”\nForce categorical columns to use consistent cases\nAcross character/factor columns recode the category “Unk” to “Unknown”\nAcross the different character/factor columns recode NA to “Unknown”\nIn the column named sym_resolved recode categories into “Yes”, “No” or “Unknown”\nTransform the gender column into a factor with these levels: “Female”, “Male” and “Unknown”\nTransform all columns that have the categories: “Yes”, “No” and “Unknown” into factors with the order of the levels as “Yes”, “No” and “Unknown”\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n     \n     # recode one value and leave the rest as they are \n     mutate(\n       died_covid = if_else(died_covid == \"Under Review\",\n                            \"Unknown\", died_covid), \n       confirmed_case = if_else(confirmed_case == \"Pending\", \n                                \"Unknown\", confirmed_case), \n     \n        # force categorical variables to use consistent cases (this can be done for others) \n        sym_myalgia = str_to_title(sym_myalgia),\n      ) %&gt;% \n     \n     #replace one value and leave the rest, across multiple variables\n      mutate(across(\n       .cols = c(contact_household, contains(\"sym_\")),\n       .fns  = ~if_else(.x == \"Unk\", \"Unknown\", .x)\n     )) %&gt;% \n     \n        # replace missing with \"Unknown\" where relevant \n     mutate(across(\n       .cols = c(case_gender, case_race, case_eth, case_zip,\n                 contact_id, contact_household, \n                 hospitalized, died, died_covid, confirmed_case,\n                 contains(\"sym_\"), age_group),\n       .fns  = ~fct_na_value_to_level(.x, level = \"Unknown\")\n     )) %&gt;% \n     \n          # recode with searching for string patterns \n     mutate(sym_resolved = case_when(\n          str_detect(sym_resolved, \"Yes\")     ~ \"Yes\", \n          str_detect(sym_resolved, \"No\")      ~ \"No\", \n          str_detect(sym_resolved, \"Unknown\") ~ \"Unknown\", \n          TRUE                                ~ \"Unknown\"\n     )) %&gt;% \n     \n      # set levels of a factor (define order)\n     mutate(case_gender      = fct_relevel(case_gender, \"Female\", \"Male\", \"Unknown\")) %&gt;% \n     \n          # set levels of all factors that are yes/no/unknown \n     mutate(across(\n          .cols = c(contact_household, hospitalized, died, died_covid,\n                    confirmed_case, contains(\"sym_\")), \n          .fns = ~fct_relevel(.x, \"Yes\", \"No\", \"Unknown\")\n     )) \n\n\n\n\n\nStep 3.9: Merge ethnicity and race\nThe linelist contains a column for ethnicity (case_eth) and a column for race (case_race). Create a new column merging information from these two existing columns. The new column should:\n\nContain a category “Hispanic, all races” when case_eth is “HISPANIC/LATINO”. For those cases where this condition is not met:\n\nShould have a category for those whose race is “Asian”, another for those whose race is “Black” and another for those whose race is “White”.\nCreate an “Other” category for the rest of races and an “Unknown” category for those with missing race\nEnsure all categories have consistent cases\n\nTransform the newly formed column into a factor with the “Unknown” category as the last level\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n          # create a composite category from race and ethnicitiy  \n     mutate(eth_race = case_when(\n          eth  == \"HISPANIC/LATINO\"                           ~ \"Hispanic, all races\", \n          race == \"ASIAN\"                                     ~ \"Asian, NH\", \n          race == \"BLACK\"                                     ~ \"Black, NH\",\n          race == \"WHITE\"                                     ~ \"White, NH\",\n      # find all instances of NATIVE (covers AMERICAN INDIAN/ALASKA NATIVE **AND** NATIVE HAWAIIAN/PACIFIC ISLANDER)\n          str_detect(race, \"NATIVE\")                          ~ \"Other, NH\",\n          race == \"OTHER\"                                     ~ \"Other, NH\", \n          TRUE                                                ~ \"Unknown\"\n     )) %&gt;% \n     mutate(eth_race = factor(eth_race, levels=c(\n          \"Black, NH\", \"White, NH\", \"Hispanic, all races\",\n          \"Asian, NH\", \"Other, NH\", \"Unknown\"\n     )))\n\n\n\n\nQuestion 3.4: A column that has ordinal data, what class should it have?\n\n logical character factor integer\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n\n\nStep 3.10: Filter data frame\nFilter the data to keep only confirmed cases whose date of report is not above the date of the report (June 30, 2021). Consider also keeping records with missing date of report.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n##############       FILTER     ##############        \n\n# store those which do not meet our filter criteria \ndropped &lt;- linelist %&gt;% \n     filter(confirmed_case != \"Yes\" |\n              date_report &gt; surveillance_date & \n                !is.na(date_report))\n\n\n# drop the cases that dont meet the criteria \nlinelist &lt;- linelist %&gt;% \n     filter(confirmed_case == \"Yes\" & \n              date_report &lt;= surveillance_date & \n                 !is.na(date_report))"
  },
  {
    "objectID": "pages/fulton.html#step-4-start-the-report-with-a-summary-of-the-findings",
    "href": "pages/fulton.html#step-4-start-the-report-with-a-summary-of-the-findings",
    "title": "Fulton (EN)",
    "section": "Step 4: Start the report with a summary of the findings",
    "text": "Step 4: Start the report with a summary of the findings\n\nWrite in rmarkdown three bullet points summarising the data we imported, showing the number of cases by the date of analysis, the number of hospitalisations and the number of deaths.\nWrite it in a dynamic way, so that the dates and numbers are updated automatically if you get a new updated dataset\n\n\n\nClick to see a solution (try it yourself first!)\n\n This is an example of how the code should look like in your rmarkdown file:"
  },
  {
    "objectID": "pages/fulton.html#step-5.-analysis-by-time",
    "href": "pages/fulton.html#step-5.-analysis-by-time",
    "title": "Fulton (EN)",
    "section": "Step 5. Analysis by time",
    "text": "Step 5. Analysis by time\n\nStep 5.1: Table weekly number of cases\nCreate a table with the number of cases per reporting week to see how the epidemic evolved by time in Fulton County\n\nQuestion 5.1: During which week do we observe the peak in cases by date of reporting?\n\n The week starting on March 02, 2021 The week starting on December 16, 2020 The week starting on January 13, 2021 The week starting on December 30, 2020\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# save a quick descriptive table of number of cases reported by week\nepiweek_table &lt;- linelist %&gt;% \n  # get counts and percentages \n  tabyl(epiweek) %&gt;% \n  # add the overall counts as a row\n  adorn_totals() %&gt;%  \n  # change from proportions to percentages (do not add a % sign)\n  adorn_pct_formatting(affix_sign = FALSE) \n\n# transform it into flextable for better visualisation\nepiweek_flextable &lt;- epiweek_table %&gt;% \n     qflextable()\n\n\n\n\n\nStep 5.2: Epicurve\nCreate an epicurve by reporting week, with the colour of the bins based on whether the cases were hospitalised or not\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n     # we first define the dataset to be used, the x axis which will be reporting week and the colour (fill) of the bins which will depend on hospitalisation outcome\nggplot(\n     data = linelist,\n     mapping = aes(\n          x = epiweek,\n          fill = hospitalized\n     )) + \n     \n     geom_histogram() + \n     \n     # we define that we want breaks by month and formated with scales::label_date_short()\n     scale_x_date(\n          date_breaks = \"month\",\n          labels = label_date_short()\n     ) +\n     \n     # we change the name of the different elements of the graph\n     labs(\n          x = \"\",\n          y = \"Weekly number of cases\",\n          fill = \"Hospitalised\",\n          caption = paste0(\"Data as of \", format(surveillance_date, \"%d %b %Y\"))\n          \n     ) + \n     \n     # we apply one of the predefined themes\n     theme_bw()"
  },
  {
    "objectID": "pages/fulton.html#step-6.-analysis-by-person",
    "href": "pages/fulton.html#step-6.-analysis-by-person",
    "title": "Fulton (EN)",
    "section": "Step 6. Analysis by person",
    "text": "Step 6. Analysis by person\n\nStep 6.1: Table with demographic information\nCreate a table summarising, with counts and percentages, the total cumulative number of cases and deaths, as well the cases and deaths notified in the last 28 days by demographic characteristics: sex, age and race.\n\nQuestion 6.1: In which age group do we observe the largest proportion of cumulative cases?\n\n 0-9 30-39 20-29 70+\n\nQuestion 6.2: In which race do we observe the largest proportion of deaths in the last 28 days?\n\n Black White Asian Hispanic\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# get counts tables for measures of interest \n############################################\n\n# we generate 3 summary tables and bind them together\n# summary demographic table for gender\ndem_gender &lt;- linelist %&gt;% \n  tabyl(gender) %&gt;% \n  select(Characteristic = gender, n, percent)\n\n# summary demographic table for age\ndem_age &lt;- linelist %&gt;% \n  tabyl(age_group) %&gt;% \n  select(Characteristic = age_group, n, percent)\n\n# summary demographic table for ethnicity and race\ndem_eth_race &lt;- linelist %&gt;% \n  tabyl(eth_race) %&gt;% \n  select(Characteristic = eth_race, n, percent)\n\n# bind all tables together\ntotal_cases &lt;- bind_rows(list(dem_gender, dem_age, dem_eth_race))\n\n# counts of new cases (last 28 days) \nrecent_cases &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter the linelist for dates on or after 28 days ago\n  .f = ~filter(linelist, \n          date_report &gt;= (surveillance_date - 28)) %&gt;% \n        # get counts based on filtered data\n        tabyl(.x) %&gt;% \n        # nb we dont keep the characteristic column because it would be duplicated\n        select(n_cases_recent = n,\n               perc_cases_recent = percent)\n  ) %&gt;%\n  bind_rows()\n\n# counts of total deaths \ntotal_deaths &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter for those who died \n  .f = ~filter(linelist, \n          died_covid == \"Yes\") %&gt;% \n        # get counts based on filtered data \n        tabyl(.x, show_na = TRUE) %&gt;%\n        select(n_deaths_total = n, perc_deaths_total = percent)\n  ) %&gt;% \n  bind_rows()\n\n# counts of new deaths (last 28 days)\nrecent_deaths &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter to those who died in the last 28 days\n  .f = ~filter(linelist, \n          died_covid == \"Yes\" & \n          date_died &gt;= (surveillance_date - 28)) %&gt;% \n        # get counts based on filtered data\n        tabyl(.x) %&gt;% \n        select(n_deaths_recent = n, perc_deaths_recent = percent) %&gt;% \n        # add in a variable column (used for colouring later) \n        mutate(variable = .x)\n  ) %&gt;% \n  bind_rows()\n\n\n# total counts for all of the above measures (not by demographic)\noverall &lt;- linelist %&gt;% \n  summarise(\n    # add in row label \n    Characteristic = \"Total\",\n    # counts of total cases \n    n_cases_total = n(),\n    # leave all percentages empty (would just be 100)\n    perc_cases_total  = NA, \n    # counts of new cases (last 28 days) \n    n_cases_recent = sum(date_report &gt;= (surveillance_date - 28)), \n    perc_cases_recent  = NA, \n    # counts of total deaths \n    n_deaths_total = sum(died_covid == \"Yes\"), \n    perc_deaths_total = NA, \n    # counts of new deaths (last 28 days)\n    n_deaths_recent = sum(died_covid == \"Yes\" & \n                          date_died &gt;= (surveillance_date - 28)),\n    perc_deaths_recent = NA, \n    # add in a variable column (used for colouring later) \n    variable = \"Overall\"\n  )\n\n\n# merge tables together \n#######################\n\n# combine all the demographic tables - side by side\ndemographics_counts &lt;- bind_cols(total_cases, recent_cases, total_deaths, recent_deaths) %&gt;% \n  # mutate each of the proportion columns to be percentages\n  mutate(across(\n    .cols = contains(\"perc\"),\n    .fns = ~round(.x * 100, digits = 1)\n    )) \n# add in the totals row at the top of the merged demographics table\ndemographics_counts &lt;- bind_rows(overall, demographics_counts)\n\n\n# define colour scheme \n######################\n\n# get the column numbers that are percentages (based on the name) \npercentage_cols &lt;- names(demographics_counts) %&gt;% \n  str_detect(\"perc\") %&gt;% \n  which()\n\n# define colour cut-offs for gender column \ngender_colours &lt;- scales::col_bin(\n  # choose colours \n  palette = c(\"#91CF60\", \"#FC8D59\"), \n  # choose min and max (range)\n  domain  = c(0, 100),\n  # choose how to split (in this case above and below 50)\n  bins    = 2\n)\n\n# define colour cut-offs for age column \nage_colours &lt;- scales::col_bin(\n  # choose colours\n  palette = c(\"#91CF60\",\"#FFFFBF\", \"#FC8D59\"),\n  # choose min and max (range)\n  domain  = c(0, 100), \n  # choose cut-off categories \n  bins    = c(0, 5, 20, 100)\n)\n\n# define colour cut-offs for ethnicity column \neth_colours &lt;- scales::col_bin(\n  palette = c(\"#91CF60\",\"#FFFFBF\", \"#FC8D59\"),\n  domain  = c(0, 100), \n  bins    = c(0, 10, 40, 100)\n)\n\n\n# create styled table  \n######################\n\ndemographics_counts %&gt;%\n  # initiate flextable to produce styled output table\n  flextable(\n    # retain variable column for formatting but do not display it\n    col_keys = names(demographics_counts)[-10]\n  ) %&gt;%\n  # redefine column names based on original names\n  set_header_labels(\n    \"n_cases_total\"       = \"Total Confirmed Cases\",\n    \"perc_cases_total\" = \"% of Total Cases\",\n    \"n_cases_recent\"       = \"Confirmed Cases past 28 days\",\n    \"perc_cases_recent\" = \"% of Confirmed Cases past 28 days\",\n    \"n_deaths_total\"       = \"Total Confirmed Deaths\",\n    \"perc_deaths_total\" = \"% of Total Deaths\",\n    \"n_deaths_recent\"       = \"Confirmed Deaths past 28 days\",\n    \"perc_deaths_recent\" = \"% of Confirmed Deaths past 28 days\"\n  ) %&gt;%\n  # move the header text to the centre\n  align(align = \"center\", part = \"header\") %&gt;%\n  # make header text bold\n  bold(part = \"header\") %&gt;%\n  # make the totals row bold (i.e. first row)\n  bold(i = 1, part = \"body\") %&gt;%\n  # fill in the cells\n  # choose the rows with gender counts\n  bg(i = ~variable == \"gender\",\n     # choose the columns with percentages in them\n     j = percentage_cols,\n     # fill in based on previous defined cut-offs\n     bg = gender_colours) %&gt;%\n  bg(i = ~variable == \"age_group\",\n     j = percentage_cols, bg = age_colours) %&gt;%\n  bg(i = ~variable == \"eth_race\",\n     j = percentage_cols, bg = eth_colours) %&gt;%\n  # add horizontal lines after the cells with totals and unknowns\n    # (short-cut to find row ending of each demographic variable)\n  hline(i = ~Characteristic %in% c(\"Total\", \"Unknown\")) %&gt;%\n  # add in footnotes for rows counting unknowns (reference in first column)\n  footnote(i = ~Characteristic == \"Unknown\", j = 1, part = \"body\", ref_symbols = c(\"a\"),\n           value = as_paragraph(\"Unknown includes cases not yet interviewed\")) %&gt;%\n  # add in footnote for deaths counts (ref in the header)\n  footnote(i = 1, j = c(6, 8), part = \"header\", ref_symbols = c(\"b\"),\n           value = as_paragraph(\"Deaths refer to all persons who had a positive PCR test result\n                                for Covid-19 and there is evidence that COVID-19 was the cause of\n                                death or a significant contributor to their death.\")) %&gt;%\n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\") %&gt;% \n  # decrease the fontsize in the header and body for aesthetic purposes in the document\n  fontsize(part = \"all\", size = 8)\n\n\n\n\n\nStep 6.2: Age pyramid\nCreate an age pyramid with the percentage of cases by age group and sex.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# prepare dataset\n\n# start a new dataframe (as dont want to overwrite the original)\nlinelist_2g &lt;- linelist %&gt;% \n  # update the gender and age_group columns\n  mutate(across(.cols = c(gender, age_group), \n                .fns = ~{\n                  # replace \"Unknown\" with NA\n                  .x = na_if(.x, \"Unknown\") \n                  # drop \"Unknown\" from the factor levels \n                  .x = fct_drop(.x)\n                }))\n\n# plot age pyramid \nage_pyramid(\n  data = linelist_2g,\n  age_group = \"age_group\",\n  split_by = \"gender\",\n  # Show as percentages of total cases\n  proportional = TRUE,\n  # remove guide line for mid-point\n  show_midpoint = FALSE) +\n  # set theme to basic \n  theme_minimal() +\n  # add labels \n  labs(\n    title = \"\",\n    subtitle = ,\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = \"Gender\",\n    # use str_glue to set dynamic captions \n    # {missing} is defined in the second argument below\n    caption = str_glue(\n      \"{missing} cases missing either age or gender are not shown. \\n Fictional COVID-19 data\",\n      missing = linelist_2g %&gt;%\n        filter(is.na(gender) | is.na(age_group)) %&gt;%\n        nrow()\n      )\n    )\n\n\n\n\n\nStep 6.3: Scatter plot\nCreate a scatter plot showing the relation between age and duration of hospital stay. Colour the points based on whether cases died or not.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n#################### C) SCATTER PLOT ####################\n# open a plot with the linelist data\nggplot(data = linelist) +\n  # add points \n  geom_point(\n    mapping = aes(\n      # plot age on the x and days hospitalised on the y axis \n      x = age,\n      y = days_hosp,\n      # color points by outcome\n      color = died),  \n    # all points 3x size\n    size = 3, \n    # opacity of 30% (i.e. relatively see-through)\n    alpha = 0.3) +      \n  # make the x and y axes start at the origin \n  scale_y_continuous(expand = c(0, 0)) + \n  scale_x_continuous(expand = c(0, 0)) + \n  # add in labels \n  labs(\n    x = \"Age (years)\",\n    y = \"Duration (days)\",\n    caption = \"Fulton COVID-19 data\",\n    color = \"Deceased\"\n    ) + \n     theme_bw()\n\n\n\n\n\nStep 6.4: Bar plot\nCreate a bar stacked bar plot showing the absolute number of cases by race and vital status\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# open a plot with the linelist data\nggplot(linelist) +\n  # add bars \n  geom_bar(\n    mapping = aes(\n      # plot the number of cases by ethnicity (ordered in reverse frequency)\n      x = fct_rev(fct_infreq(eth_race)),\n      # stack bars and colour by died (ordered in reverse frequency)\n      fill = fct_rev(fct_infreq(died))\n    )\n  ) +\n  # flip the x and y axes \n  coord_flip() +\n  # make the x axes start at the origin (nb axes flipped)\n  scale_y_continuous(expand = c(0, 0), \n                     # define where to label xaxis (nb axes flipped )\n                     breaks = seq(from = 0,\n                                  to = 35000,\n                                  by = 5000)) + \n  # add in labels \n  labs(\n    # set the axes titles (nb axes flipped)\n    x = \"Race and Ethnicity\",\n    y = \"Cases (n)\",\n    caption = \"Fictional COVID-19 data\",\n    fill = \"Deceased\"\n    ) + \n  # apply a defined theme\n     theme_bw()"
  },
  {
    "objectID": "pages/fulton.html#step-7.-analysis-by-place",
    "href": "pages/fulton.html#step-7.-analysis-by-place",
    "title": "Fulton (EN)",
    "section": "Step 7. Analysis by place",
    "text": "Step 7. Analysis by place\nCreate a table by zip code in which you show the incidence in the most recent 14 days period, the incidence in the previous 14 days period and the percentage change in incidence between these periods.\n\nQuestion 7.1: What is the change in incidence observed between periods in the zip code number 30337?\n\n +20% +36% -62.5% -25%\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n################### TABLE BY ZIP CODE\n\nzip_counts &lt;- linelist %&gt;% \n  group_by(zip) %&gt;% \n  # count cases in the appropriate period \n  summarise(\n    recent   = sum(date_report %in% recent_period),\n    previous = sum(date_report %in% previous_period)\n  ) %&gt;% \n  adorn_totals() %&gt;% \n  # a percentage change column and round the digits\n  mutate(\n    perc_change = round((recent - previous) / previous * 100, digits = 1)\n    )\n\n# extract population counts for each zip from the shapefile\nzip_pop &lt;- shapefile %&gt;% \n  # change to tibble (otherwise geo-data gets pulled with)\n  as_tibble() %&gt;% \n  # only keep zip code and population counts\n  select(ZipCode, Population) %&gt;% \n  # add a row with overall counts\n  adorn_totals()\n  \n# merge case counts and population counts\n# zip (or ZipCode in the shapefile) variable is the unique identifier\nzip_counts &lt;- left_join(zip_counts, \n                        zip_pop, \n                        by = c(\"zip\" = \"ZipCode\")\n                        ) %&gt;% \n  # calculate the incidence \n  mutate(across(\n      # for each period (recent and previous)\n      .cols = c(recent, previous), \n      # divide each variable by population (and round the outcome)\n      .fns = ~round(.x / Population * 10000, digits = 1), \n      # for each period create a new variable with _inc on the end\n      .names = \"{.col}_inc\"), \n    \n    # replace NAs in incidence with 0\n    across(\n      .cols = contains(\"inc\"),\n      .fns = ~replace_na(.x, 0)),\n    \n    perc_change = case_when(\n      # fix the outliers: set missing to 0 and infinity (divided by 0) to 100\n      is.na(perc_change)       ~ 0,\n      is.infinite(perc_change) ~ 100, \n      TRUE                     ~ perc_change\n    ))\n\n\n# choose colours to fill in cells  \nrow_colour &lt;- case_when(\n  # those less than zero will be green (decreasing cases)\n  zip_counts$perc_change &lt; 0 ~ \"#91CF60\", \n  # over zero red (increasing)\n  zip_counts$perc_change &gt; 0 ~ \"#FC8D59\", \n  # missing or zero orange\n  TRUE                       ~ \"#FFFFBF\")\n\n\nzip_counts %&gt;% \n  # keep the columns of interest and define order\n  select(zip, recent, recent_inc, previous, previous_inc, perc_change) %&gt;% \n  # initiate {flextable} to produce styled output table\n  flextable() %&gt;% \n  # fill in cells - choose the column and then pass our colour-scheme defined above\n  bg(j = \"perc_change\", \n     bg = row_colour\n     ) %&gt;% \n  # add in a header for labeling counts and incidence by period \n    # note the empty columns (\"\") to fit to the original table headers\n  add_header_row(\n    values = c(\"\", \n               str_c(\"Recent 14-day reporting period\\n\", recent_period_labels), \n               \"\", \n               str_c(\"Previous 14-day reporting period\\n\", previous_period_labels), \n               \"\", \n               \"Change between reporting periods\"\n               )) %&gt;% \n  # redefine column names based on original names\n    # note the different syntax to dplyr::select, here it is old_name = new_name\n  set_header_labels(\n    zip          = \"Zip Code\", \n    recent       = \"n\", \n    recent_inc   = \"Incidence\", \n    previous     = \"n\", \n    previous_inc = \"Incidence\", \n    perc_change  = \"%\"\n  ) %&gt;% \n  # combine the headers cells for the appropriate periods \n  # (i defines rows, j defines columns)\n  merge_at(i = 1, j = 2:3, part = \"header\") %&gt;% \n  merge_at(i = 1, j = 4:5, part = \"header\") %&gt;% \n  # move the header text to the centre\n  align(align = \"center\", part = \"header\") %&gt;% \n  # make header text bold \n  bold(part = \"header\") %&gt;% \n  # make the row with totals in it bold (i.e. the last row in the dataframe)\n  bold(i = nrow(zip_counts), part = \"body\") %&gt;% \n  # add in footnotes for variables (referencing the header cells)\n  footnote(j = c(3, 5), part = \"header\", ref_symbols = c(\"a\"),\n           value = as_paragraph(\"Incidence calculated as cases per 10,000 population by zip code\")) %&gt;% \n  footnote(j = 6, part = \"header\", ref_symbols = c(\"b\"),\n           value = as_paragraph(\"These reflect the percentage increase or decrease of new diagnoses \n                                between the 14 days preceding the past 7 days and the 14 days\n                                preceding that.\")) %&gt;% \n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\")"
  },
  {
    "objectID": "pages/fulton.html#step-8.-analysis-of-risk-factors-for-mortality",
    "href": "pages/fulton.html#step-8.-analysis-of-risk-factors-for-mortality",
    "title": "Fulton (EN)",
    "section": "Step 8. Analysis of risk factors for mortality",
    "text": "Step 8. Analysis of risk factors for mortality\n\nCreate a table in which you assess, with the appropriate statistical tests, whether the demographic characteristics of those dying from Covid-19 are significantly different from cases who did not die from it.\nFor each of the variables used in the table that you just created, carry out univariate regression using each demographic variable as the independent variable and the outcome (dead, not dead) as the dependent variables. Create a table with the estimates -alongside 95% CI - of the estimates.\n\n\nQuestion 8.1: According to the results of the univariate analysis, how was having a sore throat associated with mortality from Covid-19\n\n It was a risk factor for mortality It was a protective factor for mortality It was not associated with mortality Impossible to know\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# define a list of variables for looping over later\nsymptom_vars &lt;- linelist %&gt;% \n     # choose all columns that contain \"sym_\" in the name but exclude \"sym_resolved\"\n     select(c(contains(\"sym_\"), -sym_resolved)) %&gt;% \n     # pull the names out \n     names()\n\n# define variables of interest (save typing them out later) \ndescriptive_vars &lt;- c(\"gender\", \n                      \"age_group\",\n                      \"eth_race\",\n                      symptom_vars,\n                      \"hospitalized\",\n                      \"days_hosp\")\n\n# filter dataset  \nrf_data &lt;- linelist %&gt;% \n  # only keep variables of interest\n  select(died_covid, age, all_of(descriptive_vars)) %&gt;% \n  # set unknown back to NA for all factor variables\n  mutate(across(\n    .cols = where(is.factor),\n    .fns = ~fct_recode(.x, NULL = \"Unknown\"))) %&gt;% \n  # flip factor levels (so that the reference values are correct)\n  mutate(eth_race = fct_infreq(eth_race)) %&gt;% \n  mutate(gender = fct_relevel(gender, \"Female\", \"Male\")) %&gt;% \n  mutate(across(all_of(c(\"died_covid\", symptom_vars, \"hospitalized\")), \n                ~fct_relevel(.x, \"No\", \"Yes\")\n                )) %&gt;% \n  # only keep rows with complete data for all variables of interest\n  # note that this will drop rows where **ANY** of the listed variables are NA\n  drop_na(any_of(c(\"died_covid\", \"age\", descriptive_vars)))\n\n\n# define variable labels to show in output tables \nrf_data &lt;- rf_data %&gt;%\n  set_variable_labels(\n    died_covid = \"Died\",\n    age = \"Age (years)\",\n    gender = \"Gender\",\n    age_group = \"Age group (years)\",\n    eth_race = \"Ethnicity\",\n    sym_fever = \"Fever\",\n    sym_subjfever = \"Subjective fever\",\n    sym_myalgia = \"Myalgia\",\n    sym_losstastesmell = \"Loss taste/smell\",\n    sym_sorethroat = \"Sore throat\",\n    sym_cough = \"Cough\",\n    sym_headache = \"Headache\",\n    hospitalized = \"Hospitalized\",\n    days_hosp = \"Days in hospital\"\n  )\n\n\n\nrf_data %&gt;%\n  # keep variables of interest\n  select(died_covid, gender, eth_race, age, days_hosp) %&gt;%\n  # produce summary table and specify grouping variable\n  tbl_summary(\n    by = died_covid\n  ) %&gt;%\n  # specify what test to perform\n  add_p(\n    list(\n      all_continuous() ~ \"kruskal.test\",\n      eth_race ~ \"kruskal.test\",\n      all_dichotomous() ~ \"chisq.test\"\n    )\n  ) %&gt;%\n  # edit what the column headers say (using {gtsummary})\n  # nb. {n} automatically shows the number in that group and \\n is a linebreak\n  modify_header(update = list(\n    stat_1 ~ \"**Dead**\\n (N={n})\",\n    stat_2 ~ \"**Alive**\\n (N={n})\"\n  )) %&gt;%\n  # edit what it says in the footnote (using {gtsummary})\n  modify_footnote(update = list(\n    all_stat_cols() ~ \"n (%) for categorical;\\n median (IQR) for continuous\",\n    p.value ~ \"Pearson's Chi-squared test for dichotomous;\\n Kruskal-Wallis rank sum test for continuous and categorical\"\n  )) %&gt;%\n  # change to flextable format\n  as_flex_table() %&gt;%\n  # make header text bold (using {flextable})\n  bold(part = \"header\")\n\n###################### B) UNIVARIATE REGRESSION ANALYSIS ####################################\n\n\n# produce table with regression estimates\nregress_tab &lt;- rf_data %&gt;%\n  # drop variables not interested in \n  select(-age_group) %&gt;%\n  # produce univariate table\n  tbl_uvregression(\n    # define outcome variable\n    y = died_covid, \n    # define regression want to run (generalised linear model)\n    method = glm, \n    # define what type of glm want to run (logistic)\n    method.args = list(family = binomial), \n    # exponentiate to produce odds ratios (rather than log odds)\n    exponentiate = TRUE, \n    # do not show the overall counts (this is done in cross_tab below)\n    hide_n = TRUE,\n    ## uncomment this line if you want to not show reference rows\n    # show_single_row = c(symptom_vars, gender, hospitalized),\n    ## note: NULL at the end allows you to have a comma before a commented out row\n    NULL\n  )\n\n# produce table with counts by outcome (using the data fed to the regression above)\ncross_tab &lt;- regress_tab$inputs$data %&gt;%\n  tbl_summary(\n    # group by outcome \n    by = died_covid,\n    ## uncomment this line if you only want to show the \"Male\" row for gender\n    ## this would be run if you also uncommented the single_row in regression above\n    # value = list(gender ~\"Male\"),\n    ## show all levels (otherwise only shows the \"Yes\" level)\n    type = list(all_dichotomous() ~ \"categorical\"),\n    ## note: NULL at the end allows you to have a comma before a commented out row\n    NULL\n  )\n\n# combine tables \ntbl_merge(list(cross_tab, regress_tab)) %&gt;%\n  # edit what it says in the grouping headers \n  modify_spanning_header(update = list(\n    c(\"stat_1_1\",\"stat_2_1\") ~ \"Died\",\n    c(\"estimate_2\", \"ci_2\", \"p.value_2\") ~ \"Univariate regression\")\n    ) %&gt;% \n  # edit what it says in the footnote (using {gtsummary})\n  modify_footnote(update = list(\n    all_stat_cols() ~ \"n (%) for categorical;\\n median (IQR) for continuous\")\n    ) %&gt;% \n  # change to flextable format\n  as_flex_table() %&gt;%\n  # make header text bold (using {flextable})\n  bold(part = \"header\") %&gt;% \n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\")"
  }
]