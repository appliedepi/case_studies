[
  {
    "objectID": "pages/r_practical.html",
    "href": "pages/r_practical.html",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "Tool: R | Technical complexity: Basic | Methodological complexity: Basic\nSource: ECDC EI Group (simulated data)\nPrior knowledge required: R basics (Using Rstudio; R packages, functions and arguments, using pipes)\n\n\n\nFor instructions on how to use our case studies, see our How-to Guide. We welcome feedback and suggestions via contact@appliedepi.org. You can also discuss the case study or related concepts on the Applied Epi Community.\n\n\n\nIt is May 2022 and Mpox has just been reported for the first time across 5 countries in Europe: Countries “A”, “B”, “C”, “D”, and “E”. You have been requested to provide a basic descriptive analysis to the European Centre for Disease Prevention and Control (ECDC).\nYou are given access to:\n\nA dataset with aggregate case counts, submitted to ECDC by the five countries as part of routine European reporting\nA linelist with cases, submitted by the five countries to ECDC for this particular analysis\n\nLet’s go!\n\n\n\nIn this case study you will:\n\nExplore different types of files and how they can be imported in R.\nPerform basic data cleaning, e.g., changing the variable type, recoding variables, aggregating and filtering.\nPerform a basic descriptive analysis using tables and graphs\n\n\n\n\n\n\nStart by setting up a reproducible and well-organized workflow. This will make it easy to rerun your analysis whenever needed.\nTasks:\n\nSet up an RStudio project\nSet up clear sub-folders where your code, data, and outputs will go\nCreate an R script, or an R Markdown file if you prefer. Make sure the script purpose, date, and author are written as comments at the top.\nExtra: Ensure your working language in RStudio is appropriate (e.g. English for this exercise)\n\n\n\n Click to read a hint\n\n\n\nCreate a folder where all the work in this case study will go. For example, create ‘mpox_analysis’ on your computer desktop. Create your RStudio project to be based in this folder.\nWe suggest creating the following sub-folders: scripts (for your code), data (for your data), and outputs (for your analytical outputs).\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nCreate a folder (e.g. ‘mpox_analysis’ on your Desktop) for your work. To create an Rstudio project in your new folder, click New Project… in the top left of your R Studio, then Existing Directory, then Browse to select your new folder. For more information, look at the R projects section of the Epi R Handbook.\nStart a new R script by clicking New File… in the top left of your R Studio, then R Script. Save it immediately in the appropriate place, e.g. in a ‘scripts’ subfolder of your R Project.\nAt the top of your new R script, write some essential information like your name, the purpose of the file, and the date.\nYour R locale determines the language and regional settings used for things like date formats and translations. If your locale is different from the language you want for your report (e.g., a French locale vs. an English report), you can change it to English by running Sys.setlocale(\"LC_ALL\", \"English\"). Include this in your script if needed, or skip it if your locale is usually appropriate. This is explained in more detail in the How-to Guide.\n\n\n\n\nNext in your R script, you need to install and load the necessary R packages. This ensures that the functions you need are available for your analysis.\nYou will need the following packages: rio (for importing data), janitor (for cleaning data), lubridate (for cleaning dates), skimr (for reviewing data), epikit (for epi-related tasks), gtsummary (for presentation-ready tables), apyramid (for age-sex pyramids), and tidyverse (for general data manipulation/science tasks).\nAs you start, your trusted colleague nudges you and whispers “I’ve heard that a great way to manage your packages is with the pacman package”.\nOver to you!\n\n\nClick to see a solution (try it yourself first!)\n\n\nUse the function p_load() from pacman for this task. You provide the function with a list of packages that you want to use. It will take two steps per package: 1) Check if the package is installed on your computer, and install it if necessary, then 2) Load the package so it can be used during this R session.\nIf you don’t already have pacman installed, you will need to install it the “traditional way” first, with install.packages().\nNote that the order of packages in your p_load function can be important. If two packages have the same function names (e.g. select() in the package MASS and select() in tidyverse, which do different things), then R will use the function from the most recently loaded package. To prioritize functions from tidyverse, which are commonly used for data manipulation and visualization, load tidyverse last.\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\n\n\n\n\n\n\nECDC provides you with two files for your analysis, both updated as of 31st August 2022:\n\nA case-level linelist (“mpox_linelist.xlsx”) with case information from five countries (countries A - E)\nAn aggregate table (“mpox_aggregate_table.csv”) for those countries with cumulative case counts per day.\n\nThey provide it to you via AppliedEpi’s very useful data repository, which you can access using the {appliedepidata} package. So first you need to download these two files to your own computer, as follows:\n\nInstall the {appliedepidata} package from GitHub using the install_github() function in the {remotes} package. Install {remotes} if you need to first.\n\n\n# Install remotes if you need to (so you can install a package from GitHub)\npacman::p_load(\"remotes\")\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nSave the two datasets into a specific folder using the save_data() function from {appliedepidata}, by running the code below. The example below saves the data into a ‘data’ subfolder within the RStudio project. Note that if you do not specify a location within the ‘path’ argument of the function, a window will pop up asking you to manually select a folder.\n\n\n# Save down the two mpox files using the save_data() function from appliedepidata\nappliedepidata::save_data(\"mpox_linelist\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"mpox_aggregate_table\",\n                          path = \"data\")\n\n\n\n\nGreat! Thanks ECDC and Applied Epi! Now it’s time to import the data from that folder into RStudio, so you can analyse it.\nTask: Import the downloaded case-based and aggregated data into your R environment. Ideally you want to use one function for both datasets, despite one being a csv and the other an xlsx file.\n\n\n Click to read a hint\n\n\nUse the import function from the {rio} package, which can recognize and import different file types. It replaces importing functions that are specific to the file type, such as read.csv() from {base} for .csv files and read_excel() from {readxl} to import .xlsx files.\nIf you feel you need to know more about importing functions, read the Import and export chapter of the EpiRhandbook.\n\n\n\nClick to see a solution (try it yourself first!)\n\nBelow we use the import function to bring in both files. Note how we are assigning the imported data to two objects, one called mpox_linelist_raw, and one called mpox_agg_raw. We add the ‘raw’ suffix to distinguish this data from the cleaned versions we will make later.\n\n# Import data  --------------\n\n# Case-based data\nmpox_linelist_raw &lt;- import(\"data/mpox_linelist.xlsx\")\n\n# Aggregated data\nmpox_agg_raw &lt;- import(\"data/mpox_aggregate_table.csv\")\n\n\n\n\n\n\nThe data’s in, and now it’s time to see what story it tells. Take an initial look at your data to check its quality and how you can best use it.\nTasks: Take a look at the different data frames and determine:\n\nThe number of columns and observations (e.g. their dimensions)\nThe class of their columns and whether it matches its nature (e.g., are “dates” considered “dates” by R?)\nIf the contents of columns are clean and standardized in the mpox linelist (e.g. gender, clinical symptoms, outcome, hiv status and sexual orientation). Do you need to recode any of them?\nHow unknown or missing data is categorised in these columns. Do these values need to be standardized?\n\n\n\n Click to read a hint\n\n\nAn efficient function for initial data exploring is skim() from the {skimr} package, as it gives you a lot of information on data structure and content, including the classes of columns.\nYou can use the function tabyl() from {janitor}, to get counts and percentages of every category in the data column, one by one. These get printed to your RStudio console.\nAlso - we recommend just looking at the data itself! A good function for this is view(), a baseR function.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nUsing the skim commands you can see the rows and columns of each dataset, and you can see how most of the columns in mpox_linelist_raw (including those containing dates) are character classes. (Results not shown on this exercise page)\n\n# Explore the dimensions of the two data objects \nskim(mpox_linelist_raw)\nskim(mpox_agg_raw)\n\nTake a look at the overall data using view(). It will pop up in the Data Viewer tab and you will get a good sense of how clean the data is and what the missingness is like. This preview shows just 5 rows from the linelist data.\n\nview(mpox_linelist_raw)\n\n\n\n\n\n\n\n\nBelow is an example of using the tabyl() function from {janitor}, to look at the distribution of clinical symptoms. You can see 12 cases have missing clinical information and that many cases have a mix of symptoms.\n\ntabyl(mpox_linelist_raw, HIVStatus)  \n\n HIVStatus   n percent valid_percent\n       NEG 525  0.2625     0.4107981\n       POS 307  0.1535     0.2402191\n       UNK 446  0.2230     0.3489828\n      &lt;NA&gt; 722  0.3610            NA\n\n\nYou can explore further columns one by one (results not shown):\n\n# Explore the values of different categorical columns in the mpox linelist: with tabyl\ntabyl(mpox_linelist_raw, Gender)\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms)\n\ntabyl(mpox_linelist_raw, Outcome)\n\ntabyl(mpox_linelist_raw, SexualOrientation)\n\nYou could add extra arguments to tabyl() to customize the tables, such as adding totals and changing the proportions to percentages so they are easier to read. See the table on clinical symptoms below. But remember - this is just an initial look so don’t go too crazy.\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms) %&gt;%    # Tabulate symptoms \n  adorn_totals() %&gt;%                              # Add totals to bottom of table\n  adorn_pct_formatting(digits = 2)                # Format percentages\n\n                 ClinicalSymptoms    n percent valid_percent\n                          Lesions   14   0.70%         0.70%\n                             Rash  257  12.85%        12.93%\n                    Rash, Lesions  323  16.15%        16.25%\n          Rash, Systemic symptoms  676  33.80%        34.00%\n Rash, Systemic symptoms, Lesions  654  32.70%        32.90%\n                Systemic symptoms   28   1.40%         1.41%\n       Systemic symptoms, Lesions   36   1.80%         1.81%\n                             &lt;NA&gt;   12   0.60%             -\n                            Total 2000 100.00%       100.00%\n\n\nFinally, as an alternative approach to tabyl(), you could use tbl_summary() from the {gtsummary} package. We will describe this later.\n\n\n\n\n\n\n\n\nTest yourself!\n\nHow many columns does the aggregated data have?\n\n 2000 13 3 101\n\n\n\nWhat is the class of the column DateOfNotification in the mpox linelist?\n\n Date Character Numeric Factor\n\n\n\nFor how many cases is the HIV status Unknown or missing?\n\n 1168 722 900 446\n\n\n\n\n\n\n\n\n\n\nSo! The good news: you have information on geography, dates, demographic characteristics, and clinical details. A promising descriptive analysis lies ahead.\nBUT! You may noticed that there are a few things to fix before the real detective work begins.\nFor example:\n\nColumn names have capital letters. This isn’t outright a problem, but can lead to mistakes since R treats ColumnName and Columnname as different.\nDate columns are recognized as character classes, not dates, which would cause issues like incorrect ordering (alphabetical) in epicurves.\nSome columns have values that are unclear or unsuitable for presentation. For example gender is categorized with “F”, “M”, “O” and “UNK”. The column Outcome is “A” and “UNK”.\nMissing data is inconsistently handled, for instance with both “UNK” and NA in the HIV status column. R thinks “UNK” is a valid value, which it treats differently to true missing data (indicated by NA)\n\nTasks:\n\nCreate a clean version of your case-based data making all cleaning changes in a single piping command\nChange all column names to lower case.\nConvert all date columns to class “Date”.\nConvert all missing/unknown values to NA (to be recognized by R as missing)\nRecode non-missing “Gender” categories into: “Female”, “Male”, and “Other”\nRecode non-misising HIV status into: “Positive”, “Negative” and “Unknown”\nRecode non-missing sexual orientation into: “Bisexual”, “Heterosexual”, and “MSM/homo or bisexual male”.\nRecode non-missing “outcome” categories into: “Alive” and “Dead”.\nCheck that all changes have been made correctly\n\n\n\n Click to read a hint\n\n\nTo convert all column names to lower case at once rather than renaming each column, use the function clean_names() from the {janitor} package.\nUse {lubridate} functions to transform date columns into “Date” class. You can do this one by one, or you could do all at the same time using the across() function from {dplyr}. If you feel you need to know more about transforming dates read the chapter Working with Dates from the EpiRhandbook. If you are not sure how to use the across() function, you can also read the section on Transform multiple columns.\nThere are different functions that we can use to recode values. We propose three: The function recode() from {dplyr}, the function ifelse() from {base} and the function case_when() from {dplyr}. If you want to know more about these functions, look that the section on Re-code values from the EpiRhandbook.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nHere we clean the data using a ‘chain’ of commands connected by pipes (%&gt;%), which is the grammar of the functions in the {Tidyverse}. The output is assigned to a new object called mpox_linelist to differentiate it from the raw data. It can be helpful to have both the cleaned and raw data available in the environment to compare to the original data if needed.\nSee the series of functions and the explanation in the comments.\n\n# Create a new object called mpox_linelist which is the clean version of the raw data\nmpox_linelist &lt;- mpox_linelist_raw %&gt;% \n  \n  # standardises names and puts all into lower case \n  clean_names() %&gt;% \n  \n  #transform ONE column into date (note the column names are lower case now)\n  mutate(date_of_notification = ymd(date_of_notification)) %&gt;%  \n\n  #transforms ALL columns starting with \"date\" into dates\n  mutate(across(starts_with(\"date\"), \n                .fns = ~ ymd(.x))) %&gt;%  \n  \n  #transforms UNK to NA across all character columns \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x %in% c(\"UNK\", \"Unknown\"), NA_character_, .x)))  %&gt;% \n\n  # Recode the gender values to be more obvious  \n  mutate(gender = recode(gender,\n                         \"F\" = \"Female\",\n                         \"M\" = \"Male\",\n                         \"O\" = \"Other\")) %&gt;%\n  \n  #recode with ifelse to change only one or two categories based on a rule. \n  mutate(outcome = ifelse(outcome == \"A\", \"Alive\", outcome)) %&gt;%   \n  \n  #recode with case_when for more complex recoding \n  mutate(hiv_status = case_when(hiv_status == \"NEG\" ~ \"Negative\",    \n                                hiv_status == \"POS\" ~ \"Positive\")) %&gt;% \n  \n  mutate(sexual_orientation = case_when(sexual_orientation == \"BISEXUAL\" ~ \"Bisexual\",\n                                        sexual_orientation == \"HETERO\" ~ \"Heterosexual\",\n                                        sexual_orientation == \"MSM\" ~ \"MSM/homo or bisexual male\")) \n\nYou can then review your data by tabulating across all the different columns you have cleaned. See the preview of the HIV table below - it looks tidier now with more understandable categories, and all missing data is classified as ‘Unknown’.\n\n# Check that all changes have been made correctly\n\nskim(mpox_linelist)\n\ntabyl(mpox_linelist, gender)\n\ntabyl(mpox_linelist, clinical_symptoms)\n\ntabyl(mpox_linelist, outcome)\n\ntabyl(mpox_linelist, hiv_status)\n\ntabyl(mpox_linelist, sexual_orientation)\n\n\n\n hiv_status    n percent valid_percent\n   Negative  525  0.2625     0.6310096\n   Positive  307  0.1535     0.3689904\n       &lt;NA&gt; 1168  0.5840            NA\n\n\nIMPORTANT: If ‘unknown’ and NA had meaningful differences, combining them wouldn’t be appropriate (e.g., if ‘unknown’ meant the case was asked but didn’t want to respond, while NA meant they weren’t asked). Here, we assume no meaningful difference and want R to recognize them as missing.\n\n\n\n\n\n\n\n\nTest yourself!\n\nIs it always appropriate to combine different types of unknown data? (e.g. missing, unknown, did not respond, NA)\n\n Yes Depends on the meaning of those values No - never do this\n\n\n\nHow many male cases do we have in the data frame?\n\n 36 1960 65 1523\n\n\n\nHow many cases have ‘alive’ as an outcome?\n\n 1405 None 595\n\n\n\n\n\n\n\n\nIn a similar way, clean the aggregated data by:\n\nStandardising names to lower case\nEnsuring that date of reporting is of class “Date”\nCreating a column called “week_date” with the week of reporting starting on Monday\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nWe can first check the class of the DateRep column, which shows us that it was already recognized as a date column on import.\n\n# Check class of date of reporting column\nclass(mpox_agg_raw$DateRep)\n\nThen create a new object for the clean aggregate data, and write your cleaning coded connected with pipes.\n\n# Create a new object called mpox_agg which is the clean version of the raw data, applying the cleaning functions\n\nmpox_agg &lt;- mpox_agg_raw %&gt;% \n  \n  # standardises names and puts all into lower case\n  clean_names() %&gt;%  \n  \n  # create week column with Monday start\n  mutate(week_date = floor_date(date_rep, \n                              unit = \"week\",\n                              week_start = \"Monday\")) \n\n\n\n\n\n\n\n\n\nTest yourself!\n\nTake a look at the aggreate data. Which country reported the largest cumulative number of cases during the week 2022-04-11?\n\n Country A Country B Country C Country D Country E\n\n\n\n\n\n\n\n\n\nNow we’re getting to the heart of the investigation. Who is affected? Which locations are most affected, and how quickly is it spreading? Your ability to tell the classic “person, place, and time” story will be crucial to guiding the response. Pinpoint those hotspots and trends!\n\n\nTask: Using the mpox case linelist, create a table showing the total number of cases by country. This time, make the table more publication-friendly.\n\n\n Click to read a hint\n\n\nYou could use tabyl() like before, but an easy way to produce publication-ready tables is with the function tbl_summary() from {gtsummary} package. This formats the table for you. It will print to your Viewer rather than the console.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nCreate a new object with the table output - as this is a key output that you can then integrate into a document later rather than just viewing for now.\n\n# Create an object with the table\ncb_country_table &lt;- mpox_linelist %&gt;%\n\n  #select the column that we want to use in the table\n  select(country) %&gt;% \n  \n  # create the table. No need to specify columns; it will tabulate all available columns (selected above)\n  tbl_summary() \n\n# Print the table\ncb_country_table\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 2,0001\n    \n  \n  \n    country\n\n        CountryA\n816 (41%)\n        CountryB\n391 (20%)\n        CountryC\n474 (24%)\n        CountryD\n217 (11%)\n        CountryE\n102 (5.1%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nWhat country has the largest percentage of cases?\n\n Country C Country D Country B Country E Country A\n\n\n\n\n\n\n\n\nOkay so Country A has the most cases in total based on most recent data. But how does that change look over time?\nTasks:\n\nUsing the mpox case linelist, create an epicurve by week of notification\nUsing the mpox case linelist, create an epicurve by week of notification to enable a comparison of trends by country.\nUsing the mpox case linelist, create a heat plot with the number of cases by country and week of notification.\n\n\n\n Click to read a hint\n\n\nPrepare your data for the epicurve first. You can create a “week_date” column using the function floor_date() from {lubridate}. Take a look at the documentation to understand how it works and how to pick the starting day of the week.\nTo create the epicurve, you can use ggplot() and geom_bar(), which visualizes the number of rows within a group - e.g. number of cases per week. To compare trends in different countries, consider using the facet_wrap() function. If you are unsure on how ggplot() works, read the EpiRhandbook chapter on Epidemic curves.\nTo create a heatmap, you will need to create a table of counts by country and week of notification. You can do this using the functions group_by() and summarise() from {dplyr}. If you are unsure on how to do this, review the Grouping data chapter of the EpiRhandbook. Then, use the geom geom_tile() to create a heat plot. If you’re unsure on how to do this, read the EpiRhanbook section on Heat Plots\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nPrepare your data by creating the new column using mutate() and floor_date():\n\nmpox_linelist &lt;- mpox_linelist %&gt;% \n  # create week column with Monday start \n  mutate(week_date = floor_date(date_of_notification, unit = \"week\", week_start = \"Monday\")) \n\nThe code below creates an epicurve using ggplot() and the geom_bar() function, then applies further formatting. With geom_bar(), you only need to specify the x axis, and the function will visualize the number of rows per unique x axis value.\n\n# Open up the plot production with ggplot() function, specifying object and columns\nepicurve_mpox &lt;- ggplot(data = mpox_linelist,          \n                        aes(x = week_date)) +    \n  \n  geom_bar(fill=\"darkgreen\",                     #colour inside the bins\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  labs(title=\"Mpox cases reported in 2022 in Countries A, B, C, D, and E\",\n       subtitle = \"Date as of August 31st 2022\") +  #add a title\n  \n  theme_minimal() +                             #assign a predefined theme\n  \n  theme(axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n           \n# Print the epicurve\nepicurve_mpox\n\n\n\n\nTo examine how the outbreak spread by country, add facet_wrap() to your ggplot code. This splits the graph into multiple smaller ones. As shown below, you can even simply add the function to the national epicurve object.\nAn alternative approach would be to create a stacked epicurve, i.e. retain the single epicurve but split each bar into colors per country. You would do this by adding fill = country to the aes() in the epicurve code. However, we don’t recommend this for comparing trends, as stacked bars make it harder to see individual patterns.\n\nepicurve_epox_country &lt;- epicurve_mpox + \n \n   # Facet wrap to make mini-plots, specifying that you want two columns of plots. \n  facet_wrap(.~country,\n             ncol = 1) \n\n# Print the epicurve\nepicurve_epox_country\n\n\n\n\nFinally, if you want to demonstrate this as a weekly heatmap, you can use geom_tile(). First, aggregate the data by week. Then pipe into a ggplot(), as shown below.\n\n# Assign the output of your ggplot code to a new object\nhp_mpox &lt;- mpox_linelist %&gt;% \n  \n  #first count the number of cases by country and notification week\n  count(country, week_date) %&gt;% \n\n  #you can pipe directly into the ggplot\n    ggplot(aes(x = week_date, # notification week along the x axis\n           y = country,       # country along the y axis\n           fill = n)) +       # colour in the heatmap tiles by number\n  \n  # specify that you want this to be a heatmap with geom_tile()\n  geom_tile(colour = \"black\") +   # black is the outline of each tile\n  \n  #define the gradient of the colours\n  scale_fill_gradient(            \n    low = \"lightgreen\",\n    high = \"red\") +\n  \n  #set the x axis labels to two week intervals\n  scale_x_date(breaks = \"2 weeks\") +             \n  \n  # Add titles\n  labs(\n    title= \"Mpox cases by country and week of notification\",\n    fill = \"Number of cases\"                               \n  ) +\n  \n  # Apply an overall theme to your plot\n  theme_bw() +\n  \n  # Customize other appearance details\n  theme(legend.position = \"bottom\",       #legend position to bottom\n        axis.text = element_text(size=9),     #define axis font \n        axis.title = element_blank(),         #remove the axis titles\n        axis.text.x = element_text(angle=90)) #rotate the x axis text\n    \n\n# Print the heatmap\nhp_mpox \n\n\n\n\n\n\n\n\n\nNext, describe the age, gender, and sexual orientation of cases. What is interesting?\nTask:\n\nCreate a single table showing overall distribution of age, gender, and sexual orientation\nCreate an age-gender pyramid showing age as 10-year age bands\n\n\n\n Click to read a hint\n\n\nTo quickly create a presentation-ready table showing the breakdowns for three different columns, consider using the function tbl_summary() from {gtsummary}.\nTo create an age-gender pyramid, first create a new column with the function age_categories() from the {epikit} package. Then explore the function age_pyramid() from the {apyramid} package.You can find more about this function in the EpiRhandbook chapter Demographic pyramids and Likert-scales\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nSee below the code to quickly generate one table with the breakdown of different variables. The function tbl_summary() by default summarizes columns differently depending on their class:\n\nAge is a numeric column, so is summarized with a median and interquartile range.\nGender and sexual orientation are character values, so are described in terms of counts and percentages.\n\nYou can customize this further; explore the documentation by typing ?tbl_summary() in your console.\nNote that tbl_summary() by default does not include NAs in the counts and percentages, allowing you to see the distribution of non-missing values.\n\n# Create table of all three variables\ntab_demographics &lt;- mpox_linelist %&gt;% \n  \n  # select the columns of interest for\n  select(age, gender, sexual_orientation) %&gt;% \n  \n  # use tbl_summary() to create the table\n  tbl_summary() \n\ntab_demographics\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 2,0001\n    \n  \n  \n    age\n37 (31, 45)\n        Unknown\n3\n    gender\n\n        Female\n36 (1.8%)\n        Male\n1,960 (98%)\n        Other\n1 (&lt;0.1%)\n        Unknown\n3\n    sexual_orientation\n\n        Bisexual\n7 (0.8%)\n        Heterosexual\n46 (5.2%)\n        MSM/homo or bisexual male\n833 (94%)\n        Unknown\n1,114\n  \n  \n  \n    \n      1 Median (IQR); n (%)\n    \n  \n\n\n\n\nCreate the new age group column as follows. You can add this to the cleaning section of your script (which we covered 4.1).\n\nmpox_linelist &lt;- mpox_linelist %&gt;% \n  # Use the age_categories function to create age categories\n  mutate(age_group = age_categories(age, lower = 0, #set up the lower age\n                                    upper = 70, #set up the upper age\n                                    by = 10)) #set up the age breaks\n\nThen make the age-gender pyramid using the age_pyramid() function. It is a function that builds on ggplot, so you can then continue to add on customization, such as the theme_bw() below.\n\n# Create table of all three variables\nfigure_agesex &lt;- mpox_linelist %&gt;% \n  \n  # Filter to male and female only\n  filter(gender %in% c(\"Male\", \"Female\")) %&gt;% \n  \n  # select the columns of interest for\n  age_pyramid(age_group = \"age_group\",\n              split_by = \"gender\") +\n  \n  # change theme\n  theme_bw()\n\nfigure_agesex\n\n\n\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nWhich demographic group is more affected by Mpox?\n\n Females 60-69 Males 40-49 Females 10-19 Males 30-39\n\n\n\nWhat proportion of mpox cases were homosexual or bisexual men?\n\n 41% 42% 5% 94%\n\n\n\n\n\n\n\n\nThe media is starting to call your office and are asking what symptoms the public should look out for. Just in luck - you can check that out in the data too!\nTasks:\n\nCreate a table with the distribution of different symptoms and outcomes.\n\nNo hints! You should know this one by now!\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Table with number and percentage of cases by outcome\n\ntab_outcome &lt;- mpox_linelist %&gt;% \n  \n  # Select the columns for tabulation\n  select(outcome, clinical_symptoms) %&gt;% \n  \n  # Use tbl_summary() - note that this time we are adding on labels to change how the column name is displayed\n  tbl_summary(label = list(\n    clinical_symptoms = \"Symptoms\",\n    outcome = \"Reported outcome\")) \n\ntab_outcome\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 2,0001\n    \n  \n  \n    Reported outcome\n\n        Alive\n1,405 (100%)\n        Unknown\n595\n    Symptoms\n\n        Lesions\n14 (0.7%)\n        Rash\n257 (13%)\n        Rash, Lesions\n323 (16%)\n        Rash, Systemic symptoms\n676 (34%)\n        Rash, Systemic symptoms, Lesions\n654 (33%)\n        Systemic symptoms\n28 (1.4%)\n        Systemic symptoms, Lesions\n36 (1.8%)\n        Unknown\n12\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\n\n\n\n\nYou’ve described a lot now, but you want to make sure you understand how timely and complete your mpox linelist is, especially if it will be the basis of making decisions.\nFor example - is it possible that there are very different reporting delays between countries, meaning current case counts are not directly comparable? Oh dear, must check.\n\n\nTasks\n\nCalculate median time from symptom onset to diagnosis and from diagnosis to notification, both overall and by country\nAssess visually the number of cases by calendar period and type of date (onset, diagnosis and notification)\n\n\n\n Click to read a hint\n\n\nTo plot together the different dates you may need to transform your data from “wide” to “long” form. What we call “pivoting” in R. The objective is to have a column with the different date categories (onset, diagnosis and notification) and another column with their date value. If you are unsure on how to do this, have a look at the Pivoting data chapter of the EpiRhandbook. Then, try to plot with the daily values, but if that’s not easy to interpret you may want to aggregate cases by week.\n\n\n\n\n\n\n\n\nTest yourself!\n\nIs there a difference in the delay from diagnosis to notification by country?\n\n Yes No\n\n\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nFirst create the required columns for this analysis.\n\n# Create two columns in linelist to assess delays\ndelay_db &lt;- mpox_linelist %&gt;% \n  \n  # Time between onset and diagnosis (converted to a number)\n  mutate(delay_diag = as.numeric(date_of_diagnosis - date_of_onset)) %&gt;%   \n\n  # Time between diagnosis and notification (converted to a number)\n  mutate(delay_not = as.numeric(date_of_notification - date_of_diagnosis)) \n\nUse the summary function from base R to quickly view the median, mean, interquartile range, and rang.\n\n# Summarize the delays to diagnosis\nsummary(delay_db$delay_diag) \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n -2.000   4.000   7.000   7.758  10.000  66.000     897 \n\n# Summarize the delays from diagnosis to notification\nsummary(delay_db$delay_not)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-46.0000  -2.0000   0.0000  -0.6078   1.0000  23.0000      715 \n\n\nUse group_by() and summarize() to create a table with median delays per country.\n\ndelay_country &lt;- delay_db %&gt;% \n  \n  # Group by country\n  group_by(country) %&gt;% \n  \n  # Create columns for each delay\n  summarise(median_delay_diag = median(delay_diag, na.rm = T),\n            median_delay_not = median(delay_not, na.rm = T))\n\ndelay_country\n\n# A tibble: 5 × 3\n  country  median_delay_diag median_delay_not\n  &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt;\n1 CountryA                 7                0\n2 CountryB                 7                0\n3 CountryC                 6                0\n4 CountryD                 7                0\n5 CountryE                 6                0\n\n\nTo explore how the trends in cases over time differ when using different dates, you can reshape the linelist to create a dataset with one row per date type per case.\n\n# Prepare the data\ndates_longer &lt;- mpox_linelist %&gt;% \n  \n  select(age, gender, sexual_orientation, starts_with(\"date_\")) %&gt;% \n\n  pivot_longer(\n    \n      # all columns starting with \"date_\" will be pivoted from wide to long \n      cols=starts_with(\"date_\"),         \n    \n      # put names of the columns into a single column called \"indicator\"\n      names_to = \"indicator\",   \n      \n      # the date values will be placed in a column called \"date\"\n      values_to = \"date\")                \n\nThe data will then look like this, with three rows per case:\n\n\n\n\n\n\n\nThen tabulate cases by week per indicator\n\n# Create new object\ndates_longer_week &lt;- dates_longer  %&gt;% \n\n  # Create a new week column\n  mutate(week_date = floor_date(date, unit = \"week\", week_start = \"Monday\")) %&gt;%  \n  \n  # Within each combination of indicator and week, calculate the number of cases\n  group_by(indicator, week_date) %&gt;% \n  summarise(n=n()) %&gt;%   \n  \n  # drop the cases with no data on dates  \n  drop_na(week_date)                     \n\nThe data will then look like this, with three rows per case:\n\n\n\n\n\n\n\nFinally, create a plot with ggplot() and geom_line().\n\nplot_date_delay &lt;-   ggplot(data = dates_longer_week,\n                            aes(x = week_date, \n                                y = n, \n                                color=indicator)) +\n  \n  geom_line(linewidth = 1.5) +\n  \n  scale_x_date(breaks = \"2 weeks\")+\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\", \n        axis.text = element_text(size=9),\n        axis.title = element_blank(),\n        axis.text.x = element_text(angle=90),\n        legend.title = element_blank()) +\n  labs(title=\"Mpox cases reported in 2022, by date of onset, diagnosis and notification.\")\n\nplot_date_delay\n\n\n\n\n\n\n\n\n\nFinally, you remember that all-along you’ve had these aggregate counts from routine surveillance. You find out that these numbers are actually already being published.\nBefore you share your own numbers, you’d better check how different they are from already-published statistics!\nTask: Create a plot comparing the number of cases reported to through the case-based flow and through the aggregated flow in each country.\nNOTE: Take into consideration that the column on cases in the aggregated data frame reports the cumulative number of cases.\n\n\n\n\n\n\nTest yourself!\n\nWhich country is not reporting aggregated data?\n\n A B C D E\n\n\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nFirst, create a data frame of country totals from the aggregate data.\n\nmpox_agg_country &lt;- mpox_agg %&gt;% \n \n  # as we have cumulative data, we keep only the last week per country \n  group_by(country) %&gt;% \n  filter(date_rep == max(date_rep)) %&gt;% \n  \n  # remove unnecessary columns\n  select(-date_rep, -week_date) %&gt;%     \n\n  # create this column to distinguish the numbers from the linelist data\n  mutate(source = \"aggregated\")         \n\nThen create a data frame of country totals from the case linelist, and append it to the totals from the aggregate data.\n\nmpox_linelist_country &lt;- mpox_linelist %&gt;%\n  \n  # count cases by country, use the same column name as in the aggregate data\n  group_by(country) %&gt;% \n  summarise(cases = n()) %&gt;% \n  \n  # create this column to distinguish the numbers from the linelist data\n  mutate(source = \"case_based\")       \n  \n\n# Append both data frames. Remember this is different from merging\ntotal_data &lt;- bind_rows(mpox_linelist_country, mpox_agg_country)\n\nYou can now use this data to compare the cases reported in both sources, using ggplot().\n\ngraph_comp &lt;- ggplot(data = total_data,\n                     aes(x = source, \n                         y = cases, \n                         fill = source)) +\n  \n  #position dodge puts bars one next to each other, instead of \"stacked\"\n  geom_col(position = \"dodge\") +            \n  \n  # this command gives us one graph per country. The argument scales allows each y axis scales to adjust to the data\n  facet_wrap(~ country, scales = \"free_y\") +  \n\n  # changes the colours, but with the argument \"labels\" we can change the text of each fill.\n  scale_fill_viridis_d(\n    labels = c(\"Aggregated\", \"Case-based\")) +\n  \n  labs(\n    title = \"Number of cases of Mpox reported in 2022 according to source of data\",\n    fill = \"Source\",\n    x = \"\",\n    y = \"Total number of cases\"\n  ) + \n  \n  theme_bw() +\n  \n  # we remove the text of the x axis because it is already present in the legend\n  theme(axis.text.x = element_blank(),   \n        \n   # we also remove the ticks for aesthetic purposes\n        axis.ticks.x = element_blank())    \n\ngraph_comp\n\n\n\n\n\nInteresting! There are some differences - and this probably will be worth flagging with stakeholders and/or explaining in a footnote somewhere.\n\n\n\n\n\nWell done! Through your analysis you now understand the magnitude of the outbreak so far, where and when it spread, which demographic groups are most affected, and how the disease actually manifests in terms of symptoms and severity. ECDC is very happy with your work.\nBy coding this up in R, this analysis should be reproducible, meaning you can quickly update it with new data and keep monitoring the outbreak.\nOf course, the above data is not real. If you want to see a paper on the actual outbreak that occured in Europe in 2022, you can take a look at this Eurosurveillance paper. This ECDC page on Mpox also publishes updates on the status of mpox in Europe.\nTo further practise reproducible reports, [link to RMarkdown].\n\n\n\nAuthorship\nOriginal authors: Xanthi Andrianou, Gianfranco Spiteri (ECDC EI Group)\nData source: Fictional data provided by ECDC EI Group for training purposes\n\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nOctober 2021\nFirst draft\n1\nXanthi Andrianou\n\n\nJune 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales\n\n\nSeptember 2024\nRevise for case study repository\n1.2\nPaula Blomquist and Alanah Jansen\n\n\n\n\n\n\nDisclaimer: The information presented in this exercise and the associated data files have been deliberately changed so as to facilitate the acquisition of the learning objectives for fellows of EPIET, EUPHEM and EPIET-associated programmes. This case study was first introduced in 2022 (see Copyright and Licence agreement for more information).\nYou are free:\n\nto Share: to copy and distribute the work\nto Remix: to adapt and build upon the material\n\nUnder the following conditions:\n\nAttribution: You must attribute the work in the manner specified by the author or licensor (but not in any way that suggests that they endorse you or your use of the work). The best way to do this is to keep as it is the list of contributors: sources, authors and reviewers.\nShare Alike: If you alter, transform, or build upon this work, you may distribute the resulting work only under the same or similar license to this one. Your changes must be documented. Under that condition, you are allowed to add your name to the list of contributors.\nNotification: If you use the work in the manner specified by the author or licensor, Walter@rki.de\nYou cannot sell this work alone but you can use it as part of a teaching.\n\nWith the understanding that:\n\nWaiver: Any of the above conditions can be waived if you get permission from the copyright holder.\nPublic Domain: Where the work or any of its elements is in the public domain under applicable law, that status is in no way affected by the license.\nOther Rights: In no way are any of the following rights affected by the license:\n\nYour fair dealing or fair use rights, or other applicable copyright exceptions and limitations;\nThe author’s moral rights;\nRights other persons may have either in the work itself or in how the work is used, such as publicity or privacy rights.\n\nNotice: For any reuse or distribution, you must make clear to others the license terms of this work by keeping together this work and the current license.\n\nThis licence is based on http://creativecommons.org/licenses/by-sa/3.0/"
  },
  {
    "objectID": "pages/r_practical.html#scenario",
    "href": "pages/r_practical.html#scenario",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "It is May 2022 and Mpox has just been reported for the first time across 5 countries in Europe: Countries “A”, “B”, “C”, “D”, and “E”. You have been requested to provide a basic descriptive analysis to the European Centre for Disease Prevention and Control (ECDC).\nYou are given access to:\n\nA dataset with aggregate case counts, submitted to ECDC by the five countries as part of routine European reporting\nA linelist with cases, submitted by the five countries to ECDC for this particular analysis\n\nLet’s go!"
  },
  {
    "objectID": "pages/r_practical.html#objectives",
    "href": "pages/r_practical.html#objectives",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "In this case study you will:\n\nExplore different types of files and how they can be imported in R.\nPerform basic data cleaning, e.g., changing the variable type, recoding variables, aggregating and filtering.\nPerform a basic descriptive analysis using tables and graphs"
  },
  {
    "objectID": "pages/r_practical.html#step-1.-set-up",
    "href": "pages/r_practical.html#step-1.-set-up",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "Start by setting up a reproducible and well-organized workflow. This will make it easy to rerun your analysis whenever needed.\nTasks:\n\nSet up an RStudio project\nSet up clear sub-folders where your code, data, and outputs will go\nCreate an R script, or an R Markdown file if you prefer. Make sure the script purpose, date, and author are written as comments at the top.\nExtra: Ensure your working language in RStudio is appropriate (e.g. English for this exercise)\n\n\n\n Click to read a hint\n\n\n\nCreate a folder where all the work in this case study will go. For example, create ‘mpox_analysis’ on your computer desktop. Create your RStudio project to be based in this folder.\nWe suggest creating the following sub-folders: scripts (for your code), data (for your data), and outputs (for your analytical outputs).\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nCreate a folder (e.g. ‘mpox_analysis’ on your Desktop) for your work. To create an Rstudio project in your new folder, click New Project… in the top left of your R Studio, then Existing Directory, then Browse to select your new folder. For more information, look at the R projects section of the Epi R Handbook.\nStart a new R script by clicking New File… in the top left of your R Studio, then R Script. Save it immediately in the appropriate place, e.g. in a ‘scripts’ subfolder of your R Project.\nAt the top of your new R script, write some essential information like your name, the purpose of the file, and the date.\nYour R locale determines the language and regional settings used for things like date formats and translations. If your locale is different from the language you want for your report (e.g., a French locale vs. an English report), you can change it to English by running Sys.setlocale(\"LC_ALL\", \"English\"). Include this in your script if needed, or skip it if your locale is usually appropriate. This is explained in more detail in the How-to Guide.\n\n\n\n\nNext in your R script, you need to install and load the necessary R packages. This ensures that the functions you need are available for your analysis.\nYou will need the following packages: rio (for importing data), janitor (for cleaning data), lubridate (for cleaning dates), skimr (for reviewing data), epikit (for epi-related tasks), gtsummary (for presentation-ready tables), apyramid (for age-sex pyramids), and tidyverse (for general data manipulation/science tasks).\nAs you start, your trusted colleague nudges you and whispers “I’ve heard that a great way to manage your packages is with the pacman package”.\nOver to you!\n\n\nClick to see a solution (try it yourself first!)\n\n\nUse the function p_load() from pacman for this task. You provide the function with a list of packages that you want to use. It will take two steps per package: 1) Check if the package is installed on your computer, and install it if necessary, then 2) Load the package so it can be used during this R session.\nIf you don’t already have pacman installed, you will need to install it the “traditional way” first, with install.packages().\nNote that the order of packages in your p_load function can be important. If two packages have the same function names (e.g. select() in the package MASS and select() in tidyverse, which do different things), then R will use the function from the most recently loaded package. To prioritize functions from tidyverse, which are commonly used for data manipulation and visualization, load tidyverse last.\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)"
  },
  {
    "objectID": "pages/r_practical.html#step-2-download-and-import-the-data",
    "href": "pages/r_practical.html#step-2-download-and-import-the-data",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "ECDC provides you with two files for your analysis, both updated as of 31st August 2022:\n\nA case-level linelist (“mpox_linelist.xlsx”) with case information from five countries (countries A - E)\nAn aggregate table (“mpox_aggregate_table.csv”) for those countries with cumulative case counts per day.\n\nThey provide it to you via AppliedEpi’s very useful data repository, which you can access using the {appliedepidata} package. So first you need to download these two files to your own computer, as follows:\n\nInstall the {appliedepidata} package from GitHub using the install_github() function in the {remotes} package. Install {remotes} if you need to first.\n\n\n# Install remotes if you need to (so you can install a package from GitHub)\npacman::p_load(\"remotes\")\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nSave the two datasets into a specific folder using the save_data() function from {appliedepidata}, by running the code below. The example below saves the data into a ‘data’ subfolder within the RStudio project. Note that if you do not specify a location within the ‘path’ argument of the function, a window will pop up asking you to manually select a folder.\n\n\n# Save down the two mpox files using the save_data() function from appliedepidata\nappliedepidata::save_data(\"mpox_linelist\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"mpox_aggregate_table\",\n                          path = \"data\")\n\n\n\n\nGreat! Thanks ECDC and Applied Epi! Now it’s time to import the data from that folder into RStudio, so you can analyse it.\nTask: Import the downloaded case-based and aggregated data into your R environment. Ideally you want to use one function for both datasets, despite one being a csv and the other an xlsx file.\n\n\n Click to read a hint\n\n\nUse the import function from the {rio} package, which can recognize and import different file types. It replaces importing functions that are specific to the file type, such as read.csv() from {base} for .csv files and read_excel() from {readxl} to import .xlsx files.\nIf you feel you need to know more about importing functions, read the Import and export chapter of the EpiRhandbook.\n\n\n\nClick to see a solution (try it yourself first!)\n\nBelow we use the import function to bring in both files. Note how we are assigning the imported data to two objects, one called mpox_linelist_raw, and one called mpox_agg_raw. We add the ‘raw’ suffix to distinguish this data from the cleaned versions we will make later.\n\n# Import data  --------------\n\n# Case-based data\nmpox_linelist_raw &lt;- import(\"data/mpox_linelist.xlsx\")\n\n# Aggregated data\nmpox_agg_raw &lt;- import(\"data/mpox_aggregate_table.csv\")"
  },
  {
    "objectID": "pages/r_practical.html#step-3-explore-the-data",
    "href": "pages/r_practical.html#step-3-explore-the-data",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "The data’s in, and now it’s time to see what story it tells. Take an initial look at your data to check its quality and how you can best use it.\nTasks: Take a look at the different data frames and determine:\n\nThe number of columns and observations (e.g. their dimensions)\nThe class of their columns and whether it matches its nature (e.g., are “dates” considered “dates” by R?)\nIf the contents of columns are clean and standardized in the mpox linelist (e.g. gender, clinical symptoms, outcome, hiv status and sexual orientation). Do you need to recode any of them?\nHow unknown or missing data is categorised in these columns. Do these values need to be standardized?\n\n\n\n Click to read a hint\n\n\nAn efficient function for initial data exploring is skim() from the {skimr} package, as it gives you a lot of information on data structure and content, including the classes of columns.\nYou can use the function tabyl() from {janitor}, to get counts and percentages of every category in the data column, one by one. These get printed to your RStudio console.\nAlso - we recommend just looking at the data itself! A good function for this is view(), a baseR function.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nUsing the skim commands you can see the rows and columns of each dataset, and you can see how most of the columns in mpox_linelist_raw (including those containing dates) are character classes. (Results not shown on this exercise page)\n\n# Explore the dimensions of the two data objects \nskim(mpox_linelist_raw)\nskim(mpox_agg_raw)\n\nTake a look at the overall data using view(). It will pop up in the Data Viewer tab and you will get a good sense of how clean the data is and what the missingness is like. This preview shows just 5 rows from the linelist data.\n\nview(mpox_linelist_raw)\n\n\n\n\n\n\n\n\nBelow is an example of using the tabyl() function from {janitor}, to look at the distribution of clinical symptoms. You can see 12 cases have missing clinical information and that many cases have a mix of symptoms.\n\ntabyl(mpox_linelist_raw, HIVStatus)  \n\n HIVStatus   n percent valid_percent\n       NEG 525  0.2625     0.4107981\n       POS 307  0.1535     0.2402191\n       UNK 446  0.2230     0.3489828\n      &lt;NA&gt; 722  0.3610            NA\n\n\nYou can explore further columns one by one (results not shown):\n\n# Explore the values of different categorical columns in the mpox linelist: with tabyl\ntabyl(mpox_linelist_raw, Gender)\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms)\n\ntabyl(mpox_linelist_raw, Outcome)\n\ntabyl(mpox_linelist_raw, SexualOrientation)\n\nYou could add extra arguments to tabyl() to customize the tables, such as adding totals and changing the proportions to percentages so they are easier to read. See the table on clinical symptoms below. But remember - this is just an initial look so don’t go too crazy.\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms) %&gt;%    # Tabulate symptoms \n  adorn_totals() %&gt;%                              # Add totals to bottom of table\n  adorn_pct_formatting(digits = 2)                # Format percentages\n\n                 ClinicalSymptoms    n percent valid_percent\n                          Lesions   14   0.70%         0.70%\n                             Rash  257  12.85%        12.93%\n                    Rash, Lesions  323  16.15%        16.25%\n          Rash, Systemic symptoms  676  33.80%        34.00%\n Rash, Systemic symptoms, Lesions  654  32.70%        32.90%\n                Systemic symptoms   28   1.40%         1.41%\n       Systemic symptoms, Lesions   36   1.80%         1.81%\n                             &lt;NA&gt;   12   0.60%             -\n                            Total 2000 100.00%       100.00%\n\n\nFinally, as an alternative approach to tabyl(), you could use tbl_summary() from the {gtsummary} package. We will describe this later.\n\n\n\n\n\n\n\n\nTest yourself!\n\nHow many columns does the aggregated data have?\n\n 2000 13 3 101\n\n\n\nWhat is the class of the column DateOfNotification in the mpox linelist?\n\n Date Character Numeric Factor\n\n\n\nFor how many cases is the HIV status Unknown or missing?\n\n 1168 722 900 446"
  },
  {
    "objectID": "pages/r_practical.html#step-4-clean-the-data",
    "href": "pages/r_practical.html#step-4-clean-the-data",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "So! The good news: you have information on geography, dates, demographic characteristics, and clinical details. A promising descriptive analysis lies ahead.\nBUT! You may noticed that there are a few things to fix before the real detective work begins.\nFor example:\n\nColumn names have capital letters. This isn’t outright a problem, but can lead to mistakes since R treats ColumnName and Columnname as different.\nDate columns are recognized as character classes, not dates, which would cause issues like incorrect ordering (alphabetical) in epicurves.\nSome columns have values that are unclear or unsuitable for presentation. For example gender is categorized with “F”, “M”, “O” and “UNK”. The column Outcome is “A” and “UNK”.\nMissing data is inconsistently handled, for instance with both “UNK” and NA in the HIV status column. R thinks “UNK” is a valid value, which it treats differently to true missing data (indicated by NA)\n\nTasks:\n\nCreate a clean version of your case-based data making all cleaning changes in a single piping command\nChange all column names to lower case.\nConvert all date columns to class “Date”.\nConvert all missing/unknown values to NA (to be recognized by R as missing)\nRecode non-missing “Gender” categories into: “Female”, “Male”, and “Other”\nRecode non-misising HIV status into: “Positive”, “Negative” and “Unknown”\nRecode non-missing sexual orientation into: “Bisexual”, “Heterosexual”, and “MSM/homo or bisexual male”.\nRecode non-missing “outcome” categories into: “Alive” and “Dead”.\nCheck that all changes have been made correctly\n\n\n\n Click to read a hint\n\n\nTo convert all column names to lower case at once rather than renaming each column, use the function clean_names() from the {janitor} package.\nUse {lubridate} functions to transform date columns into “Date” class. You can do this one by one, or you could do all at the same time using the across() function from {dplyr}. If you feel you need to know more about transforming dates read the chapter Working with Dates from the EpiRhandbook. If you are not sure how to use the across() function, you can also read the section on Transform multiple columns.\nThere are different functions that we can use to recode values. We propose three: The function recode() from {dplyr}, the function ifelse() from {base} and the function case_when() from {dplyr}. If you want to know more about these functions, look that the section on Re-code values from the EpiRhandbook.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nHere we clean the data using a ‘chain’ of commands connected by pipes (%&gt;%), which is the grammar of the functions in the {Tidyverse}. The output is assigned to a new object called mpox_linelist to differentiate it from the raw data. It can be helpful to have both the cleaned and raw data available in the environment to compare to the original data if needed.\nSee the series of functions and the explanation in the comments.\n\n# Create a new object called mpox_linelist which is the clean version of the raw data\nmpox_linelist &lt;- mpox_linelist_raw %&gt;% \n  \n  # standardises names and puts all into lower case \n  clean_names() %&gt;% \n  \n  #transform ONE column into date (note the column names are lower case now)\n  mutate(date_of_notification = ymd(date_of_notification)) %&gt;%  \n\n  #transforms ALL columns starting with \"date\" into dates\n  mutate(across(starts_with(\"date\"), \n                .fns = ~ ymd(.x))) %&gt;%  \n  \n  #transforms UNK to NA across all character columns \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x %in% c(\"UNK\", \"Unknown\"), NA_character_, .x)))  %&gt;% \n\n  # Recode the gender values to be more obvious  \n  mutate(gender = recode(gender,\n                         \"F\" = \"Female\",\n                         \"M\" = \"Male\",\n                         \"O\" = \"Other\")) %&gt;%\n  \n  #recode with ifelse to change only one or two categories based on a rule. \n  mutate(outcome = ifelse(outcome == \"A\", \"Alive\", outcome)) %&gt;%   \n  \n  #recode with case_when for more complex recoding \n  mutate(hiv_status = case_when(hiv_status == \"NEG\" ~ \"Negative\",    \n                                hiv_status == \"POS\" ~ \"Positive\")) %&gt;% \n  \n  mutate(sexual_orientation = case_when(sexual_orientation == \"BISEXUAL\" ~ \"Bisexual\",\n                                        sexual_orientation == \"HETERO\" ~ \"Heterosexual\",\n                                        sexual_orientation == \"MSM\" ~ \"MSM/homo or bisexual male\")) \n\nYou can then review your data by tabulating across all the different columns you have cleaned. See the preview of the HIV table below - it looks tidier now with more understandable categories, and all missing data is classified as ‘Unknown’.\n\n# Check that all changes have been made correctly\n\nskim(mpox_linelist)\n\ntabyl(mpox_linelist, gender)\n\ntabyl(mpox_linelist, clinical_symptoms)\n\ntabyl(mpox_linelist, outcome)\n\ntabyl(mpox_linelist, hiv_status)\n\ntabyl(mpox_linelist, sexual_orientation)\n\n\n\n hiv_status    n percent valid_percent\n   Negative  525  0.2625     0.6310096\n   Positive  307  0.1535     0.3689904\n       &lt;NA&gt; 1168  0.5840            NA\n\n\nIMPORTANT: If ‘unknown’ and NA had meaningful differences, combining them wouldn’t be appropriate (e.g., if ‘unknown’ meant the case was asked but didn’t want to respond, while NA meant they weren’t asked). Here, we assume no meaningful difference and want R to recognize them as missing.\n\n\n\n\n\n\n\n\nTest yourself!\n\nIs it always appropriate to combine different types of unknown data? (e.g. missing, unknown, did not respond, NA)\n\n Yes Depends on the meaning of those values No - never do this\n\n\n\nHow many male cases do we have in the data frame?\n\n 36 1960 65 1523\n\n\n\nHow many cases have ‘alive’ as an outcome?\n\n 1405 None 595\n\n\n\n\n\n\n\n\nIn a similar way, clean the aggregated data by:\n\nStandardising names to lower case\nEnsuring that date of reporting is of class “Date”\nCreating a column called “week_date” with the week of reporting starting on Monday\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nWe can first check the class of the DateRep column, which shows us that it was already recognized as a date column on import.\n\n# Check class of date of reporting column\nclass(mpox_agg_raw$DateRep)\n\nThen create a new object for the clean aggregate data, and write your cleaning coded connected with pipes.\n\n# Create a new object called mpox_agg which is the clean version of the raw data, applying the cleaning functions\n\nmpox_agg &lt;- mpox_agg_raw %&gt;% \n  \n  # standardises names and puts all into lower case\n  clean_names() %&gt;%  \n  \n  # create week column with Monday start\n  mutate(week_date = floor_date(date_rep, \n                              unit = \"week\",\n                              week_start = \"Monday\")) \n\n\n\n\n\n\n\n\n\nTest yourself!\n\nTake a look at the aggreate data. Which country reported the largest cumulative number of cases during the week 2022-04-11?\n\n Country A Country B Country C Country D Country E"
  },
  {
    "objectID": "pages/r_practical.html#step-5-describe-outbreak-by-person-place-and-time",
    "href": "pages/r_practical.html#step-5-describe-outbreak-by-person-place-and-time",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "Now we’re getting to the heart of the investigation. Who is affected? Which locations are most affected, and how quickly is it spreading? Your ability to tell the classic “person, place, and time” story will be crucial to guiding the response. Pinpoint those hotspots and trends!\n\n\nTask: Using the mpox case linelist, create a table showing the total number of cases by country. This time, make the table more publication-friendly.\n\n\n Click to read a hint\n\n\nYou could use tabyl() like before, but an easy way to produce publication-ready tables is with the function tbl_summary() from {gtsummary} package. This formats the table for you. It will print to your Viewer rather than the console.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nCreate a new object with the table output - as this is a key output that you can then integrate into a document later rather than just viewing for now.\n\n# Create an object with the table\ncb_country_table &lt;- mpox_linelist %&gt;%\n\n  #select the column that we want to use in the table\n  select(country) %&gt;% \n  \n  # create the table. No need to specify columns; it will tabulate all available columns (selected above)\n  tbl_summary() \n\n# Print the table\ncb_country_table\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 2,0001\n    \n  \n  \n    country\n\n        CountryA\n816 (41%)\n        CountryB\n391 (20%)\n        CountryC\n474 (24%)\n        CountryD\n217 (11%)\n        CountryE\n102 (5.1%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nWhat country has the largest percentage of cases?\n\n Country C Country D Country B Country E Country A\n\n\n\n\n\n\n\n\nOkay so Country A has the most cases in total based on most recent data. But how does that change look over time?\nTasks:\n\nUsing the mpox case linelist, create an epicurve by week of notification\nUsing the mpox case linelist, create an epicurve by week of notification to enable a comparison of trends by country.\nUsing the mpox case linelist, create a heat plot with the number of cases by country and week of notification.\n\n\n\n Click to read a hint\n\n\nPrepare your data for the epicurve first. You can create a “week_date” column using the function floor_date() from {lubridate}. Take a look at the documentation to understand how it works and how to pick the starting day of the week.\nTo create the epicurve, you can use ggplot() and geom_bar(), which visualizes the number of rows within a group - e.g. number of cases per week. To compare trends in different countries, consider using the facet_wrap() function. If you are unsure on how ggplot() works, read the EpiRhandbook chapter on Epidemic curves.\nTo create a heatmap, you will need to create a table of counts by country and week of notification. You can do this using the functions group_by() and summarise() from {dplyr}. If you are unsure on how to do this, review the Grouping data chapter of the EpiRhandbook. Then, use the geom geom_tile() to create a heat plot. If you’re unsure on how to do this, read the EpiRhanbook section on Heat Plots\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nPrepare your data by creating the new column using mutate() and floor_date():\n\nmpox_linelist &lt;- mpox_linelist %&gt;% \n  # create week column with Monday start \n  mutate(week_date = floor_date(date_of_notification, unit = \"week\", week_start = \"Monday\")) \n\nThe code below creates an epicurve using ggplot() and the geom_bar() function, then applies further formatting. With geom_bar(), you only need to specify the x axis, and the function will visualize the number of rows per unique x axis value.\n\n# Open up the plot production with ggplot() function, specifying object and columns\nepicurve_mpox &lt;- ggplot(data = mpox_linelist,          \n                        aes(x = week_date)) +    \n  \n  geom_bar(fill=\"darkgreen\",                     #colour inside the bins\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  labs(title=\"Mpox cases reported in 2022 in Countries A, B, C, D, and E\",\n       subtitle = \"Date as of August 31st 2022\") +  #add a title\n  \n  theme_minimal() +                             #assign a predefined theme\n  \n  theme(axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n           \n# Print the epicurve\nepicurve_mpox\n\n\n\n\nTo examine how the outbreak spread by country, add facet_wrap() to your ggplot code. This splits the graph into multiple smaller ones. As shown below, you can even simply add the function to the national epicurve object.\nAn alternative approach would be to create a stacked epicurve, i.e. retain the single epicurve but split each bar into colors per country. You would do this by adding fill = country to the aes() in the epicurve code. However, we don’t recommend this for comparing trends, as stacked bars make it harder to see individual patterns.\n\nepicurve_epox_country &lt;- epicurve_mpox + \n \n   # Facet wrap to make mini-plots, specifying that you want two columns of plots. \n  facet_wrap(.~country,\n             ncol = 1) \n\n# Print the epicurve\nepicurve_epox_country\n\n\n\n\nFinally, if you want to demonstrate this as a weekly heatmap, you can use geom_tile(). First, aggregate the data by week. Then pipe into a ggplot(), as shown below.\n\n# Assign the output of your ggplot code to a new object\nhp_mpox &lt;- mpox_linelist %&gt;% \n  \n  #first count the number of cases by country and notification week\n  count(country, week_date) %&gt;% \n\n  #you can pipe directly into the ggplot\n    ggplot(aes(x = week_date, # notification week along the x axis\n           y = country,       # country along the y axis\n           fill = n)) +       # colour in the heatmap tiles by number\n  \n  # specify that you want this to be a heatmap with geom_tile()\n  geom_tile(colour = \"black\") +   # black is the outline of each tile\n  \n  #define the gradient of the colours\n  scale_fill_gradient(            \n    low = \"lightgreen\",\n    high = \"red\") +\n  \n  #set the x axis labels to two week intervals\n  scale_x_date(breaks = \"2 weeks\") +             \n  \n  # Add titles\n  labs(\n    title= \"Mpox cases by country and week of notification\",\n    fill = \"Number of cases\"                               \n  ) +\n  \n  # Apply an overall theme to your plot\n  theme_bw() +\n  \n  # Customize other appearance details\n  theme(legend.position = \"bottom\",       #legend position to bottom\n        axis.text = element_text(size=9),     #define axis font \n        axis.title = element_blank(),         #remove the axis titles\n        axis.text.x = element_text(angle=90)) #rotate the x axis text\n    \n\n# Print the heatmap\nhp_mpox \n\n\n\n\n\n\n\n\n\nNext, describe the age, gender, and sexual orientation of cases. What is interesting?\nTask:\n\nCreate a single table showing overall distribution of age, gender, and sexual orientation\nCreate an age-gender pyramid showing age as 10-year age bands\n\n\n\n Click to read a hint\n\n\nTo quickly create a presentation-ready table showing the breakdowns for three different columns, consider using the function tbl_summary() from {gtsummary}.\nTo create an age-gender pyramid, first create a new column with the function age_categories() from the {epikit} package. Then explore the function age_pyramid() from the {apyramid} package.You can find more about this function in the EpiRhandbook chapter Demographic pyramids and Likert-scales\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nSee below the code to quickly generate one table with the breakdown of different variables. The function tbl_summary() by default summarizes columns differently depending on their class:\n\nAge is a numeric column, so is summarized with a median and interquartile range.\nGender and sexual orientation are character values, so are described in terms of counts and percentages.\n\nYou can customize this further; explore the documentation by typing ?tbl_summary() in your console.\nNote that tbl_summary() by default does not include NAs in the counts and percentages, allowing you to see the distribution of non-missing values.\n\n# Create table of all three variables\ntab_demographics &lt;- mpox_linelist %&gt;% \n  \n  # select the columns of interest for\n  select(age, gender, sexual_orientation) %&gt;% \n  \n  # use tbl_summary() to create the table\n  tbl_summary() \n\ntab_demographics\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 2,0001\n    \n  \n  \n    age\n37 (31, 45)\n        Unknown\n3\n    gender\n\n        Female\n36 (1.8%)\n        Male\n1,960 (98%)\n        Other\n1 (&lt;0.1%)\n        Unknown\n3\n    sexual_orientation\n\n        Bisexual\n7 (0.8%)\n        Heterosexual\n46 (5.2%)\n        MSM/homo or bisexual male\n833 (94%)\n        Unknown\n1,114\n  \n  \n  \n    \n      1 Median (IQR); n (%)\n    \n  \n\n\n\n\nCreate the new age group column as follows. You can add this to the cleaning section of your script (which we covered 4.1).\n\nmpox_linelist &lt;- mpox_linelist %&gt;% \n  # Use the age_categories function to create age categories\n  mutate(age_group = age_categories(age, lower = 0, #set up the lower age\n                                    upper = 70, #set up the upper age\n                                    by = 10)) #set up the age breaks\n\nThen make the age-gender pyramid using the age_pyramid() function. It is a function that builds on ggplot, so you can then continue to add on customization, such as the theme_bw() below.\n\n# Create table of all three variables\nfigure_agesex &lt;- mpox_linelist %&gt;% \n  \n  # Filter to male and female only\n  filter(gender %in% c(\"Male\", \"Female\")) %&gt;% \n  \n  # select the columns of interest for\n  age_pyramid(age_group = \"age_group\",\n              split_by = \"gender\") +\n  \n  # change theme\n  theme_bw()\n\nfigure_agesex\n\n\n\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nWhich demographic group is more affected by Mpox?\n\n Females 60-69 Males 40-49 Females 10-19 Males 30-39\n\n\n\nWhat proportion of mpox cases were homosexual or bisexual men?\n\n 41% 42% 5% 94%\n\n\n\n\n\n\n\n\nThe media is starting to call your office and are asking what symptoms the public should look out for. Just in luck - you can check that out in the data too!\nTasks:\n\nCreate a table with the distribution of different symptoms and outcomes.\n\nNo hints! You should know this one by now!\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Table with number and percentage of cases by outcome\n\ntab_outcome &lt;- mpox_linelist %&gt;% \n  \n  # Select the columns for tabulation\n  select(outcome, clinical_symptoms) %&gt;% \n  \n  # Use tbl_summary() - note that this time we are adding on labels to change how the column name is displayed\n  tbl_summary(label = list(\n    clinical_symptoms = \"Symptoms\",\n    outcome = \"Reported outcome\")) \n\ntab_outcome\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 2,0001\n    \n  \n  \n    Reported outcome\n\n        Alive\n1,405 (100%)\n        Unknown\n595\n    Symptoms\n\n        Lesions\n14 (0.7%)\n        Rash\n257 (13%)\n        Rash, Lesions\n323 (16%)\n        Rash, Systemic symptoms\n676 (34%)\n        Rash, Systemic symptoms, Lesions\n654 (33%)\n        Systemic symptoms\n28 (1.4%)\n        Systemic symptoms, Lesions\n36 (1.8%)\n        Unknown\n12\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "pages/r_practical.html#step-6-reviewing-data-quality",
    "href": "pages/r_practical.html#step-6-reviewing-data-quality",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "You’ve described a lot now, but you want to make sure you understand how timely and complete your mpox linelist is, especially if it will be the basis of making decisions.\nFor example - is it possible that there are very different reporting delays between countries, meaning current case counts are not directly comparable? Oh dear, must check.\n\n\nTasks\n\nCalculate median time from symptom onset to diagnosis and from diagnosis to notification, both overall and by country\nAssess visually the number of cases by calendar period and type of date (onset, diagnosis and notification)\n\n\n\n Click to read a hint\n\n\nTo plot together the different dates you may need to transform your data from “wide” to “long” form. What we call “pivoting” in R. The objective is to have a column with the different date categories (onset, diagnosis and notification) and another column with their date value. If you are unsure on how to do this, have a look at the Pivoting data chapter of the EpiRhandbook. Then, try to plot with the daily values, but if that’s not easy to interpret you may want to aggregate cases by week.\n\n\n\n\n\n\n\n\nTest yourself!\n\nIs there a difference in the delay from diagnosis to notification by country?\n\n Yes No\n\n\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nFirst create the required columns for this analysis.\n\n# Create two columns in linelist to assess delays\ndelay_db &lt;- mpox_linelist %&gt;% \n  \n  # Time between onset and diagnosis (converted to a number)\n  mutate(delay_diag = as.numeric(date_of_diagnosis - date_of_onset)) %&gt;%   \n\n  # Time between diagnosis and notification (converted to a number)\n  mutate(delay_not = as.numeric(date_of_notification - date_of_diagnosis)) \n\nUse the summary function from base R to quickly view the median, mean, interquartile range, and rang.\n\n# Summarize the delays to diagnosis\nsummary(delay_db$delay_diag) \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n -2.000   4.000   7.000   7.758  10.000  66.000     897 \n\n# Summarize the delays from diagnosis to notification\nsummary(delay_db$delay_not)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-46.0000  -2.0000   0.0000  -0.6078   1.0000  23.0000      715 \n\n\nUse group_by() and summarize() to create a table with median delays per country.\n\ndelay_country &lt;- delay_db %&gt;% \n  \n  # Group by country\n  group_by(country) %&gt;% \n  \n  # Create columns for each delay\n  summarise(median_delay_diag = median(delay_diag, na.rm = T),\n            median_delay_not = median(delay_not, na.rm = T))\n\ndelay_country\n\n# A tibble: 5 × 3\n  country  median_delay_diag median_delay_not\n  &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt;\n1 CountryA                 7                0\n2 CountryB                 7                0\n3 CountryC                 6                0\n4 CountryD                 7                0\n5 CountryE                 6                0\n\n\nTo explore how the trends in cases over time differ when using different dates, you can reshape the linelist to create a dataset with one row per date type per case.\n\n# Prepare the data\ndates_longer &lt;- mpox_linelist %&gt;% \n  \n  select(age, gender, sexual_orientation, starts_with(\"date_\")) %&gt;% \n\n  pivot_longer(\n    \n      # all columns starting with \"date_\" will be pivoted from wide to long \n      cols=starts_with(\"date_\"),         \n    \n      # put names of the columns into a single column called \"indicator\"\n      names_to = \"indicator\",   \n      \n      # the date values will be placed in a column called \"date\"\n      values_to = \"date\")                \n\nThe data will then look like this, with three rows per case:\n\n\n\n\n\n\n\nThen tabulate cases by week per indicator\n\n# Create new object\ndates_longer_week &lt;- dates_longer  %&gt;% \n\n  # Create a new week column\n  mutate(week_date = floor_date(date, unit = \"week\", week_start = \"Monday\")) %&gt;%  \n  \n  # Within each combination of indicator and week, calculate the number of cases\n  group_by(indicator, week_date) %&gt;% \n  summarise(n=n()) %&gt;%   \n  \n  # drop the cases with no data on dates  \n  drop_na(week_date)                     \n\nThe data will then look like this, with three rows per case:\n\n\n\n\n\n\n\nFinally, create a plot with ggplot() and geom_line().\n\nplot_date_delay &lt;-   ggplot(data = dates_longer_week,\n                            aes(x = week_date, \n                                y = n, \n                                color=indicator)) +\n  \n  geom_line(linewidth = 1.5) +\n  \n  scale_x_date(breaks = \"2 weeks\")+\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\", \n        axis.text = element_text(size=9),\n        axis.title = element_blank(),\n        axis.text.x = element_text(angle=90),\n        legend.title = element_blank()) +\n  labs(title=\"Mpox cases reported in 2022, by date of onset, diagnosis and notification.\")\n\nplot_date_delay\n\n\n\n\n\n\n\n\n\nFinally, you remember that all-along you’ve had these aggregate counts from routine surveillance. You find out that these numbers are actually already being published.\nBefore you share your own numbers, you’d better check how different they are from already-published statistics!\nTask: Create a plot comparing the number of cases reported to through the case-based flow and through the aggregated flow in each country.\nNOTE: Take into consideration that the column on cases in the aggregated data frame reports the cumulative number of cases.\n\n\n\n\n\n\nTest yourself!\n\nWhich country is not reporting aggregated data?\n\n A B C D E\n\n\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nFirst, create a data frame of country totals from the aggregate data.\n\nmpox_agg_country &lt;- mpox_agg %&gt;% \n \n  # as we have cumulative data, we keep only the last week per country \n  group_by(country) %&gt;% \n  filter(date_rep == max(date_rep)) %&gt;% \n  \n  # remove unnecessary columns\n  select(-date_rep, -week_date) %&gt;%     \n\n  # create this column to distinguish the numbers from the linelist data\n  mutate(source = \"aggregated\")         \n\nThen create a data frame of country totals from the case linelist, and append it to the totals from the aggregate data.\n\nmpox_linelist_country &lt;- mpox_linelist %&gt;%\n  \n  # count cases by country, use the same column name as in the aggregate data\n  group_by(country) %&gt;% \n  summarise(cases = n()) %&gt;% \n  \n  # create this column to distinguish the numbers from the linelist data\n  mutate(source = \"case_based\")       \n  \n\n# Append both data frames. Remember this is different from merging\ntotal_data &lt;- bind_rows(mpox_linelist_country, mpox_agg_country)\n\nYou can now use this data to compare the cases reported in both sources, using ggplot().\n\ngraph_comp &lt;- ggplot(data = total_data,\n                     aes(x = source, \n                         y = cases, \n                         fill = source)) +\n  \n  #position dodge puts bars one next to each other, instead of \"stacked\"\n  geom_col(position = \"dodge\") +            \n  \n  # this command gives us one graph per country. The argument scales allows each y axis scales to adjust to the data\n  facet_wrap(~ country, scales = \"free_y\") +  \n\n  # changes the colours, but with the argument \"labels\" we can change the text of each fill.\n  scale_fill_viridis_d(\n    labels = c(\"Aggregated\", \"Case-based\")) +\n  \n  labs(\n    title = \"Number of cases of Mpox reported in 2022 according to source of data\",\n    fill = \"Source\",\n    x = \"\",\n    y = \"Total number of cases\"\n  ) + \n  \n  theme_bw() +\n  \n  # we remove the text of the x axis because it is already present in the legend\n  theme(axis.text.x = element_blank(),   \n        \n   # we also remove the ticks for aesthetic purposes\n        axis.ticks.x = element_blank())    \n\ngraph_comp\n\n\n\n\n\nInteresting! There are some differences - and this probably will be worth flagging with stakeholders and/or explaining in a footnote somewhere."
  },
  {
    "objectID": "pages/r_practical.html#final-thoughts",
    "href": "pages/r_practical.html#final-thoughts",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "Well done! Through your analysis you now understand the magnitude of the outbreak so far, where and when it spread, which demographic groups are most affected, and how the disease actually manifests in terms of symptoms and severity. ECDC is very happy with your work.\nBy coding this up in R, this analysis should be reproducible, meaning you can quickly update it with new data and keep monitoring the outbreak.\nOf course, the above data is not real. If you want to see a paper on the actual outbreak that occured in Europe in 2022, you can take a look at this Eurosurveillance paper. This ECDC page on Mpox also publishes updates on the status of mpox in Europe.\nTo further practise reproducible reports, [link to RMarkdown]."
  },
  {
    "objectID": "pages/r_practical.html#case-study-information",
    "href": "pages/r_practical.html#case-study-information",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "Authorship\nOriginal authors: Xanthi Andrianou, Gianfranco Spiteri (ECDC EI Group)\nData source: Fictional data provided by ECDC EI Group for training purposes\n\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nOctober 2021\nFirst draft\n1\nXanthi Andrianou\n\n\nJune 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales\n\n\nSeptember 2024\nRevise for case study repository\n1.2\nPaula Blomquist and Alanah Jansen"
  },
  {
    "objectID": "pages/instructions.html#what-is-a-case-study",
    "href": "pages/instructions.html#what-is-a-case-study",
    "title": "How-to Guide",
    "section": "What is a Case Study?",
    "text": "What is a Case Study?\nA case study is an interactive learning tool. It guides users through scenarios, with tasks and questions to practice skills and is usually completed within a few hours. The case studies in the Applied Epi repository span a variety of skills and diseases with different levels of complexity, so make sure you take a moment to find the one best suited for you!"
  },
  {
    "objectID": "pages/instructions.html#getting-started",
    "href": "pages/instructions.html#getting-started",
    "title": "How-to Guide",
    "section": "Getting Started",
    "text": "Getting Started\n\nFolder Structure\nYou’ll start by choosing a location on your computer to create a dedicated folder for your case study. Once you’ve decided on the best spot, set up a folder with the case study’s name to keep everything organized from the start.\nIn your case study folder, you should have a:\n\nsubfolder “scripts” to save any scripts related to the analysis\nsubfolder “data” which will contain the raw data you will use\nsubfolder “outputs” can be used to store any outputs (tables, graphs, documents) that are the result of the analysis\n\nMake sure your folders and subfolders are well-organised as this will save you a headache later!\n\n\nRStudio Project\nCreate an Rstudio project in the case study folder. If you are unsure on how to do that, read the EpiRhandbook on RStudio projects.\n\n\nR Scripts\nOnce you have created an RStudio project, start a new R script with an appropriate name (example case_study_name) and save it in the subfolder “scripts”.\nIf you are familiar with R markdown, you may decide to use this type of file instead of a standard R script. See below for more instructions on using R markdown.\nNo matter what type of file you choose to use, make sure the purpose, date last updated, and author are written as comments at the top.\n\n#Purpose: To practice new skills using this case study\n#Author: Your Name\n#Date: Mmm dd, yyyy or whatever format you like best\n\n\n\nR Markdown\nSome of our case studies use R markdown and the code goes within “chunks”, which is different from a standard R script. If you want to create a reproducible workflow, you need a place to save your code so you can run it again if you need to. You want all your files easily organised so you don’t get lost later on. You need to begin by setting the default chunk options.\nTypically, you want to change the default chunk options of your R markdown script to:\n\nhide all code chunks in the report\nnot show messages or warnings in the output\nshow errors if they appear, but to not stop the rendering\nset up the default figure width to 7 and the figure height to 6\nshow the figure titles on top of the plots by default\n\n\n# hide all code chunks in the output, but show errors \nknitr::opts_chunk$set(echo = FALSE,  # hide all code chunks in output\n                      error = TRUE,  # show errors if they appear, but don't stop (produce the word doc)\n                      warning = FALSE, # do not show warnings in the output word doc \n                      message = FALSE, # do not show  messages in the output word doc\n                      fig.width = 7,         # Figure width\n                      fig.height = 6,        # Figure height\n                      fig.topcaption = TRUE  # show figure titles on top of plot\n                     )\n\nBe sure to review Reports with R Markdown in the EpiRhandbook before jumping in!"
  },
  {
    "objectID": "pages/instructions.html#i-need-help",
    "href": "pages/instructions.html#i-need-help",
    "title": "How-to Guide",
    "section": "I Need Help!",
    "text": "I Need Help!\nThere are several ways to get help:\n\nLook for the hints and solutions (see below)\nTake a look at the EpiRHandbook\nPost a question in Applied Epi Community with reference to this case study\n\n\nHints and Solutions\nThere are hints and solutions throughout every case study. Here are what the “helpers” look like:\n\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see the solution\n\n\nThe solution is typically the code required to find the answer. However, sometimes it may simply be a written response designed to prompt deeper reflection on the scenario.\n\n# Example of a solution\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )"
  },
  {
    "objectID": "pages/instructions.html#install-and-update-r-and-rstudio",
    "href": "pages/instructions.html#install-and-update-r-and-rstudio",
    "title": "How-to Guide",
    "section": "Install (and update!) R and RStudio",
    "text": "Install (and update!) R and RStudio\nIf this is your first time using R and RStudio, welcome! The Epidemiologist R Handbook or EpiRhandbook has a wealth of information to support you along the way. It has everything thing you need to get started with R basics, including installing and updating R and RStudio.\nIf you are new to RStudio, it might be a good idea to spend some time reviewing that page and others before trying out any case studies. Don’t forget that we also have free self-paced R tutorials if you’d like even more guidance and practice."
  },
  {
    "objectID": "pages/instructions.html#define-r-language",
    "href": "pages/instructions.html#define-r-language",
    "title": "How-to Guide",
    "section": "Define R Language",
    "text": "Define R Language\nDepending on where you are and how you carried out R installation, your language “locale” might be different from the language of the report that you want to produce.\nFor example, a French-speaking person might have a French ‘locale’. If that is the case, when creating a graph by day of the week, “Monday” will be displayed as “lundi”. If that person wants to create an English report, as for this case study, the language ‘locale’ should be changed.\nTo ensure your ‘locale’ is set to English, use the following code:\n\n# To see your language locale\nSys.getlocale()\n\n# To change it into English\nSys.setlocale(\"LC_ALL\", \"English\")"
  },
  {
    "objectID": "pages/instructions.html#install-packages",
    "href": "pages/instructions.html#install-packages",
    "title": "How-to Guide",
    "section": "Install packages",
    "text": "Install packages\nSeveral packages are required for different aspects of analysis with R. You will need to install these before starting. We install and load packages using the {pacman} package. Its p_load() command will install packages if necessary and load them for use in the current session. If a listed package has already been installed, it will just load it. Each case study specifies at the beginning what packages you need to have installed. You can find more about installing/loading packages in the suggested packages section of the EpiRhandbook.\nNote you may end up using a long list of packages. Unfortunately different packages have functions with the same name. For example, the package {dplyr} (already installed with {tidyverse}) has a function called select() which we frequently use to subset columns of a data frame. Other packages such as {MASS} also have a function called select(). This could create headaches if you want to subset columns using dplyr’s select() but R thinks you’re calling MASS’s select() (we call this masking - dplyr’s select() is masked by MASS’s select()). Given that you are more likely to use functions from {tidyverse}, ensure that this is the last package in your p_load() list so that functions from {tidyverse} (including {dplyr} functions) will always “prevail”.\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\nIf this step is not working, you may have limited administrative rights for your computer. Making sure your IT-department gives you the correct access can save a lot of headache. See these EpiRhandbook pages on the basics of installing packages and running R from network drives (company computers) for more detail."
  },
  {
    "objectID": "pages/instructions.html#disclaimer",
    "href": "pages/instructions.html#disclaimer",
    "title": "How-to Guide",
    "section": "Disclaimer",
    "text": "Disclaimer\nAll case studies are based on real or plausible scenarios. Some will use simulated data, while others will feature open-access or provided de-identified data. The type of data used will be clearly indicated at the start of each case study."
  },
  {
    "objectID": "pages/instructions.html#licenses",
    "href": "pages/instructions.html#licenses",
    "title": "How-to Guide",
    "section": "Licenses",
    "text": "Licenses\nCase studies will be managed according to their original licenses, which you’ll be able to find at the bottom of each case study page. If you have any questions, send us an email at contact@appliedepi.org."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Epi cases studies",
    "section": "",
    "text": "Here, you can practice technical and analytical skills using real-life scenarios. The case studies, contributed by FETPs and health ministries worldwide, feature data that is either generated or anonymized for training purposes.\nFind a case study of interest with the table below, and click on the link to open it in the appropriate language for you."
  },
  {
    "objectID": "index.html#welcome-to-our-case-study-repository",
    "href": "index.html#welcome-to-our-case-study-repository",
    "title": "Applied Epi cases studies",
    "section": "",
    "text": "Here, you can practice technical and analytical skills using real-life scenarios. The case studies, contributed by FETPs and health ministries worldwide, feature data that is either generated or anonymized for training purposes.\nFind a case study of interest with the table below, and click on the link to open it in the appropriate language for you."
  },
  {
    "objectID": "index.html#about-us",
    "href": "index.html#about-us",
    "title": "Applied Epi cases studies",
    "section": "About us",
    "text": "About us\nApplied Epi is a nonprofit organisation and grassroots movement of frontline epis from around the world. We write in our spare time to offer this resource to the community. Your encouragement and feedback is most welcome:\n\nVisit our website and join our contact list\ncontact@appliedepi.org, tweet @appliedepi, or LinkedIn\nSubmit issues to our Github repository"
  },
  {
    "objectID": "pages/fulton.html",
    "href": "pages/fulton.html",
    "title": "Fulton (EN)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\nName\nFulton County\n\n\nLanguage\nEnglish\n\n\nTool\nR\n\n\nLocation\nUnited States\n\n\nScale\nLocal\n\n\nDiseases\nCOVID-19\n\n\nKeywords\nCOVID-19; SARS-COV-2; Outbreak\n\n\nTechnical complexity\nIntermediate\n\n\nMethodological complexity\nBasic\n\n\n\nAuthorship\nOriginal authors: Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer\nData source: Anonymised and jittered data provided by Fulton County for training purposes\nAdapted by: Alberto Mateo Urdiales to the case study template\n\n\n\n\n\n\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\nHere is what the “helpers” look like:\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\n\n… description here about posting in Community…\n\n\n\nXXXXXXXXXXXXXXXXXXXXX\n\n\n\n\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\n\nThe first version was written by Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer in August 2021.\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nMar 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is a an example R-markdown script which demonstrates how to create an automated outbreak situation report for COVID-19 in Fulton county, USA. The data used comes from an anonymised and fake (scrambled) linelist of COVID-19 cases in Fulton county from the beginning of the pandemic (early 2020) until July 2021.\nThe overall objective is to create an automatic and dynamic report that shows the COVID-19 epidemiological situation in Fulton County.\nIn this case study you will learn:\n\nHow to import, clean and analyse your data.\n\nCarry out descrptive analysis by time, place and person.\n\nUse the above to create an automatic and dynamic report in word using Rmarkdown.\n\n\nFor the purpose of the case study we separate this by descriptive analysis and visualisation (normally this would be mixed together of course). The visualisation section is organised in to place, time and person. This is to simplify flow for didactic delivery.\nAnalysis is loosely based off the monthly epidemiology reports for Fulton county\n\n\n\n\nUsers should have some prior experience with R, including:\n\nR basics: Several packages are required for different aspects of analysis with R. You will need to install these before starting. We install and load packages using the {pacman} package. Its p_load() command will install packages if necessary and load them for use in the current session. This might prove difficult if you have limited administrative rights for your computer. Making sure your IT-department gives you the correct access can save a lot of headache. See this handbook pages on the basics of installing packages and running R from network drives (company computers) for more detail. https://epirhandbook.com/r-basics.html#installation https://epirhandbook.com/r-on-network-drives.html#r-on-network-drives\nR projects: See Chapter 6 R Projects from the EpiRhandbook\nImport and export of data: See Chapter7 Import and export\n\n\n\n\n\nDownload folder fulton_en and extract contents in the local laptop\nOpen the Rstudio project inside the folder called fulton_en.Rproj\nInside the folder you can find the Rmd and the word output (weekly report). You can also find a word template that will be used as the template for the report. The Rmd and the output are there to help you if you struggle, but you should try to recreate these yourself following this case study.\nSubfolder data contains fulton COVID-19 data needed for the analysis\nSubfolder solution_materials has a copy of the Rmd document with the solution and a copy Word document with the output requested\nOpen a new Rmarkdown file in RStudio and save it in the root folder fulton_en. If you have any doubts about how to create an Rmarkdown follow the EpiRhandbook instructors here\nThis Rmarkdown file will be the file used throughout the case study and, rendering it will produce the weekly report in word format"
  },
  {
    "objectID": "pages/fulton.html#overview",
    "href": "pages/fulton.html#overview",
    "title": "Fulton (EN)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\nName\nFulton County\n\n\nLanguage\nEnglish\n\n\nTool\nR\n\n\nLocation\nUnited States\n\n\nScale\nLocal\n\n\nDiseases\nCOVID-19\n\n\nKeywords\nCOVID-19; SARS-COV-2; Outbreak\n\n\nTechnical complexity\nIntermediate\n\n\nMethodological complexity\nBasic\n\n\n\nAuthorship\nOriginal authors: Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer\nData source: Anonymised and jittered data provided by Fulton County for training purposes\nAdapted by: Alberto Mateo Urdiales to the case study template"
  },
  {
    "objectID": "pages/fulton.html#instructions",
    "href": "pages/fulton.html#instructions",
    "title": "Fulton (EN)",
    "section": "",
    "text": "There are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\nHere is what the “helpers” look like:\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\n\n… description here about posting in Community…\n\n\n\nXXXXXXXXXXXXXXXXXXXXX\n\n\n\n\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\n\nThe first version was written by Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer in August 2021.\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nMar 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is a an example R-markdown script which demonstrates how to create an automated outbreak situation report for COVID-19 in Fulton county, USA. The data used comes from an anonymised and fake (scrambled) linelist of COVID-19 cases in Fulton county from the beginning of the pandemic (early 2020) until July 2021.\nThe overall objective is to create an automatic and dynamic report that shows the COVID-19 epidemiological situation in Fulton County.\nIn this case study you will learn:\n\nHow to import, clean and analyse your data.\n\nCarry out descrptive analysis by time, place and person.\n\nUse the above to create an automatic and dynamic report in word using Rmarkdown.\n\n\nFor the purpose of the case study we separate this by descriptive analysis and visualisation (normally this would be mixed together of course). The visualisation section is organised in to place, time and person. This is to simplify flow for didactic delivery.\nAnalysis is loosely based off the monthly epidemiology reports for Fulton county\n\n\n\n\nUsers should have some prior experience with R, including:\n\nR basics: Several packages are required for different aspects of analysis with R. You will need to install these before starting. We install and load packages using the {pacman} package. Its p_load() command will install packages if necessary and load them for use in the current session. This might prove difficult if you have limited administrative rights for your computer. Making sure your IT-department gives you the correct access can save a lot of headache. See this handbook pages on the basics of installing packages and running R from network drives (company computers) for more detail. https://epirhandbook.com/r-basics.html#installation https://epirhandbook.com/r-on-network-drives.html#r-on-network-drives\nR projects: See Chapter 6 R Projects from the EpiRhandbook\nImport and export of data: See Chapter7 Import and export\n\n\n\n\n\nDownload folder fulton_en and extract contents in the local laptop\nOpen the Rstudio project inside the folder called fulton_en.Rproj\nInside the folder you can find the Rmd and the word output (weekly report). You can also find a word template that will be used as the template for the report. The Rmd and the output are there to help you if you struggle, but you should try to recreate these yourself following this case study.\nSubfolder data contains fulton COVID-19 data needed for the analysis\nSubfolder solution_materials has a copy of the Rmd document with the solution and a copy Word document with the output requested\nOpen a new Rmarkdown file in RStudio and save it in the root folder fulton_en. If you have any doubts about how to create an Rmarkdown follow the EpiRhandbook instructors here\nThis Rmarkdown file will be the file used throughout the case study and, rendering it will produce the weekly report in word format"
  },
  {
    "objectID": "pages/fulton.html#step-1-rmarkdown-set-up",
    "href": "pages/fulton.html#step-1-rmarkdown-set-up",
    "title": "Fulton (EN)",
    "section": "Step 1: Rmarkdown set up",
    "text": "Step 1: Rmarkdown set up\nRemember that this case study is created in Rmarkdown and that code goes within “chunks”, which is different from a standard R script. The first steps will be to define the language in which you want the report, the default chunk options and to install/load the necessary packages.\n\nStep 1.1: Define R language\nDepending on where you are and how to carried out R installation, your language “locale” might be different from the language of the report that you want to produce. For example, a french person might have a french “locale”. If that is the case, when creating a graph by day of the week, Monday will be displayed as “lundi”. If that french person wants to create an English report, as for this case study, the language “locale” should be changed.\nTask: Ensure your “locale” is in English and change it into English if it is not.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# To see your language locale\nSys.getlocale()\n\n# To change it into English\nSys.setlocale(\"LC_ALL\", \"English\")\n\n\n\n\n\nStep 1.2: Default chunk options\nChange the default chunk options of your Rmarkdown script to:\n\nhide all code chunks in the report\ndo not show messages or warnings\nshow errors if they appear, but to not stop the rendering\nset up the default figure width to 7 and the figure height to 6\nto show the figure titles on top of the plots by default\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# hide all code chunks in the output, but show errors \nknitr::opts_chunk$set(echo = FALSE,  # hide all code chunks in output\n                      error = TRUE,  # show errors if they appear, but don't stop (produce the word doc)\n                      warning = FALSE, # do not show warnings in the output word doc \n                      message = FALSE, # do not show  messages in the output word doc\n                      fig.width = 7,         # Figure width\n                      fig.height = 6,        # Figure height\n                      fig.topcaption = TRUE  # show figure titles on top of plot\n                     )\n\n\n\n\n\nStep 1.3: Install/load packages\nInstall the following packages that will be needed to carry out the analysis: officedown, officer, rio, here, skimr, janitor, lubridate, epikit, tidyverse, flextable, sf, scales, gtsummary, labelled, ggspatial, patchwork, apyramid and incidence2.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  officedown, # format MS word document output\n  officer,    # add table of contents to output\n  rio,        # importing data  \n  here,       # relative file pathways \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # age_categories() function\n  flextable,  # converting tables to pretty images\n  sf,         # manage spatial data using a Simple Feature format\n  scales,     # define colour schemes for flextables \n  gtsummary,  # summary statistics, tests and regressions \n  labelled,   # create variable labels to be displayed in table outputs\n  ggspatial,  # basemaps and scalebars \n  patchwork,  # combining multiple ggplots \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n\n)"
  },
  {
    "objectID": "pages/fulton.html#step-2-data-import-and-exploration",
    "href": "pages/fulton.html#step-2-data-import-and-exploration",
    "title": "Fulton (EN)",
    "section": "Step 2: Data import and exploration",
    "text": "Step 2: Data import and exploration\n\nStep 2.1: Data import\n\nImport the COVID-19 linelist called covid_example_data.xlsx that can be found in the following path: data/covid_example_data/.\nImport also the csv files named fulton_population.csv found in data/covid_example_data needed to retrieve the population in Fulton County.\n\n\n\nClick to see a solution code (try it yourself first!)\n\n\n\nlinelist_raw &lt;- rio::import(\n  file = here::here(\"data\", \"covid_example_data\", \"covid_example_data.xlsx\"),\n  which = \"in\"\n)\n\n# import population data by zipcode to calculate incidence\npop &lt;- import(\n     here(\"data\", \"covid_example_data\", \"fulton_population.csv\")\n)\n\n\n\n\n\nStep 2.2: Data exploration\nExplore the linelist to understand better the data.\n\nQuestion 2.1: How many rows are present in linelist_raw?\n\n 48 31 82101 5\n\nQuestion 2.2: How many columns are of class numeric?\n\n 8 4 19 31\n\n\n\n\nClick to see a solution code (try it yourself first!)\n\n\n\n# view your whole dataset interactively (in an excel style format)\nView(linelist_raw)\n\n# get mean, median and max values of numeric variables; counts for categorical variables and NAs with summary\nsummary(linelist_raw)\n\n# get information about each variable in a dataset \nskim(linelist_raw)\n\n# view unique values contained in variables - useful for categorical variables\nunique(linelist_raw$case_gender)"
  },
  {
    "objectID": "pages/fulton.html#step-3-data-cleaning",
    "href": "pages/fulton.html#step-3-data-cleaning",
    "title": "Fulton (EN)",
    "section": "Step 3: Data cleaning",
    "text": "Step 3: Data cleaning\n\nStep 3.1: Create date objects\nCreate an object called surveillance_date defined as 7 days prior to the reporting date (30 June 2021). Then, create another object rounding it to the closest Wednesday. Create two daily sequences of dates, one as the 14 days prior to the surveillance_date and another as 14-28 days prior to the same date. We will use these throughout the case study\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# create a date object for the surveillance\n# Minus 7 days from the date of report (see YAML) to account for lag in reporting lab results\nsurveillance_date &lt;- as.Date(\"2021-06-30\") - 7\n\n# create an epiweek object from the date \n# floor_date() rounds down to the closest week here\nsurveillance_week &lt;- floor_date(surveillance_date,\n                          # round by weeks\n                          unit = \"week\", \n                          # define week to start on Wednesday\n                          week_start = 3)\n\n# define recent (past 14 days) and previous (28 to 14 days prior)\nrecent_period   &lt;- seq(surveillance_week  - 13, surveillance_week, by = 1)\nprevious_period &lt;- seq(surveillance_week  - 27, surveillance_week - 14, by = 1)\n\n# define a text label of date range for the recent period (for table headers)\nrecent_period_labels &lt;- str_glue(\n  format(min(recent_period), format = \"%m/%d\"), \n  \"-\", \n  format(max(recent_period), format = \"%m/%d\")\n)\n\n# define text label of date range for previous period (for table headers) \nprevious_period_labels &lt;- str_glue(\n  format(min(previous_period), format = \"%m/%d\"), \n  \"-\", \n  format(max(previous_period), format = \"%m/%d\")\n)\n\n\n# define a label for past 28 days (for table captions)\nfull_period_labels &lt;- str_glue(\n  format(min(previous_period), format = \"%B %d\"), \n  \"-\", \n  format(surveillance_week, format = \"%B %d, %Y\")\n)\n\n\n\n\n\nStep 3.2: Clean column names\nClean the column names ensuring that names do not contain special characters. Rename the following columns from the raw data:\n\nDate of report (reprt_creationdt_FALSE) to date_report\nDate of birth (case_dob_FALSE) to date_dob\nDate of symptom onset (sym_startdt_FALSE) to date_onset\nDate of positive testing (pos_sampledt_FALSE) to date_positive\nDate of recovery (sym_resolveddt_FALSE) to date_recovery\nDate of hospitalisation (hosp_admidt_FALSE) to date_hospitalized\nDate of discharge (hosp_dischdt_FALSE) to date_discharge\nDate of death (died_dt_FALSE) to date_died\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist_raw %&gt;% \n     clean_names() %&gt;% \n     # NEW name = OLD name\n  rename( \n    date_report         = reprt_creationdt_false,      \n    date_dob            = case_dob_false,              \n    date_onset          = sym_startdt_false,\n    date_recovery       = sym_resolveddt_false, \n    date_hospitalized   = hosp_admidt_false,\n    date_discharge      = hosp_dischdt_false,\n    date_died           = died_dt_false,\n    date_positive       = pos_sampledt_false\n    )\n\n\n\n\n\nStep 3.3: Remove duplicated rows\nRemove rows that have duplicated information on: patient id, gender and date of birth. Keep duplicates in a separate dataframe.\n\n\n Click to read a hint\n\n\nTo store duplicates in a new dataframe you can use the function get_dupes() from the {janitor} package\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# get a data frame of all the duplicates. This is mostly to inspect manually, but can be used for analysing those dropped\nduplicates &lt;- linelist %&gt;% \n     get_dupes(pid, case_gender, date_dob)\n\n# find duplicates based on unique ID, gender and date of birth. Only keep the first occurrence \nlinelist &lt;- linelist %&gt;% \n  distinct(pid, case_gender, date_dob, .keep_all = TRUE)\n\n\n\n\nQuestion 3.2: How many duplicated rows were present in the raw data?\n\n 28 31 38 124\n\n\n\n\nStep 3.4: Change column class and remove data inconsistencies\nUsing the across() function from {dplyr} make the following:\n\nEnsure that dates are considered dates by R\nClean date columns dealing with values that are not compatible with the period under analysis (early 2020 to July 2021)\nMake the column age of numeric class\nSet us NA those with negative ages and missing Date of birth\nMake the zip code column a factor class column\n\n\n\n Click to read a hint\n\n\nThe across() allows to apply the same modification to multiple columns in an easy way. So, these two options are equivalent:\n\n# Without across()\n\nlinelist &lt;- linelist %&gt;% \n  mutate(date_report = as.Date(date_report)) %&gt;% \n  mutate(date_dob = as.Date(date_dob)) %&gt;% \n  mutate(date_onset = as.Date(date_onset)) %&gt;% \n  mutate(date_hospitalized = as.Date(date_hospitalized)) %&gt;% \n  mutate(date_discharge = as.Date(date_discharge)) %&gt;% \n  mutate(date_died = as.Date(date_died)) %&gt;% \n  mutate(date_positive = as.Date(date_positive))\n\n\n# With across()\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = contains(\"date\"), .fns = ~as.Date(.x)))\n\nYou can read more about across() in the EpiRhandbook section\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(\n    .cols = contains(\"date\"),\n    .fns = ~as.Date(.x)\n  )) %&gt;%\n  \n  # mark as missing onset dates prior to 2020\n  mutate(across(\n    .cols = c(date_report, date_onset, date_hospitalized, date_discharge, date_died),\n    .fns  = ~replace(.x, .x &lt; as.Date(\"2020-01-01\"), NA)\n    )) %&gt;% \n\n  # mark as missing dates after the surveillance_date (for this report) from all date columns\n  mutate(across(\n    .cols = contains(\"date\"),\n    .fns  =  ~replace(.x, .x &gt; surveillance_date, NA)\n    )) %&gt;%\n     \n  # transform age into numeric class\n  mutate(\n    # ensure that age is a numeric variable\n    case_age = as.numeric(case_age),\n    # set those with negative ages and missing DOB to missing \n    # otherwise just leave the age value as is\n          # nb. NA_real_ just ensures the variable class is not changed\n    case_age = if_else(case_age &lt; 0 & is.na(date_dob), NA_real_, case_age)\n  ) %&gt;% \n     \n  # create a factor from a default numeric class\n  mutate(case_zip = as_factor(case_zip)) \n\n\n\n\nQuestion 3.3: Which one of the following could NOT be used to transform the column sym_startdt_FALSE from the raw data frame into a date object?\n\n base::as.Date() lubridate::as_date() lubridate::ymd() lubridate::dmy()\n\n\n\n\nStep 3.5: Create a column for weeks\nCreate a column named “epiweek” using the function floor_date() from the {lubridate} package rounding the report date to the nearest week, taking “Wednesday” as the start of the week.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n  # create an \"epiweek\" column from the report date. Use floor_date() to round down to the closest week\n  mutate(epiweek = floor_date(date_report,\n                          # round by weeks\n                          unit = \"week\", \n                          # define week to start on Wednesday\n                          week_start = 3)\n  )\n\n\n\n\n\nStep 3.6: Create time difference columns\nIn this step we ask you to create columns with various time differences that will be used later on in the case study. Please, try to create:\n\nA column with the number (numeric) of days from date of symptom onset to the date of hospitalization\nIn this new column, set as missing those cases where the difference is longer than 30 days (interval is too long for the hospitalization to be due to the infection), and those less than 0 (cannot be hospitalized before the symptom onset)\nUsing the function coalesce() from {dplyr} create a new column for the date of outcome among hospitalized cases, using date of death or date of discharge, depending on whether cases died or not\nCreate a new column with the length of hospitalization in days, calculated as the time difference between date of hospitalization and the recently created date of outcome.\nIn this newly created column mark as missing cases in which the difference between the date of hospitalization and the date of death/discharge was longer than 60 days or lower than 0 days\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;%\n     \n  # delay from onset to hospitalization\n  mutate(\n    # calculate time differences\n    days_onset_hosp = as.numeric(date_hospitalized - date_onset),\n    # set those under 0 or over 30 to missing\n    days_onset_hosp = replace(days_onset_hosp, days_onset_hosp &lt; 0, NA),\n    days_onset_hosp = replace(days_onset_hosp, days_onset_hosp &gt; 30, NA)\n  ) %&gt;%\n     \n  # length of hospitalization\n  mutate(\n    # create outcome date based on whether died or was discharged\n    date_outcome = coalesce(date_died, date_discharge),\n    # calculate time difference\n    days_hosp = as.numeric(date_outcome - date_hospitalized),\n    # set those under 0 or over 60 to missing\n    days_hosp = replace(days_hosp, days_hosp &lt; 0, NA),\n    days_hosp = replace(days_hosp, days_hosp &gt; 60, NA)\n  )\n\n\n\n\n\nStep 3.7: Create age groups\nCreate a column with 10 year age groups up until 70 (and 70+ afterwards) using the age_group() function from the package {epikit}. You can also use any other alternative\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;%\n     # create age group variable\n     mutate(\n       age_group = age_categories(case_age,\n        # define break points\n        c(0, 10, 20, 30, 40, 50, 60, 70),\n        # whether last break should be highest category\n        ceiling = FALSE\n     ))\n\n\n\n\n\nStep 3.8: Recode character/categorical columns\nRecode the following columns:\n\nIn the column named died_covid recode the category “Under Review” to “Unknown”\nIn the column named confirmed_case recode the category “Pending” to “Unknown”\nForce categorical columns to use consistent cases\nAcross character/factor columns recode the category “Unk” to “Unknown”\nAcross the different character/factor columns recode NA to “Unknown”\nIn the column named sym_resolved recode categories into “Yes”, “No” or “Unknown”\nTransform the gender column into a factor with these levels: “Female”, “Male” and “Unknown”\nTransform all columns that have the categories: “Yes”, “No” and “Unknown” into factors with the order of the levels as “Yes”, “No” and “Unknown”\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n     \n     # recode one value and leave the rest as they are \n     mutate(\n       died_covid = if_else(died_covid == \"Under Review\",\n                            \"Unknown\", died_covid), \n       confirmed_case = if_else(confirmed_case == \"Pending\", \n                                \"Unknown\", confirmed_case), \n     \n        # force categorical variables to use consistent cases (this can be done for others) \n        sym_myalgia = str_to_title(sym_myalgia),\n      ) %&gt;% \n     \n     #replace one value and leave the rest, across multiple variables\n      mutate(across(\n       .cols = c(contact_household, contains(\"sym_\")),\n       .fns  = ~if_else(.x == \"Unk\", \"Unknown\", .x)\n     )) %&gt;% \n     \n        # replace missing with \"Unknown\" where relevant \n     mutate(across(\n       .cols = c(case_gender, case_race, case_eth, case_zip,\n                 contact_id, contact_household, \n                 hospitalized, died, died_covid, confirmed_case,\n                 contains(\"sym_\"), age_group),\n       .fns  = ~fct_na_value_to_level(.x, level = \"Unknown\")\n     )) %&gt;% \n     \n          # recode with searching for string patterns \n     mutate(sym_resolved = case_when(\n          str_detect(sym_resolved, \"Yes\")     ~ \"Yes\", \n          str_detect(sym_resolved, \"No\")      ~ \"No\", \n          str_detect(sym_resolved, \"Unknown\") ~ \"Unknown\", \n          TRUE                                ~ \"Unknown\"\n     )) %&gt;% \n     \n      # set levels of a factor (define order)\n     mutate(case_gender      = fct_relevel(case_gender, \"Female\", \"Male\", \"Unknown\")) %&gt;% \n     \n          # set levels of all factors that are yes/no/unknown \n     mutate(across(\n          .cols = c(contact_household, hospitalized, died, died_covid,\n                    confirmed_case, contains(\"sym_\")), \n          .fns = ~fct_relevel(.x, \"Yes\", \"No\", \"Unknown\")\n     )) \n\n\n\n\n\nStep 3.9: Merge ethnicity and race\nThe linelist contains a column for ethnicity (case_eth) and a column for race (case_race). Create a new column merging information from these two existing columns. The new column should:\n\nContain a category “Hispanic, all races” when case_eth is “HISPANIC/LATINO”. For those cases where this condition is not met:\n\nShould have a category for those whose race is “Asian”, another for those whose race is “Black” and another for those whose race is “White”.\nCreate an “Other” category for the rest of races and an “Unknown” category for those with missing race\nEnsure all categories have consistent cases\n\nTransform the newly formed column into a factor with the “Unknown” category as the last level\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n          # create a composite category from race and ethnicitiy  \n     mutate(eth_race = case_when(\n          eth  == \"HISPANIC/LATINO\"                           ~ \"Hispanic, all races\", \n          race == \"ASIAN\"                                     ~ \"Asian, NH\", \n          race == \"BLACK\"                                     ~ \"Black, NH\",\n          race == \"WHITE\"                                     ~ \"White, NH\",\n      # find all instances of NATIVE (covers AMERICAN INDIAN/ALASKA NATIVE **AND** NATIVE HAWAIIAN/PACIFIC ISLANDER)\n          str_detect(race, \"NATIVE\")                          ~ \"Other, NH\",\n          race == \"OTHER\"                                     ~ \"Other, NH\", \n          TRUE                                                ~ \"Unknown\"\n     )) %&gt;% \n     mutate(eth_race = factor(eth_race, levels=c(\n          \"Black, NH\", \"White, NH\", \"Hispanic, all races\",\n          \"Asian, NH\", \"Other, NH\", \"Unknown\"\n     )))\n\n\n\n\nQuestion 3.4: A column that has ordinal data, what class should it have?\n\n logical character factor integer\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n\n\nStep 3.10: Filter data frame\nFilter the data to keep only confirmed cases whose date of report is not above the date of the report (June 30, 2021). Consider also keeping records with missing date of report.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n##############       FILTER     ##############        \n\n# store those which do not meet our filter criteria \ndropped &lt;- linelist %&gt;% \n     filter(confirmed_case != \"Yes\" |\n              date_report &gt; surveillance_date & \n                !is.na(date_report))\n\n\n# drop the cases that dont meet the criteria \nlinelist &lt;- linelist %&gt;% \n     filter(confirmed_case == \"Yes\" & \n              date_report &lt;= surveillance_date & \n                 !is.na(date_report))"
  },
  {
    "objectID": "pages/fulton.html#step-4-start-the-report-with-a-summary-of-the-findings",
    "href": "pages/fulton.html#step-4-start-the-report-with-a-summary-of-the-findings",
    "title": "Fulton (EN)",
    "section": "Step 4: Start the report with a summary of the findings",
    "text": "Step 4: Start the report with a summary of the findings\n\nWrite in rmarkdown three bullet points summarising the data we imported, showing the number of cases by the date of analysis, the number of hospitalisations and the number of deaths.\nWrite it in a dynamic way, so that the dates and numbers are updated automatically if you get a new updated dataset\n\n\n\nClick to see a solution (try it yourself first!)\n\n This is an example of how the code should look like in your rmarkdown file:"
  },
  {
    "objectID": "pages/fulton.html#step-5.-analysis-by-time",
    "href": "pages/fulton.html#step-5.-analysis-by-time",
    "title": "Fulton (EN)",
    "section": "Step 5. Analysis by time",
    "text": "Step 5. Analysis by time\n\nStep 5.1: Table weekly number of cases\nCreate a table with the number of cases per reporting week to see how the epidemic evolved by time in Fulton County\n\nQuestion 5.1: During which week do we observe the peak in cases by date of reporting?\n\n The week starting on March 02, 2021 The week starting on December 16, 2020 The week starting on January 13, 2021 The week starting on December 30, 2020\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# save a quick descriptive table of number of cases reported by week\nepiweek_table &lt;- linelist %&gt;% \n  # get counts and percentages \n  tabyl(epiweek) %&gt;% \n  # add the overall counts as a row\n  adorn_totals() %&gt;%  \n  # change from proportions to percentages (do not add a % sign)\n  adorn_pct_formatting(affix_sign = FALSE) \n\n# transform it into flextable for better visualisation\nepiweek_flextable &lt;- epiweek_table %&gt;% \n     qflextable()\n\n\n\n\n\nStep 5.2: Epicurve\nCreate an epicurve by reporting week, with the colour of the bins based on whether the cases were hospitalised or not\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n     # we first define the dataset to be used, the x axis which will be reporting week and the colour (fill) of the bins which will depend on hospitalisation outcome\nggplot(\n     data = linelist,\n     mapping = aes(\n          x = epiweek,\n          fill = hospitalized\n     )) + \n     \n     geom_histogram() + \n     \n     # we define that we want breaks by month and formated with scales::label_date_short()\n     scale_x_date(\n          date_breaks = \"month\",\n          labels = label_date_short()\n     ) +\n     \n     # we change the name of the different elements of the graph\n     labs(\n          x = \"\",\n          y = \"Weekly number of cases\",\n          fill = \"Hospitalised\",\n          caption = paste0(\"Data as of \", format(surveillance_date, \"%d %b %Y\"))\n          \n     ) + \n     \n     # we apply one of the predefined themes\n     theme_bw()"
  },
  {
    "objectID": "pages/fulton.html#step-6.-analysis-by-person",
    "href": "pages/fulton.html#step-6.-analysis-by-person",
    "title": "Fulton (EN)",
    "section": "Step 6. Analysis by person",
    "text": "Step 6. Analysis by person\n\nStep 6.1: Table with demographic information\nCreate a table summarising, with counts and percentages, the total cumulative number of cases and deaths, as well the cases and deaths notified in the last 28 days by demographic characteristics: sex, age and race.\n\nQuestion 6.1: In which age group do we observe the largest proportion of cumulative cases?\n\n 0-9 30-39 20-29 70+\n\nQuestion 6.2: In which race do we observe the largest proportion of deaths in the last 28 days?\n\n Black White Asian Hispanic\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# get counts tables for measures of interest \n############################################\n\n# we generate 3 summary tables and bind them together\n# summary demographic table for gender\ndem_gender &lt;- linelist %&gt;% \n  tabyl(gender) %&gt;% \n  select(Characteristic = gender, n, percent)\n\n# summary demographic table for age\ndem_age &lt;- linelist %&gt;% \n  tabyl(age_group) %&gt;% \n  select(Characteristic = age_group, n, percent)\n\n# summary demographic table for ethnicity and race\ndem_eth_race &lt;- linelist %&gt;% \n  tabyl(eth_race) %&gt;% \n  select(Characteristic = eth_race, n, percent)\n\n# bind all tables together\ntotal_cases &lt;- bind_rows(list(dem_gender, dem_age, dem_eth_race))\n\n# counts of new cases (last 28 days) \nrecent_cases &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter the linelist for dates on or after 28 days ago\n  .f = ~filter(linelist, \n          date_report &gt;= (surveillance_date - 28)) %&gt;% \n        # get counts based on filtered data\n        tabyl(.x) %&gt;% \n        # nb we dont keep the characteristic column because it would be duplicated\n        select(n_cases_recent = n,\n               perc_cases_recent = percent)\n  ) %&gt;%\n  bind_rows()\n\n# counts of total deaths \ntotal_deaths &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter for those who died \n  .f = ~filter(linelist, \n          died_covid == \"Yes\") %&gt;% \n        # get counts based on filtered data \n        tabyl(.x, show_na = TRUE) %&gt;%\n        select(n_deaths_total = n, perc_deaths_total = percent)\n  ) %&gt;% \n  bind_rows()\n\n# counts of new deaths (last 28 days)\nrecent_deaths &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter to those who died in the last 28 days\n  .f = ~filter(linelist, \n          died_covid == \"Yes\" & \n          date_died &gt;= (surveillance_date - 28)) %&gt;% \n        # get counts based on filtered data\n        tabyl(.x) %&gt;% \n        select(n_deaths_recent = n, perc_deaths_recent = percent) %&gt;% \n        # add in a variable column (used for colouring later) \n        mutate(variable = .x)\n  ) %&gt;% \n  bind_rows()\n\n\n# total counts for all of the above measures (not by demographic)\noverall &lt;- linelist %&gt;% \n  summarise(\n    # add in row label \n    Characteristic = \"Total\",\n    # counts of total cases \n    n_cases_total = n(),\n    # leave all percentages empty (would just be 100)\n    perc_cases_total  = NA, \n    # counts of new cases (last 28 days) \n    n_cases_recent = sum(date_report &gt;= (surveillance_date - 28)), \n    perc_cases_recent  = NA, \n    # counts of total deaths \n    n_deaths_total = sum(died_covid == \"Yes\"), \n    perc_deaths_total = NA, \n    # counts of new deaths (last 28 days)\n    n_deaths_recent = sum(died_covid == \"Yes\" & \n                          date_died &gt;= (surveillance_date - 28)),\n    perc_deaths_recent = NA, \n    # add in a variable column (used for colouring later) \n    variable = \"Overall\"\n  )\n\n\n# merge tables together \n#######################\n\n# combine all the demographic tables - side by side\ndemographics_counts &lt;- bind_cols(total_cases, recent_cases, total_deaths, recent_deaths) %&gt;% \n  # mutate each of the proportion columns to be percentages\n  mutate(across(\n    .cols = contains(\"perc\"),\n    .fns = ~round(.x * 100, digits = 1)\n    )) \n# add in the totals row at the top of the merged demographics table\ndemographics_counts &lt;- bind_rows(overall, demographics_counts)\n\n\n# define colour scheme \n######################\n\n# get the column numbers that are percentages (based on the name) \npercentage_cols &lt;- names(demographics_counts) %&gt;% \n  str_detect(\"perc\") %&gt;% \n  which()\n\n# define colour cut-offs for gender column \ngender_colours &lt;- scales::col_bin(\n  # choose colours \n  palette = c(\"#91CF60\", \"#FC8D59\"), \n  # choose min and max (range)\n  domain  = c(0, 100),\n  # choose how to split (in this case above and below 50)\n  bins    = 2\n)\n\n# define colour cut-offs for age column \nage_colours &lt;- scales::col_bin(\n  # choose colours\n  palette = c(\"#91CF60\",\"#FFFFBF\", \"#FC8D59\"),\n  # choose min and max (range)\n  domain  = c(0, 100), \n  # choose cut-off categories \n  bins    = c(0, 5, 20, 100)\n)\n\n# define colour cut-offs for ethnicity column \neth_colours &lt;- scales::col_bin(\n  palette = c(\"#91CF60\",\"#FFFFBF\", \"#FC8D59\"),\n  domain  = c(0, 100), \n  bins    = c(0, 10, 40, 100)\n)\n\n\n# create styled table  \n######################\n\ndemographics_counts %&gt;%\n  # initiate flextable to produce styled output table\n  flextable(\n    # retain variable column for formatting but do not display it\n    col_keys = names(demographics_counts)[-10]\n  ) %&gt;%\n  # redefine column names based on original names\n  set_header_labels(\n    \"n_cases_total\"       = \"Total Confirmed Cases\",\n    \"perc_cases_total\" = \"% of Total Cases\",\n    \"n_cases_recent\"       = \"Confirmed Cases past 28 days\",\n    \"perc_cases_recent\" = \"% of Confirmed Cases past 28 days\",\n    \"n_deaths_total\"       = \"Total Confirmed Deaths\",\n    \"perc_deaths_total\" = \"% of Total Deaths\",\n    \"n_deaths_recent\"       = \"Confirmed Deaths past 28 days\",\n    \"perc_deaths_recent\" = \"% of Confirmed Deaths past 28 days\"\n  ) %&gt;%\n  # move the header text to the centre\n  align(align = \"center\", part = \"header\") %&gt;%\n  # make header text bold\n  bold(part = \"header\") %&gt;%\n  # make the totals row bold (i.e. first row)\n  bold(i = 1, part = \"body\") %&gt;%\n  # fill in the cells\n  # choose the rows with gender counts\n  bg(i = ~variable == \"gender\",\n     # choose the columns with percentages in them\n     j = percentage_cols,\n     # fill in based on previous defined cut-offs\n     bg = gender_colours) %&gt;%\n  bg(i = ~variable == \"age_group\",\n     j = percentage_cols, bg = age_colours) %&gt;%\n  bg(i = ~variable == \"eth_race\",\n     j = percentage_cols, bg = eth_colours) %&gt;%\n  # add horizontal lines after the cells with totals and unknowns\n    # (short-cut to find row ending of each demographic variable)\n  hline(i = ~Characteristic %in% c(\"Total\", \"Unknown\")) %&gt;%\n  # add in footnotes for rows counting unknowns (reference in first column)\n  footnote(i = ~Characteristic == \"Unknown\", j = 1, part = \"body\", ref_symbols = c(\"a\"),\n           value = as_paragraph(\"Unknown includes cases not yet interviewed\")) %&gt;%\n  # add in footnote for deaths counts (ref in the header)\n  footnote(i = 1, j = c(6, 8), part = \"header\", ref_symbols = c(\"b\"),\n           value = as_paragraph(\"Deaths refer to all persons who had a positive PCR test result\n                                for Covid-19 and there is evidence that COVID-19 was the cause of\n                                death or a significant contributor to their death.\")) %&gt;%\n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\") %&gt;% \n  # decrease the fontsize in the header and body for aesthetic purposes in the document\n  fontsize(part = \"all\", size = 8)\n\n\n\n\n\nStep 6.2: Age pyramid\nCreate an age pyramid with the percentage of cases by age group and sex.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# prepare dataset\n\n# start a new dataframe (as dont want to overwrite the original)\nlinelist_2g &lt;- linelist %&gt;% \n  # update the gender and age_group columns\n  mutate(across(.cols = c(gender, age_group), \n                .fns = ~{\n                  # replace \"Unknown\" with NA\n                  .x = na_if(.x, \"Unknown\") \n                  # drop \"Unknown\" from the factor levels \n                  .x = fct_drop(.x)\n                }))\n\n# plot age pyramid \nage_pyramid(\n  data = linelist_2g,\n  age_group = \"age_group\",\n  split_by = \"gender\",\n  # Show as percentages of total cases\n  proportional = TRUE,\n  # remove guide line for mid-point\n  show_midpoint = FALSE) +\n  # set theme to basic \n  theme_minimal() +\n  # add labels \n  labs(\n    title = \"\",\n    subtitle = ,\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = \"Gender\",\n    # use str_glue to set dynamic captions \n    # {missing} is defined in the second argument below\n    caption = str_glue(\n      \"{missing} cases missing either age or gender are not shown. \\n Fictional COVID-19 data\",\n      missing = linelist_2g %&gt;%\n        filter(is.na(gender) | is.na(age_group)) %&gt;%\n        nrow()\n      )\n    )\n\n\n\n\n\nStep 6.3: Scatter plot\nCreate a scatter plot showing the relation between age and duration of hospital stay. Colour the points based on whether cases died or not.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n#################### C) SCATTER PLOT ####################\n# open a plot with the linelist data\nggplot(data = linelist) +\n  # add points \n  geom_point(\n    mapping = aes(\n      # plot age on the x and days hospitalised on the y axis \n      x = age,\n      y = days_hosp,\n      # color points by outcome\n      color = died),  \n    # all points 3x size\n    size = 3, \n    # opacity of 30% (i.e. relatively see-through)\n    alpha = 0.3) +      \n  # make the x and y axes start at the origin \n  scale_y_continuous(expand = c(0, 0)) + \n  scale_x_continuous(expand = c(0, 0)) + \n  # add in labels \n  labs(\n    x = \"Age (years)\",\n    y = \"Duration (days)\",\n    caption = \"Fulton COVID-19 data\",\n    color = \"Deceased\"\n    ) + \n     theme_bw()\n\n\n\n\n\nStep 6.4: Bar plot\nCreate a bar stacked bar plot showing the absolute number of cases by race and vital status\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# open a plot with the linelist data\nggplot(linelist) +\n  # add bars \n  geom_bar(\n    mapping = aes(\n      # plot the number of cases by ethnicity (ordered in reverse frequency)\n      x = fct_rev(fct_infreq(eth_race)),\n      # stack bars and colour by died (ordered in reverse frequency)\n      fill = fct_rev(fct_infreq(died))\n    )\n  ) +\n  # flip the x and y axes \n  coord_flip() +\n  # make the x axes start at the origin (nb axes flipped)\n  scale_y_continuous(expand = c(0, 0), \n                     # define where to label xaxis (nb axes flipped )\n                     breaks = seq(from = 0,\n                                  to = 35000,\n                                  by = 5000)) + \n  # add in labels \n  labs(\n    # set the axes titles (nb axes flipped)\n    x = \"Race and Ethnicity\",\n    y = \"Cases (n)\",\n    caption = \"Fictional COVID-19 data\",\n    fill = \"Deceased\"\n    ) + \n  # apply a defined theme\n     theme_bw()"
  },
  {
    "objectID": "pages/fulton.html#step-7.-analysis-by-place",
    "href": "pages/fulton.html#step-7.-analysis-by-place",
    "title": "Fulton (EN)",
    "section": "Step 7. Analysis by place",
    "text": "Step 7. Analysis by place\nCreate a table by zip code in which you show the incidence in the most recent 14 days period, the incidence in the previous 14 days period and the percentage change in incidence between these periods.\n\nQuestion 7.1: What is the change in incidence observed between periods in the zip code number 30337?\n\n +20% +36% -62.5% -25%\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n################### TABLE BY ZIP CODE\n\nzip_counts &lt;- linelist %&gt;% \n  group_by(zip) %&gt;% \n  # count cases in the appropriate period \n  summarise(\n    recent   = sum(date_report %in% recent_period),\n    previous = sum(date_report %in% previous_period)\n  ) %&gt;% \n  adorn_totals() %&gt;% \n  # a percentage change column and round the digits\n  mutate(\n    perc_change = round((recent - previous) / previous * 100, digits = 1)\n    )\n\n# extract population counts for each zip from the shapefile\nzip_pop &lt;- shapefile %&gt;% \n  # change to tibble (otherwise geo-data gets pulled with)\n  as_tibble() %&gt;% \n  # only keep zip code and population counts\n  select(ZipCode, Population) %&gt;% \n  # add a row with overall counts\n  adorn_totals()\n  \n# merge case counts and population counts\n# zip (or ZipCode in the shapefile) variable is the unique identifier\nzip_counts &lt;- left_join(zip_counts, \n                        zip_pop, \n                        by = c(\"zip\" = \"ZipCode\")\n                        ) %&gt;% \n  # calculate the incidence \n  mutate(across(\n      # for each period (recent and previous)\n      .cols = c(recent, previous), \n      # divide each variable by population (and round the outcome)\n      .fns = ~round(.x / Population * 10000, digits = 1), \n      # for each period create a new variable with _inc on the end\n      .names = \"{.col}_inc\"), \n    \n    # replace NAs in incidence with 0\n    across(\n      .cols = contains(\"inc\"),\n      .fns = ~replace_na(.x, 0)),\n    \n    perc_change = case_when(\n      # fix the outliers: set missing to 0 and infinity (divided by 0) to 100\n      is.na(perc_change)       ~ 0,\n      is.infinite(perc_change) ~ 100, \n      TRUE                     ~ perc_change\n    ))\n\n\n# choose colours to fill in cells  \nrow_colour &lt;- case_when(\n  # those less than zero will be green (decreasing cases)\n  zip_counts$perc_change &lt; 0 ~ \"#91CF60\", \n  # over zero red (increasing)\n  zip_counts$perc_change &gt; 0 ~ \"#FC8D59\", \n  # missing or zero orange\n  TRUE                       ~ \"#FFFFBF\")\n\n\nzip_counts %&gt;% \n  # keep the columns of interest and define order\n  select(zip, recent, recent_inc, previous, previous_inc, perc_change) %&gt;% \n  # initiate {flextable} to produce styled output table\n  flextable() %&gt;% \n  # fill in cells - choose the column and then pass our colour-scheme defined above\n  bg(j = \"perc_change\", \n     bg = row_colour\n     ) %&gt;% \n  # add in a header for labeling counts and incidence by period \n    # note the empty columns (\"\") to fit to the original table headers\n  add_header_row(\n    values = c(\"\", \n               str_c(\"Recent 14-day reporting period\\n\", recent_period_labels), \n               \"\", \n               str_c(\"Previous 14-day reporting period\\n\", previous_period_labels), \n               \"\", \n               \"Change between reporting periods\"\n               )) %&gt;% \n  # redefine column names based on original names\n    # note the different syntax to dplyr::select, here it is old_name = new_name\n  set_header_labels(\n    zip          = \"Zip Code\", \n    recent       = \"n\", \n    recent_inc   = \"Incidence\", \n    previous     = \"n\", \n    previous_inc = \"Incidence\", \n    perc_change  = \"%\"\n  ) %&gt;% \n  # combine the headers cells for the appropriate periods \n  # (i defines rows, j defines columns)\n  merge_at(i = 1, j = 2:3, part = \"header\") %&gt;% \n  merge_at(i = 1, j = 4:5, part = \"header\") %&gt;% \n  # move the header text to the centre\n  align(align = \"center\", part = \"header\") %&gt;% \n  # make header text bold \n  bold(part = \"header\") %&gt;% \n  # make the row with totals in it bold (i.e. the last row in the dataframe)\n  bold(i = nrow(zip_counts), part = \"body\") %&gt;% \n  # add in footnotes for variables (referencing the header cells)\n  footnote(j = c(3, 5), part = \"header\", ref_symbols = c(\"a\"),\n           value = as_paragraph(\"Incidence calculated as cases per 10,000 population by zip code\")) %&gt;% \n  footnote(j = 6, part = \"header\", ref_symbols = c(\"b\"),\n           value = as_paragraph(\"These reflect the percentage increase or decrease of new diagnoses \n                                between the 14 days preceding the past 7 days and the 14 days\n                                preceding that.\")) %&gt;% \n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\")"
  },
  {
    "objectID": "pages/fulton.html#step-8.-analysis-of-risk-factors-for-mortality",
    "href": "pages/fulton.html#step-8.-analysis-of-risk-factors-for-mortality",
    "title": "Fulton (EN)",
    "section": "Step 8. Analysis of risk factors for mortality",
    "text": "Step 8. Analysis of risk factors for mortality\n\nCreate a table in which you assess, with the appropriate statistical tests, whether the demographic characteristics of those dying from Covid-19 are significantly different from cases who did not die from it.\nFor each of the variables used in the table that you just created, carry out univariate regression using each demographic variable as the independent variable and the outcome (dead, not dead) as the dependent variables. Create a table with the estimates -alongside 95% CI - of the estimates.\n\n\nQuestion 8.1: According to the results of the univariate analysis, how was having a sore throat associated with mortality from Covid-19\n\n It was a risk factor for mortality It was a protective factor for mortality It was not associated with mortality Impossible to know\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# define a list of variables for looping over later\nsymptom_vars &lt;- linelist %&gt;% \n     # choose all columns that contain \"sym_\" in the name but exclude \"sym_resolved\"\n     select(c(contains(\"sym_\"), -sym_resolved)) %&gt;% \n     # pull the names out \n     names()\n\n# define variables of interest (save typing them out later) \ndescriptive_vars &lt;- c(\"gender\", \n                      \"age_group\",\n                      \"eth_race\",\n                      symptom_vars,\n                      \"hospitalized\",\n                      \"days_hosp\")\n\n# filter dataset  \nrf_data &lt;- linelist %&gt;% \n  # only keep variables of interest\n  select(died_covid, age, all_of(descriptive_vars)) %&gt;% \n  # set unknown back to NA for all factor variables\n  mutate(across(\n    .cols = where(is.factor),\n    .fns = ~fct_recode(.x, NULL = \"Unknown\"))) %&gt;% \n  # flip factor levels (so that the reference values are correct)\n  mutate(eth_race = fct_infreq(eth_race)) %&gt;% \n  mutate(gender = fct_relevel(gender, \"Female\", \"Male\")) %&gt;% \n  mutate(across(all_of(c(\"died_covid\", symptom_vars, \"hospitalized\")), \n                ~fct_relevel(.x, \"No\", \"Yes\")\n                )) %&gt;% \n  # only keep rows with complete data for all variables of interest\n  # note that this will drop rows where **ANY** of the listed variables are NA\n  drop_na(any_of(c(\"died_covid\", \"age\", descriptive_vars)))\n\n\n# define variable labels to show in output tables \nrf_data &lt;- rf_data %&gt;%\n  set_variable_labels(\n    died_covid = \"Died\",\n    age = \"Age (years)\",\n    gender = \"Gender\",\n    age_group = \"Age group (years)\",\n    eth_race = \"Ethnicity\",\n    sym_fever = \"Fever\",\n    sym_subjfever = \"Subjective fever\",\n    sym_myalgia = \"Myalgia\",\n    sym_losstastesmell = \"Loss taste/smell\",\n    sym_sorethroat = \"Sore throat\",\n    sym_cough = \"Cough\",\n    sym_headache = \"Headache\",\n    hospitalized = \"Hospitalized\",\n    days_hosp = \"Days in hospital\"\n  )\n\n\n\nrf_data %&gt;%\n  # keep variables of interest\n  select(died_covid, gender, eth_race, age, days_hosp) %&gt;%\n  # produce summary table and specify grouping variable\n  tbl_summary(\n    by = died_covid\n  ) %&gt;%\n  # specify what test to perform\n  add_p(\n    list(\n      all_continuous() ~ \"kruskal.test\",\n      eth_race ~ \"kruskal.test\",\n      all_dichotomous() ~ \"chisq.test\"\n    )\n  ) %&gt;%\n  # edit what the column headers say (using {gtsummary})\n  # nb. {n} automatically shows the number in that group and \\n is a linebreak\n  modify_header(update = list(\n    stat_1 ~ \"**Dead**\\n (N={n})\",\n    stat_2 ~ \"**Alive**\\n (N={n})\"\n  )) %&gt;%\n  # edit what it says in the footnote (using {gtsummary})\n  modify_footnote(update = list(\n    all_stat_cols() ~ \"n (%) for categorical;\\n median (IQR) for continuous\",\n    p.value ~ \"Pearson's Chi-squared test for dichotomous;\\n Kruskal-Wallis rank sum test for continuous and categorical\"\n  )) %&gt;%\n  # change to flextable format\n  as_flex_table() %&gt;%\n  # make header text bold (using {flextable})\n  bold(part = \"header\")\n\n###################### B) UNIVARIATE REGRESSION ANALYSIS ####################################\n\n\n# produce table with regression estimates\nregress_tab &lt;- rf_data %&gt;%\n  # drop variables not interested in \n  select(-age_group) %&gt;%\n  # produce univariate table\n  tbl_uvregression(\n    # define outcome variable\n    y = died_covid, \n    # define regression want to run (generalised linear model)\n    method = glm, \n    # define what type of glm want to run (logistic)\n    method.args = list(family = binomial), \n    # exponentiate to produce odds ratios (rather than log odds)\n    exponentiate = TRUE, \n    # do not show the overall counts (this is done in cross_tab below)\n    hide_n = TRUE,\n    ## uncomment this line if you want to not show reference rows\n    # show_single_row = c(symptom_vars, gender, hospitalized),\n    ## note: NULL at the end allows you to have a comma before a commented out row\n    NULL\n  )\n\n# produce table with counts by outcome (using the data fed to the regression above)\ncross_tab &lt;- regress_tab$inputs$data %&gt;%\n  tbl_summary(\n    # group by outcome \n    by = died_covid,\n    ## uncomment this line if you only want to show the \"Male\" row for gender\n    ## this would be run if you also uncommented the single_row in regression above\n    # value = list(gender ~\"Male\"),\n    ## show all levels (otherwise only shows the \"Yes\" level)\n    type = list(all_dichotomous() ~ \"categorical\"),\n    ## note: NULL at the end allows you to have a comma before a commented out row\n    NULL\n  )\n\n# combine tables \ntbl_merge(list(cross_tab, regress_tab)) %&gt;%\n  # edit what it says in the grouping headers \n  modify_spanning_header(update = list(\n    c(\"stat_1_1\",\"stat_2_1\") ~ \"Died\",\n    c(\"estimate_2\", \"ci_2\", \"p.value_2\") ~ \"Univariate regression\")\n    ) %&gt;% \n  # edit what it says in the footnote (using {gtsummary})\n  modify_footnote(update = list(\n    all_stat_cols() ~ \"n (%) for categorical;\\n median (IQR) for continuous\")\n    ) %&gt;% \n  # change to flextable format\n  as_flex_table() %&gt;%\n  # make header text bold (using {flextable})\n  bold(part = \"header\") %&gt;% \n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\")"
  },
  {
    "objectID": "pages/r_practical.html#terms-of-use",
    "href": "pages/r_practical.html#terms-of-use",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "Disclaimer: The information presented in this exercise and the associated data files have been deliberately changed so as to facilitate the acquisition of the learning objectives for fellows of EPIET, EUPHEM and EPIET-associated programmes. This case study was first introduced in 2022 (see Copyright and Licence agreement for more information).\nYou are free:\n\nto Share: to copy and distribute the work\nto Remix: to adapt and build upon the material\n\nUnder the following conditions:\n\nAttribution: You must attribute the work in the manner specified by the author or licensor (but not in any way that suggests that they endorse you or your use of the work). The best way to do this is to keep as it is the list of contributors: sources, authors and reviewers.\nShare Alike: If you alter, transform, or build upon this work, you may distribute the resulting work only under the same or similar license to this one. Your changes must be documented. Under that condition, you are allowed to add your name to the list of contributors.\nNotification: If you use the work in the manner specified by the author or licensor, Walter@rki.de\nYou cannot sell this work alone but you can use it as part of a teaching.\n\nWith the understanding that:\n\nWaiver: Any of the above conditions can be waived if you get permission from the copyright holder.\nPublic Domain: Where the work or any of its elements is in the public domain under applicable law, that status is in no way affected by the license.\nOther Rights: In no way are any of the following rights affected by the license:\n\nYour fair dealing or fair use rights, or other applicable copyright exceptions and limitations;\nThe author’s moral rights;\nRights other persons may have either in the work itself or in how the work is used, such as publicity or privacy rights.\n\nNotice: For any reuse or distribution, you must make clear to others the license terms of this work by keeping together this work and the current license.\n\nThis licence is based on http://creativecommons.org/licenses/by-sa/3.0/"
  },
  {
    "objectID": "pages/instructions.html",
    "href": "pages/instructions.html",
    "title": "How-to Guide",
    "section": "",
    "text": "Choose a case study that fits your training needs based on topic, complexity, and language—details are available on the homepage and at the top of each case study page.\nYou can complete the case study individually or in a group. If facilitating, guide the group through the sections. There’s no facilitator’s guide; all learning materials are on the case study page, including the scenario, data download, tasks, and interactive hints and solutions.\n\n\n\nAside from opening up the case study, you need to:\n\nHave the relevant program on your computer, like R or Excel.\nOrganize yourself and put any related files in a project folder.\n\nFor projects using R, see more detail in the ‘New to RStudio Projects’? section below.\n\n\n\nThere are several ways to get help:\n\nLook for the hints and solutions. They look like this:\n\n\n\n Click to read a hint\n\nHere you will see a helpful hint!\n\n\n\nClick to see the solution\n\nHere you will see the solution! It will typically be the actual code or technical answer required for the task.\n\n# Example of a solution\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\n\n\nTake a look at the EpiRHandbook\nPost a question in Applied Epi Community with reference to this case study\n\n\n\n\nWe encourage open-source material and sharing for learning purposes. However, case studies will be covered by different licenses. Check the terms of use at the bottom of each case study to see if it is suitable for modification. If you have any questions, send us an email at contact@appliedepi.org.\n\n\n\nAll case studies are based on real or plausible scenarios. Some will use simulated data, while others will feature open-access or provided de-identified data. The type of data used will be clearly indicated at the start of each case study.\n\n\n\nWe recommend that you create an RStudio Project when working R. Check out the details below.\n\n\nIf this is your first time using R and RStudio, welcome! The Epidemiologist R Handbook or EpiRhandbook has a wealth of information to support you along the way. It has everything thing you need to get started with R basics, including installing and updating R and RStudio.\nIf you are new to RStudio, it might be a good idea to spend some time reviewing that page and others before trying out any case studies. Don’t forget that we also have free self-paced R tutorials if you’d like even more guidance and practice.\n\n\n\nOnce you are ready to start your case study project itself, choose a location on your computer to create a dedicated folder. Once you’ve decided on the best spot, set up a folder with the case study’s name to keep everything organized from the start.\nIn your case study folder, you should have a:\n\nsubfolder “scripts” to save any scripts related to the analysis\nsubfolder “data” which will contain the raw data you will use\nsubfolder “outputs” can be used to store any outputs (tables, graphs, documents) that are the result of the analysis\n\nMake sure your folders and subfolders are well-organised as this will save you a headache later!\n\n\n\nCreate an Rstudio project in the case study folder. If you are unsure on how to do that, read the EpiRhandbook on RStudio projects.\n\n\n\nOnce you have created an RStudio project, start a new R script with an appropriate name (example case_study_name) and save it in the subfolder “scripts”.\nIf you are familiar with R markdown, you may decide to use this type of file instead of a standard R script. See below for more instructions on using R markdown.\nNo matter what type of file you choose to use, make sure the purpose, date last updated, and author are written as comments at the top.\n\n#Purpose: To practice new skills using this case study\n#Author: Your Name\n#Date: Mmm dd, yyyy or whatever format you like best\n\n\n\n\nSome of our case studies use R markdown and the code goes within “chunks”, which is different from a standard R script. If you want to create a reproducible workflow, you need a place to save your code so you can run it again if you need to. You want all your files easily organised so you don’t get lost later on. You need to begin by setting the default chunk options.\nTypically, you want to change the default chunk options of your R markdown script to:\n\nhide all code chunks in the report\nnot show messages or warnings in the output\nshow errors if they appear, but to not stop the rendering\nset up the default figure width to 7 and the figure height to 6\nshow the figure titles on top of the plots by default\n\n\n# hide all code chunks in the output, but show errors \nknitr::opts_chunk$set(echo = FALSE,  # hide all code chunks in output\n                      error = TRUE,  # show errors if they appear, but don't stop (produce the word doc)\n                      warning = FALSE, # do not show warnings in the output word doc \n                      message = FALSE, # do not show  messages in the output word doc\n                      fig.width = 7,         # Figure width\n                      fig.height = 6,        # Figure height\n                      fig.topcaption = TRUE  # show figure titles on top of plot\n                     )\n\nBe sure to review Reports with R Markdown in the EpiRhandbook before jumping in!\n\n\n\nDepending on where you are and how you carried out R installation, your language “locale” might be different from the language of the report that you want to produce.\nFor example, a French-speaking person might have a French ‘locale’. If that is the case, when creating a graph by day of the week, “Monday” will be displayed as “lundi”. If that person wants to create an English report, as for this case study, the language ‘locale’ should be changed.\nTo ensure your ‘locale’ is set to English, use the following code:\n\n# To see your language locale\nSys.getlocale()\n\n# To change it into English\nSys.setlocale(\"LC_ALL\", \"English\")\n\n\n\n\nAt the start of every R project, you will need to install the necessary packages. We do this with the {pacman} package. Its p_load() command will install packages if necessary and load them for use in the current session. If a listed package has already been installed, it will just load it. Each case study specifies at the beginning what packages you need to have installed.\nYou can find more about installing/loading packages in the suggested packages section of the EpiRhandbook.\nExample code to install packages:\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\nIf this step is not working, you may have limited administrative rights for your computer. Making sure your IT-department gives you the correct access can save a lot of headache. See these EpiRhandbook pages on the basics of installing packages and running R from network drives (company computers) for more detail."
  },
  {
    "objectID": "pages/instructions.html#how-should-i-use-these-case-studies",
    "href": "pages/instructions.html#how-should-i-use-these-case-studies",
    "title": "How-to Guide",
    "section": "",
    "text": "Choose a case study that fits your training needs based on topic, complexity, and language—details are available on the homepage and at the top of each case study page.\nYou can complete the case study individually or in a group. If facilitating, guide the group through the sections. There’s no facilitator’s guide; all learning materials are on the case study page, including the scenario, data download, tasks, and interactive hints and solutions."
  },
  {
    "objectID": "pages/instructions.html#what-do-i-need-to-complete-a-case-study",
    "href": "pages/instructions.html#what-do-i-need-to-complete-a-case-study",
    "title": "How-to Guide",
    "section": "",
    "text": "Aside from opening up the case study, you need to:\n\nHave the relevant program on your computer, like R or Excel.\nOrganize yourself and put any related files in a project folder.\n\nFor projects using R, see more detail in the ‘New to RStudio Projects’? section below."
  },
  {
    "objectID": "pages/instructions.html#how-can-i-get-help",
    "href": "pages/instructions.html#how-can-i-get-help",
    "title": "How-to Guide",
    "section": "",
    "text": "There are several ways to get help:\n\nLook for the hints and solutions. They look like this:\n\n\n\n Click to read a hint\n\nHere you will see a helpful hint!\n\n\n\nClick to see the solution\n\nHere you will see the solution! It will typically be the actual code or technical answer required for the task.\n\n# Example of a solution\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\n\n\nTake a look at the EpiRHandbook\nPost a question in Applied Epi Community with reference to this case study"
  },
  {
    "objectID": "pages/instructions.html#can-i-edit-this-case-study",
    "href": "pages/instructions.html#can-i-edit-this-case-study",
    "title": "How-to Guide",
    "section": "",
    "text": "We encourage open-source material and sharing for learning purposes. However, case studies will be covered by different licenses. Check the terms of use at the bottom of each case study to see if it is suitable for modification. If you have any questions, send us an email at contact@appliedepi.org."
  },
  {
    "objectID": "pages/instructions.html#where-do-the-case-studies-come-from",
    "href": "pages/instructions.html#where-do-the-case-studies-come-from",
    "title": "How-to Guide",
    "section": "",
    "text": "All case studies are based on real or plausible scenarios. Some will use simulated data, while others will feature open-access or provided de-identified data. The type of data used will be clearly indicated at the start of each case study."
  },
  {
    "objectID": "pages/instructions.html#new-to-rstudio-and-rstudio-projects",
    "href": "pages/instructions.html#new-to-rstudio-and-rstudio-projects",
    "title": "How-to Guide",
    "section": "",
    "text": "We recommend that you create an RStudio Project when working R. Check out the details below.\n\n\nIf this is your first time using R and RStudio, welcome! The Epidemiologist R Handbook or EpiRhandbook has a wealth of information to support you along the way. It has everything thing you need to get started with R basics, including installing and updating R and RStudio.\nIf you are new to RStudio, it might be a good idea to spend some time reviewing that page and others before trying out any case studies. Don’t forget that we also have free self-paced R tutorials if you’d like even more guidance and practice.\n\n\n\nOnce you are ready to start your case study project itself, choose a location on your computer to create a dedicated folder. Once you’ve decided on the best spot, set up a folder with the case study’s name to keep everything organized from the start.\nIn your case study folder, you should have a:\n\nsubfolder “scripts” to save any scripts related to the analysis\nsubfolder “data” which will contain the raw data you will use\nsubfolder “outputs” can be used to store any outputs (tables, graphs, documents) that are the result of the analysis\n\nMake sure your folders and subfolders are well-organised as this will save you a headache later!\n\n\n\nCreate an Rstudio project in the case study folder. If you are unsure on how to do that, read the EpiRhandbook on RStudio projects.\n\n\n\nOnce you have created an RStudio project, start a new R script with an appropriate name (example case_study_name) and save it in the subfolder “scripts”.\nIf you are familiar with R markdown, you may decide to use this type of file instead of a standard R script. See below for more instructions on using R markdown.\nNo matter what type of file you choose to use, make sure the purpose, date last updated, and author are written as comments at the top.\n\n#Purpose: To practice new skills using this case study\n#Author: Your Name\n#Date: Mmm dd, yyyy or whatever format you like best\n\n\n\n\nSome of our case studies use R markdown and the code goes within “chunks”, which is different from a standard R script. If you want to create a reproducible workflow, you need a place to save your code so you can run it again if you need to. You want all your files easily organised so you don’t get lost later on. You need to begin by setting the default chunk options.\nTypically, you want to change the default chunk options of your R markdown script to:\n\nhide all code chunks in the report\nnot show messages or warnings in the output\nshow errors if they appear, but to not stop the rendering\nset up the default figure width to 7 and the figure height to 6\nshow the figure titles on top of the plots by default\n\n\n# hide all code chunks in the output, but show errors \nknitr::opts_chunk$set(echo = FALSE,  # hide all code chunks in output\n                      error = TRUE,  # show errors if they appear, but don't stop (produce the word doc)\n                      warning = FALSE, # do not show warnings in the output word doc \n                      message = FALSE, # do not show  messages in the output word doc\n                      fig.width = 7,         # Figure width\n                      fig.height = 6,        # Figure height\n                      fig.topcaption = TRUE  # show figure titles on top of plot\n                     )\n\nBe sure to review Reports with R Markdown in the EpiRhandbook before jumping in!\n\n\n\nDepending on where you are and how you carried out R installation, your language “locale” might be different from the language of the report that you want to produce.\nFor example, a French-speaking person might have a French ‘locale’. If that is the case, when creating a graph by day of the week, “Monday” will be displayed as “lundi”. If that person wants to create an English report, as for this case study, the language ‘locale’ should be changed.\nTo ensure your ‘locale’ is set to English, use the following code:\n\n# To see your language locale\nSys.getlocale()\n\n# To change it into English\nSys.setlocale(\"LC_ALL\", \"English\")\n\n\n\n\nAt the start of every R project, you will need to install the necessary packages. We do this with the {pacman} package. Its p_load() command will install packages if necessary and load them for use in the current session. If a listed package has already been installed, it will just load it. Each case study specifies at the beginning what packages you need to have installed.\nYou can find more about installing/loading packages in the suggested packages section of the EpiRhandbook.\nExample code to install packages:\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\nIf this step is not working, you may have limited administrative rights for your computer. Making sure your IT-department gives you the correct access can save a lot of headache. See these EpiRhandbook pages on the basics of installing packages and running R from network drives (company computers) for more detail."
  }
]