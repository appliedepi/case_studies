[
  {
    "objectID": "pages/under_construction.fr.html",
    "href": "pages/under_construction.fr.html",
    "title": "Page en construction",
    "section": "",
    "text": "Page en construction\n\n\n\n\n\n\nEN CONSTRUCTION\n\n\n\nCette page est en cours de développement. Le contenu et l’URL vont changer.\n\n\nPour des instructions sur la façon d’utiliser nos études de cas, consultez notre How-to Guide. Nous accueillons vos retours et suggestions à l’adresse contact@appliedepi.org. Vous pouvez également discuter de l’étude de cas ou des concepts connexes sur la Applied Epi Community."
  },
  {
    "objectID": "pages/oswego.es.html",
    "href": "pages/oswego.es.html",
    "title": "Oswego (ES)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\n\n\n\nName\nOswego\n\n\nTool\nR\n\n\nLanguage\nSpanish/Español\n\n\nLocation\nUnited States\n\n\nScale\nLocal\n\n\nDiseases\nGastrointestinal\n\n\nKeywords\nGastrointestinal;Outbreak investigation\n\n\nTechnical complexity\nIntermidiate\n\n\nMethodolocial complexity\nIntermidiate\n\n\n\nAuthorship\nOriginal authors: Centre for Disease Prevention and Control (CDC)\nData source: Epi Info, version 3.5.4 (CDC)\nAdapted to R by: Leonel Lerebours Nadal y Alberto Mateo Urdiales\n\n\n\n\n\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\nHere is what the “helpers” look like:\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\n\n… description here about posting in Community… TO BE COMPLETED BY APPLIED EPI\n\n\n\nYou will see these icons throughout the exercises:\n\n\n\n\n\n\n\nIcon\nMeaning\n\n\n\n\n\nObserve\n\n\n\nAlert!\n\n\n\nAn informative note\n\n\n\nTime for you to code!\n\n\n\nChange to another window\n\n\n\nRemember this for later\n\n\n\n\n\n\n\nThis case study has been adapted from an existing tutorial on Epi Info created by the Centre for Disease Prevention and Control (CDC). Epi Info™ is a trademark of CDC. Epi Info™ programs are provided in the public domain to promote public health. Programs might be freely translated, copied, or distributed. No warranty is made or implied for use of the software for any particular purpose.\n Applied Epi Incorporated, 2022 This work is licensed by Applied Epi Incorporated under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\nPlease email contact@appliedepi.org with questions about the use of these materials for academic courses and epidemiologist training programs.\n\n\n\n\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\n\n16 November 2023\n\n\n\nEsto es un estudio de caso diseñado por el Centre for Disease Prevention and Control (CDC) como tutorial de Epi Info. Puede consultar más detalles en este Enlace\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\n\n\n\n\n16 November\nAdapted to template\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLos objetivos de este estudio de caso son:\n\nEntender los diferentes pasos en la investigación de un brote de casos de enfermedad gastrointestinal\nAdquirir confianza en el manejo de datos de un listado nominal con el software estadístico R\nAdquirir experience en el análisis descriptivo en R, particularmente curvas epidémicas\nAdquirir experience construyendo tablas 2x2 con exposición y desenlace que nos permitan calcular medidas de asociación\nAplicar los conocimientos adquiridos a posibles actividades de control y prevención de brotes infecciosos de origen alimentario\n\n\n\nEn este estudio de caso se asume un conocimiento básico de los principios fundamental de la investigación epidemiológica de brotes gastrointestinales. Se asume también un conocimiento básico de R.\n\n\n\nAntes de iniciar este estudio de caso, le aconsejamos que:\n\nDescargue en su computadora la carpeta “oswego_cs_es” y que extraiga todos sus componentes, preferibilmente en su escritorio o en un lugar de fácil acceso. Evite extraerlo en servicios de nube o “drives”\n\nDentro de la carpeta, encontrará un proyecto de R llamado “oswego_cs”. Es un archivo de tipo “R project” y debe siempre asegurarse que está trabajando en RStudio desde el proyecto. La forma más fácil es que habra RStudio cada vez a través de abrir este archivo.\nDentro de la carpeta “oswego_cs_es” encontrará una subcarpeta llamada data en el que encontrará todos los datos necesarios para realizar el análisis en un file llamado “oswego.xlsx”.\nDeberá crear un script dentro de la carpeta scripts en el que usted escribe el código para el análisis. Puede utilizar el script que ya está presente llamado “01_oswego_sol” que contiene el código de análisis si se encuentra atascado o si quiere comparar el código que usted realiza con la solución.\nEn la subcarpeta outputs encontrará todos los gráficos y tablas generadas en el anlálisis.\n\n\nPrimera parte - AntecedentesSegunda parte - El EventoTercera parte - AnálisisCuarta Parte - Conclusión\n\n\n\n\n\n\n\nEl 19 de abril de 1940, el oficial de salud local en el pueblo de Lycoming, condado de Oswego, Nueva York, informó de la ocurrencia de un brote de enfermedad gastrointestinal al Distrito de Salud Oficial en Siracusa. Dr. A. M. Rubin, epidemiólogo en formación, fue asignado para investigar lo ocurrido.\nCuando el Dr. Rubin llegó al campo, determinó a través del oficial de salud que todas las personas que enfermaron había asistido a una cena en la iglesia celebrada la noche anterior, 18 de abril. Otra información importante fue que los familiares que no asistieron a la cena, no enfermaron.\nEn consecuencia, el Dr. Rubin centró la investigación sobre lo ocurrido en la cena. Pudo completar 75 entrevistas de las 80 personas conocidas que asistieron a la cena, recopilando información sobre los ocurrencia y tiempo de aparición de los síntomas, y alimentos consumidos. de las 75 personas entrevistados, 46 personas presentaron síntomas de enfermedad gastrointestinal.\n\n\n\n¿Ante que tipo de situación está presente el Dr Rubin?\n\n Una epidemia Una serie de casos Un brote No se puede establecer\n\n\n\n\n\n Click para leer una pista\n\n\nPuede utilizar este glosario preparado por el Gobierno de México para encontrar la definición que se ajusta más a la situación descrita Enlace \n\n\n\nClick para ver la explicación (¡Inténtelo usted primero!)\n\n\nNumero 1 - No es la respuesta correcta; revisa el concepto de epidemia, tiene que ver con la cantidad de personas afectadas.\nNumero 2 - Es posible, pero también debes tomar en cuenta otros factores, como el hecho de que los casos tienen una relación epidemiológica entre ellos.\nNumero 4 - No te preocupes, en este tutorial vas a poder aprender los pasos del trabajo de campo.\n\n\n\n\n\n\nLos pasos de una investigación de brote son:\n\n Determinar la existencia del brote, análisis descriptivo, generar hipótesis, confirmar hipótesis, controlar brote, conclusiones y recomendaciones, informe final Una serie de casos Determinar la existencia del brote, confirmar diagnóstico, contar casos, análisis descriptivo, determinar quién está a riesgo de enfermar, desarrollar hipótesis, confirmar hipótesis, controlar brote, conclusiones y recomendaciones, informe final Determinar la existencia del brote, confirmar el diagnóstico, controlar brote, comunicar brote, generar hipótesis, confirmar hipótesis, controlar brote, conclusiones y recomendaciones, informe final\n\n\n\n\nClick para ver la explicación (¡Inténtelo usted primero!)\n\n\nPuede utilizar el sitio de la OPS para profundizar sobre el tema Enlace\n\n\n\n\n\nEl inicio de la enfermedad en todos los casos fue agudo, caracterizada principalmente por náuseas, vómitos, diarrea y dolor abdominal. Ninguno de los enfermos personas reportaron tener un nivel elevado temperatura; todos se recuperaron dentro de las 24 a 30 horas.\nAproximadamente el 20% de los enfermos que visitaron al médico no se les realizó examen de muestras fecales para el examen bacteriológico.\n\n\nEnumere una de las grandes categorías de agentes causales de enfermedades que se deben considerar en el diagnóstico diferencial de un brote de enfermedad gastrointestinal como el de Oswego:\n\n\n\n\nClick para ver la explicación de la solución (¡Inténtelo usted primero!)\n\n\n\nBacterias\nVirus\nParásitos\nToxinas\n\nPuede utilizar el sitio de la OPS para profundizar sobre el tema Enlace\n\n\n\nLos investigadores en Oswego, desconocen el agente causal, pero sospechan de que la génesis de este brote fue través de los alimentos como vehiculo de transmisión entre los afectados.\n\n\n\nEn lenguaje epidemiológico, ¿Qué es un vehículo? ¿Qué es un vector? ¿Cuáles son otros modos?\nPiense en estos conceptos y cuando esté listo, vea la solución propuesta\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEn la jerga epidemiológica, un ‘vehículo’ es un objeto o sustancia inanimada que puede transportar un patógeno y transmitirlo a un huésped susceptible. Ejemplos de vehículos incluyen alimentos o agua contaminados, fómites (objetos inanimados como pomos de puertas o ropa) o partículas transportadas por el aire. En este contexto, un vehículo no es un modo de transporte, sino más bien un medio de transmisión de un agente infeccioso. Por otro lado, un ‘vector’ es un objeto animado, generalmente un artrópodo como un mosquito, una garrapata o una pulga, que puede transportar un agente infeccioso desde un huésped infectado a un huésped susceptible. El vector puede transmitir el patógeno directamente a través de su picadura o indirectamente al depositar el patógeno en una superficie o en una fuente de alimentos o agua. Los otros modos de transmisión de agentes infecciosos incluyen el contacto persona a persona, ya sea directamente a través del contacto físico, como el tacto o el beso, o indirectamente a través de gotas generadas durante la tos o el estornudo, o mediante transmisión aérea en espacios cerrados. Además, algunos agentes infecciosos pueden ser transmitidos a través del contacto sexual, la transmisión perinatal de la madre al hijo o mediante la exposición a fluidos corporales, como la sangre o el semen. Los factores ambientales, como la mala higiene, el hacinamiento o la exposición a animales, también pueden desempeñar un papel en la transmisión de ciertos agentes infecciosos.\n\n\n\nEl Dr. Rubin decidió administrar un cuestionario a los participantes de la cena de la iglesia para averiguar qué alimento podía estar asociado al desarrollo de los síntomas\n\n\n\nSi fuese usted el que administra el cuestionario, ¿qué información recopilaría? Agrupa la información en categorías. Una vez que haya escrito sus categorías, puede ver abajo la solución.\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstos son algunos de los campos que normalmente se includirían en un cuestionario en un brote similar:\n\nInformación demográfica\nInformaión clínica\nDatos de laboratorio si disponibles\nFactores de riesgo (exposición): Alimentos y bebidas ingeridas durante la cena\n\n\n\n\nAdemás de decidir la información que quería recolectar, el Dr. Rubin decidió recolectó los datos entrevistados a través de un listado nominal.\n\n\n\n\n¿En que NO nos ayuda un listado nominal?\n\n Organizar los datos y describirlos por tiempo, lugar y persona Clasificar a los individuos como casos, no casos y sospechosos A diagnosticar a los pacientes A manejar un documento dinámico que se puede actualizar constantemente\n\n\nPor favor, continue el caso entrando en la pestaña “Segunda parte - El Evento” en la parte superior\n\n\n\n\n\n\nLa investigación del Dr. Rubin también implicó averiguar más detalles sobre la cena. Después de hablar con los organizadores, descubrió que la cena se celebró en el sótano del iglesia del pueblo. Los alimentos fueron aportados por numerosos miembros de la congregación. La cena comenzaba a las 6:00 p.m. y continuó hasta 11.00 pm.\nLa comida estaba esparcida sobre una mesa y fue consumida durante un período de varias horas. Los datos sobre el inicio de la enfermedad y los alimentos consumidos por cada una de las 75 personas entrevistados se proporcionan en la listado adjunto.\nLa hora aproximada de participación en el evento solo se recolectó aproximadamente la mitad de las personas que tuvo una enfermedad gastrointestinal.\n\n\n¿Cuál es el valor de una curva epidémica en la investigación de un brote?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstas son algunos de los usos de las curvas epidémicas cuando se investigan brotes:\n\nNos permite ver la evolución en el tiempo de un evento forma rápida\nAporta información para tomar decisiones para medidas de control\nAyuda a revelar patrones y tendencias sobre un evento\n\n\n\n\n\n\n\n¿Qué nos dice el siguiente gráfico?\n\n\n\n\n\n\n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nLa curva epidémica nos dice que:\n\nTodos los casos ocurrieron antes de las 10am del día siguiente (19 de abril)\nDesde la 11pm del 18 a las 3am del 19 de abril ocurrieron la mayoría de los casos\nNos muestra la magnitud del evento y como se propaga, así como ver valores extremos\n\n\n\n\n\n\n\n¿Hay algún caso en el que los tiempos de inicio no coincidan con los generales? ¿experiencia? ¿Cómo podrían explicarse?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nConsidere que: - Hay casos que la hora de inicio de signos y sintomas fueron antes de la cena, pudo ser que se contaminara antes durante los preparativos - Un caso ocurrió 17 horas después de la cena, posiblemente es alguien que comió más tarde o que la infomación es incorrecta (otra enfermedad parecida) o un caso secundario\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¿Cómo podrían presentarse mejor los datos en el listado nominal de participantes?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nDos ideas, aunque puede haber más son:\n\nLos datos pudieron ser separados de acuerdo al estatus de enfermedad y tiempo de inicio de sintomas\nSi se hubiese usado el formato del en tiempo militar, (ej. 00:00 o 14:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAhora vamos a comenzar con uno de los pasos más importantes en la investigación de brote, el análisis de los datos donde a través de este vamos a determinar cual o cuales son las posibles causas del brote, medidas a tomar entre otros pasos. ¡También vamos a usar un poco de R para ayudar con este proceso de análisis!.\n\n\n \nPara contestar esta pregunta, vamos hacer los siguientes pasos usando R:\n \n\nen Rstudio, crea un nuevo script para cargar los datos (cargar el archivo “oswego.xlsx”, que está en la carpeta data) y explore las dos columnas que contienen la información necesaria para calcular los períodos de incubación: TimeSupper (hora de la cena) y DateOnset (Fecha inizio síntomas)\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#Cargar los paquetes necesarios\npacman::p_load(rio,\n               here,\n               tidyverse, \n               epitools, \n               lubridate,\n               DT)\n\n#Importar los datos\nlistado &lt;- import(\"../case_studies_to_translate/ESP/oswego_cs_es/data/oswego.xlsx\")\n\n#Explorar las variables de la fecha y hora del almuerzo\nhead(oswego_db$TimeSupper)\n\n[1] NA                        NA                       \n[3] NA                        \"1940-04-18 22:00:00 UTC\"\n[5] \"1940-04-18 19:30:00 UTC\" \"1940-04-18 19:30:00 UTC\"\n\nhead(oswego_db$DateOnset)\n\n[1] \"1940-04-18 23:00:00 UTC\" NA                       \n[3] \"1940-04-18 22:30:00 UTC\" \"1940-04-19 01:00:00 UTC\"\n[5] \"1940-04-19 02:30:00 UTC\" \"1940-04-18 23:30:00 UTC\"\n\n\n\n\n\nPara referencia sobre como importar archivos, ver el capítulo 7 del libro de R para epidemiologos\n \n\nEl listado cargado ya tiene el formato correcto de la fecha y hora de almuerzo y la fecha y hora de inicio de síntomas ahora intente crear un código para crear una nueva variable con los periodos de incubación para cada caso. (recuerda que con las variables de tiempo en R se pueden hacer operaciones matemáticas)\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n# Crear la variable del período de incubación\n# puedes copiar este código en rstudio en tu editor de códigos\n#las funciones \"interval\" y \"dhours()\" son las que usaremos para calcular la diferencia en hora\n\nlistado_incubacion &lt;- listado %&gt;%\n  \n  mutate(incubacion=interval(TimeSupper, DateOnset) / dhours(1)) \n\n\n\n\nPara más detalles de como trabajar con fechas, ver el capítulo 9 del libro de R para epidemiologos\n \n\nAhora intente hacer un gráfico de barras con el período de incubación usando ggplot para visualizar la distribución. Puede encontrar pistas sobre como hacer un gráfico de barras en la sección dedicada del EpiRhandbook\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n# Hacer un gráfico de barra de los periodos de incubación calculados\n# puedes copiar este código en rstudio en tu editor de códigos\n\nlistado_incubacion %&gt;% \n  \n  ggplot(aes(x=incubacion))+\n  \n  geom_bar()+\n  \n  labs(title=\"Casos de enfermedad gastrointestinal por período de incubación en horas\",\n       subtitle = \"Oswego, NY, 18-19 de abril, 1940\",\n       x=\"Período de incubación (Horas)\",\n       y=\"n de casos\")+\n  \n  theme_minimal()\n\nWarning: Removed 53 rows containing non-finite values (`stat_count()`).\n\n\n\n\n#Si quieres asignar este gráfico a un objeto, solo tienes que en la primera línea del código \n#usar un nombre (como grafico1) y escribir el signo de asignación (&lt;-)\n\n\n\n\nPara más detalles de como trabajar con gráficos en general, ver el capítulo 30 del libro de R para epidemiologos\n \n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n22\nPara saberlo, puedes verificar viendo el listado directamente o con el siguiente código\n\n\n\n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n Para ejecutar esto en R hay varias formas, usando ya sea las funciones base o de otros paquetes. Aquí tiene un ejemplo usando el paquete {dplyr} que viene integrado en el paquete {tidyverse}\n\n# Calcular el rango, la mediana y el periodo de incubacion\n# puedes copiar este código en rstudio en tu editor de códigos\n\nresumen_estadistico &lt;- listado_incubacion %&gt;% \n  filter(!is.na(incubacion)) %&gt;% \n  reframe(mediana=median(incubacion),\n          min=min(incubacion),\n          max=max(incubacion),\n          rango=max-min)\n\nresumen_estadistico\n\n  mediana min max rango\n1       4   3   7     4\n\n\nLa mediana del periodo de incubación fue 4 horas, así como el rango del periodo del periodo de incubación también fue de 4 horas\n\n\n\n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nNos ayuda porque:\n\nCada enfermedad transmitida por los alimentos tiene un período de incubación característico, síntomas específicos y alimentos con los que es más probable que esté asociada\nEl período de incubación observado es demasiado largo para los metales pesados y demasiado corto para los agentes virales y el botulismo\nLa intoxicación alimentaria estafilocócica tiene un período de incubación promedio de 2 a 4 horas\nEstos datos son insuficientes para saber cual puede ser el agente causal \n\n\n\n\n\n\n \nPara contestar esta pregunta, intente hacer los siguientes pasos usando R con el mismo script que creaste anteriormente:\n\nCree un objeto “data.frame” con el resumen de los alimentos ingeridos por los que enfermaron y otro con el resumen de los alimentos ingeridos por los que no enfermaron. Recodifique las variables para asignar el valor de 1 si fue consumido y 0 para no consumido.\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#Ve copiando el codigo a rstudio (este ejercicio es un poco largo)\n\npacman::p_load(janitor, gtsummary)\n\n\n#Comieron\n#hacer un dataframe con un resumen de los alimentos por los que enfermaron\ntotal_por_alimentos_casos_a &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no enfermo\")) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"enfermo\") %&gt;% \nslice_tail()\n\n#hacer un dataframe con un resumen de los alimentos por los que no enfermaron\ntotal_por_alimentos_no_casos_a &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no_enfermo\")) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"no_enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"no_enfermo\") %&gt;% \nslice_tail()\n\n\n\n\nUna los dos objectos “data.frame” y calcule la proporción de personas enfermas y no enfermas que consumieron cada alimento\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#Combinar ambos dataframes, transformarlo a formato extendido y calcular la proporción de los que consumieron\ntabla_maestra_a &lt;- bind_rows(total_por_alimentos_casos_a,\n                           total_por_alimentos_no_casos_a) %&gt;% \n  pivot_longer(2:ncol(.), names_to = \"alimentos\", values_to = \"n\") %&gt;% \n  pivot_wider(names_from = tipo_caso, values_from = n) %&gt;% \n  mutate(total=enfermo+no_enfermo,\n         ptc_enfermo=enfermo/total,\n         ptc_no_enfermo=no_enfermo/total)\n\n\n\n#Combinar ambos dataframes, transformarlo a formato extendido y calcular la proporción de los que no consumieron \ntabla_maestra_b &lt;- bind_rows(total_por_alimentos_casos_b,\n                           total_por_alimentos_no_casos_b) %&gt;% \n  pivot_longer(2:ncol(.), names_to = \"alimentos\", values_to = \"n\") %&gt;% \n  pivot_wider(names_from = tipo_caso, values_from = n) %&gt;% \n  mutate(total=enfermo+no_enfermo,\n         ptc_enfermo=enfermo/total,\n         ptc_no_enfermo=no_enfermo/total)\n\ntabla_final &lt;- tabla_maestra_a %&gt;% \n  left_join(tabla_maestra_b,suffix = c(\"_consumieron\", \"_no_consumieron\"), by=\"alimentos\") %&gt;% \n  mutate(tasa_ataque=ptc_enfermo_consumieron/ptc_enfermo_no_consumieron)\n\nView(tabla_final)\n\n\n\n\nCalcule una medida de asociación para estimar qué alimento se asoció en mayor medida a enfermar\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#otra forma.. para obtener los OR de cada alimento\n\n#crear un modelo de regresión logistica\nmodel &lt;- glm(data=listado, enfermo~m_jamon_horneado+\n            m_espinaca+m_pure_papa+m_ensa_repollo+\n            m_gelatina+m_rollos+m_pan+m_lehe+m_cafe+m_agua+\n            m_bizcocho+m_hel_vainilla+m_hel_chocolate+m_ens_fruta,\n            family=binomial())\n#Luego una tabla\ntbl_regression(model, exponentiate = TRUE)\n\ntest &lt;- listado %&gt;% \n  select(enfermo, starts_with(\"m_\")) %&gt;% \n  tbl_summary(by=enfermo)\n\n\n\n\nPara más detalles de como trabajar con transformación de datos y tablas, ver el capítulo 17 del libro de R para epidemiologos\n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstas son las principales investigaciones adicionales que deben llevarse a cabo:\n\nRevisión detallada de la fuente, los ingredientes, la preparación y el almacenamiento de los alimentos incriminados\nIntentar explicar los casos con tiempo de inicio atípico\nSe podría hacer un examen de laboratorio\nDeterminar si se produjo una propagación secundaria en los miembros de la familia\nCálculos adicionales (p. ej., tasas de ataque específicas por edad o género) \n\n\n\n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstas son las principales medidas de control y prevención en un brote de estas características:\n\nEvite el consumo del helado de vainilla restante\nPrevenga la recurrencia de eventos similares en el futuro educando a los manipuladores de alimentos\nSe podría hacer un examen de laboratorio\nDeterminar si se trata de un producto comercial\nEliminó cualquier fuente contaminada de alimentos\n\n\n\n\n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nTrabajar en este brote ayudó a:\n\nDescartar la contaminación de un producto comercial. Si se trata de un producto comercial, la intervención inmediata puede prevenir un número considerable de casos adicionales\nPrevenir futuros brotes mediante la identificación de manipuladores de alimentos infectados, lagunas específicas en la educación o técnicas de manipulación de alimentos\nLos funcionarios de salud pública deben responder a tales problemas de manera oportuna para mantener una relación de cooperación con los departamentos de salud locales, los médicos privados y la comunidad\nUna explicación epidemiológica de la causa del brote puede disipar los temores y preocupaciones de la comunidad\nLa investigación del brote puede brindar oportunidades para que los investigadores respondan preguntas sobre el agente, el huésped, el entorno, el período de incubación, etc.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLo siguiente se cita textualmente del informe preparado por el Dr. Rubin:\nEl helado fue preparado por el Petrie hermanas de la siguiente manera: En la tarde del 17 de abril la leche cruda de la La granja Petrie en Lycoming se desbordó al baño maría se le agrega azúcar y huevos y un poco de harina para darle cuerpo a la mezcla. El se prepararon helado de chocolate y vainilla por separado.\nEl chocolate de Hershey era necesariamente añadido a la mezcla de chocolate. A las 6 pm. los dos las mezclas se llevaban en recipientes tapados al sótano de la iglesia y se dejó reposar durante la noche. Presuntamente no fueron tocados por nadie. durante este período.\nEn la mañana del 18 de abril, el Sr. Coe agregó cinco onzas de vainilla y dos latas de leche condensada a la mezcla de vainilla y tres onzas de vainilla y una lata de leche condensada a la mezcla de chocolate. Luego el helado de vainilla se transfirió a un lata de congelación y se coloca en un congelador eléctrico durante 20 minutos, después de lo cual el helado de vainilla se sacó de la lata del congelador y se envasó en otra lata que había sido previamente lavado con agua hirviendo. Entonces el chocolate la mezcla se puso en la lata del congelador que había sido se enjuaga con agua del grifo y se deja congelardurante 20 minutos.”\nAl concluir esto, ambos las latas se taparon y se colocaron en grandes recipientes de madera recipientes llenos de hielo. Como señaló, el helado de chocolate permaneció en el una lata de congelador.\nTodos los manipuladores del helado fueron examinados. Sin lesiones externas ni respiratorias altas se notaron infecciones. Cultivos de nariz y garganta fueron tomados de dos individuos que prepararon el helado.\nLos exámenes bacteriológicos fueron hechos por el División de Laboratorios e Investigación, Albany, en ambos helados. Su informe es el siguiente:\n‘Un gran número de Staphylococcus aureus y albus se encontraron en la muestra de hielo de vainilla crema. Sólo unos pocos estafilococos fueron demostrado en el helado de chocolate.’\nInforme de los cultivos de nariz y garganta de Los Petries que prepararon el helado decía lo siguiente:\nPresencia de Staphylococcus aureus y hemolítica del cultivo nasal y Staphylococcus albus del cultivo faríngeo de Gracia Petrie. Tambien Staphylococcus albus del cultivo de la nariz de Marian Petrie. Los estreptococos hemolíticos no eran del tipo generalmente asociado con infecciones en el hombre.\nDiscusión sobre la fuente: la fuente de contaminación bacteriana del helado de vainilla no está claro. Cualquiera que sea el método de la introducción de los estafilococos, parece razonable suponer que debe haber ocurrido entre la tarde del 17 de abril y la mañana del 18 de abril. Sin motivo de contaminación Se conoce la peculiaridad del helado de vainilla. “Al dispensar los helados, la misma cuchara se utilizó. Por lo tanto, no es improbable suponer que alguna contaminación al helado de chocolate crema ocurrió de esta manera. Esto parecería ser la explicación más plausible para la enfermedad en los tres individuos que no comieron el helado de vainilla.\nMedidas de Control: El 19 de mayo, todo el helado restantes fue condenado. Todos los demás alimentos en el la cena de la iglesia había sido consumida.\nConclusiones: Un brote de gastroenteritis ocurrió después de una cena en la iglesia en Lycoming. La causa del brote fue helado de vainilla por contaminado. El método de contaminación de helado no se entiende claramente.\nSi el estafilococo dio positivo de la nariz y la garganta de los cultivos realizados en la familia Petrie haba todo lo que tenga que ver con la contaminación es un asunto por nexo epidemiológico.\nNota: El paciente #52 era un niño que mientras viendo el procedimiento de congelación se le dio una plato de helado de vainilla a las 11:00 am en abril 18."
  },
  {
    "objectID": "pages/oswego.es.html#overview",
    "href": "pages/oswego.es.html#overview",
    "title": "Oswego (ES)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\n\n\n\nName\nOswego\n\n\nTool\nR\n\n\nLanguage\nSpanish/Español\n\n\nLocation\nUnited States\n\n\nScale\nLocal\n\n\nDiseases\nGastrointestinal\n\n\nKeywords\nGastrointestinal;Outbreak investigation\n\n\nTechnical complexity\nIntermidiate\n\n\nMethodolocial complexity\nIntermidiate\n\n\n\nAuthorship\nOriginal authors: Centre for Disease Prevention and Control (CDC)\nData source: Epi Info, version 3.5.4 (CDC)\nAdapted to R by: Leonel Lerebours Nadal y Alberto Mateo Urdiales"
  },
  {
    "objectID": "pages/oswego.es.html#instructions",
    "href": "pages/oswego.es.html#instructions",
    "title": "Oswego (ES)",
    "section": "",
    "text": "There are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\nHere is what the “helpers” look like:\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\n\n… description here about posting in Community… TO BE COMPLETED BY APPLIED EPI\n\n\n\nYou will see these icons throughout the exercises:\n\n\n\n\n\n\n\nIcon\nMeaning\n\n\n\n\n\nObserve\n\n\n\nAlert!\n\n\n\nAn informative note\n\n\n\nTime for you to code!\n\n\n\nChange to another window\n\n\n\nRemember this for later\n\n\n\n\n\n\n\nThis case study has been adapted from an existing tutorial on Epi Info created by the Centre for Disease Prevention and Control (CDC). Epi Info™ is a trademark of CDC. Epi Info™ programs are provided in the public domain to promote public health. Programs might be freely translated, copied, or distributed. No warranty is made or implied for use of the software for any particular purpose.\n Applied Epi Incorporated, 2022 This work is licensed by Applied Epi Incorporated under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\nPlease email contact@appliedepi.org with questions about the use of these materials for academic courses and epidemiologist training programs."
  },
  {
    "objectID": "pages/oswego.es.html#feedback-suggestions",
    "href": "pages/oswego.es.html#feedback-suggestions",
    "title": "Oswego (ES)",
    "section": "",
    "text": "You can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org"
  },
  {
    "objectID": "pages/oswego.es.html#version-1",
    "href": "pages/oswego.es.html#version-1",
    "title": "Oswego (ES)",
    "section": "",
    "text": "16 November 2023"
  },
  {
    "objectID": "pages/oswego.es.html#disclaimer",
    "href": "pages/oswego.es.html#disclaimer",
    "title": "Oswego (ES)",
    "section": "",
    "text": "Esto es un estudio de caso diseñado por el Centre for Disease Prevention and Control (CDC) como tutorial de Epi Info. Puede consultar más detalles en este Enlace"
  },
  {
    "objectID": "pages/oswego.es.html#revisions",
    "href": "pages/oswego.es.html#revisions",
    "title": "Oswego (ES)",
    "section": "",
    "text": "Date\nChanges made\nVersion\n\n\n\n\n16 November\nAdapted to template\n1"
  },
  {
    "objectID": "pages/oswego.es.html#objetivos-de-este-estudio-de-caso",
    "href": "pages/oswego.es.html#objetivos-de-este-estudio-de-caso",
    "title": "Oswego (ES)",
    "section": "",
    "text": "Los objetivos de este estudio de caso son:\n\nEntender los diferentes pasos en la investigación de un brote de casos de enfermedad gastrointestinal\nAdquirir confianza en el manejo de datos de un listado nominal con el software estadístico R\nAdquirir experience en el análisis descriptivo en R, particularmente curvas epidémicas\nAdquirir experience construyendo tablas 2x2 con exposición y desenlace que nos permitan calcular medidas de asociación\nAplicar los conocimientos adquiridos a posibles actividades de control y prevención de brotes infecciosos de origen alimentario\n\n\n\nEn este estudio de caso se asume un conocimiento básico de los principios fundamental de la investigación epidemiológica de brotes gastrointestinales. Se asume también un conocimiento básico de R.\n\n\n\nAntes de iniciar este estudio de caso, le aconsejamos que:\n\nDescargue en su computadora la carpeta “oswego_cs_es” y que extraiga todos sus componentes, preferibilmente en su escritorio o en un lugar de fácil acceso. Evite extraerlo en servicios de nube o “drives”\n\nDentro de la carpeta, encontrará un proyecto de R llamado “oswego_cs”. Es un archivo de tipo “R project” y debe siempre asegurarse que está trabajando en RStudio desde el proyecto. La forma más fácil es que habra RStudio cada vez a través de abrir este archivo.\nDentro de la carpeta “oswego_cs_es” encontrará una subcarpeta llamada data en el que encontrará todos los datos necesarios para realizar el análisis en un file llamado “oswego.xlsx”.\nDeberá crear un script dentro de la carpeta scripts en el que usted escribe el código para el análisis. Puede utilizar el script que ya está presente llamado “01_oswego_sol” que contiene el código de análisis si se encuentra atascado o si quiere comparar el código que usted realiza con la solución.\nEn la subcarpeta outputs encontrará todos los gráficos y tablas generadas en el anlálisis.\n\n\nPrimera parte - AntecedentesSegunda parte - El EventoTercera parte - AnálisisCuarta Parte - Conclusión\n\n\n\n\n\n\n\nEl 19 de abril de 1940, el oficial de salud local en el pueblo de Lycoming, condado de Oswego, Nueva York, informó de la ocurrencia de un brote de enfermedad gastrointestinal al Distrito de Salud Oficial en Siracusa. Dr. A. M. Rubin, epidemiólogo en formación, fue asignado para investigar lo ocurrido.\nCuando el Dr. Rubin llegó al campo, determinó a través del oficial de salud que todas las personas que enfermaron había asistido a una cena en la iglesia celebrada la noche anterior, 18 de abril. Otra información importante fue que los familiares que no asistieron a la cena, no enfermaron.\nEn consecuencia, el Dr. Rubin centró la investigación sobre lo ocurrido en la cena. Pudo completar 75 entrevistas de las 80 personas conocidas que asistieron a la cena, recopilando información sobre los ocurrencia y tiempo de aparición de los síntomas, y alimentos consumidos. de las 75 personas entrevistados, 46 personas presentaron síntomas de enfermedad gastrointestinal.\n\n\n\n¿Ante que tipo de situación está presente el Dr Rubin?\n\n Una epidemia Una serie de casos Un brote No se puede establecer\n\n\n\n\n\n Click para leer una pista\n\n\nPuede utilizar este glosario preparado por el Gobierno de México para encontrar la definición que se ajusta más a la situación descrita Enlace \n\n\n\nClick para ver la explicación (¡Inténtelo usted primero!)\n\n\nNumero 1 - No es la respuesta correcta; revisa el concepto de epidemia, tiene que ver con la cantidad de personas afectadas.\nNumero 2 - Es posible, pero también debes tomar en cuenta otros factores, como el hecho de que los casos tienen una relación epidemiológica entre ellos.\nNumero 4 - No te preocupes, en este tutorial vas a poder aprender los pasos del trabajo de campo.\n\n\n\n\n\n\nLos pasos de una investigación de brote son:\n\n Determinar la existencia del brote, análisis descriptivo, generar hipótesis, confirmar hipótesis, controlar brote, conclusiones y recomendaciones, informe final Una serie de casos Determinar la existencia del brote, confirmar diagnóstico, contar casos, análisis descriptivo, determinar quién está a riesgo de enfermar, desarrollar hipótesis, confirmar hipótesis, controlar brote, conclusiones y recomendaciones, informe final Determinar la existencia del brote, confirmar el diagnóstico, controlar brote, comunicar brote, generar hipótesis, confirmar hipótesis, controlar brote, conclusiones y recomendaciones, informe final\n\n\n\n\nClick para ver la explicación (¡Inténtelo usted primero!)\n\n\nPuede utilizar el sitio de la OPS para profundizar sobre el tema Enlace\n\n\n\n\n\nEl inicio de la enfermedad en todos los casos fue agudo, caracterizada principalmente por náuseas, vómitos, diarrea y dolor abdominal. Ninguno de los enfermos personas reportaron tener un nivel elevado temperatura; todos se recuperaron dentro de las 24 a 30 horas.\nAproximadamente el 20% de los enfermos que visitaron al médico no se les realizó examen de muestras fecales para el examen bacteriológico.\n\n\nEnumere una de las grandes categorías de agentes causales de enfermedades que se deben considerar en el diagnóstico diferencial de un brote de enfermedad gastrointestinal como el de Oswego:\n\n\n\n\nClick para ver la explicación de la solución (¡Inténtelo usted primero!)\n\n\n\nBacterias\nVirus\nParásitos\nToxinas\n\nPuede utilizar el sitio de la OPS para profundizar sobre el tema Enlace\n\n\n\nLos investigadores en Oswego, desconocen el agente causal, pero sospechan de que la génesis de este brote fue través de los alimentos como vehiculo de transmisión entre los afectados.\n\n\n\nEn lenguaje epidemiológico, ¿Qué es un vehículo? ¿Qué es un vector? ¿Cuáles son otros modos?\nPiense en estos conceptos y cuando esté listo, vea la solución propuesta\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEn la jerga epidemiológica, un ‘vehículo’ es un objeto o sustancia inanimada que puede transportar un patógeno y transmitirlo a un huésped susceptible. Ejemplos de vehículos incluyen alimentos o agua contaminados, fómites (objetos inanimados como pomos de puertas o ropa) o partículas transportadas por el aire. En este contexto, un vehículo no es un modo de transporte, sino más bien un medio de transmisión de un agente infeccioso. Por otro lado, un ‘vector’ es un objeto animado, generalmente un artrópodo como un mosquito, una garrapata o una pulga, que puede transportar un agente infeccioso desde un huésped infectado a un huésped susceptible. El vector puede transmitir el patógeno directamente a través de su picadura o indirectamente al depositar el patógeno en una superficie o en una fuente de alimentos o agua. Los otros modos de transmisión de agentes infecciosos incluyen el contacto persona a persona, ya sea directamente a través del contacto físico, como el tacto o el beso, o indirectamente a través de gotas generadas durante la tos o el estornudo, o mediante transmisión aérea en espacios cerrados. Además, algunos agentes infecciosos pueden ser transmitidos a través del contacto sexual, la transmisión perinatal de la madre al hijo o mediante la exposición a fluidos corporales, como la sangre o el semen. Los factores ambientales, como la mala higiene, el hacinamiento o la exposición a animales, también pueden desempeñar un papel en la transmisión de ciertos agentes infecciosos.\n\n\n\nEl Dr. Rubin decidió administrar un cuestionario a los participantes de la cena de la iglesia para averiguar qué alimento podía estar asociado al desarrollo de los síntomas\n\n\n\nSi fuese usted el que administra el cuestionario, ¿qué información recopilaría? Agrupa la información en categorías. Una vez que haya escrito sus categorías, puede ver abajo la solución.\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstos son algunos de los campos que normalmente se includirían en un cuestionario en un brote similar:\n\nInformación demográfica\nInformaión clínica\nDatos de laboratorio si disponibles\nFactores de riesgo (exposición): Alimentos y bebidas ingeridas durante la cena\n\n\n\n\nAdemás de decidir la información que quería recolectar, el Dr. Rubin decidió recolectó los datos entrevistados a través de un listado nominal.\n\n\n\n\n¿En que NO nos ayuda un listado nominal?\n\n Organizar los datos y describirlos por tiempo, lugar y persona Clasificar a los individuos como casos, no casos y sospechosos A diagnosticar a los pacientes A manejar un documento dinámico que se puede actualizar constantemente\n\n\nPor favor, continue el caso entrando en la pestaña “Segunda parte - El Evento” en la parte superior\n\n\n\n\n\n\nLa investigación del Dr. Rubin también implicó averiguar más detalles sobre la cena. Después de hablar con los organizadores, descubrió que la cena se celebró en el sótano del iglesia del pueblo. Los alimentos fueron aportados por numerosos miembros de la congregación. La cena comenzaba a las 6:00 p.m. y continuó hasta 11.00 pm.\nLa comida estaba esparcida sobre una mesa y fue consumida durante un período de varias horas. Los datos sobre el inicio de la enfermedad y los alimentos consumidos por cada una de las 75 personas entrevistados se proporcionan en la listado adjunto.\nLa hora aproximada de participación en el evento solo se recolectó aproximadamente la mitad de las personas que tuvo una enfermedad gastrointestinal.\n\n\n¿Cuál es el valor de una curva epidémica en la investigación de un brote?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstas son algunos de los usos de las curvas epidémicas cuando se investigan brotes:\n\nNos permite ver la evolución en el tiempo de un evento forma rápida\nAporta información para tomar decisiones para medidas de control\nAyuda a revelar patrones y tendencias sobre un evento\n\n\n\n\n\n\n\n¿Qué nos dice el siguiente gráfico?\n\n\n\n\n\n\n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nLa curva epidémica nos dice que:\n\nTodos los casos ocurrieron antes de las 10am del día siguiente (19 de abril)\nDesde la 11pm del 18 a las 3am del 19 de abril ocurrieron la mayoría de los casos\nNos muestra la magnitud del evento y como se propaga, así como ver valores extremos\n\n\n\n\n\n\n\n¿Hay algún caso en el que los tiempos de inicio no coincidan con los generales? ¿experiencia? ¿Cómo podrían explicarse?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nConsidere que: - Hay casos que la hora de inicio de signos y sintomas fueron antes de la cena, pudo ser que se contaminara antes durante los preparativos - Un caso ocurrió 17 horas después de la cena, posiblemente es alguien que comió más tarde o que la infomación es incorrecta (otra enfermedad parecida) o un caso secundario\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¿Cómo podrían presentarse mejor los datos en el listado nominal de participantes?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nDos ideas, aunque puede haber más son:\n\nLos datos pudieron ser separados de acuerdo al estatus de enfermedad y tiempo de inicio de sintomas\nSi se hubiese usado el formato del en tiempo militar, (ej. 00:00 o 14:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAhora vamos a comenzar con uno de los pasos más importantes en la investigación de brote, el análisis de los datos donde a través de este vamos a determinar cual o cuales son las posibles causas del brote, medidas a tomar entre otros pasos. ¡También vamos a usar un poco de R para ayudar con este proceso de análisis!.\n\n\n \nPara contestar esta pregunta, vamos hacer los siguientes pasos usando R:\n \n\nen Rstudio, crea un nuevo script para cargar los datos (cargar el archivo “oswego.xlsx”, que está en la carpeta data) y explore las dos columnas que contienen la información necesaria para calcular los períodos de incubación: TimeSupper (hora de la cena) y DateOnset (Fecha inizio síntomas)\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#Cargar los paquetes necesarios\npacman::p_load(rio,\n               here,\n               tidyverse, \n               epitools, \n               lubridate,\n               DT)\n\n#Importar los datos\nlistado &lt;- import(\"../case_studies_to_translate/ESP/oswego_cs_es/data/oswego.xlsx\")\n\n#Explorar las variables de la fecha y hora del almuerzo\nhead(oswego_db$TimeSupper)\n\n[1] NA                        NA                       \n[3] NA                        \"1940-04-18 22:00:00 UTC\"\n[5] \"1940-04-18 19:30:00 UTC\" \"1940-04-18 19:30:00 UTC\"\n\nhead(oswego_db$DateOnset)\n\n[1] \"1940-04-18 23:00:00 UTC\" NA                       \n[3] \"1940-04-18 22:30:00 UTC\" \"1940-04-19 01:00:00 UTC\"\n[5] \"1940-04-19 02:30:00 UTC\" \"1940-04-18 23:30:00 UTC\"\n\n\n\n\n\nPara referencia sobre como importar archivos, ver el capítulo 7 del libro de R para epidemiologos\n \n\nEl listado cargado ya tiene el formato correcto de la fecha y hora de almuerzo y la fecha y hora de inicio de síntomas ahora intente crear un código para crear una nueva variable con los periodos de incubación para cada caso. (recuerda que con las variables de tiempo en R se pueden hacer operaciones matemáticas)\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n# Crear la variable del período de incubación\n# puedes copiar este código en rstudio en tu editor de códigos\n#las funciones \"interval\" y \"dhours()\" son las que usaremos para calcular la diferencia en hora\n\nlistado_incubacion &lt;- listado %&gt;%\n  \n  mutate(incubacion=interval(TimeSupper, DateOnset) / dhours(1)) \n\n\n\n\nPara más detalles de como trabajar con fechas, ver el capítulo 9 del libro de R para epidemiologos\n \n\nAhora intente hacer un gráfico de barras con el período de incubación usando ggplot para visualizar la distribución. Puede encontrar pistas sobre como hacer un gráfico de barras en la sección dedicada del EpiRhandbook\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n# Hacer un gráfico de barra de los periodos de incubación calculados\n# puedes copiar este código en rstudio en tu editor de códigos\n\nlistado_incubacion %&gt;% \n  \n  ggplot(aes(x=incubacion))+\n  \n  geom_bar()+\n  \n  labs(title=\"Casos de enfermedad gastrointestinal por período de incubación en horas\",\n       subtitle = \"Oswego, NY, 18-19 de abril, 1940\",\n       x=\"Período de incubación (Horas)\",\n       y=\"n de casos\")+\n  \n  theme_minimal()\n\nWarning: Removed 53 rows containing non-finite values (`stat_count()`).\n\n\n\n\n#Si quieres asignar este gráfico a un objeto, solo tienes que en la primera línea del código \n#usar un nombre (como grafico1) y escribir el signo de asignación (&lt;-)\n\n\n\n\nPara más detalles de como trabajar con gráficos en general, ver el capítulo 30 del libro de R para epidemiologos\n \n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n22\nPara saberlo, puedes verificar viendo el listado directamente o con el siguiente código\n\n\n\n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n Para ejecutar esto en R hay varias formas, usando ya sea las funciones base o de otros paquetes. Aquí tiene un ejemplo usando el paquete {dplyr} que viene integrado en el paquete {tidyverse}\n\n# Calcular el rango, la mediana y el periodo de incubacion\n# puedes copiar este código en rstudio en tu editor de códigos\n\nresumen_estadistico &lt;- listado_incubacion %&gt;% \n  filter(!is.na(incubacion)) %&gt;% \n  reframe(mediana=median(incubacion),\n          min=min(incubacion),\n          max=max(incubacion),\n          rango=max-min)\n\nresumen_estadistico\n\n  mediana min max rango\n1       4   3   7     4\n\n\nLa mediana del periodo de incubación fue 4 horas, así como el rango del periodo del periodo de incubación también fue de 4 horas\n\n\n\n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nNos ayuda porque:\n\nCada enfermedad transmitida por los alimentos tiene un período de incubación característico, síntomas específicos y alimentos con los que es más probable que esté asociada\nEl período de incubación observado es demasiado largo para los metales pesados y demasiado corto para los agentes virales y el botulismo\nLa intoxicación alimentaria estafilocócica tiene un período de incubación promedio de 2 a 4 horas\nEstos datos son insuficientes para saber cual puede ser el agente causal \n\n\n\n\n\n\n \nPara contestar esta pregunta, intente hacer los siguientes pasos usando R con el mismo script que creaste anteriormente:\n\nCree un objeto “data.frame” con el resumen de los alimentos ingeridos por los que enfermaron y otro con el resumen de los alimentos ingeridos por los que no enfermaron. Recodifique las variables para asignar el valor de 1 si fue consumido y 0 para no consumido.\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#Ve copiando el codigo a rstudio (este ejercicio es un poco largo)\n\npacman::p_load(janitor, gtsummary)\n\n\n#Comieron\n#hacer un dataframe con un resumen de los alimentos por los que enfermaron\ntotal_por_alimentos_casos_a &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no enfermo\")) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"enfermo\") %&gt;% \nslice_tail()\n\n#hacer un dataframe con un resumen de los alimentos por los que no enfermaron\ntotal_por_alimentos_no_casos_a &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no_enfermo\")) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"no_enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"no_enfermo\") %&gt;% \nslice_tail()\n\n\n\n\nUna los dos objectos “data.frame” y calcule la proporción de personas enfermas y no enfermas que consumieron cada alimento\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#Combinar ambos dataframes, transformarlo a formato extendido y calcular la proporción de los que consumieron\ntabla_maestra_a &lt;- bind_rows(total_por_alimentos_casos_a,\n                           total_por_alimentos_no_casos_a) %&gt;% \n  pivot_longer(2:ncol(.), names_to = \"alimentos\", values_to = \"n\") %&gt;% \n  pivot_wider(names_from = tipo_caso, values_from = n) %&gt;% \n  mutate(total=enfermo+no_enfermo,\n         ptc_enfermo=enfermo/total,\n         ptc_no_enfermo=no_enfermo/total)\n\n\n\n#Combinar ambos dataframes, transformarlo a formato extendido y calcular la proporción de los que no consumieron \ntabla_maestra_b &lt;- bind_rows(total_por_alimentos_casos_b,\n                           total_por_alimentos_no_casos_b) %&gt;% \n  pivot_longer(2:ncol(.), names_to = \"alimentos\", values_to = \"n\") %&gt;% \n  pivot_wider(names_from = tipo_caso, values_from = n) %&gt;% \n  mutate(total=enfermo+no_enfermo,\n         ptc_enfermo=enfermo/total,\n         ptc_no_enfermo=no_enfermo/total)\n\ntabla_final &lt;- tabla_maestra_a %&gt;% \n  left_join(tabla_maestra_b,suffix = c(\"_consumieron\", \"_no_consumieron\"), by=\"alimentos\") %&gt;% \n  mutate(tasa_ataque=ptc_enfermo_consumieron/ptc_enfermo_no_consumieron)\n\nView(tabla_final)\n\n\n\n\nCalcule una medida de asociación para estimar qué alimento se asoció en mayor medida a enfermar\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#otra forma.. para obtener los OR de cada alimento\n\n#crear un modelo de regresión logistica\nmodel &lt;- glm(data=listado, enfermo~m_jamon_horneado+\n            m_espinaca+m_pure_papa+m_ensa_repollo+\n            m_gelatina+m_rollos+m_pan+m_lehe+m_cafe+m_agua+\n            m_bizcocho+m_hel_vainilla+m_hel_chocolate+m_ens_fruta,\n            family=binomial())\n#Luego una tabla\ntbl_regression(model, exponentiate = TRUE)\n\ntest &lt;- listado %&gt;% \n  select(enfermo, starts_with(\"m_\")) %&gt;% \n  tbl_summary(by=enfermo)\n\n\n\n\nPara más detalles de como trabajar con transformación de datos y tablas, ver el capítulo 17 del libro de R para epidemiologos\n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstas son las principales investigaciones adicionales que deben llevarse a cabo:\n\nRevisión detallada de la fuente, los ingredientes, la preparación y el almacenamiento de los alimentos incriminados\nIntentar explicar los casos con tiempo de inicio atípico\nSe podría hacer un examen de laboratorio\nDeterminar si se produjo una propagación secundaria en los miembros de la familia\nCálculos adicionales (p. ej., tasas de ataque específicas por edad o género) \n\n\n\n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstas son las principales medidas de control y prevención en un brote de estas características:\n\nEvite el consumo del helado de vainilla restante\nPrevenga la recurrencia de eventos similares en el futuro educando a los manipuladores de alimentos\nSe podría hacer un examen de laboratorio\nDeterminar si se trata de un producto comercial\nEliminó cualquier fuente contaminada de alimentos\n\n\n\n\n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nTrabajar en este brote ayudó a:\n\nDescartar la contaminación de un producto comercial. Si se trata de un producto comercial, la intervención inmediata puede prevenir un número considerable de casos adicionales\nPrevenir futuros brotes mediante la identificación de manipuladores de alimentos infectados, lagunas específicas en la educación o técnicas de manipulación de alimentos\nLos funcionarios de salud pública deben responder a tales problemas de manera oportuna para mantener una relación de cooperación con los departamentos de salud locales, los médicos privados y la comunidad\nUna explicación epidemiológica de la causa del brote puede disipar los temores y preocupaciones de la comunidad\nLa investigación del brote puede brindar oportunidades para que los investigadores respondan preguntas sobre el agente, el huésped, el entorno, el período de incubación, etc.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLo siguiente se cita textualmente del informe preparado por el Dr. Rubin:\nEl helado fue preparado por el Petrie hermanas de la siguiente manera: En la tarde del 17 de abril la leche cruda de la La granja Petrie en Lycoming se desbordó al baño maría se le agrega azúcar y huevos y un poco de harina para darle cuerpo a la mezcla. El se prepararon helado de chocolate y vainilla por separado.\nEl chocolate de Hershey era necesariamente añadido a la mezcla de chocolate. A las 6 pm. los dos las mezclas se llevaban en recipientes tapados al sótano de la iglesia y se dejó reposar durante la noche. Presuntamente no fueron tocados por nadie. durante este período.\nEn la mañana del 18 de abril, el Sr. Coe agregó cinco onzas de vainilla y dos latas de leche condensada a la mezcla de vainilla y tres onzas de vainilla y una lata de leche condensada a la mezcla de chocolate. Luego el helado de vainilla se transfirió a un lata de congelación y se coloca en un congelador eléctrico durante 20 minutos, después de lo cual el helado de vainilla se sacó de la lata del congelador y se envasó en otra lata que había sido previamente lavado con agua hirviendo. Entonces el chocolate la mezcla se puso en la lata del congelador que había sido se enjuaga con agua del grifo y se deja congelardurante 20 minutos.”\nAl concluir esto, ambos las latas se taparon y se colocaron en grandes recipientes de madera recipientes llenos de hielo. Como señaló, el helado de chocolate permaneció en el una lata de congelador.\nTodos los manipuladores del helado fueron examinados. Sin lesiones externas ni respiratorias altas se notaron infecciones. Cultivos de nariz y garganta fueron tomados de dos individuos que prepararon el helado.\nLos exámenes bacteriológicos fueron hechos por el División de Laboratorios e Investigación, Albany, en ambos helados. Su informe es el siguiente:\n‘Un gran número de Staphylococcus aureus y albus se encontraron en la muestra de hielo de vainilla crema. Sólo unos pocos estafilococos fueron demostrado en el helado de chocolate.’\nInforme de los cultivos de nariz y garganta de Los Petries que prepararon el helado decía lo siguiente:\nPresencia de Staphylococcus aureus y hemolítica del cultivo nasal y Staphylococcus albus del cultivo faríngeo de Gracia Petrie. Tambien Staphylococcus albus del cultivo de la nariz de Marian Petrie. Los estreptococos hemolíticos no eran del tipo generalmente asociado con infecciones en el hombre.\nDiscusión sobre la fuente: la fuente de contaminación bacteriana del helado de vainilla no está claro. Cualquiera que sea el método de la introducción de los estafilococos, parece razonable suponer que debe haber ocurrido entre la tarde del 17 de abril y la mañana del 18 de abril. Sin motivo de contaminación Se conoce la peculiaridad del helado de vainilla. “Al dispensar los helados, la misma cuchara se utilizó. Por lo tanto, no es improbable suponer que alguna contaminación al helado de chocolate crema ocurrió de esta manera. Esto parecería ser la explicación más plausible para la enfermedad en los tres individuos que no comieron el helado de vainilla.\nMedidas de Control: El 19 de mayo, todo el helado restantes fue condenado. Todos los demás alimentos en el la cena de la iglesia había sido consumida.\nConclusiones: Un brote de gastroenteritis ocurrió después de una cena en la iglesia en Lycoming. La causa del brote fue helado de vainilla por contaminado. El método de contaminación de helado no se entiende claramente.\nSi el estafilococo dio positivo de la nariz y la garganta de los cultivos realizados en la familia Petrie haba todo lo que tenga que ver con la contaminación es un asunto por nexo epidemiológico.\nNota: El paciente #52 era un niño que mientras viendo el procedimiento de congelación se le dio una plato de helado de vainilla a las 11:00 am en abril 18."
  },
  {
    "objectID": "pages/stegen-en.html",
    "href": "pages/stegen-en.html",
    "title": "An Outbreak of Gastroenteritis in Stegen, Germany (ENG)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\nName:\nAn Outbreak of Gastroenteritis in Stegen, Germany\n\n\nLanguage:\nEnglish\n\n\nTool:\nR;\n\n\nLocation:\nGermany\n\n\nScale:\nLocal\n\n\nDiseases:\nGI\n\n\nKeywords:\nGI; Stratified analysis; R\n\n\nTechnical complexity:\nIntermediate\n\n\nMethodological complexity:\nBasic"
  },
  {
    "objectID": "pages/stegen-en.html#overview",
    "href": "pages/stegen-en.html#overview",
    "title": "An Outbreak of Gastroenteritis in Stegen, Germany (ENG)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\nName:\nAn Outbreak of Gastroenteritis in Stegen, Germany\n\n\nLanguage:\nEnglish\n\n\nTool:\nR;\n\n\nLocation:\nGermany\n\n\nScale:\nLocal\n\n\nDiseases:\nGI\n\n\nKeywords:\nGI; Stratified analysis; R\n\n\nTechnical complexity:\nIntermediate\n\n\nMethodological complexity:\nBasic"
  },
  {
    "objectID": "pages/stegen-en.html#instructions",
    "href": "pages/stegen-en.html#instructions",
    "title": "An Outbreak of Gastroenteritis in Stegen, Germany (ENG)",
    "section": "Instructions",
    "text": "Instructions\n\nGetting Help\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\nHints and Solutions\nHere is what the “helpers” look like:\n\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see the solution\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\nPosting a question in the Community Forum\n… description here about posting in Community… TO BE COMPLETED BY APPLIED EPI\n\n\nTerms of Use\nDisclaimer: The information presented in this exercise and the associated data files have been deliberately changed so as to facilitate the acquisition of the learning objectives for fellows of EPIET, EUPHEM and EPIET-associated programmes. This case study was first introduced in 2022 (see Copyright and Licence agreement for more information).\nYou are free:\n\nto Share: to copy and distribute the work\nto Remix: to adapt and build upon the material\n\nUnder the following conditions:\n\nAttribution: You must attribute the work in the manner specified by the author or licensor (but not in any way that suggests that they endorse you or your use of the work). The best way to do this is to keep as it is the list of contributors: sources, authors and reviewers.\nShare Alike: If you alter, transform, or build upon this work, you may distribute the resulting work only under the same or similar license to this one. Your changes must be documented. Under that condition, you are allowed to add your name to the list of contributors.\nNotification: If you use the work in the manner specified by the author or licensor, Walter@rki.de\nYou cannot sell this work alone but you can use it as part of a teaching.\n\nWith the understanding that:\n\nWaiver: Any of the above conditions can be waived if you get permission from the copyright holder.\nPublic Domain: Where the work or any of its elements is in the public domain under applicable law, that status is in no way affected by the license.\nOther Rights: In no way are any of the following rights affected by the license:\n\nYour fair dealing or fair use rights, or other applicable copyright exceptions and limitations;\nThe author’s moral rights;\nRights other persons may have either in the work itself or in how the work is used, such as publicity or privacy rights.\n\nNotice: For any reuse or distribution, you must make clear to others the license terms of this work by keeping together this work and the current license.\n\nThis licence is based on http://creativecommons.org/licenses/by-sa/3.0/\n\n\n\nFeedback & suggestions\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\nVersion and revisions\nWrite date of first version\nWrite any revisions made to the case study\n\n\n\n\n\n\n\n\nDate\nChanges made\nAuthor\n\n\n\n\n2015\nThe case study has been divided in two parts: the first includes descriptive, univariable and stratified analysis as pre-module homework; the second includes logistic and binary regression (not shown here). Unnecessary toponymes were removed.\nAlicia Barrasa (EPIET) and Ioannis Karagiannis (Publich Health England-PHE)\n\n\n2017\nQuestions were rephrased to reflect real life scenarios (rather than academic exercise)\nAlicia Barrasa (EPIET) and Giri Shankar (Public Health Wales-PHW)\n\n\n2017\nThe case study was adapted to include the help on R\nNiklas Willrich (Robert Koch Institute-RKI), Patrick Keating (Austrian Agency for Health and Food Safety-AGES) and Alexander Spina (AGES)\n\n\n2017\nContribution to the R code\nDaniel Gardiner (Public Health England-PHE) and Lukas Richter (AGES)\n\n\n2022\nMinor revisions to the R code and explanations\n\n\n\n2023\nMajor revision of the R code. R code was simplified and R tidyverse code was implemented\nLiese Van Gompel (MedEPIET)\n\n\n2024\nRevision of the R code, i.e. use of EpiStas package for univariable and multivariable analysis, simplification and harmonisation of the R code\nKostas Danis (MediPIET)\n\n\n2017\nRevision of content, structure, R code and adaptation of format to Applied Epi’s template of case studies\nAlberto Mateo Urdiales (ISS)"
  },
  {
    "objectID": "pages/stegen-en.html#guidance",
    "href": "pages/stegen-en.html#guidance",
    "title": "An Outbreak of Gastroenteritis in Stegen, Germany (ENG)",
    "section": "Guidance",
    "text": "Guidance\n\nObjectives of this case study\nAt the end of this case study, participants should:\n\nknow and be able to perform the fundamental steps of a descriptive statistical analysis of a foodborne outbreak (including quantitative assessment (frequency distributions, missing values, means/medians/modes, quartiles/SDs) and visualization of the data (histogram, boxplot))\nbe able to perform univariate statistical analysis to identify potential vehicles of a foodborne outbreak (including risk ratios and/or odds ratios, depending on the design)\nknow why and how stratification can be conducted in datasets related to an outbreak investigation\nbe able to conduct a stratified analysis with respect to potential risk factors and confounders/effect modifiers\n\n\n\nPrevious level of expertise assumed\nParticipants are expected to be familiar with data management and basic analysis in R.\n\n\nPreparation for the case study\n\nDownload folder named stengen_mva and extract contents in the local laptop\nCreate an Rstudio project in the folder stengen_mva If you are unsure on how to do that, read the EpiRhandbook Chapter on R projects\nInside the folder stengen_mva: Subfolder “data” contains a raw data file named tira.csv. This is the only data file you will use in this case study. In the same folder you can find the data dictionary with a description of the dataframe variables.\nSubfolder scripts should be used to save any scripts related to the analysis. Inside “backup” you will find a solution script with the code of the case study named stengen_analysis_backup.R.\nSubfolder “outputs” could be used to store all outputs (tables, graphs, documents) that are the result of the analysis"
  },
  {
    "objectID": "pages/stegen-en.html#introduction",
    "href": "pages/stegen-en.html#introduction",
    "title": "An Outbreak of Gastroenteritis in Stegen, Germany (ENG)",
    "section": "Introduction",
    "text": "Introduction\nOn 26 June 1998, the St Sebastian High School in Stegen (school A), Germany, celebrated a graduation party, where 250 to 350 participants were expected. Attendees included graduates from that school, their families and friends, teachers, 12th grade students and some graduates from a nearby school (school B).\nA self-service party buffet was supplied by a commercial caterer in Freiburg. Food was prepared on the day of the party and transported in a refrigerated van to the school.\nFestivities started with a dinner buffet which opened from 8:30 pm onwards and were followed by a dessert buffet offered from 10 pm. The party and the buffet extended late during the night and alcoholic beverages were quite popular. All agreed it was a party to be remembered."
  },
  {
    "objectID": "pages/stegen-en.html#the-alert",
    "href": "pages/stegen-en.html#the-alert",
    "title": "An Outbreak of Gastroenteritis in Stegen, Germany (ENG)",
    "section": "The alert",
    "text": "The alert\nOn 2nd July 1998, the Freiburg local health office reported to the Robert Koch Institute (RKI) in Berlin the occurrence of many cases of gastroenteritis following the graduation party described above. More than 100 cases were suspected among attendees and some of them were admitted to nearby hospitals. Sick people suffered from fever, nausea, diarrhoea and vomiting that lasted for several days. Most believed that the tiramisu consumed at dinner was responsible for their illness. Salmonella Enteritidis was isolated from 19 stool samples.\nThe Freiburg health office sent a team to investigate the kitchen facilities of the caterer. Food preparation procedures were reviewed. Food samples, except tiramisu (none was left over), were sent to the laboratory of Freiburg University. Microbiological analyses were performed on samples of the following: brown chocolate mousse, caramel cream, remoulade sauce, yoghurt dill sauce and 10 raw eggs.\nThe Freiburg health office requested help from the RKI in the investigation to assess the magnitude of the outbreak and identify potential vehicle(s) and risk factors for transmission in order to better control the outbreak."
  },
  {
    "objectID": "pages/stegen-en.html#the-study",
    "href": "pages/stegen-en.html#the-study",
    "title": "An Outbreak of Gastroenteritis in Stegen, Germany (ENG)",
    "section": "The study",
    "text": "The study\nCases were defined as any person who had attended the party at St Sebastian High School who suffered from diarrhoea (≥ 3 loose stool for 24 hours) between 27 June and 29 June 1998; or who suffered from at least three of the following symptoms: vomiting, fever ≥38.5°C, nausea, abdominal pain, and headache.\nStudents from both schools attending the party were asked through phone interviews to provide names of persons who attended the party.\nOverall, 291 responded to enquiries and 103 cases were identified (attack rate: 35%). Among these cases, 84 (82%) received medical treatment and four were admitted to hospitals. Attack rates by age group were 36.6% for persons &lt;20 years, 32.1% for persons 20 to 29 years, and 36.8% for persons older than 29 years.\n\n\n\nFigure 1: Cases of gastroenteritis by time of onset among attendees of a high-school graduation ceremony (n=103), Germany, June 1998\n\n\nQUESTION 1. What would be your hypothesis concerning the source of the outbreak?\n\n\nClick to see the solution\n\n\nThe shape of the epidemic curve and the attendance to a single event (a buffet) pointed towards a foodborne outbreak related to a point source of infection.\n\n\nQUESTION 2. What study design would you choose to test this hypothesis?\n\n\nClick to see the solution\n\n\nUsing the updated list of attendants, a retrospective cohort study including all attendants to the party (that could be reached) was conducted. All had received a standard questionnaire asking for demographic information, signs, symptoms and duration, admission to hospital, and food and beverages consumption at the party including amount consumed. Food-specific attack rates were computed for more than 50 food items and beverages.\n\n\nQuestion 3. What would your overall plan of analysis be?\n\n\nClick to see the solution\n\n\nPerform data cleaning\n\nFor each variable, look at the range, unexpected and missing values.\nCorrect data using the original forms used if needed\n\nDescribe each variable\n\nFor each variable, describe frequency distributions including missing values and, if needed, means, median, modes, quartiles, standard deviation, outliers\nMake appropriate histograms and box plots\nChoose relevant characteristics to describe the population\n\nIdentify the outbreak vehicle if any\n\nCalculate food-specific attack rates\nLook at the proportions of cases exposed\nChose the appropriate measure of association\nChose the appropriate statistical tests and significance level\nCalculate the percentages of cases exposed to each exposure\nSearch for any dose-response relationship if appropriate\nInterpret the results\n\nPerform a stratified analysis\n\nIdentify the variables that are potential effect modifiers (EM) and confounders\nDesign appropriate stratification tables\nStratify on each level taken by the EM and confounders\nCompute appropriate measurements to identify confounding and effect modification\nConduct appropriate statistical tests\nInterpret the results\n\nPerform a multivariable analysis\n\nThis will be discussed during the module."
  },
  {
    "objectID": "pages/under_construction.html",
    "href": "pages/under_construction.html",
    "title": "Under-construction case study page",
    "section": "",
    "text": "Under-construction case study page\n\n\n\n\n\n\nWEBSITE UNDER CONSTRUCTION\n\n\n\nThis case study is being developed. The content and URL will change.\n\n\nFor instructions on how to use our case studies, see our How-to Guide. We welcome feedback and suggestions via contact@appliedepi.org. You can also discuss the case study or related concepts on the Applied Epi Community."
  },
  {
    "objectID": "pages/fulton.html",
    "href": "pages/fulton.html",
    "title": "Fulton (EN)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\nName\nFulton County\n\n\nLanguage\nEnglish\n\n\nTool\nR\n\n\nLocation\nUnited States\n\n\nScale\nLocal\n\n\nDiseases\nCOVID-19\n\n\nKeywords\nCOVID-19; SARS-COV-2; Outbreak\n\n\nTechnical complexity\nIntermediate\n\n\nMethodological complexity\nBasic\n\n\n\nAuthorship\nOriginal authors: Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer\nData source: Anonymised and jittered data provided by Fulton County for training purposes\nAdapted by: Alberto Mateo Urdiales to the case study template\n\n\n\n\n\n\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\nHere is what the “helpers” look like:\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\n\n… description here about posting in Community…\n\n\n\nXXXXXXXXXXXXXXXXXXXXX\n\n\n\n\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\n\nThe first version was written by Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer in August 2021.\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nMar 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is a an example R-markdown script which demonstrates how to create an automated outbreak situation report for COVID-19 in Fulton county, USA. The data used comes from an anonymised and fake (scrambled) linelist of COVID-19 cases in Fulton county from the beginning of the pandemic (early 2020) until July 2021.\nThe overall objective is to create an automatic and dynamic report that shows the COVID-19 epidemiological situation in Fulton County.\nIn this case study you will learn:\n\nHow to import, clean and analyse your data.\n\nCarry out descrptive analysis by time, place and person.\n\nUse the above to create an automatic and dynamic report in word using Rmarkdown.\n\n\nFor the purpose of the case study we separate this by descriptive analysis and visualisation (normally this would be mixed together of course). The visualisation section is organised in to place, time and person. This is to simplify flow for didactic delivery.\nAnalysis is loosely based off the monthly epidemiology reports for Fulton county\n\n\n\n\nUsers should have some prior experience with R, including:\n\nR basics: Several packages are required for different aspects of analysis with R. You will need to install these before starting. We install and load packages using the {pacman} package. Its p_load() command will install packages if necessary and load them for use in the current session. This might prove difficult if you have limited administrative rights for your computer. Making sure your IT-department gives you the correct access can save a lot of headache. See this handbook pages on the basics of installing packages and running R from network drives (company computers) for more detail. https://epirhandbook.com/r-basics.html#installation https://epirhandbook.com/r-on-network-drives.html#r-on-network-drives\nR projects: See Chapter 6 R Projects from the EpiRhandbook\nImport and export of data: See Chapter7 Import and export\n\n\n\n\n\nDownload folder fulton_en and extract contents in the local laptop\nOpen the Rstudio project inside the folder called fulton_en.Rproj\nInside the folder you can find the Rmd and the word output (weekly report). You can also find a word template that will be used as the template for the report. The Rmd and the output are there to help you if you struggle, but you should try to recreate these yourself following this case study.\nSubfolder data contains fulton COVID-19 data needed for the analysis\nSubfolder solution_materials has a copy of the Rmd document with the solution and a copy Word document with the output requested\nOpen a new Rmarkdown file in RStudio and save it in the root folder fulton_en. If you have any doubts about how to create an Rmarkdown follow the EpiRhandbook instructors here\nThis Rmarkdown file will be the file used throughout the case study and, rendering it will produce the weekly report in word format"
  },
  {
    "objectID": "pages/fulton.html#overview",
    "href": "pages/fulton.html#overview",
    "title": "Fulton (EN)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\nName\nFulton County\n\n\nLanguage\nEnglish\n\n\nTool\nR\n\n\nLocation\nUnited States\n\n\nScale\nLocal\n\n\nDiseases\nCOVID-19\n\n\nKeywords\nCOVID-19; SARS-COV-2; Outbreak\n\n\nTechnical complexity\nIntermediate\n\n\nMethodological complexity\nBasic\n\n\n\nAuthorship\nOriginal authors: Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer\nData source: Anonymised and jittered data provided by Fulton County for training purposes\nAdapted by: Alberto Mateo Urdiales to the case study template"
  },
  {
    "objectID": "pages/fulton.html#instructions",
    "href": "pages/fulton.html#instructions",
    "title": "Fulton (EN)",
    "section": "",
    "text": "There are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\nHere is what the “helpers” look like:\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\n\n… description here about posting in Community…\n\n\n\nXXXXXXXXXXXXXXXXXXXXX\n\n\n\n\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\n\nThe first version was written by Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer in August 2021.\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nMar 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is a an example R-markdown script which demonstrates how to create an automated outbreak situation report for COVID-19 in Fulton county, USA. The data used comes from an anonymised and fake (scrambled) linelist of COVID-19 cases in Fulton county from the beginning of the pandemic (early 2020) until July 2021.\nThe overall objective is to create an automatic and dynamic report that shows the COVID-19 epidemiological situation in Fulton County.\nIn this case study you will learn:\n\nHow to import, clean and analyse your data.\n\nCarry out descrptive analysis by time, place and person.\n\nUse the above to create an automatic and dynamic report in word using Rmarkdown.\n\n\nFor the purpose of the case study we separate this by descriptive analysis and visualisation (normally this would be mixed together of course). The visualisation section is organised in to place, time and person. This is to simplify flow for didactic delivery.\nAnalysis is loosely based off the monthly epidemiology reports for Fulton county\n\n\n\n\nUsers should have some prior experience with R, including:\n\nR basics: Several packages are required for different aspects of analysis with R. You will need to install these before starting. We install and load packages using the {pacman} package. Its p_load() command will install packages if necessary and load them for use in the current session. This might prove difficult if you have limited administrative rights for your computer. Making sure your IT-department gives you the correct access can save a lot of headache. See this handbook pages on the basics of installing packages and running R from network drives (company computers) for more detail. https://epirhandbook.com/r-basics.html#installation https://epirhandbook.com/r-on-network-drives.html#r-on-network-drives\nR projects: See Chapter 6 R Projects from the EpiRhandbook\nImport and export of data: See Chapter7 Import and export\n\n\n\n\n\nDownload folder fulton_en and extract contents in the local laptop\nOpen the Rstudio project inside the folder called fulton_en.Rproj\nInside the folder you can find the Rmd and the word output (weekly report). You can also find a word template that will be used as the template for the report. The Rmd and the output are there to help you if you struggle, but you should try to recreate these yourself following this case study.\nSubfolder data contains fulton COVID-19 data needed for the analysis\nSubfolder solution_materials has a copy of the Rmd document with the solution and a copy Word document with the output requested\nOpen a new Rmarkdown file in RStudio and save it in the root folder fulton_en. If you have any doubts about how to create an Rmarkdown follow the EpiRhandbook instructors here\nThis Rmarkdown file will be the file used throughout the case study and, rendering it will produce the weekly report in word format"
  },
  {
    "objectID": "pages/fulton.html#step-1-rmarkdown-set-up",
    "href": "pages/fulton.html#step-1-rmarkdown-set-up",
    "title": "Fulton (EN)",
    "section": "Step 1: Rmarkdown set up",
    "text": "Step 1: Rmarkdown set up\nRemember that this case study is created in Rmarkdown and that code goes within “chunks”, which is different from a standard R script. The first steps will be to define the language in which you want the report, the default chunk options and to install/load the necessary packages.\n\nStep 1.1: Define R language\nDepending on where you are and how to carried out R installation, your language “locale” might be different from the language of the report that you want to produce. For example, a french person might have a french “locale”. If that is the case, when creating a graph by day of the week, Monday will be displayed as “lundi”. If that french person wants to create an English report, as for this case study, the language “locale” should be changed.\nTask: Ensure your “locale” is in English and change it into English if it is not.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# To see your language locale\nSys.getlocale()\n\n# To change it into English\nSys.setlocale(\"LC_ALL\", \"English\")\n\n\n\n\n\nStep 1.2: Default chunk options\nChange the default chunk options of your Rmarkdown script to:\n\nhide all code chunks in the report\ndo not show messages or warnings\nshow errors if they appear, but to not stop the rendering\nset up the default figure width to 7 and the figure height to 6\nto show the figure titles on top of the plots by default\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# hide all code chunks in the output, but show errors \nknitr::opts_chunk$set(echo = FALSE,  # hide all code chunks in output\n                      error = TRUE,  # show errors if they appear, but don't stop (produce the word doc)\n                      warning = FALSE, # do not show warnings in the output word doc \n                      message = FALSE, # do not show  messages in the output word doc\n                      fig.width = 7,         # Figure width\n                      fig.height = 6,        # Figure height\n                      fig.topcaption = TRUE  # show figure titles on top of plot\n                     )\n\n\n\n\n\nStep 1.3: Install/load packages\nInstall the following packages that will be needed to carry out the analysis: officedown, officer, rio, here, skimr, janitor, lubridate, epikit, tidyverse, flextable, sf, scales, gtsummary, labelled, ggspatial, patchwork, apyramid and incidence2.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  officedown, # format MS word document output\n  officer,    # add table of contents to output\n  rio,        # importing data  \n  here,       # relative file pathways \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # age_categories() function\n  flextable,  # converting tables to pretty images\n  sf,         # manage spatial data using a Simple Feature format\n  scales,     # define colour schemes for flextables \n  gtsummary,  # summary statistics, tests and regressions \n  labelled,   # create variable labels to be displayed in table outputs\n  ggspatial,  # basemaps and scalebars \n  patchwork,  # combining multiple ggplots \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n\n)"
  },
  {
    "objectID": "pages/fulton.html#step-2-data-import-and-exploration",
    "href": "pages/fulton.html#step-2-data-import-and-exploration",
    "title": "Fulton (EN)",
    "section": "Step 2: Data import and exploration",
    "text": "Step 2: Data import and exploration\n\nStep 2.1: Data import\n\nImport the COVID-19 linelist called covid_example_data.xlsx that can be found in the following path: data/covid_example_data/.\nImport also the csv files named fulton_population.csv found in data/covid_example_data needed to retrieve the population in Fulton County.\n\n\n\nClick to see a solution code (try it yourself first!)\n\n\n\nlinelist_raw &lt;- rio::import(\n  file = here::here(\"data\", \"covid_example_data\", \"covid_example_data.xlsx\"),\n  which = \"in\"\n)\n\n# import population data by zipcode to calculate incidence\npop &lt;- import(\n     here(\"data\", \"covid_example_data\", \"fulton_population.csv\")\n)\n\n\n\n\n\nStep 2.2: Data exploration\nExplore the linelist to understand better the data.\n\nQuestion 2.1: How many rows are present in linelist_raw?\n\n 48 31 82101 5\n\nQuestion 2.2: How many columns are of class numeric?\n\n 8 4 19 31\n\n\n\n\nClick to see a solution code (try it yourself first!)\n\n\n\n# view your whole dataset interactively (in an excel style format)\nView(linelist_raw)\n\n# get mean, median and max values of numeric variables; counts for categorical variables and NAs with summary\nsummary(linelist_raw)\n\n# get information about each variable in a dataset \nskim(linelist_raw)\n\n# view unique values contained in variables - useful for categorical variables\nunique(linelist_raw$case_gender)"
  },
  {
    "objectID": "pages/fulton.html#step-3-data-cleaning",
    "href": "pages/fulton.html#step-3-data-cleaning",
    "title": "Fulton (EN)",
    "section": "Step 3: Data cleaning",
    "text": "Step 3: Data cleaning\n\nStep 3.1: Create date objects\nCreate an object called surveillance_date defined as 7 days prior to the reporting date (30 June 2021). Then, create another object rounding it to the closest Wednesday. Create two daily sequences of dates, one as the 14 days prior to the surveillance_date and another as 14-28 days prior to the same date. We will use these throughout the case study\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# create a date object for the surveillance\n# Minus 7 days from the date of report (see YAML) to account for lag in reporting lab results\nsurveillance_date &lt;- as.Date(\"2021-06-30\") - 7\n\n# create an epiweek object from the date \n# floor_date() rounds down to the closest week here\nsurveillance_week &lt;- floor_date(surveillance_date,\n                          # round by weeks\n                          unit = \"week\", \n                          # define week to start on Wednesday\n                          week_start = 3)\n\n# define recent (past 14 days) and previous (28 to 14 days prior)\nrecent_period   &lt;- seq(surveillance_week  - 13, surveillance_week, by = 1)\nprevious_period &lt;- seq(surveillance_week  - 27, surveillance_week - 14, by = 1)\n\n# define a text label of date range for the recent period (for table headers)\nrecent_period_labels &lt;- str_glue(\n  format(min(recent_period), format = \"%m/%d\"), \n  \"-\", \n  format(max(recent_period), format = \"%m/%d\")\n)\n\n# define text label of date range for previous period (for table headers) \nprevious_period_labels &lt;- str_glue(\n  format(min(previous_period), format = \"%m/%d\"), \n  \"-\", \n  format(max(previous_period), format = \"%m/%d\")\n)\n\n\n# define a label for past 28 days (for table captions)\nfull_period_labels &lt;- str_glue(\n  format(min(previous_period), format = \"%B %d\"), \n  \"-\", \n  format(surveillance_week, format = \"%B %d, %Y\")\n)\n\n\n\n\n\nStep 3.2: Clean column names\nClean the column names ensuring that names do not contain special characters. Rename the following columns from the raw data:\n\nDate of report (reprt_creationdt_FALSE) to date_report\nDate of birth (case_dob_FALSE) to date_dob\nDate of symptom onset (sym_startdt_FALSE) to date_onset\nDate of positive testing (pos_sampledt_FALSE) to date_positive\nDate of recovery (sym_resolveddt_FALSE) to date_recovery\nDate of hospitalisation (hosp_admidt_FALSE) to date_hospitalized\nDate of discharge (hosp_dischdt_FALSE) to date_discharge\nDate of death (died_dt_FALSE) to date_died\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist_raw %&gt;% \n     clean_names() %&gt;% \n     # NEW name = OLD name\n  rename( \n    date_report         = reprt_creationdt_false,      \n    date_dob            = case_dob_false,              \n    date_onset          = sym_startdt_false,\n    date_recovery       = sym_resolveddt_false, \n    date_hospitalized   = hosp_admidt_false,\n    date_discharge      = hosp_dischdt_false,\n    date_died           = died_dt_false,\n    date_positive       = pos_sampledt_false\n    )\n\n\n\n\n\nStep 3.3: Remove duplicated rows\nRemove rows that have duplicated information on: patient id, gender and date of birth. Keep duplicates in a separate dataframe.\n\n\n Click to read a hint\n\n\nTo store duplicates in a new dataframe you can use the function get_dupes() from the {janitor} package\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# get a data frame of all the duplicates. This is mostly to inspect manually, but can be used for analysing those dropped\nduplicates &lt;- linelist %&gt;% \n     get_dupes(pid, case_gender, date_dob)\n\n# find duplicates based on unique ID, gender and date of birth. Only keep the first occurrence \nlinelist &lt;- linelist %&gt;% \n  distinct(pid, case_gender, date_dob, .keep_all = TRUE)\n\n\n\n\nQuestion 3.2: How many duplicated rows were present in the raw data?\n\n 28 31 38 124\n\n\n\n\nStep 3.4: Change column class and remove data inconsistencies\nUsing the across() function from {dplyr} make the following:\n\nEnsure that dates are considered dates by R\nClean date columns dealing with values that are not compatible with the period under analysis (early 2020 to July 2021)\nMake the column age of numeric class\nSet us NA those with negative ages and missing Date of birth\nMake the zip code column a factor class column\n\n\n\n Click to read a hint\n\n\nThe across() allows to apply the same modification to multiple columns in an easy way. So, these two options are equivalent:\n\n# Without across()\n\nlinelist &lt;- linelist %&gt;% \n  mutate(date_report = as.Date(date_report)) %&gt;% \n  mutate(date_dob = as.Date(date_dob)) %&gt;% \n  mutate(date_onset = as.Date(date_onset)) %&gt;% \n  mutate(date_hospitalized = as.Date(date_hospitalized)) %&gt;% \n  mutate(date_discharge = as.Date(date_discharge)) %&gt;% \n  mutate(date_died = as.Date(date_died)) %&gt;% \n  mutate(date_positive = as.Date(date_positive))\n\n\n# With across()\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = contains(\"date\"), .fns = ~as.Date(.x)))\n\nYou can read more about across() in the EpiRhandbook section\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(\n    .cols = contains(\"date\"),\n    .fns = ~as.Date(.x)\n  )) %&gt;%\n  \n  # mark as missing onset dates prior to 2020\n  mutate(across(\n    .cols = c(date_report, date_onset, date_hospitalized, date_discharge, date_died),\n    .fns  = ~replace(.x, .x &lt; as.Date(\"2020-01-01\"), NA)\n    )) %&gt;% \n\n  # mark as missing dates after the surveillance_date (for this report) from all date columns\n  mutate(across(\n    .cols = contains(\"date\"),\n    .fns  =  ~replace(.x, .x &gt; surveillance_date, NA)\n    )) %&gt;%\n     \n  # transform age into numeric class\n  mutate(\n    # ensure that age is a numeric variable\n    case_age = as.numeric(case_age),\n    # set those with negative ages and missing DOB to missing \n    # otherwise just leave the age value as is\n          # nb. NA_real_ just ensures the variable class is not changed\n    case_age = if_else(case_age &lt; 0 & is.na(date_dob), NA_real_, case_age)\n  ) %&gt;% \n     \n  # create a factor from a default numeric class\n  mutate(case_zip = as_factor(case_zip)) \n\n\n\n\nQuestion 3.3: Which one of the following could NOT be used to transform the column sym_startdt_FALSE from the raw data frame into a date object?\n\n base::as.Date() lubridate::as_date() lubridate::ymd() lubridate::dmy()\n\n\n\n\nStep 3.5: Create a column for weeks\nCreate a column named “epiweek” using the function floor_date() from the {lubridate} package rounding the report date to the nearest week, taking “Wednesday” as the start of the week.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n  # create an \"epiweek\" column from the report date. Use floor_date() to round down to the closest week\n  mutate(epiweek = floor_date(date_report,\n                          # round by weeks\n                          unit = \"week\", \n                          # define week to start on Wednesday\n                          week_start = 3)\n  )\n\n\n\n\n\nStep 3.6: Create time difference columns\nIn this step we ask you to create columns with various time differences that will be used later on in the case study. Please, try to create:\n\nA column with the number (numeric) of days from date of symptom onset to the date of hospitalization\nIn this new column, set as missing those cases where the difference is longer than 30 days (interval is too long for the hospitalization to be due to the infection), and those less than 0 (cannot be hospitalized before the symptom onset)\nUsing the function coalesce() from {dplyr} create a new column for the date of outcome among hospitalized cases, using date of death or date of discharge, depending on whether cases died or not\nCreate a new column with the length of hospitalization in days, calculated as the time difference between date of hospitalization and the recently created date of outcome.\nIn this newly created column mark as missing cases in which the difference between the date of hospitalization and the date of death/discharge was longer than 60 days or lower than 0 days\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;%\n     \n  # delay from onset to hospitalization\n  mutate(\n    # calculate time differences\n    days_onset_hosp = as.numeric(date_hospitalized - date_onset),\n    # set those under 0 or over 30 to missing\n    days_onset_hosp = replace(days_onset_hosp, days_onset_hosp &lt; 0, NA),\n    days_onset_hosp = replace(days_onset_hosp, days_onset_hosp &gt; 30, NA)\n  ) %&gt;%\n     \n  # length of hospitalization\n  mutate(\n    # create outcome date based on whether died or was discharged\n    date_outcome = coalesce(date_died, date_discharge),\n    # calculate time difference\n    days_hosp = as.numeric(date_outcome - date_hospitalized),\n    # set those under 0 or over 60 to missing\n    days_hosp = replace(days_hosp, days_hosp &lt; 0, NA),\n    days_hosp = replace(days_hosp, days_hosp &gt; 60, NA)\n  )\n\n\n\n\n\nStep 3.7: Create age groups\nCreate a column with 10 year age groups up until 70 (and 70+ afterwards) using the age_group() function from the package {epikit}. You can also use any other alternative\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;%\n     # create age group variable\n     mutate(\n       age_group = age_categories(case_age,\n        # define break points\n        c(0, 10, 20, 30, 40, 50, 60, 70),\n        # whether last break should be highest category\n        ceiling = FALSE\n     ))\n\n\n\n\n\nStep 3.8: Recode character/categorical columns\nRecode the following columns:\n\nIn the column named died_covid recode the category “Under Review” to “Unknown”\nIn the column named confirmed_case recode the category “Pending” to “Unknown”\nForce categorical columns to use consistent cases\nAcross character/factor columns recode the category “Unk” to “Unknown”\nAcross the different character/factor columns recode NA to “Unknown”\nIn the column named sym_resolved recode categories into “Yes”, “No” or “Unknown”\nTransform the gender column into a factor with these levels: “Female”, “Male” and “Unknown”\nTransform all columns that have the categories: “Yes”, “No” and “Unknown” into factors with the order of the levels as “Yes”, “No” and “Unknown”\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n     \n     # recode one value and leave the rest as they are \n     mutate(\n       died_covid = if_else(died_covid == \"Under Review\",\n                            \"Unknown\", died_covid), \n       confirmed_case = if_else(confirmed_case == \"Pending\", \n                                \"Unknown\", confirmed_case), \n     \n        # force categorical variables to use consistent cases (this can be done for others) \n        sym_myalgia = str_to_title(sym_myalgia),\n      ) %&gt;% \n     \n     #replace one value and leave the rest, across multiple variables\n      mutate(across(\n       .cols = c(contact_household, contains(\"sym_\")),\n       .fns  = ~if_else(.x == \"Unk\", \"Unknown\", .x)\n     )) %&gt;% \n     \n        # replace missing with \"Unknown\" where relevant \n     mutate(across(\n       .cols = c(case_gender, case_race, case_eth, case_zip,\n                 contact_id, contact_household, \n                 hospitalized, died, died_covid, confirmed_case,\n                 contains(\"sym_\"), age_group),\n       .fns  = ~fct_na_value_to_level(.x, level = \"Unknown\")\n     )) %&gt;% \n     \n          # recode with searching for string patterns \n     mutate(sym_resolved = case_when(\n          str_detect(sym_resolved, \"Yes\")     ~ \"Yes\", \n          str_detect(sym_resolved, \"No\")      ~ \"No\", \n          str_detect(sym_resolved, \"Unknown\") ~ \"Unknown\", \n          TRUE                                ~ \"Unknown\"\n     )) %&gt;% \n     \n      # set levels of a factor (define order)\n     mutate(case_gender      = fct_relevel(case_gender, \"Female\", \"Male\", \"Unknown\")) %&gt;% \n     \n          # set levels of all factors that are yes/no/unknown \n     mutate(across(\n          .cols = c(contact_household, hospitalized, died, died_covid,\n                    confirmed_case, contains(\"sym_\")), \n          .fns = ~fct_relevel(.x, \"Yes\", \"No\", \"Unknown\")\n     )) \n\n\n\n\n\nStep 3.9: Merge ethnicity and race\nThe linelist contains a column for ethnicity (case_eth) and a column for race (case_race). Create a new column merging information from these two existing columns. The new column should:\n\nContain a category “Hispanic, all races” when case_eth is “HISPANIC/LATINO”. For those cases where this condition is not met:\n\nShould have a category for those whose race is “Asian”, another for those whose race is “Black” and another for those whose race is “White”.\nCreate an “Other” category for the rest of races and an “Unknown” category for those with missing race\nEnsure all categories have consistent cases\n\nTransform the newly formed column into a factor with the “Unknown” category as the last level\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n          # create a composite category from race and ethnicitiy  \n     mutate(eth_race = case_when(\n          eth  == \"HISPANIC/LATINO\"                           ~ \"Hispanic, all races\", \n          race == \"ASIAN\"                                     ~ \"Asian, NH\", \n          race == \"BLACK\"                                     ~ \"Black, NH\",\n          race == \"WHITE\"                                     ~ \"White, NH\",\n      # find all instances of NATIVE (covers AMERICAN INDIAN/ALASKA NATIVE **AND** NATIVE HAWAIIAN/PACIFIC ISLANDER)\n          str_detect(race, \"NATIVE\")                          ~ \"Other, NH\",\n          race == \"OTHER\"                                     ~ \"Other, NH\", \n          TRUE                                                ~ \"Unknown\"\n     )) %&gt;% \n     mutate(eth_race = factor(eth_race, levels=c(\n          \"Black, NH\", \"White, NH\", \"Hispanic, all races\",\n          \"Asian, NH\", \"Other, NH\", \"Unknown\"\n     )))\n\n\n\n\nQuestion 3.4: A column that has ordinal data, what class should it have?\n\n logical character factor integer\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n\n\nStep 3.10: Filter data frame\nFilter the data to keep only confirmed cases whose date of report is not above the date of the report (June 30, 2021). Consider also keeping records with missing date of report.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n##############       FILTER     ##############        \n\n# store those which do not meet our filter criteria \ndropped &lt;- linelist %&gt;% \n     filter(confirmed_case != \"Yes\" |\n              date_report &gt; surveillance_date & \n                !is.na(date_report))\n\n\n# drop the cases that dont meet the criteria \nlinelist &lt;- linelist %&gt;% \n     filter(confirmed_case == \"Yes\" & \n              date_report &lt;= surveillance_date & \n                 !is.na(date_report))"
  },
  {
    "objectID": "pages/fulton.html#step-4-start-the-report-with-a-summary-of-the-findings",
    "href": "pages/fulton.html#step-4-start-the-report-with-a-summary-of-the-findings",
    "title": "Fulton (EN)",
    "section": "Step 4: Start the report with a summary of the findings",
    "text": "Step 4: Start the report with a summary of the findings\n\nWrite in rmarkdown three bullet points summarising the data we imported, showing the number of cases by the date of analysis, the number of hospitalisations and the number of deaths.\nWrite it in a dynamic way, so that the dates and numbers are updated automatically if you get a new updated dataset\n\n\n\nClick to see a solution (try it yourself first!)\n\n This is an example of how the code should look like in your rmarkdown file:"
  },
  {
    "objectID": "pages/fulton.html#step-5.-analysis-by-time",
    "href": "pages/fulton.html#step-5.-analysis-by-time",
    "title": "Fulton (EN)",
    "section": "Step 5. Analysis by time",
    "text": "Step 5. Analysis by time\n\nStep 5.1: Table weekly number of cases\nCreate a table with the number of cases per reporting week to see how the epidemic evolved by time in Fulton County\n\nQuestion 5.1: During which week do we observe the peak in cases by date of reporting?\n\n The week starting on March 02, 2021 The week starting on December 16, 2020 The week starting on January 13, 2021 The week starting on December 30, 2020\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# save a quick descriptive table of number of cases reported by week\nepiweek_table &lt;- linelist %&gt;% \n  # get counts and percentages \n  tabyl(epiweek) %&gt;% \n  # add the overall counts as a row\n  adorn_totals() %&gt;%  \n  # change from proportions to percentages (do not add a % sign)\n  adorn_pct_formatting(affix_sign = FALSE) \n\n# transform it into flextable for better visualisation\nepiweek_flextable &lt;- epiweek_table %&gt;% \n     qflextable()\n\n\n\n\n\nStep 5.2: Epicurve\nCreate an epicurve by reporting week, with the colour of the bins based on whether the cases were hospitalised or not\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n     # we first define the dataset to be used, the x axis which will be reporting week and the colour (fill) of the bins which will depend on hospitalisation outcome\nggplot(\n     data = linelist,\n     mapping = aes(\n          x = epiweek,\n          fill = hospitalized\n     )) + \n     \n     geom_histogram() + \n     \n     # we define that we want breaks by month and formated with scales::label_date_short()\n     scale_x_date(\n          date_breaks = \"month\",\n          labels = label_date_short()\n     ) +\n     \n     # we change the name of the different elements of the graph\n     labs(\n          x = \"\",\n          y = \"Weekly number of cases\",\n          fill = \"Hospitalised\",\n          caption = paste0(\"Data as of \", format(surveillance_date, \"%d %b %Y\"))\n          \n     ) + \n     \n     # we apply one of the predefined themes\n     theme_bw()"
  },
  {
    "objectID": "pages/fulton.html#step-6.-analysis-by-person",
    "href": "pages/fulton.html#step-6.-analysis-by-person",
    "title": "Fulton (EN)",
    "section": "Step 6. Analysis by person",
    "text": "Step 6. Analysis by person\n\nStep 6.1: Table with demographic information\nCreate a table summarising, with counts and percentages, the total cumulative number of cases and deaths, as well the cases and deaths notified in the last 28 days by demographic characteristics: sex, age and race.\n\nQuestion 6.1: In which age group do we observe the largest proportion of cumulative cases?\n\n 0-9 30-39 20-29 70+\n\nQuestion 6.2: In which race do we observe the largest proportion of deaths in the last 28 days?\n\n Black White Asian Hispanic\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# get counts tables for measures of interest \n############################################\n\n# we generate 3 summary tables and bind them together\n# summary demographic table for gender\ndem_gender &lt;- linelist %&gt;% \n  tabyl(gender) %&gt;% \n  select(Characteristic = gender, n, percent)\n\n# summary demographic table for age\ndem_age &lt;- linelist %&gt;% \n  tabyl(age_group) %&gt;% \n  select(Characteristic = age_group, n, percent)\n\n# summary demographic table for ethnicity and race\ndem_eth_race &lt;- linelist %&gt;% \n  tabyl(eth_race) %&gt;% \n  select(Characteristic = eth_race, n, percent)\n\n# bind all tables together\ntotal_cases &lt;- bind_rows(list(dem_gender, dem_age, dem_eth_race))\n\n# counts of new cases (last 28 days) \nrecent_cases &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter the linelist for dates on or after 28 days ago\n  .f = ~filter(linelist, \n          date_report &gt;= (surveillance_date - 28)) %&gt;% \n        # get counts based on filtered data\n        tabyl(.x) %&gt;% \n        # nb we dont keep the characteristic column because it would be duplicated\n        select(n_cases_recent = n,\n               perc_cases_recent = percent)\n  ) %&gt;%\n  bind_rows()\n\n# counts of total deaths \ntotal_deaths &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter for those who died \n  .f = ~filter(linelist, \n          died_covid == \"Yes\") %&gt;% \n        # get counts based on filtered data \n        tabyl(.x, show_na = TRUE) %&gt;%\n        select(n_deaths_total = n, perc_deaths_total = percent)\n  ) %&gt;% \n  bind_rows()\n\n# counts of new deaths (last 28 days)\nrecent_deaths &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter to those who died in the last 28 days\n  .f = ~filter(linelist, \n          died_covid == \"Yes\" & \n          date_died &gt;= (surveillance_date - 28)) %&gt;% \n        # get counts based on filtered data\n        tabyl(.x) %&gt;% \n        select(n_deaths_recent = n, perc_deaths_recent = percent) %&gt;% \n        # add in a variable column (used for colouring later) \n        mutate(variable = .x)\n  ) %&gt;% \n  bind_rows()\n\n\n# total counts for all of the above measures (not by demographic)\noverall &lt;- linelist %&gt;% \n  summarise(\n    # add in row label \n    Characteristic = \"Total\",\n    # counts of total cases \n    n_cases_total = n(),\n    # leave all percentages empty (would just be 100)\n    perc_cases_total  = NA, \n    # counts of new cases (last 28 days) \n    n_cases_recent = sum(date_report &gt;= (surveillance_date - 28)), \n    perc_cases_recent  = NA, \n    # counts of total deaths \n    n_deaths_total = sum(died_covid == \"Yes\"), \n    perc_deaths_total = NA, \n    # counts of new deaths (last 28 days)\n    n_deaths_recent = sum(died_covid == \"Yes\" & \n                          date_died &gt;= (surveillance_date - 28)),\n    perc_deaths_recent = NA, \n    # add in a variable column (used for colouring later) \n    variable = \"Overall\"\n  )\n\n\n# merge tables together \n#######################\n\n# combine all the demographic tables - side by side\ndemographics_counts &lt;- bind_cols(total_cases, recent_cases, total_deaths, recent_deaths) %&gt;% \n  # mutate each of the proportion columns to be percentages\n  mutate(across(\n    .cols = contains(\"perc\"),\n    .fns = ~round(.x * 100, digits = 1)\n    )) \n# add in the totals row at the top of the merged demographics table\ndemographics_counts &lt;- bind_rows(overall, demographics_counts)\n\n\n# define colour scheme \n######################\n\n# get the column numbers that are percentages (based on the name) \npercentage_cols &lt;- names(demographics_counts) %&gt;% \n  str_detect(\"perc\") %&gt;% \n  which()\n\n# define colour cut-offs for gender column \ngender_colours &lt;- scales::col_bin(\n  # choose colours \n  palette = c(\"#91CF60\", \"#FC8D59\"), \n  # choose min and max (range)\n  domain  = c(0, 100),\n  # choose how to split (in this case above and below 50)\n  bins    = 2\n)\n\n# define colour cut-offs for age column \nage_colours &lt;- scales::col_bin(\n  # choose colours\n  palette = c(\"#91CF60\",\"#FFFFBF\", \"#FC8D59\"),\n  # choose min and max (range)\n  domain  = c(0, 100), \n  # choose cut-off categories \n  bins    = c(0, 5, 20, 100)\n)\n\n# define colour cut-offs for ethnicity column \neth_colours &lt;- scales::col_bin(\n  palette = c(\"#91CF60\",\"#FFFFBF\", \"#FC8D59\"),\n  domain  = c(0, 100), \n  bins    = c(0, 10, 40, 100)\n)\n\n\n# create styled table  \n######################\n\ndemographics_counts %&gt;%\n  # initiate flextable to produce styled output table\n  flextable(\n    # retain variable column for formatting but do not display it\n    col_keys = names(demographics_counts)[-10]\n  ) %&gt;%\n  # redefine column names based on original names\n  set_header_labels(\n    \"n_cases_total\"       = \"Total Confirmed Cases\",\n    \"perc_cases_total\" = \"% of Total Cases\",\n    \"n_cases_recent\"       = \"Confirmed Cases past 28 days\",\n    \"perc_cases_recent\" = \"% of Confirmed Cases past 28 days\",\n    \"n_deaths_total\"       = \"Total Confirmed Deaths\",\n    \"perc_deaths_total\" = \"% of Total Deaths\",\n    \"n_deaths_recent\"       = \"Confirmed Deaths past 28 days\",\n    \"perc_deaths_recent\" = \"% of Confirmed Deaths past 28 days\"\n  ) %&gt;%\n  # move the header text to the centre\n  align(align = \"center\", part = \"header\") %&gt;%\n  # make header text bold\n  bold(part = \"header\") %&gt;%\n  # make the totals row bold (i.e. first row)\n  bold(i = 1, part = \"body\") %&gt;%\n  # fill in the cells\n  # choose the rows with gender counts\n  bg(i = ~variable == \"gender\",\n     # choose the columns with percentages in them\n     j = percentage_cols,\n     # fill in based on previous defined cut-offs\n     bg = gender_colours) %&gt;%\n  bg(i = ~variable == \"age_group\",\n     j = percentage_cols, bg = age_colours) %&gt;%\n  bg(i = ~variable == \"eth_race\",\n     j = percentage_cols, bg = eth_colours) %&gt;%\n  # add horizontal lines after the cells with totals and unknowns\n    # (short-cut to find row ending of each demographic variable)\n  hline(i = ~Characteristic %in% c(\"Total\", \"Unknown\")) %&gt;%\n  # add in footnotes for rows counting unknowns (reference in first column)\n  footnote(i = ~Characteristic == \"Unknown\", j = 1, part = \"body\", ref_symbols = c(\"a\"),\n           value = as_paragraph(\"Unknown includes cases not yet interviewed\")) %&gt;%\n  # add in footnote for deaths counts (ref in the header)\n  footnote(i = 1, j = c(6, 8), part = \"header\", ref_symbols = c(\"b\"),\n           value = as_paragraph(\"Deaths refer to all persons who had a positive PCR test result\n                                for Covid-19 and there is evidence that COVID-19 was the cause of\n                                death or a significant contributor to their death.\")) %&gt;%\n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\") %&gt;% \n  # decrease the fontsize in the header and body for aesthetic purposes in the document\n  fontsize(part = \"all\", size = 8)\n\n\n\n\n\nStep 6.2: Age pyramid\nCreate an age pyramid with the percentage of cases by age group and sex.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# prepare dataset\n\n# start a new dataframe (as dont want to overwrite the original)\nlinelist_2g &lt;- linelist %&gt;% \n  # update the gender and age_group columns\n  mutate(across(.cols = c(gender, age_group), \n                .fns = ~{\n                  # replace \"Unknown\" with NA\n                  .x = na_if(.x, \"Unknown\") \n                  # drop \"Unknown\" from the factor levels \n                  .x = fct_drop(.x)\n                }))\n\n# plot age pyramid \nage_pyramid(\n  data = linelist_2g,\n  age_group = \"age_group\",\n  split_by = \"gender\",\n  # Show as percentages of total cases\n  proportional = TRUE,\n  # remove guide line for mid-point\n  show_midpoint = FALSE) +\n  # set theme to basic \n  theme_minimal() +\n  # add labels \n  labs(\n    title = \"\",\n    subtitle = ,\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = \"Gender\",\n    # use str_glue to set dynamic captions \n    # {missing} is defined in the second argument below\n    caption = str_glue(\n      \"{missing} cases missing either age or gender are not shown. \\n Fictional COVID-19 data\",\n      missing = linelist_2g %&gt;%\n        filter(is.na(gender) | is.na(age_group)) %&gt;%\n        nrow()\n      )\n    )\n\n\n\n\n\nStep 6.3: Scatter plot\nCreate a scatter plot showing the relation between age and duration of hospital stay. Colour the points based on whether cases died or not.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n#################### C) SCATTER PLOT ####################\n# open a plot with the linelist data\nggplot(data = linelist) +\n  # add points \n  geom_point(\n    mapping = aes(\n      # plot age on the x and days hospitalised on the y axis \n      x = age,\n      y = days_hosp,\n      # color points by outcome\n      color = died),  \n    # all points 3x size\n    size = 3, \n    # opacity of 30% (i.e. relatively see-through)\n    alpha = 0.3) +      \n  # make the x and y axes start at the origin \n  scale_y_continuous(expand = c(0, 0)) + \n  scale_x_continuous(expand = c(0, 0)) + \n  # add in labels \n  labs(\n    x = \"Age (years)\",\n    y = \"Duration (days)\",\n    caption = \"Fulton COVID-19 data\",\n    color = \"Deceased\"\n    ) + \n     theme_bw()\n\n\n\n\n\nStep 6.4: Bar plot\nCreate a bar stacked bar plot showing the absolute number of cases by race and vital status\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# open a plot with the linelist data\nggplot(linelist) +\n  # add bars \n  geom_bar(\n    mapping = aes(\n      # plot the number of cases by ethnicity (ordered in reverse frequency)\n      x = fct_rev(fct_infreq(eth_race)),\n      # stack bars and colour by died (ordered in reverse frequency)\n      fill = fct_rev(fct_infreq(died))\n    )\n  ) +\n  # flip the x and y axes \n  coord_flip() +\n  # make the x axes start at the origin (nb axes flipped)\n  scale_y_continuous(expand = c(0, 0), \n                     # define where to label xaxis (nb axes flipped )\n                     breaks = seq(from = 0,\n                                  to = 35000,\n                                  by = 5000)) + \n  # add in labels \n  labs(\n    # set the axes titles (nb axes flipped)\n    x = \"Race and Ethnicity\",\n    y = \"Cases (n)\",\n    caption = \"Fictional COVID-19 data\",\n    fill = \"Deceased\"\n    ) + \n  # apply a defined theme\n     theme_bw()"
  },
  {
    "objectID": "pages/fulton.html#step-7.-analysis-by-place",
    "href": "pages/fulton.html#step-7.-analysis-by-place",
    "title": "Fulton (EN)",
    "section": "Step 7. Analysis by place",
    "text": "Step 7. Analysis by place\nCreate a table by zip code in which you show the incidence in the most recent 14 days period, the incidence in the previous 14 days period and the percentage change in incidence between these periods.\n\nQuestion 7.1: What is the change in incidence observed between periods in the zip code number 30337?\n\n +20% +36% -62.5% -25%\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n################### TABLE BY ZIP CODE\n\nzip_counts &lt;- linelist %&gt;% \n  group_by(zip) %&gt;% \n  # count cases in the appropriate period \n  summarise(\n    recent   = sum(date_report %in% recent_period),\n    previous = sum(date_report %in% previous_period)\n  ) %&gt;% \n  adorn_totals() %&gt;% \n  # a percentage change column and round the digits\n  mutate(\n    perc_change = round((recent - previous) / previous * 100, digits = 1)\n    )\n\n# extract population counts for each zip from the shapefile\nzip_pop &lt;- shapefile %&gt;% \n  # change to tibble (otherwise geo-data gets pulled with)\n  as_tibble() %&gt;% \n  # only keep zip code and population counts\n  select(ZipCode, Population) %&gt;% \n  # add a row with overall counts\n  adorn_totals()\n  \n# merge case counts and population counts\n# zip (or ZipCode in the shapefile) variable is the unique identifier\nzip_counts &lt;- left_join(zip_counts, \n                        zip_pop, \n                        by = c(\"zip\" = \"ZipCode\")\n                        ) %&gt;% \n  # calculate the incidence \n  mutate(across(\n      # for each period (recent and previous)\n      .cols = c(recent, previous), \n      # divide each variable by population (and round the outcome)\n      .fns = ~round(.x / Population * 10000, digits = 1), \n      # for each period create a new variable with _inc on the end\n      .names = \"{.col}_inc\"), \n    \n    # replace NAs in incidence with 0\n    across(\n      .cols = contains(\"inc\"),\n      .fns = ~replace_na(.x, 0)),\n    \n    perc_change = case_when(\n      # fix the outliers: set missing to 0 and infinity (divided by 0) to 100\n      is.na(perc_change)       ~ 0,\n      is.infinite(perc_change) ~ 100, \n      TRUE                     ~ perc_change\n    ))\n\n\n# choose colours to fill in cells  \nrow_colour &lt;- case_when(\n  # those less than zero will be green (decreasing cases)\n  zip_counts$perc_change &lt; 0 ~ \"#91CF60\", \n  # over zero red (increasing)\n  zip_counts$perc_change &gt; 0 ~ \"#FC8D59\", \n  # missing or zero orange\n  TRUE                       ~ \"#FFFFBF\")\n\n\nzip_counts %&gt;% \n  # keep the columns of interest and define order\n  select(zip, recent, recent_inc, previous, previous_inc, perc_change) %&gt;% \n  # initiate {flextable} to produce styled output table\n  flextable() %&gt;% \n  # fill in cells - choose the column and then pass our colour-scheme defined above\n  bg(j = \"perc_change\", \n     bg = row_colour\n     ) %&gt;% \n  # add in a header for labeling counts and incidence by period \n    # note the empty columns (\"\") to fit to the original table headers\n  add_header_row(\n    values = c(\"\", \n               str_c(\"Recent 14-day reporting period\\n\", recent_period_labels), \n               \"\", \n               str_c(\"Previous 14-day reporting period\\n\", previous_period_labels), \n               \"\", \n               \"Change between reporting periods\"\n               )) %&gt;% \n  # redefine column names based on original names\n    # note the different syntax to dplyr::select, here it is old_name = new_name\n  set_header_labels(\n    zip          = \"Zip Code\", \n    recent       = \"n\", \n    recent_inc   = \"Incidence\", \n    previous     = \"n\", \n    previous_inc = \"Incidence\", \n    perc_change  = \"%\"\n  ) %&gt;% \n  # combine the headers cells for the appropriate periods \n  # (i defines rows, j defines columns)\n  merge_at(i = 1, j = 2:3, part = \"header\") %&gt;% \n  merge_at(i = 1, j = 4:5, part = \"header\") %&gt;% \n  # move the header text to the centre\n  align(align = \"center\", part = \"header\") %&gt;% \n  # make header text bold \n  bold(part = \"header\") %&gt;% \n  # make the row with totals in it bold (i.e. the last row in the dataframe)\n  bold(i = nrow(zip_counts), part = \"body\") %&gt;% \n  # add in footnotes for variables (referencing the header cells)\n  footnote(j = c(3, 5), part = \"header\", ref_symbols = c(\"a\"),\n           value = as_paragraph(\"Incidence calculated as cases per 10,000 population by zip code\")) %&gt;% \n  footnote(j = 6, part = \"header\", ref_symbols = c(\"b\"),\n           value = as_paragraph(\"These reflect the percentage increase or decrease of new diagnoses \n                                between the 14 days preceding the past 7 days and the 14 days\n                                preceding that.\")) %&gt;% \n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\")"
  },
  {
    "objectID": "pages/fulton.html#step-8.-analysis-of-risk-factors-for-mortality",
    "href": "pages/fulton.html#step-8.-analysis-of-risk-factors-for-mortality",
    "title": "Fulton (EN)",
    "section": "Step 8. Analysis of risk factors for mortality",
    "text": "Step 8. Analysis of risk factors for mortality\n\nCreate a table in which you assess, with the appropriate statistical tests, whether the demographic characteristics of those dying from Covid-19 are significantly different from cases who did not die from it.\nFor each of the variables used in the table that you just created, carry out univariate regression using each demographic variable as the independent variable and the outcome (dead, not dead) as the dependent variables. Create a table with the estimates -alongside 95% CI - of the estimates.\n\n\nQuestion 8.1: According to the results of the univariate analysis, how was having a sore throat associated with mortality from Covid-19\n\n It was a risk factor for mortality It was a protective factor for mortality It was not associated with mortality Impossible to know\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# define a list of variables for looping over later\nsymptom_vars &lt;- linelist %&gt;% \n     # choose all columns that contain \"sym_\" in the name but exclude \"sym_resolved\"\n     select(c(contains(\"sym_\"), -sym_resolved)) %&gt;% \n     # pull the names out \n     names()\n\n# define variables of interest (save typing them out later) \ndescriptive_vars &lt;- c(\"gender\", \n                      \"age_group\",\n                      \"eth_race\",\n                      symptom_vars,\n                      \"hospitalized\",\n                      \"days_hosp\")\n\n# filter dataset  \nrf_data &lt;- linelist %&gt;% \n  # only keep variables of interest\n  select(died_covid, age, all_of(descriptive_vars)) %&gt;% \n  # set unknown back to NA for all factor variables\n  mutate(across(\n    .cols = where(is.factor),\n    .fns = ~fct_recode(.x, NULL = \"Unknown\"))) %&gt;% \n  # flip factor levels (so that the reference values are correct)\n  mutate(eth_race = fct_infreq(eth_race)) %&gt;% \n  mutate(gender = fct_relevel(gender, \"Female\", \"Male\")) %&gt;% \n  mutate(across(all_of(c(\"died_covid\", symptom_vars, \"hospitalized\")), \n                ~fct_relevel(.x, \"No\", \"Yes\")\n                )) %&gt;% \n  # only keep rows with complete data for all variables of interest\n  # note that this will drop rows where **ANY** of the listed variables are NA\n  drop_na(any_of(c(\"died_covid\", \"age\", descriptive_vars)))\n\n\n# define variable labels to show in output tables \nrf_data &lt;- rf_data %&gt;%\n  set_variable_labels(\n    died_covid = \"Died\",\n    age = \"Age (years)\",\n    gender = \"Gender\",\n    age_group = \"Age group (years)\",\n    eth_race = \"Ethnicity\",\n    sym_fever = \"Fever\",\n    sym_subjfever = \"Subjective fever\",\n    sym_myalgia = \"Myalgia\",\n    sym_losstastesmell = \"Loss taste/smell\",\n    sym_sorethroat = \"Sore throat\",\n    sym_cough = \"Cough\",\n    sym_headache = \"Headache\",\n    hospitalized = \"Hospitalized\",\n    days_hosp = \"Days in hospital\"\n  )\n\n\n\nrf_data %&gt;%\n  # keep variables of interest\n  select(died_covid, gender, eth_race, age, days_hosp) %&gt;%\n  # produce summary table and specify grouping variable\n  tbl_summary(\n    by = died_covid\n  ) %&gt;%\n  # specify what test to perform\n  add_p(\n    list(\n      all_continuous() ~ \"kruskal.test\",\n      eth_race ~ \"kruskal.test\",\n      all_dichotomous() ~ \"chisq.test\"\n    )\n  ) %&gt;%\n  # edit what the column headers say (using {gtsummary})\n  # nb. {n} automatically shows the number in that group and \\n is a linebreak\n  modify_header(update = list(\n    stat_1 ~ \"**Dead**\\n (N={n})\",\n    stat_2 ~ \"**Alive**\\n (N={n})\"\n  )) %&gt;%\n  # edit what it says in the footnote (using {gtsummary})\n  modify_footnote(update = list(\n    all_stat_cols() ~ \"n (%) for categorical;\\n median (IQR) for continuous\",\n    p.value ~ \"Pearson's Chi-squared test for dichotomous;\\n Kruskal-Wallis rank sum test for continuous and categorical\"\n  )) %&gt;%\n  # change to flextable format\n  as_flex_table() %&gt;%\n  # make header text bold (using {flextable})\n  bold(part = \"header\")\n\n###################### B) UNIVARIATE REGRESSION ANALYSIS ####################################\n\n\n# produce table with regression estimates\nregress_tab &lt;- rf_data %&gt;%\n  # drop variables not interested in \n  select(-age_group) %&gt;%\n  # produce univariate table\n  tbl_uvregression(\n    # define outcome variable\n    y = died_covid, \n    # define regression want to run (generalised linear model)\n    method = glm, \n    # define what type of glm want to run (logistic)\n    method.args = list(family = binomial), \n    # exponentiate to produce odds ratios (rather than log odds)\n    exponentiate = TRUE, \n    # do not show the overall counts (this is done in cross_tab below)\n    hide_n = TRUE,\n    ## uncomment this line if you want to not show reference rows\n    # show_single_row = c(symptom_vars, gender, hospitalized),\n    ## note: NULL at the end allows you to have a comma before a commented out row\n    NULL\n  )\n\n# produce table with counts by outcome (using the data fed to the regression above)\ncross_tab &lt;- regress_tab$inputs$data %&gt;%\n  tbl_summary(\n    # group by outcome \n    by = died_covid,\n    ## uncomment this line if you only want to show the \"Male\" row for gender\n    ## this would be run if you also uncommented the single_row in regression above\n    # value = list(gender ~\"Male\"),\n    ## show all levels (otherwise only shows the \"Yes\" level)\n    type = list(all_dichotomous() ~ \"categorical\"),\n    ## note: NULL at the end allows you to have a comma before a commented out row\n    NULL\n  )\n\n# combine tables \ntbl_merge(list(cross_tab, regress_tab)) %&gt;%\n  # edit what it says in the grouping headers \n  modify_spanning_header(update = list(\n    c(\"stat_1_1\",\"stat_2_1\") ~ \"Died\",\n    c(\"estimate_2\", \"ci_2\", \"p.value_2\") ~ \"Univariate regression\")\n    ) %&gt;% \n  # edit what it says in the footnote (using {gtsummary})\n  modify_footnote(update = list(\n    all_stat_cols() ~ \"n (%) for categorical;\\n median (IQR) for continuous\")\n    ) %&gt;% \n  # change to flextable format\n  as_flex_table() %&gt;%\n  # make header text bold (using {flextable})\n  bold(part = \"header\") %&gt;% \n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Epi Open Case Study Repository",
    "section": "",
    "text": "A case study is a fun, interactive way to learn—guiding you through real-life scenarios with tasks and questions. You’ll find a variety of topics, skill levels, and diseases below, most of which take just a few hours to complete. You can filter and order the rows to pick the one that fits you best. Click the link corresponding to your preferred language to open it up. The data used in the case studies is either generated or anonymized.\nFor more information on how to use the case studies, click the How-to Guide."
  },
  {
    "objectID": "index.html#welcome-to-our-open-case-study-repository",
    "href": "index.html#welcome-to-our-open-case-study-repository",
    "title": "Applied Epi Open Case Study Repository",
    "section": "",
    "text": "A case study is a fun, interactive way to learn—guiding you through real-life scenarios with tasks and questions. You’ll find a variety of topics, skill levels, and diseases below, most of which take just a few hours to complete. You can filter and order the rows to pick the one that fits you best. Click the link corresponding to your preferred language to open it up. The data used in the case studies is either generated or anonymized.\nFor more information on how to use the case studies, click the How-to Guide."
  },
  {
    "objectID": "index.html#about-us",
    "href": "index.html#about-us",
    "title": "Applied Epi Open Case Study Repository",
    "section": "About us",
    "text": "About us\nApplied Epi is a nonprofit organisation and grassroots movement of frontline epidemiologists from around the world. Your encouragement and feedback is most welcome:\n\nVisit our website and join our contact list\ncontact@appliedepi.org, tweet @appliedepi, or LinkedIn\nSubmit issues to our Github repository"
  },
  {
    "objectID": "pages/instructions.html",
    "href": "pages/instructions.html",
    "title": "How-to Guide",
    "section": "",
    "text": "Choose a case study that fits your training needs based on topic, complexity, and language—details are available on the homepage and at the top of each case study page.\nYou can complete the case study individually or in a group. If facilitating, guide the group through the sections. There’s no facilitator’s guide; all learning materials are on the case study page, including the scenario, data download, tasks, and interactive hints and solutions.\n\n\n\nAside from opening up the case study, you need to:\n\nHave the relevant program on your computer, like R or Microsoft Excel.\nOrganize yourself and put any related files in a project folder.\n\nFor projects using R, see more detail in the ‘New to RStudio Projects’? section below.\n\n\n\nThere are several ways to get help:\n\nLook for the hints and solutions. They look like this:\n\n\n\n Click to read a hint\n\nHere you will see a helpful hint!\n\n\n\nClick to see the solution\n\nHere you will see the solution! It will typically be the actual code or technical answer required for the task.\n\n# Example of a solution\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\n\n\nTake a look at the EpiRHandbook\nPost a question in Applied Epi Community with reference to this case study\n\n\n\n\nWe encourage open-source material and sharing for learning purposes. However, case studies will be covered by different licenses. Check the terms of use at the bottom of each case study to see if it is suitable for modification. If you have any questions, send us an email at contact@appliedepi.org.\n\n\n\nAll case studies are based on real or plausible scenarios. Some will use simulated data, while others will feature open-access or provided de-identified data. The type of data used will be clearly indicated at the start of each case study.\n\n\n\nWe recommend that you create an RStudio Project when working R. Check out the details below.\n\n\nIf this is your first time using R and RStudio, welcome! The Epidemiologist R Handbook or EpiRhandbook has a wealth of information to support you along the way. It has everything thing you need to get started with R basics, including installing and updating R and RStudio.\nIf you are new to RStudio, it might be a good idea to spend some time reviewing that page and others before trying out any case studies. Don’t forget that we also have free self-paced R tutorials if you’d like even more guidance and practice.\n\n\n\nOnce you are ready to start your case study project itself, choose a location on your computer to create a dedicated folder. Once you’ve decided on the best spot, set up a folder with the case study’s name to keep everything organized from the start.\nIn your case study folder, you should have a:\n\nsubfolder “scripts” to save any scripts related to the analysis\nsubfolder “data” which will contain the raw data you will use\nsubfolder “outputs” can be used to store any outputs (tables, graphs, documents) that are the result of the analysis\n\nMake sure your folders and subfolders are well-organised as this will save you a headache later!\n\n\n\nCreate an Rstudio project in the case study folder. If you are unsure on how to do that, read the EpiRhandbook on RStudio projects.\n\n\n\nOnce you have created an RStudio project, start a new R script with an appropriate name (example case_study_name) and save it in the subfolder “scripts”.\nIf you are familiar with R markdown, you may decide to use this type of file instead of a standard R script. See below for more instructions on using R markdown.\nNo matter what type of file you choose to use, make sure the purpose, date last updated, and author are written as comments at the top.\n\n#Purpose: To practice new skills using this case study\n#Author: Your Name\n#Date: Mmm dd, yyyy or whatever format you like best\n\n\n\n\nSome of our case studies use R markdown and the code goes within “chunks”, which is different from a standard R script. If you want to create a reproducible workflow, you need a place to save your code so you can run it again if you need to. You want all your files easily organised so you don’t get lost later on. You need to begin by setting the default chunk options.\nTypically, you want to change the default chunk options of your R markdown script to:\n\nhide all code chunks in the report\nnot show messages or warnings in the output\nshow errors if they appear, but to not stop the rendering\nset up the default figure width to 7 and the figure height to 6\nshow the figure titles on top of the plots by default\n\n\n# hide all code chunks in the output, but show errors \nknitr::opts_chunk$set(echo = FALSE,  # hide all code chunks in output\n                      error = TRUE,  # show errors if they appear, but don't stop (produce the word doc)\n                      warning = FALSE, # do not show warnings in the output word doc \n                      message = FALSE, # do not show  messages in the output word doc\n                      fig.width = 7,         # Figure width\n                      fig.height = 6,        # Figure height\n                      fig.topcaption = TRUE  # show figure titles on top of plot\n                     )\n\nBe sure to review Reports with R Markdown in the EpiRhandbook before jumping in!\n\n\n\nDepending on where you are and how you carried out R installation, your language “locale” might be different from the language of the report that you want to produce.\nFor example, a French-speaking person might have a French ‘locale’. If that is the case, when creating a graph by day of the week, “Monday” will be displayed as “lundi”. If that person wants to create an English report, as for this case study, the language ‘locale’ should be changed.\nTo ensure your ‘locale’ is set to English, use the following code:\n\n# To see your language locale\nSys.getlocale()\n\n# To change it into English\nSys.setlocale(\"LC_ALL\", \"English\")\n\n\n\n\nAt the start of every R project, you will need to install the necessary packages. We do this with the {pacman} package. Its p_load() command will install packages if necessary and load them for use in the current session. If a listed package has already been installed, it will just load it. Each case study specifies at the beginning what packages you need to have installed.\nYou can find more about installing/loading packages in the suggested packages section of the EpiRhandbook.\nExample code to install packages:\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\nIf this step is not working, you may have limited administrative rights for your computer. Making sure your IT-department gives you the correct access can save a lot of headache. See these EpiRhandbook pages on the basics of installing packages and running R from network drives (company computers) for more detail."
  },
  {
    "objectID": "pages/instructions.html#how-should-i-use-these-case-studies",
    "href": "pages/instructions.html#how-should-i-use-these-case-studies",
    "title": "How-to Guide",
    "section": "",
    "text": "Choose a case study that fits your training needs based on topic, complexity, and language—details are available on the homepage and at the top of each case study page.\nYou can complete the case study individually or in a group. If facilitating, guide the group through the sections. There’s no facilitator’s guide; all learning materials are on the case study page, including the scenario, data download, tasks, and interactive hints and solutions."
  },
  {
    "objectID": "pages/instructions.html#what-do-i-need-to-complete-a-case-study",
    "href": "pages/instructions.html#what-do-i-need-to-complete-a-case-study",
    "title": "How-to Guide",
    "section": "",
    "text": "Aside from opening up the case study, you need to:\n\nHave the relevant program on your computer, like R or Microsoft Excel.\nOrganize yourself and put any related files in a project folder.\n\nFor projects using R, see more detail in the ‘New to RStudio Projects’? section below."
  },
  {
    "objectID": "pages/instructions.html#how-can-i-get-help",
    "href": "pages/instructions.html#how-can-i-get-help",
    "title": "How-to Guide",
    "section": "",
    "text": "There are several ways to get help:\n\nLook for the hints and solutions. They look like this:\n\n\n\n Click to read a hint\n\nHere you will see a helpful hint!\n\n\n\nClick to see the solution\n\nHere you will see the solution! It will typically be the actual code or technical answer required for the task.\n\n# Example of a solution\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\n\n\nTake a look at the EpiRHandbook\nPost a question in Applied Epi Community with reference to this case study"
  },
  {
    "objectID": "pages/instructions.html#can-i-edit-this-case-study",
    "href": "pages/instructions.html#can-i-edit-this-case-study",
    "title": "How-to Guide",
    "section": "",
    "text": "We encourage open-source material and sharing for learning purposes. However, case studies will be covered by different licenses. Check the terms of use at the bottom of each case study to see if it is suitable for modification. If you have any questions, send us an email at contact@appliedepi.org."
  },
  {
    "objectID": "pages/instructions.html#where-do-the-case-studies-come-from",
    "href": "pages/instructions.html#where-do-the-case-studies-come-from",
    "title": "How-to Guide",
    "section": "",
    "text": "All case studies are based on real or plausible scenarios. Some will use simulated data, while others will feature open-access or provided de-identified data. The type of data used will be clearly indicated at the start of each case study."
  },
  {
    "objectID": "pages/instructions.html#new-to-rstudio-and-rstudio-projects",
    "href": "pages/instructions.html#new-to-rstudio-and-rstudio-projects",
    "title": "How-to Guide",
    "section": "",
    "text": "We recommend that you create an RStudio Project when working R. Check out the details below.\n\n\nIf this is your first time using R and RStudio, welcome! The Epidemiologist R Handbook or EpiRhandbook has a wealth of information to support you along the way. It has everything thing you need to get started with R basics, including installing and updating R and RStudio.\nIf you are new to RStudio, it might be a good idea to spend some time reviewing that page and others before trying out any case studies. Don’t forget that we also have free self-paced R tutorials if you’d like even more guidance and practice.\n\n\n\nOnce you are ready to start your case study project itself, choose a location on your computer to create a dedicated folder. Once you’ve decided on the best spot, set up a folder with the case study’s name to keep everything organized from the start.\nIn your case study folder, you should have a:\n\nsubfolder “scripts” to save any scripts related to the analysis\nsubfolder “data” which will contain the raw data you will use\nsubfolder “outputs” can be used to store any outputs (tables, graphs, documents) that are the result of the analysis\n\nMake sure your folders and subfolders are well-organised as this will save you a headache later!\n\n\n\nCreate an Rstudio project in the case study folder. If you are unsure on how to do that, read the EpiRhandbook on RStudio projects.\n\n\n\nOnce you have created an RStudio project, start a new R script with an appropriate name (example case_study_name) and save it in the subfolder “scripts”.\nIf you are familiar with R markdown, you may decide to use this type of file instead of a standard R script. See below for more instructions on using R markdown.\nNo matter what type of file you choose to use, make sure the purpose, date last updated, and author are written as comments at the top.\n\n#Purpose: To practice new skills using this case study\n#Author: Your Name\n#Date: Mmm dd, yyyy or whatever format you like best\n\n\n\n\nSome of our case studies use R markdown and the code goes within “chunks”, which is different from a standard R script. If you want to create a reproducible workflow, you need a place to save your code so you can run it again if you need to. You want all your files easily organised so you don’t get lost later on. You need to begin by setting the default chunk options.\nTypically, you want to change the default chunk options of your R markdown script to:\n\nhide all code chunks in the report\nnot show messages or warnings in the output\nshow errors if they appear, but to not stop the rendering\nset up the default figure width to 7 and the figure height to 6\nshow the figure titles on top of the plots by default\n\n\n# hide all code chunks in the output, but show errors \nknitr::opts_chunk$set(echo = FALSE,  # hide all code chunks in output\n                      error = TRUE,  # show errors if they appear, but don't stop (produce the word doc)\n                      warning = FALSE, # do not show warnings in the output word doc \n                      message = FALSE, # do not show  messages in the output word doc\n                      fig.width = 7,         # Figure width\n                      fig.height = 6,        # Figure height\n                      fig.topcaption = TRUE  # show figure titles on top of plot\n                     )\n\nBe sure to review Reports with R Markdown in the EpiRhandbook before jumping in!\n\n\n\nDepending on where you are and how you carried out R installation, your language “locale” might be different from the language of the report that you want to produce.\nFor example, a French-speaking person might have a French ‘locale’. If that is the case, when creating a graph by day of the week, “Monday” will be displayed as “lundi”. If that person wants to create an English report, as for this case study, the language ‘locale’ should be changed.\nTo ensure your ‘locale’ is set to English, use the following code:\n\n# To see your language locale\nSys.getlocale()\n\n# To change it into English\nSys.setlocale(\"LC_ALL\", \"English\")\n\n\n\n\nAt the start of every R project, you will need to install the necessary packages. We do this with the {pacman} package. Its p_load() command will install packages if necessary and load them for use in the current session. If a listed package has already been installed, it will just load it. Each case study specifies at the beginning what packages you need to have installed.\nYou can find more about installing/loading packages in the suggested packages section of the EpiRhandbook.\nExample code to install packages:\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\nIf this step is not working, you may have limited administrative rights for your computer. Making sure your IT-department gives you the correct access can save a lot of headache. See these EpiRhandbook pages on the basics of installing packages and running R from network drives (company computers) for more detail."
  },
  {
    "objectID": "pages/r_practical.html",
    "href": "pages/r_practical.html",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "Tool: R | Technical complexity: Basic | Methodological complexity: Basic\nSource: ECDC EI Group (simulated data)\nPrior knowledge required: R basics (Using Rstudio; R packages, functions and arguments, using pipes)\n\n\n\nFor instructions on how to use our case studies, see our How-to Guide. We welcome feedback and suggestions via contact@appliedepi.org. You can also discuss the case study or related concepts on the Applied Epi Community.\n\n\n\nIt is May 2022 and Mpox has just been reported for the first time across 5 countries in Europe: Countries “A”, “B”, “C”, “D”, and “E”. You have been requested to provide a basic descriptive analysis to the European Centre for Disease Prevention and Control (ECDC).\nYou are given access to:\n\nA dataset with aggregate case counts, submitted to ECDC by the five countries as part of routine European reporting\nA linelist with cases, submitted by the five countries to ECDC for this particular analysis\n\nLet’s go!\n\n\n\nIn this case study you will:\n\nExplore different types of files and how they can be imported in R.\nPerform basic data cleaning, e.g., changing the variable type, recoding variables, aggregating and filtering.\nPerform a basic descriptive analysis using tables and graphs\n\n\n\n\n\n\nStart by setting up a reproducible and well-organized workflow. This will make it easy to rerun your analysis whenever needed.\nTasks:\n\nSet up an RStudio project\nSet up clear sub-folders where your code, data, and outputs will go\nCreate an R script, or an R Markdown file if you prefer. Make sure the script purpose, date, and author are written as comments at the top.\nExtra: Ensure your working language in RStudio is appropriate (e.g. English for this exercise)\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\n\nCreate a folder where all the work in this case study will go. For example, create ‘mpox_analysis’ on your computer desktop. Create your RStudio project to be based in this folder.\nWe suggest creating the following sub-folders: scripts (for your code), data (for your data), and outputs (for your analytical outputs).\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nCreate a folder (e.g. ‘mpox_analysis’ on your Desktop) for your work. To create an Rstudio project in your new folder, click New Project… in the top left of your R Studio, then Existing Directory, then Browse to select your new folder. For more information, look at the R projects section of the Epi R Handbook.\nStart a new R script by clicking New File… in the top left of your R Studio, then R Script. Save it immediately in the appropriate place, e.g. in a ‘scripts’ subfolder of your R Project.\nAt the top of your new R script, write some essential information like your name, the purpose of the file, and the date.\nYour R locale determines the language and regional settings used for things like date formats and translations. If your locale is different from the language you want for your report (e.g., a French locale vs. an English report), you can change it to English by running Sys.setlocale(\"LC_ALL\", \"English\"). Include this in your script if needed, or skip it if your locale is usually appropriate. This is explained in more detail in the How-to Guide.\n\n\n\n\n\n\nNext in your R script, you need to install and load the necessary R packages. This ensures that the functions you need are available for your analysis.\nYou will need the following packages: rio (for importing data), janitor (for cleaning data), lubridate (for cleaning dates), skimr (for reviewing data), epikit (for epi-related tasks), gtsummary (for presentation-ready tables), apyramid (for age-sex pyramids), and tidyverse (for general data manipulation/science tasks).\nAs you start, your trusted colleague nudges you and whispers “I’ve heard that a great way to manage your packages is with the pacman package”.\nOver to you!\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse the function p_load() from pacman for this task. You provide the function with a list of packages that you want to use. It will take two steps per package: 1) Check if the package is installed on your computer, and install it if necessary, then 2) Load the package so it can be used during this R session.\nIf you don’t already have pacman installed, you will need to install it the “traditional way” first, with install.packages().\nNote that the order of packages in your p_load function can be important. If two packages have the same function names (e.g. select() in the package MASS and select() in tidyverse, which do different things), then R will use the function from the most recently loaded package. To prioritize functions from tidyverse, which are commonly used for data manipulation and visualization, load tidyverse last.\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\n\n\n\n\n\n\n\n\n\nECDC provides you with two files for your analysis, both updated as of 31st August 2022:\n\nA case-level linelist (“mpox_linelist.xlsx”) with case information from five countries (countries A - E)\nAn aggregate table (“mpox_aggregate_table.csv”) for those countries with cumulative case counts per day.\n\nThey provide it to you via AppliedEpi’s very useful data repository, which you can access using the {appliedepidata} package. So first you need to download these two files to your own computer, as follows:\n\nInstall the {appliedepidata} package from GitHub using the install_github() function in the {remotes} package. Install {remotes} if you need to first.\n\n\n# Install remotes if you need to (so you can install a package from GitHub)\npacman::p_load(\"remotes\")\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nSave the two datasets into a specific folder using the save_data() function from {appliedepidata}, by running the code below. The example below saves the data into a ‘data’ subfolder within the RStudio project. Note that if you do not specify a location within the ‘path’ argument of the function, a window will pop up asking you to manually select a folder.\n\n\n# Save down the two mpox files using the save_data() function from appliedepidata\nappliedepidata::save_data(\"mpox_linelist\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"mpox_aggregate_table\",\n                          path = \"data\")\n\n\n\n\nGreat! Thanks ECDC and Applied Epi! Now it’s time to import the data from that folder into RStudio, so you can analyse it.\nTask: Import the downloaded case-based and aggregated data into your R environment. Ideally you want to use one function for both datasets, despite one being a csv and the other an xlsx file.\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nUse the import function from the {rio} package, which can recognize and import different file types. It replaces importing functions that are specific to the file type, such as read.csv() from {base} for .csv files and read_excel() from {readxl} to import .xlsx files.\nIf you feel you need to know more about importing functions, read the Import and export chapter of the EpiRhandbook.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nBelow we use the import function to bring in both files. Note how we are assigning the imported data to two objects, one called mpox_linelist_raw, and one called mpox_agg_raw. We add the ‘raw’ suffix to distinguish this data from the cleaned versions we will make later.\n\n# Import data  --------------\n\n# Case-based data\nmpox_linelist_raw &lt;- import(\"data/mpox_linelist.xlsx\")\n\n# Aggregated data\nmpox_agg_raw &lt;- import(\"data/mpox_aggregate_table.csv\")\n\n\n\n\n\n\n\n\nThe data’s in, and now it’s time to see what story it tells. Take an initial look at your data to check its quality and how you can best use it.\nTasks: Take a look at the different data frames and determine:\n\nThe number of columns and observations (e.g. their dimensions)\nThe class of their columns and whether it matches its nature (e.g., are “dates” considered “dates” by R?)\nIf the contents of columns are clean and standardized in the mpox linelist (e.g. gender, clinical symptoms, outcome, hiv status and sexual orientation). Do you need to recode any of them?\nHow unknown or missing data is categorized in these columns. Do these values need to be standardized?\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nAn efficient function for initial data exploring is skim() from the {skimr} package, as it gives you a lot of information on data structure and content, including the classes of columns.\nYou can use the function tabyl() from {janitor}, to get counts and percentages of every category in the data column, one by one. These get printed to your RStudio console.\nAlso - we recommend just looking at the data itself! A good function for this is view(), a baseR function.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing the skim commands you can see the rows and columns of each dataset, and you can see how most of the columns in mpox_linelist_raw (including those containing dates) are character classes. (Results not shown on this exercise page)\n\n# Explore the dimensions of the two data objects \nskim(mpox_linelist_raw)\nskim(mpox_agg_raw)\n\nTake a look at the overall data using view(). It will pop up in the Data Viewer tab and you will get a good sense of how clean the data is and what the missingness is like. This preview shows just 5 rows from the linelist data.\n\nview(mpox_linelist_raw)\n\n\n\n\n\n\n\nBelow is an example of using the tabyl() function from {janitor}, to look at the distribution of clinical symptoms. You can see 12 cases have missing clinical information and that many cases have a mix of symptoms.\n\ntabyl(mpox_linelist_raw, HIVStatus)  \n\n HIVStatus   n percent valid_percent\n       NEG 525  0.2625     0.4107981\n       POS 307  0.1535     0.2402191\n       UNK 446  0.2230     0.3489828\n      &lt;NA&gt; 722  0.3610            NA\n\n\nYou can explore further columns one by one (results not shown):\n\n# Explore the values of different categorical columns in the mpox linelist: with tabyl\ntabyl(mpox_linelist_raw, Gender)\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms)\n\ntabyl(mpox_linelist_raw, Outcome)\n\ntabyl(mpox_linelist_raw, SexualOrientation)\n\nYou could add extra arguments to tabyl() to customize the tables, such as adding totals and changing the proportions to percentages so they are easier to read. See the table on clinical symptoms below. But remember - this is just an initial look so don’t go too crazy.\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms) %&gt;%    # Tabulate symptoms \n  adorn_totals() %&gt;%                              # Add totals to bottom of table\n  adorn_pct_formatting(digits = 2)                # Format percentages\n\n                 ClinicalSymptoms    n percent valid_percent\n                          Lesions   14   0.70%         0.70%\n                             Rash  257  12.85%        12.93%\n                    Rash, Lesions  323  16.15%        16.25%\n          Rash, Systemic symptoms  676  33.80%        34.00%\n Rash, Systemic symptoms, Lesions  654  32.70%        32.90%\n                Systemic symptoms   28   1.40%         1.41%\n       Systemic symptoms, Lesions   36   1.80%         1.81%\n                             &lt;NA&gt;   12   0.60%             -\n                            Total 2000 100.00%       100.00%\n\n\nFinally, as an alternative approach to tabyl(), you could use tbl_summary() from the {gtsummary} package. We will describe this later.\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nPaket ‘webexercises’ erfolgreich ausgepackt und MD5 Summen abgeglichen\nDie heruntergeladenen Binärpakete sind in C:6X8m_packages How many columns does the aggregated data have?\n\n 2000 13 3 101\n\n\n\nWhat is the class of the column DateOfNotification in the mpox linelist?\n\n Date Character Numeric Factor\n\n\n\nFor how many cases is the HIV status Unknown or missing?\n\n 1168 722 900 446\n\n\n\n\n\n\n\n\n\n\nSo! The good news: you have information on geography, dates, demographic characteristics, and clinical details. A promising descriptive analysis lies ahead.\nBUT! You may noticed that there are a few things to fix before the real detective work begins.\nFor example:\n\nColumn names have capital letters. This isn’t outright a problem, but can lead to mistakes since R treats ColumnName and Columnname as different.\nDate columns are recognized as character classes, not dates, which would cause issues like incorrect ordering (alphabetical) in epicurves.\nSome columns have values that are unclear or unsuitable for presentation. For example gender is categorized with “F”, “M”, “O” and “UNK”. The column Outcome is “A” and “UNK”.\nMissing data is inconsistently handled, for instance with both “UNK” and NA in the HIV status column. R thinks “UNK” is a valid value, which it treats differently to true missing data (indicated by NA)\n\nTasks:\n\nCreate a clean version of your case-based data making all cleaning changes in a single piping command\nChange all column names to lower case.\nConvert all date columns to class “Date”.\nConvert all missing/unknown values to NA (to be recognized by R as missing)\nRecode non-missing “Gender” categories into: “Female”, “Male”, and “Other”\nRecode non-misising HIV status into: “Positive”, “Negative” and “Unknown”\nRecode non-missing sexual orientation into: “Bisexual”, “Heterosexual”, and “MSM/homo or bisexual male”.\nRecode non-missing “outcome” categories into: “Alive” and “Dead”.\nCheck that all changes have been made correctly\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTo convert all column names to lower case at once rather than renaming each column, use the function clean_names() from the {janitor} package.\nUse {lubridate} functions to transform date columns into “Date” class. You can do this one by one, or you could do all at the same time using the across() function from {dplyr}. If you feel you need to know more about transforming dates read the chapter Working with Dates from the EpiRhandbook. If you are not sure how to use the across() function, you can also read the section on Transform multiple columns.\nThere are different functions that we can use to recode values. We propose three: The function recode() from {dplyr}, the function ifelse() from {base} and the function case_when() from {dplyr}. If you want to know more about these functions, look that the section on Re-code values from the EpiRhandbook.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere we clean the data using a ‘chain’ of commands connected by pipes (%&gt;%), which is the grammar of the functions in the {Tidyverse}. The output is assigned to a new object called mpox_linelist to differentiate it from the raw data. It can be helpful to have both the cleaned and raw data available in the environment to compare to the original data if needed.\nSee the series of functions and the explanation in the comments.\n\n# Create a new object called mpox_linelist which is the clean version of the raw data\nmpox_linelist &lt;- mpox_linelist_raw %&gt;% \n  \n  # standardises names and puts all into lower case \n  clean_names() %&gt;% \n  \n  #transform ONE column into date (note the column names are lower case now)\n  mutate(date_of_notification = ymd(date_of_notification)) %&gt;%  \n\n  #transforms ALL columns starting with \"date\" into dates\n  mutate(across(starts_with(\"date\"), \n                .fns = ~ ymd(.x))) %&gt;%  \n  \n  #transforms UNK to NA across all character columns \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x %in% c(\"UNK\", \"Unknown\"), NA_character_, .x)))  %&gt;% \n\n  # Recode the gender values to be more obvious  \n  mutate(gender = recode(gender,\n                         \"F\" = \"Female\",\n                         \"M\" = \"Male\",\n                         \"O\" = \"Other\")) %&gt;%\n  \n  #recode with ifelse to change only one or two categories based on a rule. \n  mutate(outcome = ifelse(outcome == \"A\", \"Alive\", outcome)) %&gt;%   \n  \n  #recode with case_when for more complex recoding \n  mutate(hiv_status = case_when(hiv_status == \"NEG\" ~ \"Negative\",    \n                                hiv_status == \"POS\" ~ \"Positive\")) %&gt;% \n  \n  mutate(sexual_orientation = case_when(sexual_orientation == \"BISEXUAL\" ~ \"Bisexual\",\n                                        sexual_orientation == \"HETERO\" ~ \"Heterosexual\",\n                                        sexual_orientation == \"MSM\" ~ \"MSM/homo or bisexual male\")) \n\nYou can then review your data by tabulating across all the different columns you have cleaned. See the preview of the HIV table below - it looks tidier now with more understandable categories, and all missing data is classified as ‘Unknown’.\n\n# Check that all changes have been made correctly\n\nskim(mpox_linelist)\n\ntabyl(mpox_linelist, gender)\n\ntabyl(mpox_linelist, clinical_symptoms)\n\ntabyl(mpox_linelist, outcome)\n\ntabyl(mpox_linelist, hiv_status)\n\ntabyl(mpox_linelist, sexual_orientation)\n\n\n\n hiv_status    n percent valid_percent\n   Negative  525  0.2625     0.6310096\n   Positive  307  0.1535     0.3689904\n       &lt;NA&gt; 1168  0.5840            NA\n\n\nIMPORTANT: If ‘unknown’ and NA had meaningful differences, combining them wouldn’t be appropriate (e.g., if ‘unknown’ meant the case was asked but didn’t want to respond, while NA meant they weren’t asked). Here, we assume no meaningful difference and want R to recognize them as missing.\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nIs it always appropriate to combine different types of unknown data? (e.g. missing, unknown, did not respond, NA)\n\n Yes Depends on the meaning of those values No - never do this\n\n\n\nHow many male cases do we have in the data frame?\n\n 36 1960 65 1523\n\n\n\nHow many cases have ‘alive’ as an outcome?\n\n 1405 None 595\n\n\n\n\n\n\n\n\nIn a similar way, clean the aggregated data by:\n\nStandardising names to lower case\nEnsuring that date of reporting is of class “Date”\nCreating a column called “week_date” with the week of reporting starting on Monday\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nWe can first check the class of the DateRep column, which shows us that it was already recognized as a date column on import.\n\n# Check class of date of reporting column\nclass(mpox_agg_raw$DateRep)\n\nThen create a new object for the clean aggregate data, and write your cleaning coded connected with pipes.\n\n# Create a new object called mpox_agg which is the clean version of the raw data, applying the cleaning functions\n\nmpox_agg &lt;- mpox_agg_raw %&gt;% \n  \n  # standardises names and puts all into lower case\n  clean_names() %&gt;%  \n  \n  # create week column with Monday start\n  mutate(week_date = floor_date(date_rep, \n                              unit = \"week\",\n                              week_start = \"Monday\")) \n\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nTake a look at the aggreate data. Which country reported the largest cumulative number of cases during the week 2022-04-11?\n\n Country A Country B Country C Country D Country E\n\n\n\n\n\n\n\n\n\nNow we’re getting to the heart of the investigation. Who is affected? Which locations are most affected, and how quickly is it spreading? Your ability to tell the classic “person, place, and time” story will be crucial to guiding the response. Pinpoint those hotspots and trends!\n\n\nTask: Using the mpox case linelist, create a table showing the total number of cases by country. This time, make the table more publication-friendly.\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nYou could use tabyl() like before, but an easy way to produce publication-ready tables is with the function tbl_summary() from {gtsummary} package. This formats the table for you. It will print to your Viewer rather than the console.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nCreate a new object with the table output - as this is a key output that you can then integrate into a document later rather than just viewing for now.\n\n# Create an object with the table\ncb_country_table &lt;- mpox_linelist %&gt;%\n\n  #select the column that we want to use in the table\n  select(country) %&gt;% \n  \n  # create the table. No need to specify columns; it will tabulate all available columns (selected above)\n  tbl_summary() \n\n# Print the table\ncb_country_table\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 2,0001\n\n\n\n\ncountry\n\n\n\n\n    CountryA\n816 (41%)\n\n\n    CountryB\n391 (20%)\n\n\n    CountryC\n474 (24%)\n\n\n    CountryD\n217 (11%)\n\n\n    CountryE\n102 (5.1%)\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nWhat country has the largest percentage of cases?\n\n Country C Country D Country B Country E Country A\n\n\n\n\n\n\n\n\nOkay so Country A has the most cases in total based on most recent data. But how does that change look over time?\nTasks:\n\nUsing the mpox case linelist, create an epicurve by week of notification\nUsing the mpox case linelist, create an epicurve by week of notification to enable a comparison of trends by country.\nUsing the mpox case linelist, create a heat plot with the number of cases by country and week of notification.\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nPrepare your data for the epicurve first. You can create a “week_date” column using the function floor_date() from {lubridate}. Take a look at the documentation to understand how it works and how to pick the starting day of the week.\nTo create the epicurve, you can use ggplot() and geom_bar(), which visualizes the number of rows within a group - e.g. number of cases per week. To compare trends in different countries, consider using the facet_wrap() function. If you are unsure on how ggplot() works, read the EpiRhandbook chapter on Epidemic curves.\nTo create a heatmap, you will need to create a table of counts by country and week of notification. You can do this using the functions group_by() and summarise() from {dplyr}. If you are unsure on how to do this, review the Grouping data chapter of the EpiRhandbook. Then, use the geom geom_tile() to create a heat plot. If you’re unsure on how to do this, read the EpiRhanbook section on Heat Plots\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nPrepare your data by creating the new column using mutate() and floor_date():\n\nmpox_linelist &lt;- mpox_linelist %&gt;% \n  # create week column with Monday start \n  mutate(week_date = floor_date(date_of_notification, unit = \"week\", week_start = \"Monday\")) \n\nThe code below creates an epicurve using ggplot() and the geom_bar() function, then applies further formatting. With geom_bar(), you only need to specify the x axis, and the function will visualize the number of rows per unique x axis value.\n\n# Open up the plot production with ggplot() function, specifying object and columns\nepicurve_mpox &lt;- ggplot(data = mpox_linelist,          \n                        aes(x = week_date)) +    \n  \n  geom_bar(fill=\"darkgreen\",                     #colour inside the bins\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  labs(title=\"Mpox cases reported in 2022 in Countries A, B, C, D, and E\",\n       subtitle = \"Date as of August 31st 2022\") +  #add a title\n  \n  theme_minimal() +                             #assign a predefined theme\n  \n  theme(axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n           \n# Print the epicurve\nepicurve_mpox\n\n\n\n\n\n\n\n\nTo examine how the outbreak spread by country, add facet_wrap() to your ggplot code. This splits the graph into multiple smaller ones. As shown below, you can even simply add the function to the national epicurve object.\nAn alternative approach would be to create a stacked epicurve, i.e. retain the single epicurve but split each bar into colors per country. You would do this by adding fill = country to the aes() in the epicurve code. However, we don’t recommend this for comparing trends, as stacked bars make it harder to see individual patterns.\n\nepicurve_epox_country &lt;- epicurve_mpox + \n \n   # Facet wrap to make mini-plots, specifying that you want two columns of plots. \n  facet_wrap(.~country,\n             ncol = 1) \n\n# Print the epicurve\nepicurve_epox_country\n\n\n\n\n\n\n\n\nFinally, if you want to demonstrate this as a weekly heatmap, you can use geom_tile(). First, aggregate the data by week. Then pipe into a ggplot(), as shown below.\n\n# Assign the output of your ggplot code to a new object\nhp_mpox &lt;- mpox_linelist %&gt;% \n  \n  #first count the number of cases by country and notification week\n  count(country, week_date) %&gt;% \n\n  #you can pipe directly into the ggplot\n    ggplot(aes(x = week_date, # notification week along the x axis\n           y = country,       # country along the y axis\n           fill = n)) +       # colour in the heatmap tiles by number\n  \n  # specify that you want this to be a heatmap with geom_tile()\n  geom_tile(colour = \"black\") +   # black is the outline of each tile\n  \n  #define the gradient of the colours\n  scale_fill_gradient(            \n    low = \"lightgreen\",\n    high = \"red\") +\n  \n  #set the x axis labels to two week intervals\n  scale_x_date(breaks = \"2 weeks\") +             \n  \n  # Add titles\n  labs(\n    title= \"Mpox cases by country and week of notification\",\n    fill = \"Number of cases\"                               \n  ) +\n  \n  # Apply an overall theme to your plot\n  theme_bw() +\n  \n  # Customize other appearance details\n  theme(legend.position = \"bottom\",       #legend position to bottom\n        axis.text = element_text(size=9),     #define axis font \n        axis.title = element_blank(),         #remove the axis titles\n        axis.text.x = element_text(angle=90)) #rotate the x axis text\n    \n\n# Print the heatmap\nhp_mpox \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext, describe the age, gender, and sexual orientation of cases. What is interesting?\nTask:\n\nCreate a single table showing overall distribution of age, gender, and sexual orientation\nCreate an age-gender pyramid showing age as 10-year age bands\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTo quickly create a presentation-ready table showing the breakdowns for three different columns, consider using the function tbl_summary() from {gtsummary}.\nTo create an age-gender pyramid, first create a new column with the function age_categories() from the {epikit} package. Then explore the function age_pyramid() from the {apyramid} package.You can find more about this function in the EpiRhandbook chapter Demographic pyramids and Likert-scales\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nSee below the code to quickly generate one table with the breakdown of different variables. The function tbl_summary() by default summarizes columns differently depending on their class:\n\nAge is a numeric column, so is summarized with a median and interquartile range.\nGender and sexual orientation are character values, so are described in terms of counts and percentages.\n\nYou can customize this further; explore the documentation by typing ?tbl_summary() in your console.\nNote that tbl_summary() by default does not include NAs in the counts and percentages, allowing you to see the distribution of non-missing values.\n\n# Create table of all three variables\ntab_demographics &lt;- mpox_linelist %&gt;% \n  \n  # select the columns of interest for\n  select(age, gender, sexual_orientation) %&gt;% \n  \n  # use tbl_summary() to create the table\n  tbl_summary() \n\ntab_demographics\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 2,0001\n\n\n\n\nage\n37 (31, 45)\n\n\n    Unknown\n3\n\n\ngender\n\n\n\n\n    Female\n36 (1.8%)\n\n\n    Male\n1,960 (98%)\n\n\n    Other\n1 (&lt;0.1%)\n\n\n    Unknown\n3\n\n\nsexual_orientation\n\n\n\n\n    Bisexual\n7 (0.8%)\n\n\n    Heterosexual\n46 (5.2%)\n\n\n    MSM/homo or bisexual male\n833 (94%)\n\n\n    Unknown\n1,114\n\n\n\n1 Median (Q1, Q3); n (%)\n\n\n\n\n\n\n\n\nCreate the new age group column as follows. You can add this to the cleaning section of your script (which we covered 4.1).\n\nmpox_linelist &lt;- mpox_linelist %&gt;% \n  # Use the age_categories function to create age categories\n  mutate(age_group = age_categories(age, lower = 0, #set up the lower age\n                                    upper = 70, #set up the upper age\n                                    by = 10)) #set up the age breaks\n\nThen make the age-gender pyramid using the age_pyramid() function. It is a function that builds on ggplot, so you can then continue to add on customization, such as the theme_bw() below.\n\n# Create table of all three variables\nfigure_agesex &lt;- mpox_linelist %&gt;% \n  \n  # Filter to male and female only\n  filter(gender %in% c(\"Male\", \"Female\")) %&gt;% \n  \n  # select the columns of interest for\n  age_pyramid(age_group = \"age_group\",\n              split_by = \"gender\") +\n  \n  # change theme\n  theme_bw()\n\nfigure_agesex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nWhich demographic group is more affected by Mpox?\n\n Females 60-69 Males 40-49 Females 10-19 Males 30-39\n\n\n\nWhat proportion of mpox cases were homosexual or bisexual men?\n\n 41% 42% 5% 94%\n\n\n\n\n\n\n\n\nThe media is starting to call your office and are asking what symptoms the public should look out for. Just in luck - you can check that out in the data too!\nTasks:\n\nCreate a table with the distribution of different symptoms and outcomes.\n\nNo hints! You should know this one by now!\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\n\n# Table with number and percentage of cases by outcome\n\ntab_outcome &lt;- mpox_linelist %&gt;% \n  \n  # Select the columns for tabulation\n  select(outcome, clinical_symptoms) %&gt;% \n  \n  # Use tbl_summary() - note that this time we are adding on labels to change how the column name is displayed\n  tbl_summary(label = list(\n    clinical_symptoms = \"Symptoms\",\n    outcome = \"Reported outcome\")) \n\ntab_outcome\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 2,0001\n\n\n\n\nReported outcome\n\n\n\n\n    Alive\n1,405 (100%)\n\n\n    Unknown\n595\n\n\nSymptoms\n\n\n\n\n    Lesions\n14 (0.7%)\n\n\n    Rash\n257 (13%)\n\n\n    Rash, Lesions\n323 (16%)\n\n\n    Rash, Systemic symptoms\n676 (34%)\n\n\n    Rash, Systemic symptoms, Lesions\n654 (33%)\n\n\n    Systemic symptoms\n28 (1.4%)\n\n\n    Systemic symptoms, Lesions\n36 (1.8%)\n\n\n    Unknown\n12\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou’ve described a lot now, but you want to make sure you understand how timely and complete your mpox linelist is, especially if it will be the basis of making decisions.\nFor example - is it possible that there are very different reporting delays between countries, meaning current case counts are not directly comparable? Oh dear, must check.\n\n\nTasks\n\nCalculate median time from symptom onset to diagnosis and from diagnosis to notification, both overall and by country\nAssess visually the number of cases by calendar period and type of date (onset, diagnosis and notification)\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTo plot together the different dates you may need to transform your data from “wide” to “long” form. What we call “pivoting” in R. The objective is to have a column with the different date categories (onset, diagnosis and notification) and another column with their date value. If you are unsure on how to do this, have a look at the Pivoting data chapter of the EpiRhandbook. Then, try to plot with the daily values, but if that’s not easy to interpret you may want to aggregate cases by week.\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nIs there a difference in the delay from diagnosis to notification by country?\n\n Yes No\n\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFirst create the required columns for this analysis.\n\n# Create two columns in linelist to assess delays\ndelay_db &lt;- mpox_linelist %&gt;% \n  \n  # Time between onset and diagnosis (converted to a number)\n  mutate(delay_diag = as.numeric(date_of_diagnosis - date_of_onset)) %&gt;%   \n\n  # Time between diagnosis and notification (converted to a number)\n  mutate(delay_not = as.numeric(date_of_notification - date_of_diagnosis)) \n\nUse the summary function from base R to quickly view the median, mean, interquartile range, and rang.\n\n# Summarize the delays to diagnosis\nsummary(delay_db$delay_diag) \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n -2.000   4.000   7.000   7.758  10.000  66.000     897 \n\n# Summarize the delays from diagnosis to notification\nsummary(delay_db$delay_not)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-46.0000  -2.0000   0.0000  -0.6078   1.0000  23.0000      715 \n\n\nUse group_by() and summarize() to create a table with median delays per country.\n\ndelay_country &lt;- delay_db %&gt;% \n  \n  # Group by country\n  group_by(country) %&gt;% \n  \n  # Create columns for each delay\n  summarise(median_delay_diag = median(delay_diag, na.rm = T),\n            median_delay_not = median(delay_not, na.rm = T))\n\ndelay_country\n\n# A tibble: 5 × 3\n  country  median_delay_diag median_delay_not\n  &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt;\n1 CountryA                 7                0\n2 CountryB                 7                0\n3 CountryC                 6                0\n4 CountryD                 7                0\n5 CountryE                 6                0\n\n\nTo explore how the trends in cases over time differ when using different dates, you can reshape the linelist to create a dataset with one row per date type per case.\n\n# Prepare the data\ndates_longer &lt;- mpox_linelist %&gt;% \n  \n  select(age, gender, sexual_orientation, starts_with(\"date_\")) %&gt;% \n\n  pivot_longer(\n    \n      # all columns starting with \"date_\" will be pivoted from wide to long \n      cols=starts_with(\"date_\"),         \n    \n      # put names of the columns into a single column called \"indicator\"\n      names_to = \"indicator\",   \n      \n      # the date values will be placed in a column called \"date\"\n      values_to = \"date\")                \n\nThe data will then look like this, with three rows per case:\n\n\n\n\n\n\nThen tabulate cases by week per indicator\n\n# Create new object\ndates_longer_week &lt;- dates_longer  %&gt;% \n\n  # Create a new week column\n  mutate(week_date = floor_date(date, unit = \"week\", week_start = \"Monday\")) %&gt;%  \n  \n  # Within each combination of indicator and week, calculate the number of cases\n  group_by(indicator, week_date) %&gt;% \n  summarise(n=n()) %&gt;%   \n  \n  # drop the cases with no data on dates  \n  drop_na(week_date)                     \n\nThe data will then look like this, with three rows per case:\n\n\n\n\n\n\nFinally, create a plot with ggplot() and geom_line().\n\nplot_date_delay &lt;-   ggplot(data = dates_longer_week,\n                            aes(x = week_date, \n                                y = n, \n                                color=indicator)) +\n  \n  geom_line(linewidth = 1.5) +\n  \n  scale_x_date(breaks = \"2 weeks\")+\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\", \n        axis.text = element_text(size=9),\n        axis.title = element_blank(),\n        axis.text.x = element_text(angle=90),\n        legend.title = element_blank()) +\n  labs(title=\"Mpox cases reported in 2022, by date of onset, diagnosis and notification.\")\n\nplot_date_delay\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinally, you remember that all-along you’ve had these aggregate counts from routine surveillance. You find out that these numbers are actually already being published.\nBefore you share your own numbers, you’d better check how different they are from already-published statistics!\nTask: Create a plot comparing the number of cases reported to through the case-based flow and through the aggregated flow in each country.\nNOTE: Take into consideration that the column on cases in the aggregated data frame reports the cumulative number of cases.\n\n\n\n\n\n\nTest yourself!\n\nWhich country is not reporting aggregated data?\n\n A B C D E\n\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFirst, create a data frame of country totals from the aggregate data.\n\nmpox_agg_country &lt;- mpox_agg %&gt;% \n \n  # as we have cumulative data, we keep only the last week per country \n  group_by(country) %&gt;% \n  filter(date_rep == max(date_rep)) %&gt;% \n  \n  # remove unnecessary columns\n  select(-date_rep, -week_date) %&gt;%     \n\n  # create this column to distinguish the numbers from the linelist data\n  mutate(source = \"aggregated\")         \n\nThen create a data frame of country totals from the case linelist, and append it to the totals from the aggregate data.\n\nmpox_linelist_country &lt;- mpox_linelist %&gt;%\n  \n  # count cases by country, use the same column name as in the aggregate data\n  group_by(country) %&gt;% \n  summarise(cases = n()) %&gt;% \n  \n  # create this column to distinguish the numbers from the linelist data\n  mutate(source = \"case_based\")       \n  \n\n# Append both data frames. Remember this is different from merging\ntotal_data &lt;- bind_rows(mpox_linelist_country, mpox_agg_country)\n\nYou can now use this data to compare the cases reported in both sources, using ggplot().\n\ngraph_comp &lt;- ggplot(data = total_data,\n                     aes(x = source, \n                         y = cases, \n                         fill = source)) +\n  \n  #position dodge puts bars one next to each other, instead of \"stacked\"\n  geom_col(position = \"dodge\") +            \n  \n  # this command gives us one graph per country. The argument scales allows each y axis scales to adjust to the data\n  facet_wrap(~ country, scales = \"free_y\") +  \n\n  # changes the colours, but with the argument \"labels\" we can change the text of each fill.\n  scale_fill_viridis_d(\n    labels = c(\"Aggregated\", \"Case-based\")) +\n  \n  labs(\n    title = \"Number of cases of Mpox reported in 2022 according to source of data\",\n    fill = \"Source\",\n    x = \"\",\n    y = \"Total number of cases\"\n  ) + \n  \n  theme_bw() +\n  \n  # we remove the text of the x axis because it is already present in the legend\n  theme(axis.text.x = element_blank(),   \n        \n   # we also remove the ticks for aesthetic purposes\n        axis.ticks.x = element_blank())    \n\ngraph_comp\n\n\n\n\n\n\n\n\n\nInteresting! There are some differences - and this probably will be worth flagging with stakeholders and/or explaining in a footnote somewhere.\n\n\n\n\n\n\n\nWell done! Through your analysis you now understand the magnitude of the outbreak so far, where and when it spread, which demographic groups are most affected, and how the disease actually manifests in terms of symptoms and severity. ECDC is very happy with your work.\nBy coding this up in R, this analysis should be reproducible, meaning you can quickly update it with new data and keep monitoring the outbreak.\nOf course, the above data is not real. If you want to see a paper on the actual outbreak that occured in Europe in 2022, you can take a look at this Eurosurveillance paper. This ECDC page on Mpox also publishes updates on the status of mpox in Europe.\nTo further practise reproducible reports, [link to RMarkdown].\n\n\n\nAuthorship\nOriginal authors: Xanthi Andrianou, Gianfranco Spiteri (ECDC EI Group)\nData source: Fictional data provided by ECDC EI Group for training purposes\n\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nOctober 2021\nFirst draft\n1\nXanthi Andrianou\n\n\nJune 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales\n\n\nSeptember 2024\nRevise for case study repository\n1.2\nPaula Blomquist and Alanah Jansen\n\n\n\n\n\n\nLicense: This case study is under a derivation of the CC BY-SA 3.0 license"
  },
  {
    "objectID": "pages/r_practical.html#scenario",
    "href": "pages/r_practical.html#scenario",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "It is May 2022 and Mpox has just been reported for the first time across 5 countries in Europe: Countries “A”, “B”, “C”, “D”, and “E”. You have been requested to provide a basic descriptive analysis to the European Centre for Disease Prevention and Control (ECDC).\nYou are given access to:\n\nA dataset with aggregate case counts, submitted to ECDC by the five countries as part of routine European reporting\nA linelist with cases, submitted by the five countries to ECDC for this particular analysis\n\nLet’s go!"
  },
  {
    "objectID": "pages/r_practical.html#objectives",
    "href": "pages/r_practical.html#objectives",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "In this case study you will:\n\nExplore different types of files and how they can be imported in R.\nPerform basic data cleaning, e.g., changing the variable type, recoding variables, aggregating and filtering.\nPerform a basic descriptive analysis using tables and graphs"
  },
  {
    "objectID": "pages/r_practical.html#step-1.-set-up",
    "href": "pages/r_practical.html#step-1.-set-up",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "Start by setting up a reproducible and well-organized workflow. This will make it easy to rerun your analysis whenever needed.\nTasks:\n\nSet up an RStudio project\nSet up clear sub-folders where your code, data, and outputs will go\nCreate an R script, or an R Markdown file if you prefer. Make sure the script purpose, date, and author are written as comments at the top.\nExtra: Ensure your working language in RStudio is appropriate (e.g. English for this exercise)\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\n\nCreate a folder where all the work in this case study will go. For example, create ‘mpox_analysis’ on your computer desktop. Create your RStudio project to be based in this folder.\nWe suggest creating the following sub-folders: scripts (for your code), data (for your data), and outputs (for your analytical outputs).\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nCreate a folder (e.g. ‘mpox_analysis’ on your Desktop) for your work. To create an Rstudio project in your new folder, click New Project… in the top left of your R Studio, then Existing Directory, then Browse to select your new folder. For more information, look at the R projects section of the Epi R Handbook.\nStart a new R script by clicking New File… in the top left of your R Studio, then R Script. Save it immediately in the appropriate place, e.g. in a ‘scripts’ subfolder of your R Project.\nAt the top of your new R script, write some essential information like your name, the purpose of the file, and the date.\nYour R locale determines the language and regional settings used for things like date formats and translations. If your locale is different from the language you want for your report (e.g., a French locale vs. an English report), you can change it to English by running Sys.setlocale(\"LC_ALL\", \"English\"). Include this in your script if needed, or skip it if your locale is usually appropriate. This is explained in more detail in the How-to Guide.\n\n\n\n\n\n\nNext in your R script, you need to install and load the necessary R packages. This ensures that the functions you need are available for your analysis.\nYou will need the following packages: rio (for importing data), janitor (for cleaning data), lubridate (for cleaning dates), skimr (for reviewing data), epikit (for epi-related tasks), gtsummary (for presentation-ready tables), apyramid (for age-sex pyramids), and tidyverse (for general data manipulation/science tasks).\nAs you start, your trusted colleague nudges you and whispers “I’ve heard that a great way to manage your packages is with the pacman package”.\nOver to you!\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse the function p_load() from pacman for this task. You provide the function with a list of packages that you want to use. It will take two steps per package: 1) Check if the package is installed on your computer, and install it if necessary, then 2) Load the package so it can be used during this R session.\nIf you don’t already have pacman installed, you will need to install it the “traditional way” first, with install.packages().\nNote that the order of packages in your p_load function can be important. If two packages have the same function names (e.g. select() in the package MASS and select() in tidyverse, which do different things), then R will use the function from the most recently loaded package. To prioritize functions from tidyverse, which are commonly used for data manipulation and visualization, load tidyverse last.\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)"
  },
  {
    "objectID": "pages/r_practical.html#step-2-download-and-import-the-data",
    "href": "pages/r_practical.html#step-2-download-and-import-the-data",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "ECDC provides you with two files for your analysis, both updated as of 31st August 2022:\n\nA case-level linelist (“mpox_linelist.xlsx”) with case information from five countries (countries A - E)\nAn aggregate table (“mpox_aggregate_table.csv”) for those countries with cumulative case counts per day.\n\nThey provide it to you via AppliedEpi’s very useful data repository, which you can access using the {appliedepidata} package. So first you need to download these two files to your own computer, as follows:\n\nInstall the {appliedepidata} package from GitHub using the install_github() function in the {remotes} package. Install {remotes} if you need to first.\n\n\n# Install remotes if you need to (so you can install a package from GitHub)\npacman::p_load(\"remotes\")\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nSave the two datasets into a specific folder using the save_data() function from {appliedepidata}, by running the code below. The example below saves the data into a ‘data’ subfolder within the RStudio project. Note that if you do not specify a location within the ‘path’ argument of the function, a window will pop up asking you to manually select a folder.\n\n\n# Save down the two mpox files using the save_data() function from appliedepidata\nappliedepidata::save_data(\"mpox_linelist\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"mpox_aggregate_table\",\n                          path = \"data\")\n\n\n\n\nGreat! Thanks ECDC and Applied Epi! Now it’s time to import the data from that folder into RStudio, so you can analyse it.\nTask: Import the downloaded case-based and aggregated data into your R environment. Ideally you want to use one function for both datasets, despite one being a csv and the other an xlsx file.\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nUse the import function from the {rio} package, which can recognize and import different file types. It replaces importing functions that are specific to the file type, such as read.csv() from {base} for .csv files and read_excel() from {readxl} to import .xlsx files.\nIf you feel you need to know more about importing functions, read the Import and export chapter of the EpiRhandbook.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nBelow we use the import function to bring in both files. Note how we are assigning the imported data to two objects, one called mpox_linelist_raw, and one called mpox_agg_raw. We add the ‘raw’ suffix to distinguish this data from the cleaned versions we will make later.\n\n# Import data  --------------\n\n# Case-based data\nmpox_linelist_raw &lt;- import(\"data/mpox_linelist.xlsx\")\n\n# Aggregated data\nmpox_agg_raw &lt;- import(\"data/mpox_aggregate_table.csv\")"
  },
  {
    "objectID": "pages/r_practical.html#step-3-explore-the-data",
    "href": "pages/r_practical.html#step-3-explore-the-data",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "The data’s in, and now it’s time to see what story it tells. Take an initial look at your data to check its quality and how you can best use it.\nTasks: Take a look at the different data frames and determine:\n\nThe number of columns and observations (e.g. their dimensions)\nThe class of their columns and whether it matches its nature (e.g., are “dates” considered “dates” by R?)\nIf the contents of columns are clean and standardized in the mpox linelist (e.g. gender, clinical symptoms, outcome, hiv status and sexual orientation). Do you need to recode any of them?\nHow unknown or missing data is categorized in these columns. Do these values need to be standardized?\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nAn efficient function for initial data exploring is skim() from the {skimr} package, as it gives you a lot of information on data structure and content, including the classes of columns.\nYou can use the function tabyl() from {janitor}, to get counts and percentages of every category in the data column, one by one. These get printed to your RStudio console.\nAlso - we recommend just looking at the data itself! A good function for this is view(), a baseR function.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing the skim commands you can see the rows and columns of each dataset, and you can see how most of the columns in mpox_linelist_raw (including those containing dates) are character classes. (Results not shown on this exercise page)\n\n# Explore the dimensions of the two data objects \nskim(mpox_linelist_raw)\nskim(mpox_agg_raw)\n\nTake a look at the overall data using view(). It will pop up in the Data Viewer tab and you will get a good sense of how clean the data is and what the missingness is like. This preview shows just 5 rows from the linelist data.\n\nview(mpox_linelist_raw)\n\n\n\n\n\n\n\nBelow is an example of using the tabyl() function from {janitor}, to look at the distribution of clinical symptoms. You can see 12 cases have missing clinical information and that many cases have a mix of symptoms.\n\ntabyl(mpox_linelist_raw, HIVStatus)  \n\n HIVStatus   n percent valid_percent\n       NEG 525  0.2625     0.4107981\n       POS 307  0.1535     0.2402191\n       UNK 446  0.2230     0.3489828\n      &lt;NA&gt; 722  0.3610            NA\n\n\nYou can explore further columns one by one (results not shown):\n\n# Explore the values of different categorical columns in the mpox linelist: with tabyl\ntabyl(mpox_linelist_raw, Gender)\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms)\n\ntabyl(mpox_linelist_raw, Outcome)\n\ntabyl(mpox_linelist_raw, SexualOrientation)\n\nYou could add extra arguments to tabyl() to customize the tables, such as adding totals and changing the proportions to percentages so they are easier to read. See the table on clinical symptoms below. But remember - this is just an initial look so don’t go too crazy.\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms) %&gt;%    # Tabulate symptoms \n  adorn_totals() %&gt;%                              # Add totals to bottom of table\n  adorn_pct_formatting(digits = 2)                # Format percentages\n\n                 ClinicalSymptoms    n percent valid_percent\n                          Lesions   14   0.70%         0.70%\n                             Rash  257  12.85%        12.93%\n                    Rash, Lesions  323  16.15%        16.25%\n          Rash, Systemic symptoms  676  33.80%        34.00%\n Rash, Systemic symptoms, Lesions  654  32.70%        32.90%\n                Systemic symptoms   28   1.40%         1.41%\n       Systemic symptoms, Lesions   36   1.80%         1.81%\n                             &lt;NA&gt;   12   0.60%             -\n                            Total 2000 100.00%       100.00%\n\n\nFinally, as an alternative approach to tabyl(), you could use tbl_summary() from the {gtsummary} package. We will describe this later.\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nPaket ‘webexercises’ erfolgreich ausgepackt und MD5 Summen abgeglichen\nDie heruntergeladenen Binärpakete sind in C:6X8m_packages How many columns does the aggregated data have?\n\n 2000 13 3 101\n\n\n\nWhat is the class of the column DateOfNotification in the mpox linelist?\n\n Date Character Numeric Factor\n\n\n\nFor how many cases is the HIV status Unknown or missing?\n\n 1168 722 900 446"
  },
  {
    "objectID": "pages/r_practical.html#step-4-clean-the-data",
    "href": "pages/r_practical.html#step-4-clean-the-data",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "So! The good news: you have information on geography, dates, demographic characteristics, and clinical details. A promising descriptive analysis lies ahead.\nBUT! You may noticed that there are a few things to fix before the real detective work begins.\nFor example:\n\nColumn names have capital letters. This isn’t outright a problem, but can lead to mistakes since R treats ColumnName and Columnname as different.\nDate columns are recognized as character classes, not dates, which would cause issues like incorrect ordering (alphabetical) in epicurves.\nSome columns have values that are unclear or unsuitable for presentation. For example gender is categorized with “F”, “M”, “O” and “UNK”. The column Outcome is “A” and “UNK”.\nMissing data is inconsistently handled, for instance with both “UNK” and NA in the HIV status column. R thinks “UNK” is a valid value, which it treats differently to true missing data (indicated by NA)\n\nTasks:\n\nCreate a clean version of your case-based data making all cleaning changes in a single piping command\nChange all column names to lower case.\nConvert all date columns to class “Date”.\nConvert all missing/unknown values to NA (to be recognized by R as missing)\nRecode non-missing “Gender” categories into: “Female”, “Male”, and “Other”\nRecode non-misising HIV status into: “Positive”, “Negative” and “Unknown”\nRecode non-missing sexual orientation into: “Bisexual”, “Heterosexual”, and “MSM/homo or bisexual male”.\nRecode non-missing “outcome” categories into: “Alive” and “Dead”.\nCheck that all changes have been made correctly\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTo convert all column names to lower case at once rather than renaming each column, use the function clean_names() from the {janitor} package.\nUse {lubridate} functions to transform date columns into “Date” class. You can do this one by one, or you could do all at the same time using the across() function from {dplyr}. If you feel you need to know more about transforming dates read the chapter Working with Dates from the EpiRhandbook. If you are not sure how to use the across() function, you can also read the section on Transform multiple columns.\nThere are different functions that we can use to recode values. We propose three: The function recode() from {dplyr}, the function ifelse() from {base} and the function case_when() from {dplyr}. If you want to know more about these functions, look that the section on Re-code values from the EpiRhandbook.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere we clean the data using a ‘chain’ of commands connected by pipes (%&gt;%), which is the grammar of the functions in the {Tidyverse}. The output is assigned to a new object called mpox_linelist to differentiate it from the raw data. It can be helpful to have both the cleaned and raw data available in the environment to compare to the original data if needed.\nSee the series of functions and the explanation in the comments.\n\n# Create a new object called mpox_linelist which is the clean version of the raw data\nmpox_linelist &lt;- mpox_linelist_raw %&gt;% \n  \n  # standardises names and puts all into lower case \n  clean_names() %&gt;% \n  \n  #transform ONE column into date (note the column names are lower case now)\n  mutate(date_of_notification = ymd(date_of_notification)) %&gt;%  \n\n  #transforms ALL columns starting with \"date\" into dates\n  mutate(across(starts_with(\"date\"), \n                .fns = ~ ymd(.x))) %&gt;%  \n  \n  #transforms UNK to NA across all character columns \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x %in% c(\"UNK\", \"Unknown\"), NA_character_, .x)))  %&gt;% \n\n  # Recode the gender values to be more obvious  \n  mutate(gender = recode(gender,\n                         \"F\" = \"Female\",\n                         \"M\" = \"Male\",\n                         \"O\" = \"Other\")) %&gt;%\n  \n  #recode with ifelse to change only one or two categories based on a rule. \n  mutate(outcome = ifelse(outcome == \"A\", \"Alive\", outcome)) %&gt;%   \n  \n  #recode with case_when for more complex recoding \n  mutate(hiv_status = case_when(hiv_status == \"NEG\" ~ \"Negative\",    \n                                hiv_status == \"POS\" ~ \"Positive\")) %&gt;% \n  \n  mutate(sexual_orientation = case_when(sexual_orientation == \"BISEXUAL\" ~ \"Bisexual\",\n                                        sexual_orientation == \"HETERO\" ~ \"Heterosexual\",\n                                        sexual_orientation == \"MSM\" ~ \"MSM/homo or bisexual male\")) \n\nYou can then review your data by tabulating across all the different columns you have cleaned. See the preview of the HIV table below - it looks tidier now with more understandable categories, and all missing data is classified as ‘Unknown’.\n\n# Check that all changes have been made correctly\n\nskim(mpox_linelist)\n\ntabyl(mpox_linelist, gender)\n\ntabyl(mpox_linelist, clinical_symptoms)\n\ntabyl(mpox_linelist, outcome)\n\ntabyl(mpox_linelist, hiv_status)\n\ntabyl(mpox_linelist, sexual_orientation)\n\n\n\n hiv_status    n percent valid_percent\n   Negative  525  0.2625     0.6310096\n   Positive  307  0.1535     0.3689904\n       &lt;NA&gt; 1168  0.5840            NA\n\n\nIMPORTANT: If ‘unknown’ and NA had meaningful differences, combining them wouldn’t be appropriate (e.g., if ‘unknown’ meant the case was asked but didn’t want to respond, while NA meant they weren’t asked). Here, we assume no meaningful difference and want R to recognize them as missing.\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nIs it always appropriate to combine different types of unknown data? (e.g. missing, unknown, did not respond, NA)\n\n Yes Depends on the meaning of those values No - never do this\n\n\n\nHow many male cases do we have in the data frame?\n\n 36 1960 65 1523\n\n\n\nHow many cases have ‘alive’ as an outcome?\n\n 1405 None 595\n\n\n\n\n\n\n\n\nIn a similar way, clean the aggregated data by:\n\nStandardising names to lower case\nEnsuring that date of reporting is of class “Date”\nCreating a column called “week_date” with the week of reporting starting on Monday\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nWe can first check the class of the DateRep column, which shows us that it was already recognized as a date column on import.\n\n# Check class of date of reporting column\nclass(mpox_agg_raw$DateRep)\n\nThen create a new object for the clean aggregate data, and write your cleaning coded connected with pipes.\n\n# Create a new object called mpox_agg which is the clean version of the raw data, applying the cleaning functions\n\nmpox_agg &lt;- mpox_agg_raw %&gt;% \n  \n  # standardises names and puts all into lower case\n  clean_names() %&gt;%  \n  \n  # create week column with Monday start\n  mutate(week_date = floor_date(date_rep, \n                              unit = \"week\",\n                              week_start = \"Monday\")) \n\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nTake a look at the aggreate data. Which country reported the largest cumulative number of cases during the week 2022-04-11?\n\n Country A Country B Country C Country D Country E"
  },
  {
    "objectID": "pages/r_practical.html#step-5-describe-outbreak-by-person-place-and-time",
    "href": "pages/r_practical.html#step-5-describe-outbreak-by-person-place-and-time",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "Now we’re getting to the heart of the investigation. Who is affected? Which locations are most affected, and how quickly is it spreading? Your ability to tell the classic “person, place, and time” story will be crucial to guiding the response. Pinpoint those hotspots and trends!\n\n\nTask: Using the mpox case linelist, create a table showing the total number of cases by country. This time, make the table more publication-friendly.\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nYou could use tabyl() like before, but an easy way to produce publication-ready tables is with the function tbl_summary() from {gtsummary} package. This formats the table for you. It will print to your Viewer rather than the console.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nCreate a new object with the table output - as this is a key output that you can then integrate into a document later rather than just viewing for now.\n\n# Create an object with the table\ncb_country_table &lt;- mpox_linelist %&gt;%\n\n  #select the column that we want to use in the table\n  select(country) %&gt;% \n  \n  # create the table. No need to specify columns; it will tabulate all available columns (selected above)\n  tbl_summary() \n\n# Print the table\ncb_country_table\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 2,0001\n\n\n\n\ncountry\n\n\n\n\n    CountryA\n816 (41%)\n\n\n    CountryB\n391 (20%)\n\n\n    CountryC\n474 (24%)\n\n\n    CountryD\n217 (11%)\n\n\n    CountryE\n102 (5.1%)\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nWhat country has the largest percentage of cases?\n\n Country C Country D Country B Country E Country A\n\n\n\n\n\n\n\n\nOkay so Country A has the most cases in total based on most recent data. But how does that change look over time?\nTasks:\n\nUsing the mpox case linelist, create an epicurve by week of notification\nUsing the mpox case linelist, create an epicurve by week of notification to enable a comparison of trends by country.\nUsing the mpox case linelist, create a heat plot with the number of cases by country and week of notification.\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nPrepare your data for the epicurve first. You can create a “week_date” column using the function floor_date() from {lubridate}. Take a look at the documentation to understand how it works and how to pick the starting day of the week.\nTo create the epicurve, you can use ggplot() and geom_bar(), which visualizes the number of rows within a group - e.g. number of cases per week. To compare trends in different countries, consider using the facet_wrap() function. If you are unsure on how ggplot() works, read the EpiRhandbook chapter on Epidemic curves.\nTo create a heatmap, you will need to create a table of counts by country and week of notification. You can do this using the functions group_by() and summarise() from {dplyr}. If you are unsure on how to do this, review the Grouping data chapter of the EpiRhandbook. Then, use the geom geom_tile() to create a heat plot. If you’re unsure on how to do this, read the EpiRhanbook section on Heat Plots\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nPrepare your data by creating the new column using mutate() and floor_date():\n\nmpox_linelist &lt;- mpox_linelist %&gt;% \n  # create week column with Monday start \n  mutate(week_date = floor_date(date_of_notification, unit = \"week\", week_start = \"Monday\")) \n\nThe code below creates an epicurve using ggplot() and the geom_bar() function, then applies further formatting. With geom_bar(), you only need to specify the x axis, and the function will visualize the number of rows per unique x axis value.\n\n# Open up the plot production with ggplot() function, specifying object and columns\nepicurve_mpox &lt;- ggplot(data = mpox_linelist,          \n                        aes(x = week_date)) +    \n  \n  geom_bar(fill=\"darkgreen\",                     #colour inside the bins\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  labs(title=\"Mpox cases reported in 2022 in Countries A, B, C, D, and E\",\n       subtitle = \"Date as of August 31st 2022\") +  #add a title\n  \n  theme_minimal() +                             #assign a predefined theme\n  \n  theme(axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n           \n# Print the epicurve\nepicurve_mpox\n\n\n\n\n\n\n\n\nTo examine how the outbreak spread by country, add facet_wrap() to your ggplot code. This splits the graph into multiple smaller ones. As shown below, you can even simply add the function to the national epicurve object.\nAn alternative approach would be to create a stacked epicurve, i.e. retain the single epicurve but split each bar into colors per country. You would do this by adding fill = country to the aes() in the epicurve code. However, we don’t recommend this for comparing trends, as stacked bars make it harder to see individual patterns.\n\nepicurve_epox_country &lt;- epicurve_mpox + \n \n   # Facet wrap to make mini-plots, specifying that you want two columns of plots. \n  facet_wrap(.~country,\n             ncol = 1) \n\n# Print the epicurve\nepicurve_epox_country\n\n\n\n\n\n\n\n\nFinally, if you want to demonstrate this as a weekly heatmap, you can use geom_tile(). First, aggregate the data by week. Then pipe into a ggplot(), as shown below.\n\n# Assign the output of your ggplot code to a new object\nhp_mpox &lt;- mpox_linelist %&gt;% \n  \n  #first count the number of cases by country and notification week\n  count(country, week_date) %&gt;% \n\n  #you can pipe directly into the ggplot\n    ggplot(aes(x = week_date, # notification week along the x axis\n           y = country,       # country along the y axis\n           fill = n)) +       # colour in the heatmap tiles by number\n  \n  # specify that you want this to be a heatmap with geom_tile()\n  geom_tile(colour = \"black\") +   # black is the outline of each tile\n  \n  #define the gradient of the colours\n  scale_fill_gradient(            \n    low = \"lightgreen\",\n    high = \"red\") +\n  \n  #set the x axis labels to two week intervals\n  scale_x_date(breaks = \"2 weeks\") +             \n  \n  # Add titles\n  labs(\n    title= \"Mpox cases by country and week of notification\",\n    fill = \"Number of cases\"                               \n  ) +\n  \n  # Apply an overall theme to your plot\n  theme_bw() +\n  \n  # Customize other appearance details\n  theme(legend.position = \"bottom\",       #legend position to bottom\n        axis.text = element_text(size=9),     #define axis font \n        axis.title = element_blank(),         #remove the axis titles\n        axis.text.x = element_text(angle=90)) #rotate the x axis text\n    \n\n# Print the heatmap\nhp_mpox \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext, describe the age, gender, and sexual orientation of cases. What is interesting?\nTask:\n\nCreate a single table showing overall distribution of age, gender, and sexual orientation\nCreate an age-gender pyramid showing age as 10-year age bands\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTo quickly create a presentation-ready table showing the breakdowns for three different columns, consider using the function tbl_summary() from {gtsummary}.\nTo create an age-gender pyramid, first create a new column with the function age_categories() from the {epikit} package. Then explore the function age_pyramid() from the {apyramid} package.You can find more about this function in the EpiRhandbook chapter Demographic pyramids and Likert-scales\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nSee below the code to quickly generate one table with the breakdown of different variables. The function tbl_summary() by default summarizes columns differently depending on their class:\n\nAge is a numeric column, so is summarized with a median and interquartile range.\nGender and sexual orientation are character values, so are described in terms of counts and percentages.\n\nYou can customize this further; explore the documentation by typing ?tbl_summary() in your console.\nNote that tbl_summary() by default does not include NAs in the counts and percentages, allowing you to see the distribution of non-missing values.\n\n# Create table of all three variables\ntab_demographics &lt;- mpox_linelist %&gt;% \n  \n  # select the columns of interest for\n  select(age, gender, sexual_orientation) %&gt;% \n  \n  # use tbl_summary() to create the table\n  tbl_summary() \n\ntab_demographics\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 2,0001\n\n\n\n\nage\n37 (31, 45)\n\n\n    Unknown\n3\n\n\ngender\n\n\n\n\n    Female\n36 (1.8%)\n\n\n    Male\n1,960 (98%)\n\n\n    Other\n1 (&lt;0.1%)\n\n\n    Unknown\n3\n\n\nsexual_orientation\n\n\n\n\n    Bisexual\n7 (0.8%)\n\n\n    Heterosexual\n46 (5.2%)\n\n\n    MSM/homo or bisexual male\n833 (94%)\n\n\n    Unknown\n1,114\n\n\n\n1 Median (Q1, Q3); n (%)\n\n\n\n\n\n\n\n\nCreate the new age group column as follows. You can add this to the cleaning section of your script (which we covered 4.1).\n\nmpox_linelist &lt;- mpox_linelist %&gt;% \n  # Use the age_categories function to create age categories\n  mutate(age_group = age_categories(age, lower = 0, #set up the lower age\n                                    upper = 70, #set up the upper age\n                                    by = 10)) #set up the age breaks\n\nThen make the age-gender pyramid using the age_pyramid() function. It is a function that builds on ggplot, so you can then continue to add on customization, such as the theme_bw() below.\n\n# Create table of all three variables\nfigure_agesex &lt;- mpox_linelist %&gt;% \n  \n  # Filter to male and female only\n  filter(gender %in% c(\"Male\", \"Female\")) %&gt;% \n  \n  # select the columns of interest for\n  age_pyramid(age_group = \"age_group\",\n              split_by = \"gender\") +\n  \n  # change theme\n  theme_bw()\n\nfigure_agesex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nWhich demographic group is more affected by Mpox?\n\n Females 60-69 Males 40-49 Females 10-19 Males 30-39\n\n\n\nWhat proportion of mpox cases were homosexual or bisexual men?\n\n 41% 42% 5% 94%\n\n\n\n\n\n\n\n\nThe media is starting to call your office and are asking what symptoms the public should look out for. Just in luck - you can check that out in the data too!\nTasks:\n\nCreate a table with the distribution of different symptoms and outcomes.\n\nNo hints! You should know this one by now!\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\n\n# Table with number and percentage of cases by outcome\n\ntab_outcome &lt;- mpox_linelist %&gt;% \n  \n  # Select the columns for tabulation\n  select(outcome, clinical_symptoms) %&gt;% \n  \n  # Use tbl_summary() - note that this time we are adding on labels to change how the column name is displayed\n  tbl_summary(label = list(\n    clinical_symptoms = \"Symptoms\",\n    outcome = \"Reported outcome\")) \n\ntab_outcome\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 2,0001\n\n\n\n\nReported outcome\n\n\n\n\n    Alive\n1,405 (100%)\n\n\n    Unknown\n595\n\n\nSymptoms\n\n\n\n\n    Lesions\n14 (0.7%)\n\n\n    Rash\n257 (13%)\n\n\n    Rash, Lesions\n323 (16%)\n\n\n    Rash, Systemic symptoms\n676 (34%)\n\n\n    Rash, Systemic symptoms, Lesions\n654 (33%)\n\n\n    Systemic symptoms\n28 (1.4%)\n\n\n    Systemic symptoms, Lesions\n36 (1.8%)\n\n\n    Unknown\n12\n\n\n\n1 n (%)"
  },
  {
    "objectID": "pages/r_practical.html#step-6-reviewing-data-quality",
    "href": "pages/r_practical.html#step-6-reviewing-data-quality",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "You’ve described a lot now, but you want to make sure you understand how timely and complete your mpox linelist is, especially if it will be the basis of making decisions.\nFor example - is it possible that there are very different reporting delays between countries, meaning current case counts are not directly comparable? Oh dear, must check.\n\n\nTasks\n\nCalculate median time from symptom onset to diagnosis and from diagnosis to notification, both overall and by country\nAssess visually the number of cases by calendar period and type of date (onset, diagnosis and notification)\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTo plot together the different dates you may need to transform your data from “wide” to “long” form. What we call “pivoting” in R. The objective is to have a column with the different date categories (onset, diagnosis and notification) and another column with their date value. If you are unsure on how to do this, have a look at the Pivoting data chapter of the EpiRhandbook. Then, try to plot with the daily values, but if that’s not easy to interpret you may want to aggregate cases by week.\n\n\n\n\n\n\n\n\n\nTest yourself!\n\nIs there a difference in the delay from diagnosis to notification by country?\n\n Yes No\n\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFirst create the required columns for this analysis.\n\n# Create two columns in linelist to assess delays\ndelay_db &lt;- mpox_linelist %&gt;% \n  \n  # Time between onset and diagnosis (converted to a number)\n  mutate(delay_diag = as.numeric(date_of_diagnosis - date_of_onset)) %&gt;%   \n\n  # Time between diagnosis and notification (converted to a number)\n  mutate(delay_not = as.numeric(date_of_notification - date_of_diagnosis)) \n\nUse the summary function from base R to quickly view the median, mean, interquartile range, and rang.\n\n# Summarize the delays to diagnosis\nsummary(delay_db$delay_diag) \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n -2.000   4.000   7.000   7.758  10.000  66.000     897 \n\n# Summarize the delays from diagnosis to notification\nsummary(delay_db$delay_not)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-46.0000  -2.0000   0.0000  -0.6078   1.0000  23.0000      715 \n\n\nUse group_by() and summarize() to create a table with median delays per country.\n\ndelay_country &lt;- delay_db %&gt;% \n  \n  # Group by country\n  group_by(country) %&gt;% \n  \n  # Create columns for each delay\n  summarise(median_delay_diag = median(delay_diag, na.rm = T),\n            median_delay_not = median(delay_not, na.rm = T))\n\ndelay_country\n\n# A tibble: 5 × 3\n  country  median_delay_diag median_delay_not\n  &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt;\n1 CountryA                 7                0\n2 CountryB                 7                0\n3 CountryC                 6                0\n4 CountryD                 7                0\n5 CountryE                 6                0\n\n\nTo explore how the trends in cases over time differ when using different dates, you can reshape the linelist to create a dataset with one row per date type per case.\n\n# Prepare the data\ndates_longer &lt;- mpox_linelist %&gt;% \n  \n  select(age, gender, sexual_orientation, starts_with(\"date_\")) %&gt;% \n\n  pivot_longer(\n    \n      # all columns starting with \"date_\" will be pivoted from wide to long \n      cols=starts_with(\"date_\"),         \n    \n      # put names of the columns into a single column called \"indicator\"\n      names_to = \"indicator\",   \n      \n      # the date values will be placed in a column called \"date\"\n      values_to = \"date\")                \n\nThe data will then look like this, with three rows per case:\n\n\n\n\n\n\nThen tabulate cases by week per indicator\n\n# Create new object\ndates_longer_week &lt;- dates_longer  %&gt;% \n\n  # Create a new week column\n  mutate(week_date = floor_date(date, unit = \"week\", week_start = \"Monday\")) %&gt;%  \n  \n  # Within each combination of indicator and week, calculate the number of cases\n  group_by(indicator, week_date) %&gt;% \n  summarise(n=n()) %&gt;%   \n  \n  # drop the cases with no data on dates  \n  drop_na(week_date)                     \n\nThe data will then look like this, with three rows per case:\n\n\n\n\n\n\nFinally, create a plot with ggplot() and geom_line().\n\nplot_date_delay &lt;-   ggplot(data = dates_longer_week,\n                            aes(x = week_date, \n                                y = n, \n                                color=indicator)) +\n  \n  geom_line(linewidth = 1.5) +\n  \n  scale_x_date(breaks = \"2 weeks\")+\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\", \n        axis.text = element_text(size=9),\n        axis.title = element_blank(),\n        axis.text.x = element_text(angle=90),\n        legend.title = element_blank()) +\n  labs(title=\"Mpox cases reported in 2022, by date of onset, diagnosis and notification.\")\n\nplot_date_delay\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinally, you remember that all-along you’ve had these aggregate counts from routine surveillance. You find out that these numbers are actually already being published.\nBefore you share your own numbers, you’d better check how different they are from already-published statistics!\nTask: Create a plot comparing the number of cases reported to through the case-based flow and through the aggregated flow in each country.\nNOTE: Take into consideration that the column on cases in the aggregated data frame reports the cumulative number of cases.\n\n\n\n\n\n\nTest yourself!\n\nWhich country is not reporting aggregated data?\n\n A B C D E\n\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFirst, create a data frame of country totals from the aggregate data.\n\nmpox_agg_country &lt;- mpox_agg %&gt;% \n \n  # as we have cumulative data, we keep only the last week per country \n  group_by(country) %&gt;% \n  filter(date_rep == max(date_rep)) %&gt;% \n  \n  # remove unnecessary columns\n  select(-date_rep, -week_date) %&gt;%     \n\n  # create this column to distinguish the numbers from the linelist data\n  mutate(source = \"aggregated\")         \n\nThen create a data frame of country totals from the case linelist, and append it to the totals from the aggregate data.\n\nmpox_linelist_country &lt;- mpox_linelist %&gt;%\n  \n  # count cases by country, use the same column name as in the aggregate data\n  group_by(country) %&gt;% \n  summarise(cases = n()) %&gt;% \n  \n  # create this column to distinguish the numbers from the linelist data\n  mutate(source = \"case_based\")       \n  \n\n# Append both data frames. Remember this is different from merging\ntotal_data &lt;- bind_rows(mpox_linelist_country, mpox_agg_country)\n\nYou can now use this data to compare the cases reported in both sources, using ggplot().\n\ngraph_comp &lt;- ggplot(data = total_data,\n                     aes(x = source, \n                         y = cases, \n                         fill = source)) +\n  \n  #position dodge puts bars one next to each other, instead of \"stacked\"\n  geom_col(position = \"dodge\") +            \n  \n  # this command gives us one graph per country. The argument scales allows each y axis scales to adjust to the data\n  facet_wrap(~ country, scales = \"free_y\") +  \n\n  # changes the colours, but with the argument \"labels\" we can change the text of each fill.\n  scale_fill_viridis_d(\n    labels = c(\"Aggregated\", \"Case-based\")) +\n  \n  labs(\n    title = \"Number of cases of Mpox reported in 2022 according to source of data\",\n    fill = \"Source\",\n    x = \"\",\n    y = \"Total number of cases\"\n  ) + \n  \n  theme_bw() +\n  \n  # we remove the text of the x axis because it is already present in the legend\n  theme(axis.text.x = element_blank(),   \n        \n   # we also remove the ticks for aesthetic purposes\n        axis.ticks.x = element_blank())    \n\ngraph_comp\n\n\n\n\n\n\n\n\n\nInteresting! There are some differences - and this probably will be worth flagging with stakeholders and/or explaining in a footnote somewhere."
  },
  {
    "objectID": "pages/r_practical.html#final-thoughts",
    "href": "pages/r_practical.html#final-thoughts",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "Well done! Through your analysis you now understand the magnitude of the outbreak so far, where and when it spread, which demographic groups are most affected, and how the disease actually manifests in terms of symptoms and severity. ECDC is very happy with your work.\nBy coding this up in R, this analysis should be reproducible, meaning you can quickly update it with new data and keep monitoring the outbreak.\nOf course, the above data is not real. If you want to see a paper on the actual outbreak that occured in Europe in 2022, you can take a look at this Eurosurveillance paper. This ECDC page on Mpox also publishes updates on the status of mpox in Europe.\nTo further practise reproducible reports, [link to RMarkdown]."
  },
  {
    "objectID": "pages/r_practical.html#case-study-information",
    "href": "pages/r_practical.html#case-study-information",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "Authorship\nOriginal authors: Xanthi Andrianou, Gianfranco Spiteri (ECDC EI Group)\nData source: Fictional data provided by ECDC EI Group for training purposes\n\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nOctober 2021\nFirst draft\n1\nXanthi Andrianou\n\n\nJune 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales\n\n\nSeptember 2024\nRevise for case study repository\n1.2\nPaula Blomquist and Alanah Jansen"
  },
  {
    "objectID": "pages/r_practical.html#terms-of-use",
    "href": "pages/r_practical.html#terms-of-use",
    "title": "Descriptive analysis of the 2022 Mpox outbreak in Europe",
    "section": "",
    "text": "License: This case study is under a derivation of the CC BY-SA 3.0 license"
  },
  {
    "objectID": "pages/tbe.html",
    "href": "pages/tbe.html",
    "title": "TBE - Linear regression (ENG)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\nName:\nTBE - linear regression\n\n\nLanguage:\nEnglish\n\n\nTool:\nR; DAGitty\n\n\nLocation:\nGermany\n\n\nScale:\nNational\n\n\nDiseases:\nTBE\n\n\nKeywords:\nTBE; Linear Regression; R\n\n\nTechnical complexity:\nIntermediate\n\n\nMethodological complexity:\nIntermediate\n\n\n\nAuthorship\nOriginal authors: Teresa Nygren (RKI), Alicia Barrasa Blanco (UK FETP), Jan Walter (RKI) and Achim Dörre (RKI)\nData source: Data is fictional and was inspired by Nygren et al. Tick-borne encephalitis: acute clinical manifestations and severity in 581 cases from Germany, 2018-2020. Journal of Infection. 2023 Apr 1;86(4):369-75\nAdapted by: Liese Van Gompel (MediPIET), Joana Gomes Dias (ECDC), Chiara Entradi (ECDC) and Alberto Mateo Urdiales (ISS)\n\n\n\n\n\n\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\n\nHere is what the “helpers” look like:\n\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see the solution\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\n\n… description here about posting in Community… TO BE COMPLETED BY APPLIED EPI\n\n\n\nDisclaimer: The information presented in this exercise and the associated data files have been deliberately changed so as to facilitate the acquisition of the learning objectives for fellows of EPIET, EUPHEM and EPIET-associated programmes. This case study was first introduced in 2022 (see Copyright and Licence agreement for more information).\nYou are free:\n\nto Share: to copy and distribute the work\nto Remix: to adapt and build upon the material\n\nUnder the following conditions:\n\nAttribution: You must attribute the work in the manner specified by the author or licensor (but not in any way that suggests that they endorse you or your use of the work). The best way to do this is to keep as it is the list of contributors: sources, authors and reviewers.\nShare Alike: If you alter, transform, or build upon this work, you may distribute the resulting work only under the same or similar license to this one. Your changes must be documented. Under that condition, you are allowed to add your name to the list of contributors.\nNotification: If you use the work in the manner specified by the author or licensor, Walter@rki.de\nYou cannot sell this work alone but you can use it as part of a teaching.\n\nWith the understanding that:\n\nWaiver: Any of the above conditions can be waived if you get permission from the copyright holder.\nPublic Domain: Where the work or any of its elements is in the public domain under applicable law, that status is in no way affected by the license.\nOther Rights: In no way are any of the following rights affected by the license:\n\nYour fair dealing or fair use rights, or other applicable copyright exceptions and limitations;\nThe author’s moral rights;\nRights other persons may have either in the work itself or in how the work is used, such as publicity or privacy rights.\n\nNotice: For any reuse or distribution, you must make clear to others the license terms of this work by keeping together this work and the current license.\n\nThis licence is based on http://creativecommons.org/licenses/by-sa/3.0/\n\n\n\n\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\n\nWrite date of first version\nWrite any revisions made to the case study\n\n\n\n\n\n\n\n\nDate\nChanges made\nAuthor\n\n\n\n\n2023\nRevision R code\nLiese Van Gompel (MediPIET)\n\n\n2024\nRevision R code\nJoana Gomes Dias and Chiara Entradi (ECDC)\n\n\n2024\nRevision of content, structure, R code and adaptation of format to Applied Epi’s template of case studies\nAlberto Mateo Urdiales (ISS)\n\n\n\n\n\n\n\n\n\n\nAt the end of the case study, participants should be able to:\n\nUse directed acyclic graphs (DAG) to identify variables suitable to control for confounding;\nTo perform linear regression in R;\nTo write down the associated models and interpret them.\n\n\n\n\nParticipants are expected to be familiar with directed acyclic graphs (DAGs) and the use of DAGitty (a browser-based environment for creating DAGS) for the first part; and with data management as well as descriptive and stratified analysis in R for the second part.\n\n\n\nInclude the steps needed to start replicating the analysis of the case study\nFor example:\n\nDownload folder named tbe_en and extract contents in the local laptop\nCreate an Rstudio project in the folder tbe_en. If you are unsure on how to do that, read the EpiRhandbook Chapter on R projects\nInside the folder “tbe_en”: Subfolder “data” contains a raw data file named tbe.RDS. This is the only data file you will use in this case study.\nSubfolder scripts should be used to save any scripts related to the analysis. Inside “backup” you will find a solution script with the code of the case study named tbe_lr_backup.R. You will also find an image which corresponds to the proposed DAG solution.\nSubfolder “outputs” could be used to store all outputs (tables, graphs, documents) that are the result of the analysis\nYou will also find inside “tbe_en” a word document called starter_guide_DAGitty.docx in case you need help using this website"
  },
  {
    "objectID": "pages/tbe.html#overview",
    "href": "pages/tbe.html#overview",
    "title": "TBE - Linear regression (ENG)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\nName:\nTBE - linear regression\n\n\nLanguage:\nEnglish\n\n\nTool:\nR; DAGitty\n\n\nLocation:\nGermany\n\n\nScale:\nNational\n\n\nDiseases:\nTBE\n\n\nKeywords:\nTBE; Linear Regression; R\n\n\nTechnical complexity:\nIntermediate\n\n\nMethodological complexity:\nIntermediate\n\n\n\nAuthorship\nOriginal authors: Teresa Nygren (RKI), Alicia Barrasa Blanco (UK FETP), Jan Walter (RKI) and Achim Dörre (RKI)\nData source: Data is fictional and was inspired by Nygren et al. Tick-borne encephalitis: acute clinical manifestations and severity in 581 cases from Germany, 2018-2020. Journal of Infection. 2023 Apr 1;86(4):369-75\nAdapted by: Liese Van Gompel (MediPIET), Joana Gomes Dias (ECDC), Chiara Entradi (ECDC) and Alberto Mateo Urdiales (ISS)"
  },
  {
    "objectID": "pages/tbe.html#instructions",
    "href": "pages/tbe.html#instructions",
    "title": "TBE - Linear regression (ENG)",
    "section": "",
    "text": "There are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\n\nHere is what the “helpers” look like:\n\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see the solution\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\n\n… description here about posting in Community… TO BE COMPLETED BY APPLIED EPI\n\n\n\nDisclaimer: The information presented in this exercise and the associated data files have been deliberately changed so as to facilitate the acquisition of the learning objectives for fellows of EPIET, EUPHEM and EPIET-associated programmes. This case study was first introduced in 2022 (see Copyright and Licence agreement for more information).\nYou are free:\n\nto Share: to copy and distribute the work\nto Remix: to adapt and build upon the material\n\nUnder the following conditions:\n\nAttribution: You must attribute the work in the manner specified by the author or licensor (but not in any way that suggests that they endorse you or your use of the work). The best way to do this is to keep as it is the list of contributors: sources, authors and reviewers.\nShare Alike: If you alter, transform, or build upon this work, you may distribute the resulting work only under the same or similar license to this one. Your changes must be documented. Under that condition, you are allowed to add your name to the list of contributors.\nNotification: If you use the work in the manner specified by the author or licensor, Walter@rki.de\nYou cannot sell this work alone but you can use it as part of a teaching.\n\nWith the understanding that:\n\nWaiver: Any of the above conditions can be waived if you get permission from the copyright holder.\nPublic Domain: Where the work or any of its elements is in the public domain under applicable law, that status is in no way affected by the license.\nOther Rights: In no way are any of the following rights affected by the license:\n\nYour fair dealing or fair use rights, or other applicable copyright exceptions and limitations;\nThe author’s moral rights;\nRights other persons may have either in the work itself or in how the work is used, such as publicity or privacy rights.\n\nNotice: For any reuse or distribution, you must make clear to others the license terms of this work by keeping together this work and the current license.\n\nThis licence is based on http://creativecommons.org/licenses/by-sa/3.0/\n\n\n\n\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\n\nWrite date of first version\nWrite any revisions made to the case study\n\n\n\n\n\n\n\n\nDate\nChanges made\nAuthor\n\n\n\n\n2023\nRevision R code\nLiese Van Gompel (MediPIET)\n\n\n2024\nRevision R code\nJoana Gomes Dias and Chiara Entradi (ECDC)\n\n\n2024\nRevision of content, structure, R code and adaptation of format to Applied Epi’s template of case studies\nAlberto Mateo Urdiales (ISS)"
  },
  {
    "objectID": "pages/tbe.html#guidance",
    "href": "pages/tbe.html#guidance",
    "title": "TBE - Linear regression (ENG)",
    "section": "",
    "text": "At the end of the case study, participants should be able to:\n\nUse directed acyclic graphs (DAG) to identify variables suitable to control for confounding;\nTo perform linear regression in R;\nTo write down the associated models and interpret them.\n\n\n\n\nParticipants are expected to be familiar with directed acyclic graphs (DAGs) and the use of DAGitty (a browser-based environment for creating DAGS) for the first part; and with data management as well as descriptive and stratified analysis in R for the second part.\n\n\n\nInclude the steps needed to start replicating the analysis of the case study\nFor example:\n\nDownload folder named tbe_en and extract contents in the local laptop\nCreate an Rstudio project in the folder tbe_en. If you are unsure on how to do that, read the EpiRhandbook Chapter on R projects\nInside the folder “tbe_en”: Subfolder “data” contains a raw data file named tbe.RDS. This is the only data file you will use in this case study.\nSubfolder scripts should be used to save any scripts related to the analysis. Inside “backup” you will find a solution script with the code of the case study named tbe_lr_backup.R. You will also find an image which corresponds to the proposed DAG solution.\nSubfolder “outputs” could be used to store all outputs (tables, graphs, documents) that are the result of the analysis\nYou will also find inside “tbe_en” a word document called starter_guide_DAGitty.docx in case you need help using this website"
  },
  {
    "objectID": "pages/tbe.html#goal-1-draw-a-directed-acyclic-graph-dag",
    "href": "pages/tbe.html#goal-1-draw-a-directed-acyclic-graph-dag",
    "title": "TBE - Linear regression (ENG)",
    "section": "Goal 1: Draw a Directed Acyclic Graph (DAG)",
    "text": "Goal 1: Draw a Directed Acyclic Graph (DAG)\nSince you are interested in a causal question, please draw a DAG. If you want to use a computer, you may try http://www.dagitty.net/.\n\nWhich variables would you need to adjust for?\n\nIf you are new to DAGitty you can find a few helpful information in the document called starter_guide_DAGitty.docx present in the “tbe_en” folder you have downloaded in your laptop (See Preparation for the case study).\nOnce you have drawn your DAG, click on the solution below to see the DAG we propose.\n\n\nClick to see the solution\n\n\nWhen planning the study, the epidemiologist considered this DAG:\n\n\n\n\nAccording to this DAG, if you want to explore the association between hypertension and severe TBE, you should adjust for:\n\nTBE diagnosis\nTBE vaccination\nage\nlarge tick (=large viral load)\nmonophasic course\nother comorbidities\nsex.\n\nTBE Diagnosis is controlled by design (only cases are included).\nProbably your DAG will look differently. This is absolutely fine, since there is not only one possible DAG. But you should be able to justify your DAG based on the existing evidence."
  },
  {
    "objectID": "pages/tbe.html#goal-2-perform-linear-regression-in-r",
    "href": "pages/tbe.html#goal-2-perform-linear-regression-in-r",
    "title": "TBE - Linear regression (ENG)",
    "section": "Goal 2: Perform linear regression in R",
    "text": "Goal 2: Perform linear regression in R\nNow we will work on the data frame provided which includes data for 523 patients who have been hospitalized with TBE in the years 2018 to 2020 in Germany and for whom data were collected.\nThe following variables are provided:\nTable 1: Data dictionary for the dataframe “tbe.RDS”:\n\n\n\nVariable\nDescription\nValues\n\n\n\n\nage\nage in years\ncontinuous\n\n\nhyper\nhypertension\n1= yes, 0=no\n\n\nvac\nvaccinated against TBE\n1= yes, 0=no\n\n\nmono\nmonophasic disease course\n1= yes, 0=no\n\n\nother\nother comorbidities\n1= yes, 0=no\n\n\ntick\nlarge tick at removal\n1= yes, 0=no\n\n\nsex\nsex\n1= female, 0= male\n\n\nhospd\nlength of hospitalisation in days\ncontinuous\n\n\n\n\nStep 1: Set up\n\nStep 1.1: Create a new R script\nOnce you have created an Rproject inside the “tbe_en” folder (as specified in the second point of the section Preparation for the case study). Create a new script with the name tbe_lr and save it in the subfolder “scripts”. If you are familiar with Rmarkdown, you may decide to use this type of file instead of a standard R script.\n\n\nStep 1.2: Define R language\nDepending on where you are and how you carried out R installation, your language “locale” might be different from the language of the graphs that you want to produce. For example, a french person might have a french “locale”. If that is the case, when creating a graph by day of the week, Monday will be displayed as “lundi”. If that french person wants to create an English report, as for this case study, the language “locale” should be changed.\nTask: Ensure your “locale” is in English and change it into English if it is not. If you don’t know how to do this try finding it online (searching for online help is an important skill for R users!). Otherwise, see the solution below\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# To see your language locale\nSys.getlocale()\n\n# To change it into English\nSys.setlocale(\"LC_ALL\", \"English\")\n\n\n\n\n\nStep 1.3: Install/load packages\nInstall and load the following packages: rio, skimr, janitor, gtsummary, broom, rstatix, ggfortify and tidyverse.\nYou can find more about installing/loading packages in the Packages section of the EpiRhandbook.\n\n\n Click to read a hint\n\n\nYou may end up using a long list of packages. Unfortunately different packages have functions with the same name. For example, the package {dplyr} (already installed with {tidyverse}) has a function called select() which we frequently use to subset columns of a data frame. But other packages such as {MASS} do also have a function called select(). This could create headaches if you want to subset columns using dplyr’s select() but R thinks you’re calling MASS’s select() (we call this masking - dplyr::select() is masked by MASS::select()). Given that you are more likely to use functions from {tidyverse}, ensure that this is the last package in your p_load() list so that functions from {tidyverse} (including {dplyr} functions) will always “prevail”.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  gtsummary,  # summary statistics, tests and regressions \n  broom,      # to generate tidy tibbles of regression analysis\n  rstatix,    # for statistics, including statistical tests\n  ggfortify,  # data visualisation for statistical analysis results\n  tidyverse  # data management and visualization\n)\n\n\n\n\n\n\nStep 2: Import and explore data\n\nStep 2.1: Import the data and brief exploration\nImport the data frame called “tbe.RDS” inside the “data” subfolder. If you are working within a project, finding the path to the dataframe should be relatively straightfoward. An “.RDS” file is an R object file. You can import this dataframe using the readRDS() function from {base}. However, we recommend that you use the import() function from {rio} because, as you may remember, this function will recognise the file type and import it whether the file is from R, Stata, excel or many others. If you have any doubts about importing review the Import and export chapter of the EpiRhandbook.\nThen, explore the data trying to answer the following questions:\n\nQUESTION: How many columns does the dataframe have?\n\n 523 2 8 6\n\n\n\nQUESTION: How many rows have missing the column ‘Other comorbidities’?\n\n 958 22 18 39\n\n\n\nQUESTION: How many cases have hypertension?\n\n 119 191 332 285\n\n\n\nQUESTION: How many character columns does the dataframe have?\n\n 0 6 2 8\n\n\n\nQUESTION: What is the difference between a column of class ‘character’ and a column of class ‘factor’?\n\n There is no difference between these classes, those are synonims Character columns contain text, whereas factors contain numbers Factors are used when we have more than 5 categories of data Both classes contain text, but factors are used when there are a limited number of unique character strings and they often represent categorical data\n\n\n\n\n Click to read a hint\n\n\nAn efficient way to explore data is to use the function skim() from the {skimr} package, as it gives you all the information needed with only one command. Of course, there are several alternatives.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Import the data\n\ntbe &lt;- import(\"data/tbe.RDS\")\n\n\n# Explore the dataframe\nskim(tbe)\n\n\nData summary\n\n\nName\ntbe\n\n\nNumber of rows\n523\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n6\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nhyper\n0\n1.00\nFALSE\n2\nno: 404, yes: 119\n\n\nvac\n0\n1.00\nFALSE\n2\nno: 503, yes: 20\n\n\nmono\n0\n1.00\nFALSE\n2\nno: 285, yes: 238\n\n\nother\n22\n0.96\nFALSE\n2\nyes: 317, no: 184\n\n\ntick\n0\n1.00\nFALSE\n2\nno: 345, yes: 178\n\n\nsex\n0\n1.00\nFALSE\n2\nmal: 332, fem: 191\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n18\n0.97\n47.30\n18.97\n1\n34\n47.0\n61\n90\n▂▅▇▆▂\n\n\nhospd\n39\n0.93\n42.23\n13.59\n3\n33\n41.5\n52\n86\n▁▆▇▃▁\n\n\n\n\n\n\n\nNormally, at this point we would start cleaning our data. Fortunately for you, the tbe data has already been cleaned, so you can jump directly to the fun part. However, feel free to rename/recode or change any aspect of the dataframe to accomodate it to your personal preferences.\n\n\nStep 2.2: Inspect factor columns\nAs we saw before, we have 6 factor columns representing categorical variables in our dataframe. Although we looked at them with the skim() function, explore them further with the tabyl() function from the {janitor} package.\n\n\n Click to read a hint\n\n\nTo save time, try to always use functions that allow you to apply the same function to many different objects (e.g., multiple columns) simultaneously. You can achieve this using several approaches, such as loops, lapply or purrr. Here we give the solution with purrr, so if you want to explore further purrr have a look at the dedicated section in the EpiRhandbook.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n### One by one\ntabyl(tbe, hyper)\n\n\n\n\n\nhyper\nn\npercent\n\n\n\n\nno\n404\n0.7724665\n\n\nyes\n119\n0.2275335\n\n\n\n\n\ntabyl(tbe, vac)\n\n\n\n\n\nvac\nn\npercent\n\n\n\n\nno\n503\n0.9617591\n\n\nyes\n20\n0.0382409\n\n\n\n\n\n#### All at once\ntbe %&gt;% \n  \n  select(where(is.factor)) %&gt;% #we first select only the columns that are of class 'factor'\n  \n  map(.f = tabyl)              #inside map() from {purrr} we specify the function we want to apply to the entire dataframe\n\n$hyper\n .x[[i]]   n   percent\n      no 404 0.7724665\n     yes 119 0.2275335\n\n$vac\n .x[[i]]   n    percent\n      no 503 0.96175908\n     yes  20 0.03824092\n\n$mono\n .x[[i]]   n   percent\n      no 285 0.5449331\n     yes 238 0.4550669\n\n$other\n .x[[i]]   n    percent valid_percent\n      no 184 0.35181644     0.3672655\n     yes 317 0.60611855     0.6327345\n    &lt;NA&gt;  22 0.04206501            NA\n\n$tick\n .x[[i]]   n   percent\n      no 345 0.6596558\n     yes 178 0.3403442\n\n$sex\n .x[[i]]   n   percent\n    male 332 0.6347992\n  female 191 0.3652008\n\n\n\n\n\n\nStep 2.3: Histogram with length of hospitalisation\nOur outcome variable will be length of hospitalisation in days (column hospd). It might be worth it looking at this column in more detail, as its characteristics may influence how will carry out the analysis later on. One important aspect is to check its distribution and ascertain, at least visually, if it follows a normal distribution.\nTask Create an histogram with the distribution of hospd. Try adding the normal curve to this histogram.\n\nQUESTION: Does lenght of hospitalisation look like normally distributed?\n\n Yes No\n\n\n\n\n Click to read a hint\n\n\nThere are many ways to create an histogram in R, but try using the package {ggplot2}. You can have a look at the ggplot basics chapter of the EpiRhandbook if you struggle.\nAdding the normal curve to the histogram may prove quite challenging. Do not worry if you don’t manage. One hint is that, in the histogram, you will need to display the density and not the frequency count. Try asking a search engine or any AI platform for help. Most of us use these tools on a daily basis to ask for help in R.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\ntbe %&gt;%                                  #we call the data first and we pass it into ggplot with the pipe operator\n  \n  ggplot(mapping = aes(x = hospd)) +     #when drawing an histogram we only need to specify the x-axis   \n  \n  geom_histogram(aes(y = ..density..)) + #here we are telling ggplot2 to display the density and not the freq count\n  \n  #the function below will add the normal curve. \n  stat_function(fun = dnorm,  #In the fun = argument we are specifying that we want the normal curve         \n                args = list(mean = mean(tbe$hospd, na.rm = T), #to draw a normal curve we need to give the mean and standard deviation of our column\n                            sd   = sd(tbe$hospd, na.rm = T)),  \n                \n                col = \"darkblue\", lwd = 1) # Identify the colour and line width of the normal curve\n\n\n\n\nNow, that was tough! But we’re here to push you out of your comfort zone. Let’s go into more detail about what we have done.\nBy now, you should feel comfortable creating a basic histogram using ggplot, so let’s focus on the new things. We have added another aesthetic to the geom_histogram() in which we specify that we want the density plotted and not the frequency count. Why is that? Displaying the density is more appropriate when we want to focus on the shape of the data, as we can see the underlying probability distribution more clearly.\nBut, what is actually the density? The density represents the relative frequency, what we do is scale the y-axis so that the area under the histogram equals 1, normalising the histogram to represent probabilities (density) rather than raw counts. In fact, look at how the y-axis changes when you represent the density and when you represent the counts.\nFinally, why are we putting two dots before and after density in the aes()? The double dots before and after ..density.. are a special syntax used within ggplot2. They indicate an internal variable that ggplot2 calculates during the plotting process. So, ggplot2 normally calculates the density for histograms, but it does not display it unless you specify it (with this syntax).\n\n\n\n\nStep 2.4: Create a cross-table and calculate a statistical test\nLet’s say that we now want to explore whether sex is associated with hypertension. To find this out, create a cross-table displaying these two variables and calculate the appropriate statistical test to know if there is a statistical association between them.\n\n\n Click to read a hint\n\n\nThere are several ways in which you can do this. You could, for example, create the cross-table with tabyl() and then separately calculate the statistical test. The easiest way would be to use the tbl_summary() function from the {gtsummary} package, which allows you to do both, the cross tabulation and the statistical tests, in the same command. You should be familiar with this package by now, but if you need a little refresher have a look at the dedicated chapter of the EpiRhandbook.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\ntbe %&gt;% \n  select(hyper, sex) %&gt;%   #we select the columns we are interested in\n  tbl_summary(by = hyper) %&gt;% #we specify that we want by hypertension status\n  add_p()                     # adding this command will calculate the most appropriate statistical test\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      no, N = 4041\n      yes, N = 1191\n      p-value2\n    \n  \n  \n    sex\n\n\n0.5\n        male\n253 (63%)\n79 (66%)\n\n        female\n151 (37%)\n40 (34%)\n\n  \n  \n  \n    \n      1 n (%)\n    \n    \n      2 Pearson’s Chi-squared test\n    \n  \n\n\n\n\n\n\nAs you can see, there isn’t a significant association between sex and hypertension.\n\n\n\nStep 3: Check if there is a linear association between length of hospitalisation and age\nAge is a potential confounder for a more severe course of TBE involving a longer stay in hospital, for which we would like to adjust. Since age is a continuous variable, we could include it in the regression model in various ways (e.g. as a continuous variable, in categories, by transforming it, etc.). In order to decide this, we need to analyze the association of age with the length of hospitalisation.\n\nStep 3.1: Inspect a potential linear association\nPlease first have a look at the relationship between age and length of hospitalisation using a scatterplot.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\ntbe %&gt;%    \n  \n  ggplot(mapping = aes(x = age,        # we put length of hospitalisation on the y-axis because this axis usually contains the dependent variable; and here we want to know if hospd depends on age\n                       y = hospd)) +    \n  \n  geom_point() +                       # this geometry will create a scatterplot\n    \n  scale_x_continuous(name = \"Age\" , limits = c(0,100)) +          # Format the x-axis to a range between 0 and 100 \n  \n  scale_y_continuous(limits = c(0,70)) +                          # Format the y axis to a range between 0 and 70\n  \n  labs(\n    x = \"Age\",\n    y = \"Length of hospitalisation in days\"\n  ) + \n  \n  \n  theme_bw()                            # Add a pre-defined theme for formatting\n\n\n\n\n\n\nWhat do you think? Is there a linear association? How can you be sure? Add a linear model trend line to help you with the interpretation.\n\n\n Click to read a hint\n\n\nFor the trend line, you can add a geom_smooth() geometry. Look up the documentation for geom_smooth (you can type ?geom_smooth() in the console and press “Enter”) and search for the methods option.For a linear trend line you can assign the methods argument to “lm” (linear model). \n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\ntbe %&gt;%    \n  \n  ggplot(mapping = aes(x = age,        # we put length of hospitalisation on the y-axis because this axis usually contains the dependent variable; and here we want to know if hospd depends on age\n                       y = hospd)) +    \n  \n  geom_point() +                       # this geometry will create a scatterplot\n  \n  geom_smooth(method = lm) +           # this geometry will add a trend line. \"lm\" is for \"linear model\"\n  \n  scale_x_continuous(name = \"Age\" , limits = c(0,100)) +          # Format the x-axis to a range between 0 and 100 \n  \n  scale_y_continuous(limits = c(0,70)) +                          # Format the y axis to a range between 0 and 70\n  \n  labs(\n    x = \"Age\",\n    y = \"Length of hospitalisation in days\"\n  ) + \n  \n  \n  theme_bw()                            # Add a pre-defined theme for formatting\n\n\n\n\n\n\nNow you have visual evidence of a linear association of age with the duration of hospitalisation. Therefore, it seems reasonable to include age as a continuous variable in the analysis.\n\n\nStep 3.2: Check if the association between age and length of hospitalisation varies by sex\nNow, check visually whether the association between age and hospd differs by sex\n\n\n Click to read a hint\n\n\nYou may choose to create separate graphs adding a facet_grid() to your ggplot() (try looking up the syntax yourself). You may also decide to use colour coding to differentiate between factor levels of sex. For the latter, where do you think you should specify the colour, inside or outside the aes()? Read this section of the EpiRhandbook if you have doubts.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# As separate graphs\ntbe %&gt;%    \n  \n  ggplot(mapping = aes(x = age,        # we put length of hospitalisation on the y-axis because this axis usually contains the dependent variable; and here we want to know if hospd depends on age\n                       y = hospd)) +    \n  \n  geom_point() +                       # this geometry will create a scatterplot\n  \n  geom_smooth(method = lm) +           # this geometry will add a trend line. \"lm\" is for \"linear model\"\n  \n  facet_grid(~sex)  +                   # adding this function will generate a separate graph for each category of sex\n\n  \n  scale_x_continuous(name = \"Age\" , limits = c(0,100)) +          # Format the x-axis to a range between 0 and 100 \n  \n  scale_y_continuous(limits = c(0,70)) +                          # Format the y axis to a range between 0 and 70\n  \n  labs(\n    x = \"Age\",\n    y = \"Length of hospitalisation in days\"\n  ) + \n  \n  \n  theme_bw()                            # Add a pre-defined theme for formatting\n\n\n\n# Same graphs with different colours\ntbe %&gt;%    \n  \n  ggplot(mapping = aes(x = age,        # we put length of hospitalisation on the y-axis because this axis usually contains the dependent variable; and here we want to know if hospd depends on age\n                       y = hospd,\n                       colour = sex )) + #we add the colour in the aes so that it varies according to the categories of sex   \n  \n  geom_point() +                       # this geometry will create a scatterplot\n  \n  geom_smooth(method = lm) +           # this geometry will add a trend line. \"lm\" is for \"linear model\"\n  \n  scale_x_continuous(name = \"Age\" , limits = c(0,100)) +          # Format the x-axis to a range between 0 and 100 \n  \n  scale_y_continuous(limits = c(0,70)) +                          # Format the y axis to a range between 0 and 70\n  \n  labs(\n    x = \"Age\",\n    y = \"Length of hospitalisation in days\"\n  ) + \n  \n  \n  theme_bw()                            # Add a pre-defined theme for formatting\n\n\n\n\n\n\n\nWhat do you observe? The lines for female and male patients have different slopes, indicating that the association between age and hospitalisation days is modified by sex.\nWhy does this matter? Since there are different effects of age on the length of the hospitalisation by sex, you may want to control for this.\n\n\n\n\nStep 4: Check if there is a difference in length of hospitalisation by hypertension status\nLet’s now focus on our exposure of interest (hypertension). We can check whether TBE cases with high blood pressure have a significant longer stay in hospital compared with those without high blood pressure either by carrying out a simple statistical test or through univariate regression. We will do both.\n\nStep 4.1: Simple statistical test\nOne way would be to carry out a simple statistical test which enables us to ascertain if there is a significant difference between groups. As you know, the choice of statistical test will be determined by the number of groups that we have and the nature of the variables. If you don’t remember well how to choose the appropriate statistical test have a look at this BMJ article\n\nQUESTION: What simple statistical tests do you think would be most appropriate in this case?\n\n Chi-square or Fisher's exact test ANOVA or Kruskal Wallis Student t test or Mann Whitney/Wilcoxon rank-sum test McNemar's test or Spears Rank\n\n\nIn this case we have independent data, two groups (hypertension yes/no) and a quantitative dependent outcome (length of hospitalisation), so we will choose either a t-test or Wilcoxon rank-sum test (also known as Mann-Whitney). We’d do a t-test if length of hospitalisation is normally distributed and Wilcoxon if it isn’t. We already checked in Step 2.3 that the distribution of hospd looked normal from the histogram, let’s now have a look if the distribution looks normal for both categories of hypertension: hypertension-yes and hypertension-no.\nTask Check visually whether length of hospitalisation is normally distributed for both categories of hypertension.\n\n\n Click to read a hint\n\n\nA simple way to check this is by generating a histogram for hospd using ggplot(). Stratification by hyper is easily done by adding a facet_grid() to your ggplot, as we have already seen with the scatterplot. Looking at the frecuency distribution of “hospd” by “hypertension” can already give us an idea of whether the data is normally distributed or not.However, if we want to to add a normal curve, we’d need to plot the density and not the frequency, as you may rembember from the histogram we built above in Sep 2.3. \n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Plot the frecuency distribution by hypertension status\ntbe %&gt;%\n  \n  ggplot(mapping = aes(x = hospd)) +\n  \n    geom_histogram() + \n    \n    facet_grid(~hyper) # add facet_grid() to get a graph for each hyper status\n\n\n\n# Plot the density and add a  normal curve\ntbe %&gt;%                                  \n  \n  ggplot(mapping = aes(x = hospd, fill = hyper)) +  #remember that for bars, fill is is the interior colour     \n  \n    geom_histogram(aes(y = ..density..)) + #here we are telling ggplot2 to display the density and not the freq count\n  \n    facet_grid(~hyper) + # add facet_grid() to get a graph for each hyper status\n\n    #the function below will add the normal curve. \n    stat_function(fun = dnorm,  #The fun = argument we are specifying that we want the normal curve         \n                args = list(mean = mean(tbe$hospd, na.rm = T), #to draw a normal curve we need to give the mean and standard deviation of our column\n                            sd   = sd(tbe$hospd, na.rm = T)),  \n                \n                col = \"darkblue\", lwd = 1) + # Identify the colour and line width of the normal curve\n    labs(\n      x = \"Length of hospitalisation in days\",\n      y = \"Density\"\n      )\n\n\n\n\n\n\nFrom the graphs looks like the data is normally distributed, but there is a test we can do to determine this: Shapiro-Wilk test.\nTask: Use the Shapiro test to determine whether length of hospitalisation comes from a normally-distributed population.\n\n\n Click to read a hint\n\n\nYou can choose {base} functions to carry out the Shapiro test (and any other statistical test) or functions from the {rstatix} package. Here we will use the latter, because {rstatix} has a syntax that is compatible with {dplyr}, which can be an advantage. In any case the name of the functions are very similar. For example, using {base} the Shapiro test function is shapiro.test(); and with {rstatix} the same function is written as: shapiro_test(). If you want to know more about how to carry out simple statistical tests in R, read the EpiRhandbook Chapter on Simple statistical tests\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\ntbe %&gt;%\n  \n  group_by(hyper) %&gt;% #we first group by out independent or exposure variable\n  \n  \n  shapiro_test(hospd)  # this function performs the Shapiro-Wilk test for all groups separately\n\n\n\n\n\nhyper\nvariable\nstatistic\np\n\n\n\n\nno\nhospd\n0.9946512\n0.2207864\n\n\nyes\nhospd\n0.9870178\n0.3632204\n\n\n\n\n\n\n\n\nThe null hypothesis of Shapiro’test is that data is normally distributed. As our results were non-significant (p&gt;0.05) we cannot reject such null hypothesis. In other words, we can conclude that data is normally distributed.\nNote: A statistician, or an epidemiologist pretending to be a statistician, would feel very uncomfortable by the conclusion written above. When we are unable to reject a null hypothesis we cannot conclude that this hypothesis (in this case that data is normally distributed) is true, but we should simply state that we were unable to reject it. However, in practical terms, by carrying out a Shapiro test we are assuming that the data is normally distributed….so word it as you like, but the consequences are the same.\n\nQUESTION: Now that we know that the data is normally distributed, what test should we carry out?\n\n Student t-test Wilcoxon rank-sum test\n\n\nTask Carry out the statistical test to ascertain if there are significant differences in length of hospitalisation according to hypertension status\n\n\nClick to see a solution (try it yourself first!)\n\n\n\ntbe %&gt;%\n  \n  t_test(hospd ~ hyper)  # we write first our dependent variable and then the exposure one\n\n\n\n\n\n.y.\ngroup1\ngroup2\nn1\nn2\nstatistic\ndf\np\n\n\n\n\nhospd\nno\nyes\n373\n111\n-2.706422\n181.4443\n0.00745\n\n\n\n\n\n\n\n\n\nQUESTION: Is there a significant difference in the length of hospitalisation among patients with and without hypertension?\n\n Yes No\n\n\nNote: In large datasets (as this one) the Shapiro-Wilk test may reject the normality hypothesis even though the deviation from the normal distribution is rather small. In this case you may still choose to calculate the t-test despite the violation of the normality assumption. This is acceptable because for large samples, the error imposed by t-test approximation is negligible.\n\n\nStep 4.2: Univariate linear regression between hospd and hyper\nThe other way was through univariate regression. Carry out a univariate linear regression with length of hospitalisation (hospd) as the dependent variable and hypertension as the independent variable. Assign this model to an object named: hyper_hospd_lm. If this is the first time doing regression in R, have a look at the Univariate regression chapter of the EpiRhandbook.\n\n\n Click to read a hint\n\n\nAs we are doing linear regression, we could use the lm() function from {base} to analyse the association between hypertension and length of hospitalisation. The syntax is: lm(outcome/dependent variable ~ exposure/independent variable, data = dataframe) You can print the model output in a subsequent command using the summary() function. However, the tidy() function from {broom} provides an overview which can be more easily compiled and used in down-stream analyses if needed.\nThe approach described above is the {base} R approach. You can also perform univariate regression analysis using the function tbl_uvregression() from the {gtsummary} package. If you want to explore this alternative approach further read the dedicated EpiRhandbook chapter \n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n#First we write the formula (lm stands for linear model) and assign the model to an object\nhyper_hospd_lm &lt;- lm(hospd ~ hyper, data= tbe)\n\n# Prin the detailed output of the model\nsummary(hyper_hospd_lm)\n\n\nCall:\nlm(formula = hospd ~ hyper, data = tbe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-38.324  -9.324  -1.261   9.676  44.676 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  41.3244     0.6991  59.113  &lt; 2e-16 ***\nhyperyes      3.9369     1.4598   2.697  0.00724 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.5 on 482 degrees of freedom\n  (39 observations deleted due to missingness)\nMultiple R-squared:  0.01487,   Adjusted R-squared:  0.01282 \nF-statistic: 7.273 on 1 and 482 DF,  p-value: 0.007243\n\n# Print the main model parameters\nresults_hyper_hospd_lm &lt;- tidy(hyper_hospd_lm) \nresults_hyper_hospd_lm\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n41.324397\n0.6990698\n59.113403\n0.0000000\n\n\nhyperyes\n3.936864\n1.4597610\n2.696924\n0.0072434\n\n\n\n\n\n\n\n\n\nQUESTION: Based on the results of this model, is there a significant association between hypertension and hospd?\n\n Yes No\n\n\n\nQUESTION: How much does having hypertension increase length of hospitalisation (in days)?\n\n 3.9 41.3 1.46 1.2\n\n\n\nQUESTION: What % of the variability in length of hospitalisation can be explained by hypertension?\n\n 2.7% 41% 1.3% 3%\n\n\nIn this case the regression equation is: \\(hopsd(predicted)=41.3+3.9⋅hyper\\).\nNow let’s go through the outputs of the model. We will first review the outputs of the tidy() function. As explained before, the advantage of using tidy() is that we can save the output as an object for further manipulation. Also, tidy() keeps what we would normally need in epidemiology for the interpretation of the model:\nWe have four columns and two rows. The rows refer to the intercept (baseline value for hospd when there is NO hypertension: 41.3) and our only exposure/predictor (hypertension). In most cases, you will be interested in the row for hypertension (your predictor) and in the columns estimate and p.value. The estimate of hypertension tells us the estimated change in hospd when you go from NO hypertension to YES hypertension (that’s why it is written as hyperyes). In this case, it’s approximately 3.94, meaning that having hypertension is associated with an increase in 3.94 days of hospitalisation. The column p.value tells us whether this estimate is statistically significant.\nThis is most of what you need to know to be a functional epidemiologist. But if you want to know more, we will explain the rest of the elements of the output of both functions:\nThe column std.error provides an estimate of the variability or uncertainty associated with the estimate. In this case it means that the estimated effect of hypertension on hospitalisation duration (hospd) is expected to vary by about 1.46 days (on average) due to sampling variability. Finally, the statistic column gives us a value of the statistical test (t-test in this case) used to ascertain if the estimate is significantly different from 0 (normally you can ignore this column).\nYou may have noticed that the summary() output has more information than the tidy() output. Here we leave a brief explanation on what each part of the summary() output means:\nCall: This line shows the formula used for the regression model.\nResiduals: These are the differences between the actual hospd values and the predicted values from the regression model. The summary provides statistics like minimum, median, and maximum residuals.\nCoefficients: This is the bit that interests us the most:\n\nIntercept: The estimated intercept (baseline value) for hospd when age is zero. In this case, it’s approximately 41.3.\nhyperyes: The estimated change in hospd when you go from NO hypertension to YES hypertension. Here, it’s approximately 3.9. The t-value and p-value indicate whether this coefficient is statistically significant.\n\nSignificance Codes: Indicate whether the p-value is highly significant (*** p &lt; 0.001) or only marginally significant (* p&lt;0.05)\nResidual Standard Error: This measures the average deviation of the observed hospd values from the regression line. In this case, it’s approximately 13.5.\nMultiple and Adjusted R-squared: These values (0.01487 and 0.01282) represent the proportion of variance in hospd explained by the linear relationship with hypertension. Higher values indicate better fit. The adjusted one is adjusted for the number of predictors. In this case we could say that around 1.3% of the variability in hospd is explained by hypertension.\nF-statistic and p-value: The F-statistic tests whether the overall model (including all predictors) is significant. A low p-value (like this one, &lt; 0.007243) indicates that the model is significant.\n\n\n\nStep 5: Check if there is a linear association between length of hospitalisation and the rest of variables\nWe also need to know if there is a univariate association between our outcome (length of hospitalisation) and the confounders we may want to introduce in our model. We will do this in two steps, first with the continous variable and then with the factor variables.\n\nStep 5.1: Univariate linear regression between length of hospitalisation and age\nTry running a linear regression model with length of hospitalisation (hospd) as the dependent variable and age as the independent variable.\n\nQUESTION: Based on the results of the model, is there a significant association between age and hospd?\n\n Yes No\n\n\n\nQUESTION: How much does an additional year of age increase length of hospitalisation (in days)?\n\n 0.372 24.5 0.271 1.42\n\n\n\nQUESTION: What % of the variability in length of hospitalisation can be explained by age?\n\n 65% 15% 27% 99%\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Run the linear regression and assign the output to age_hospd_lm\nage_hospd_lm &lt;- lm(hospd ~ age, data = tbe)\n\n# Print the results using the summary() function\nsummary(age_hospd_lm)\n\n\nCall:\nlm(formula = hospd ~ age, data = tbe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-35.676  -7.893   0.521   6.844  32.279 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  24.5314     1.4233   17.24   &lt;2e-16 ***\nage           0.3722     0.0278   13.39   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.61 on 482 degrees of freedom\n  (39 observations deleted due to missingness)\nMultiple R-squared:  0.2711,    Adjusted R-squared:  0.2696 \nF-statistic: 179.2 on 1 and 482 DF,  p-value: &lt; 2.2e-16\n\n# Print the results of the regression analysis with the tidy() function\ntidy(age_hospd_lm)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n24.5314214\n1.4232588\n17.23609\n0\n\n\nage\n0.3722366\n0.0278031\n13.38831\n0\n\n\n\n\n\n\n\n\n\n\nStep 5.2: Univariate linear regression between length of hospitalisation and factor variables\nNow carry out a similar univariate model for each of the factor variables that we have not explored to ascertain which ones are significantly associated with length of hospitalisation.\n\nQUESTION: What of the following variables have a significant linear association with length of hospitalisation?\n\n Sex Other comorbidities Monophasic disease Large tick at removal Vaccinated against TBE\n\n\n\n\n Click to read a hint\n\n\nWe have seen already how to write a linear formula with lm(). You can then use either summary() from {base} or tidy() from {broom} to look at the coefficient and significance value. You could write these functions for each variable, but you could also try to use map() from {purrr} to do them all at once, as we did in the Step 2.2. Have a look at the Chapter on Purrr in the EpiRhandbook if you have any doubts.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n## Here we write one by one for each variable the formula and tidy\n\n#sex\nsex_hospd_lm &lt;- lm(hospd ~ sex, data = tbe)\ntidy(sex_hospd_lm)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n46.66559\n0.6932755\n67.31176\n0\n\n\nsexfemale\n-12.41704\n1.1595927\n-10.70810\n0\n\n\n\n\n\n#other comorbidities\nother_hospd_lm &lt;- lm(hospd ~ other, data = tbe)\ntidy(other_hospd_lm)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n39.590909\n1.014237\n39.035162\n0.0000000\n\n\notheryes\n4.142857\n1.271413\n3.258466\n0.0011993\n\n\n\n\n\n#vaccination\nvac_hospd_lm    &lt;- lm(hospd ~ vac, data = tbe)\ntidy(vac_hospd_lm)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n42.556989\n0.6262426\n67.956072\n0.0000000\n\n\nvacyes\n-8.399095\n3.1607381\n-2.657321\n0.0081379\n\n\n\n\n\n#monophasic course\nmono_hospd_lm   &lt;- lm(hospd ~ mono, data = tbe)\ntidy(mono_hospd_lm)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n40.690566\n0.8291071\n49.077574\n0.0000000\n\n\nmonoyes\n3.396192\n1.2325691\n2.755377\n0.0060844\n\n\n\n\n\n#large tick at removal\ntick_hospd_lm   &lt;- lm(hospd ~ tick, data = tbe) \ntidy(tick_hospd_lm)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n42.731250\n0.7593945\n56.270158\n0.0000000\n\n\ntickyes\n-1.487348\n1.3045725\n-1.140103\n0.2548094\n\n\n\n\n\n## Here we do it with {purrr} all in one command\ntbe %&gt;% \n  select(-hyper, -age, -hospd) %&gt;% # we first remove the columns we have explored before + the outcome column\n  map(.f = ~lm(hospd ~ .x, data = tbe)) %&gt;%   # here we carry out the model for each column. \".x\" represents all the column\n  map(tidy)                                   # finally we do tidy on each model\n\n$vac\n# A tibble: 2 x 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    42.6      0.626     68.0  4.69e-249\n2 .xyes          -8.40     3.16      -2.66 8.14e-  3\n\n$mono\n# A tibble: 2 x 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    40.7      0.829     49.1  1.30e-189\n2 .xyes           3.40     1.23       2.76 6.08e-  3\n\n$other\n# A tibble: 2 x 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    39.6       1.01     39.0  2.43e-151\n2 .xyes           4.14      1.27      3.26 1.20e-  3\n\n$tick\n# A tibble: 2 x 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    42.7      0.759     56.3  5.50e-214\n2 .xyes          -1.49     1.30      -1.14 2.55e-  1\n\n$sex\n# A tibble: 2 x 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     46.7     0.693      67.3 2.99e-247\n2 .xfemale       -12.4     1.16      -10.7 3.79e- 24\n\n\n\n\nStatistically significant (\\(p&lt;0.05\\)) univariable effects were observed for sex, other comorbidities, vaccination and monophasic disease course but not for large tick at removal. Women had on average 12.4 days shorter hospitalisation stay than men, other comorbidities increase the hospitalisation by 4.1 days, vaccination reduced it by 8.4 days, and monophasic disease course increased it by 3.4 days.\n\n\n\nStep 6: Multivariable analysis\nTo control for possible confounding, we will adjust for the minimum adjustment set that we have identified through the DAG analysis (Goal 1), adding each variable in different steps.\n\nStep 6.1: Add age as a covariate to the model\nAs a first step, add age to the model of the main effect.\n\n\n Click to read a hint\n\n\nWe have already calculated and saved the model of our main effect (hyper_hospd_lm). You can add age to this model by creating a new model and adding the additional variable, so that the formula syntax is model &lt;- lm(hospd ~ hyper + newVariable, data = data)\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Creating a new model and adding age \nhyper_hospd_adj_lm &lt;- lm(hospd ~ hyper + age, data = tbe)\n\ntidy(hyper_hospd_adj_lm)                                   \n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n23.6918245\n1.437666\n16.479366\n0.0000000\n\n\nhyperyes\n3.8015966\n1.245007\n3.053473\n0.0023875\n\n\nage\n0.3715581\n0.027567\n13.478364\n0.0000000\n\n\n\n\n\n\n\n\nAdjusting for age, we find that hypertension is associated with a 3.8 increase in the days of hospitalisations. This is only a slight change compared to the effect in the unadjusted model (where the coefficient was 3.9).\n\n\nStep 6.2: Compare the performance of both models\nWe have the univariate model (hyper_hospd_lm), and now we have one adjusted by age (hyper_hospd_adj_lm). Compare both models calculating model performance metrics such as AIC and logLik.\n\n\n Click to read a hint\n\n\nOne easy function to calculate performance metrics is glance() from the {broom} package. But, of course, there are many others. Choose the one you feel most comfortable with!\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nglance(hyper_hospd_lm)   # performance metrics of the univariate model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.0148657\n0.0128219\n13.50128\n7.273399\n0.0072434\n1\n-1945.512\n3897.024\n3909.57\n87861.17\n482\n484\n\n\n\n\n\nglance(hyper_hospd_adj_lm) # performance metrics of the adjusted model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.2849348\n0.2819616\n11.51466\n95.83297\n0\n2\n-1867.974\n3743.948\n3760.676\n63774.52\n481\n484\n\n\n\n\n\n\n\n\nThe output of glance() gives us several performance metrics. If you want to focus on the important bits, you can look at the logLik and the AIC. A larger logLik means a better model; and a lower AIC means also a better model. So, if your logLik goes up and your AIC goes down, you are going in the right direction. The advantage of the logLik is that there is a formal test (Likelihood Ratio Test) to test if two logLiks are significantly different. However, AIC takes more things into consideration than the logLik, such as the complexity of the model (favours simpler models), so it is very useful to compare models with different numbers of parameters (like this case).\nIf you want to know more, let’s review each element of the output given by glance():\n\nr.squared: This is a measure of how well the independent variables in your model explain the variability of the dependent variable. Think of it as a percentage that tells you how much of the changes in the outcome can be predicted by the model. So, in our example, hypertension alone explains 1.5% of the variability in length of hospitalisation, but when we add age, that model explains 28.5% of the variability in our dependent variable.\nadj.r.squared: The adjusted R-squared value adjusts the R-squared value based on the number of predictors in the model. It is a more accurate measure when comparing models with different numbers of predictors (as in this case). Here, it is slightly lower at 28.2%, indicating a small adjustment for the number of predictors.\nsigma: This represents the residual standard error, which is the standard deviation of the residuals.\nstatistic: This is the F-statistic value for the overall significance of the model. It tests whether at least one predictor variable has a non-zero coefficient.\np.value: The p-value associated with the F-statistic.\ndf: Degrees of freedom associated with the model which typically correspond to the number of predictors (1 in the first case and 2 in the second).\nlogLik: The log-likelihood of the model, which is a measure of the model fit. Higher values indicate a better fit. As stated above, one of the main performance measures that you will use as an epidemiologist.\nAIC: Akaike Information Criterion, which is used for model comparison. Lower values indicate a better model.\nBIC: Bayesian Information Criterion, similar to AIC but with a higher penalty for models with more parameters.\ndeviance: This is a measure of the goodness of fit of the model. Lower values indicate a better fit.\ndf.residual: The residual degrees of freedom, which is the number of observations minus the number of parameters estimated.\nnobs: The number of observations used in the model, which is 484 in our case\n\n\n\n(Optional) Step 6.3: Plotting effects of age by hypertension\nIf you remember, in Step 3.2 we checked visually for the association between age and length of hospitalisation by sex. Now, we will do something similar by plotting the estimated effect of age on length of hospitalisation by hypertension status. The final output that we want is a scatterplot displaying the raw data (length of hospitalisation by age), and then the fitted regression line by hypertension status.\n\n\n Click to read a hint\n\n\nIn order to plot the estimated effects of age by hypertension we have to extract the fitted values of “hospd” from the model and add them to the dataframe. This only works if we have removed all rows that contain NAs in the hospd column before. we can then pass this new dataframe to a ggplot() with a geom_point() for the scatterplot and geom_line() for the fitted trend lines. Note: Previously, we used geom_smooth() to add trend lines to the scatterplot. Because we want to plot the predicted values of an existing model and not fit a linear model within ggplot(), we have to use geom_line() and use the predicted values of our model as input for y.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# First add a variable with the fitted values to the dataframe\ndata_fitted &lt;- tbe %&gt;%\n  \n  filter(!is.na(hospd)) %&gt;%   # Remove NAs \n\n  mutate(fit = predict(hyper_hospd_adj_lm)) # Create a new variable with the predicted values\n\n### You can now open data_fitted to have a look at the new column\n\n# Now we do the plot with the fitted lines\n\nplot_fitted &lt;- data_fitted %&gt;%\n  \n  ggplot(mapping = aes(x = age, \n                       y = hospd,\n                       colour = hyper)) +\n  \n  geom_point() +                            # Adding a scatter plot\n  \n  geom_line(aes(y = fit)) +                 # we add a line specifying that we want the fitted and not the observed values in the y-axis\n\n  labs(\n    title = \"Effect of age on TBE hospital stay length for people\\nwith and without hypertension \", # Title of the plot, note that \"\\n\" breaks the title into the next line\n    x = \"Age\",\n    y = \"Length of hospitalisation in days\",\n    colour = \"Hypertension\"\n  ) +\n  \n  theme_bw()                                  # we add a predefined theme\n\nplot_fitted\n\n\n\n\n\n\nWe did not allow the association between age and hospitalisation to vary by levels of hypertension. So we force them to be parallel by the way we specify the model. If we want the slopes to differ, we would need to allow for an interaction term. We’ll get to that later.\n\n\nStep 6.4: Continue building the adjusted model and check quality of the model\nContinue adding the rest of variables that we have to adjust for according to the DAG (TBE vaccination, age, large tick, monophasic course, other comorbidities and sex) to the model hyper_hospd_adj_lm one by one. Check, after you add each variable, model performance metrics to ensure that the model is improving.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n### We first add sex to the previous model\nhyper_hospd_adj_lm &lt;- lm(hospd ~ hyper + age + sex, data = tbe) # formula\ntidy(hyper_hospd_adj_lm)                                # estimates\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n28.9661798\n1.3613386\n21.277718\n0.000000\n\n\nhyperyes\n3.4659484\n1.1079250\n3.128324\n0.001865\n\n\nage\n0.3452202\n0.0246333\n14.014368\n0.000000\n\n\nsexfemale\n-11.0377082\n0.9762639\n-11.306071\n0.000000\n\n\n\n\n\nglance(hyper_hospd_adj_lm)                              # performance metrics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.4353144\n0.4317851\n10.24315\n123.3435\n0\n3\n-1810.837\n3631.674\n3652.584\n50362.62\n480\n484\n\n\n\n\n\n### TBE vaccination\nhyper_hospd_adj_lm &lt;- lm(hospd ~ hyper + age + sex + vac, data = tbe) # formula\ntidy(hyper_hospd_adj_lm)                                # estimates\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n29.0192105\n1.3398585\n21.658415\n0.0000000\n\n\nhyperyes\n3.5401913\n1.0905445\n3.246260\n0.0012512\n\n\nage\n0.3507362\n0.0242813\n14.444681\n0.0000000\n\n\nsexfemale\n-10.9105961\n0.9613218\n-11.349577\n0.0000000\n\n\nvacyes\n-9.6218919\n2.3644063\n-4.069475\n0.0000551\n\n\n\n\n\nglance(hyper_hospd_adj_lm)                              # performance metrics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.454185\n0.4496271\n10.08105\n99.6467\n0\n4\n-1802.611\n3617.223\n3642.315\n48679.6\n479\n484\n\n\n\n\n\n### Monophasic disease course\nhyper_hospd_adj_lm &lt;- lm(hospd ~ hyper + age + sex + vac + mono, data = tbe) # formula\ntidy(hyper_hospd_adj_lm)                                # estimates\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n27.9231475\n1.3632885\n20.482199\n0.0000000\n\n\nhyperyes\n3.7307298\n1.0799901\n3.454411\n0.0006006\n\n\nage\n0.3443505\n0.0240868\n14.296254\n0.0000000\n\n\nsexfemale\n-11.0608203\n0.9517650\n-11.621378\n0.0000000\n\n\nvacyes\n-9.8262935\n2.3391721\n-4.200757\n0.0000317\n\n\nmonoyes\n3.1330906\n0.9155900\n3.421936\n0.0006751\n\n\n\n\n\nglance(hyper_hospd_adj_lm)                              # performance metrics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.4672362\n0.4616634\n9.970207\n83.84164\n0\n5\n-1796.755\n3607.509\n3636.784\n47515.6\n478\n484\n\n\n\n\n\n### Large tick at removal\nhyper_hospd_adj_lm &lt;- lm(hospd ~ hyper + age + sex + vac + mono + tick, data = tbe) # formula\ntidy(hyper_hospd_adj_lm)                                # estimates\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n28.1079813\n1.3968015\n20.1231029\n0.0000000\n\n\nhyperyes\n3.7655402\n1.0821694\n3.4796219\n0.0005482\n\n\nage\n0.3446256\n0.0241066\n14.2959288\n0.0000000\n\n\nsexfemale\n-11.0239613\n0.9542624\n-11.5523372\n0.0000000\n\n\nvacyes\n-9.7114161\n2.3481138\n-4.1358371\n0.0000418\n\n\nmonoyes\n3.0852716\n0.9194697\n3.3554903\n0.0008555\n\n\ntickyes\n-0.5959864\n0.9677751\n-0.6158315\n0.5382995\n\n\n\n\n\nglance(hyper_hospd_adj_lm)                              # performance metrics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.4676595\n0.4609634\n9.976687\n69.8405\n0\n6\n-1796.562\n3609.124\n3642.581\n47477.85\n477\n484\n\n\n\n\n\n### Other comorbidities\nhyper_hospd_adj_lm &lt;- lm(hospd ~ hyper + age + sex + vac + mono + tick + other, data = tbe) # formula\ntidy(hyper_hospd_adj_lm)                                # estimates\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n27.1251926\n1.4596417\n18.5834593\n0.0000000\n\n\nhyperyes\n2.7139444\n1.1769928\n2.3058292\n0.0215491\n\n\nage\n0.3406119\n0.0240754\n14.1477140\n0.0000000\n\n\nsexfemale\n-11.0797108\n0.9506756\n-11.6545649\n0.0000000\n\n\nvacyes\n-9.2298015\n2.3484899\n-3.9301005\n0.0000975\n\n\nmonoyes\n3.0995048\n0.9157172\n3.3847838\n0.0007712\n\n\ntickyes\n-0.7577796\n0.9665465\n-0.7840074\n0.4334257\n\n\notheryes\n2.3008449\n1.0351078\n2.2228070\n0.0266978\n\n\n\n\n\nglance(hyper_hospd_adj_lm)                              # performance metrics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.4731284\n0.4653803\n9.935728\n61.06371\n0\n7\n-1794.063\n3606.126\n3643.765\n46990.1\n476\n484\n\n\n\n\n\n\n\n\nAs you can see, adding the rest of variables identified through the DAG improved the model, according to the metrics. The only exception was the addition of the variable “Large tick at removal”. However, the choice of covariates should be made conceptually through the DAG, and not based on whether there are small differences in AIC/logLik. If you concluded that this variable was a possible confounder, then keep it in the model.\n\n\nStep 6.5: Adding an interaction term\nWe saw in Step 3.2 that the effect of age on length of hospitalisation is modified by sex. We knew this because the slopes were different for males and females. Given this information add now to the model an interaction term between sex and age.\n\n\n Click to read a hint\n\n\nAn interaction can be written as a multiplication of two variables in your regression formula, e.g. age*sex. There is no need to keep both variables individually in the formula AND in the interaction term. By just including the interaction term, R will estimate the coefficients independently for both variables and with the interaction.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nhyper_hospd_adj_lm &lt;- lm(hospd ~ hyper + vac + mono + tick + other + age*sex, data = tbe) # formula\n\ntidy(hyper_hospd_adj_lm)                                # estimates\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n24.2675847\n1.6629366\n14.5932114\n0.0000000\n\n\nhyperyes\n2.9092258\n1.1650411\n2.4971014\n0.0128588\n\n\nvacyes\n-9.0596630\n2.3224314\n-3.9009389\n0.0001096\n\n\nmonoyes\n2.9451978\n0.9064522\n3.2491487\n0.0012396\n\n\ntickyes\n-0.6988387\n0.9557594\n-0.7311868\n0.4650256\n\n\notheryes\n2.2322254\n1.0235851\n2.1807913\n0.0296887\n\n\nage\n0.3998845\n0.0293313\n13.6333864\n0.0000000\n\n\nsexfemale\n-3.0511594\n2.5045520\n-1.2182456\n0.2237354\n\n\nage:sexfemale\n-0.1728331\n0.0499755\n-3.4583541\n0.0005924\n\n\n\n\n\nglance(hyper_hospd_adj_lm)                              # performance metrics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.4860689\n0.4774132\n9.823278\n56.15605\n0\n8\n-1788.045\n3596.09\n3637.911\n45835.97\n475\n484\n\n\n\n\n\n\n\n\n\nQUESTION: Looking at the estimates of the model, for females, what is the net effect of age on length of hospitalisation?\n\n +0.4 +0.23 -0.17 +0.17 -0.32\n\n\nLooking at the results, we see that age has an estimate of 0.4, which means that one additional year of age is associated with an increase in 0.4 days of hospitalisation. We also see that being female is associated with a decrease in 3 days of hospitalisation (compared with being male). The interaction estimate of -0.17 means that for females, each additional year of age is associated with a decrease in 0.17 days of hospitalisation. So, to sum up, all things equal, a female of 41 years, compared to one of 40 years, would have +0.4 days of hospitalisation for having one extra year, but as she is female you have to add the interaction term (-0.17), so the net effect would be +0.23. For males, one extra year would still be associated with +0.4 days of hospitalisation.\nWe also see that adding the interaction term changes the effect estimate for hypertension and improves the model, so we may want to keep the interaction in the model, assuming that this ensures a better control for confounding of “age” and “sex”.\nNote: You should also look for other effect interaction terms in the dataframe. In the interest of the exercise, we will skip this step.\n\n\n\nStep 7: Model diagnostics\nThe multiple linear regression model that we just run, like all models, has several assumptions:\n\nLinearity: The relationship between the independent variables and the dependent variable (length of hospitalisation) is linear. This means that the change in the dependent variable is proportional to the change in the independent variables.\nIndependence: The observations are independent of each other.\nNormality of Residuals: The residuals of the model are normally distributed, meaning that they are symmetrically distributed around 0 and the residuals’ distribution is bell-shaped.\nHomoscedasticity: The residuals (difference between the observed values and the values estimated from the model) have constant variance at every level of the independent variables. This means that the spread of the residuals should be roughly the same across all levels of the independent variables.\nNo Multicollinearity: The independent variables are not highly correlated with each other. High multicollinearity can make it difficult to determine the individual effect of each independent variable on the dependent variable.\nNo Autocorrelation: The residuals are not correlated with each other. This is particularly important in time series data where observations are ordered in time.\n\nIn this case study we will learn how to check two of these assumptions: Normality of residuals and Homoscedasticity\n\nStep 7.1: Normality assumption\nTo assess whether the residuals of our model are normally distributed or not we will do these three things:\n\nGenerating some diagnostic plots of the model\nCreating an histogram with the residuals\nCarrying out a Shapiro-test\n\nTask: Generate diagnostic plots of the model hyper_hospd_adj_lm. Don’t worry if you don’t find out how to do these. If you struggle, have a look at the hint below.\n\n\n Click to read a hint\n\n\nYou can retrieve diagnostic plots by using the function autoplot() from {ggfortify}. Pass your model object to the autoplot() function to generate three basic diagnostic plots. You can also specify which plot autoplot() needs to generate using the which = argument. In the solution, we specify that we want the first 2 plots.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nautoplot(hyper_hospd_adj_lm, which = 1:2)\n\n\n\n\n\n\nLet’s interpret each graph:\n\nResiduals vs. fitted plot (plot 1, upper left corner): You see a scatterplot with a blue line (LOESS smoothing curve). If the residuals are normally distributed around zero, then the blue line will be horizontal (parallel to the zero line).\nQ-Q plot (plot 2, upper right plot): The Q-Q plot shows you whether or not the residuals are normally distributed. On the X-axis you can see the quantiles of a normal distribution, while on the Y-axis you can see the standardized residuals (residuals dived by their standard deviation). If the residuals are normally distributed, in general, most of the points need to lie on the diagonal.\n\n\nQUESTION: Are residuals normally distributed, based on these plots?\n\n No Yes\n\n\nTask: Build an histogram with the residuals of the hyper_hospd_adj_lm model.\n\n\n Click to read a hint\n\n\nTo do an histogram of the residuals you can follow a similar approach than the one we used in the step 6.3. That is, first adding to the tbe dataframe the residuals as a column (you can use the function resid()) and then using ggplot() to plot this column in the x-axis of a geom_histogram()\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# First add a variable with the residual values to the dataframe\ndata_res &lt;- tbe %&gt;%\n  \n  filter(!is.na(hospd)) %&gt;%   # Remove NAs \n  \n  mutate(res = resid(hyper_hospd_adj_lm)) # Create a new variable with the residual values\n\n### You can now open data_res to have a look at the new column\n\n# Now we do the histogram with the residuals\n\ndata_res %&gt;%\n  \n  ggplot(mapping = aes(x = res)) +\n  \n  geom_histogram(aes(y = ..density..)) +                        # Adding a histogram with density\n  \n  #the function below will add the normal curve. \n  stat_function(fun = dnorm,  #The fun = argument we are specifying that we want the normal curve         \n                args = list(mean = mean(data_res$res, na.rm = T), #to draw a normal curve we need to give the mean and standard deviation of our column\n                            sd   = sd(data_res$res, na.rm = T)),  \n                \n                col = \"darkblue\", lwd = 1) +\n  labs(\n    title = \"Histogram of Residuals\", \n    x = \"Residuals\",\n    y = \"Frequency\"\n  ) +\n  \n  theme_bw()                                  # we add a predefined theme\n\n\n\n\n\n\n\nQUESTION: Does the histogram suggest a normal distribution of residuals?\n\n No Yes\n\n\nTask: Carry out a Shapiro-Wilk test to ascertain statistically if residuals are normally distributed\n\n\n Click to read a hint\n\n\nReview Step 4.1 and/or have a look at the EpiRhandbook Chapter on Simple statistical tests if you still have doubts.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\ndata_res %&gt;%\n  shapiro_test(res)\n\n\n\n\n\nvariable\nstatistic\np\n\n\n\n\nres\n0.9960796\n0.2762974\n\n\n\n\n\n\n\n\n\nQUESTION: How do you interpret the result of the Shapiro-Wilk test?\n\n Residuals do not follow a normal distribution We cannot reject the null hypothesis that residuals follow a normal distribution We accept the alternative hypothesis\n\n\n\n\nStep 7.2: Homoscedasticity\nNow we will check the other assumption, that the variance of the residuals (i.e., the magnitude of their distance to 0) does not depend on the predictor.\nCheck homoscedasticity by running plot number 3 (Scale-location plot) in the autoplot() function.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Generate the scale-location plot\nautoplot(hyper_hospd_adj_lm, which = 3)\n\n\n\n\n\n\nThis plot is called a scale-location plot and represents the fitted values vs. the square root of the standardized residuals. With this plot it is possible to check for heteroscedasticity (i.e., heterogeneity of variance - the opposite of homoscedasticity). Ideally, the residuals should be evenly spread out across all levels of fitted values. This means there should be no clear pattern or systematic change in the spread of residuals as you move along the x-axis. If the residuals form a funnel shape (narrow at one end and wide at the other), this indicates heteroscedasticity, meaning the variance of the residuals is not constant. The blue smoothed line should be roughly horizontal and close to zero. Significant deviations from this line can indicate issues with homoscedasticity.\n\nQUESTION: Based on this graph, do you think that the assumption of homoscedasticity is reasonably met?\n\n No Yes\n\n\n\n\n\nStep 8: Public health relevance\n\nDiscuss the PH relevance of your findings and any next steps and recommendations that may result from this.\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nThis is the first time that an association between hypertension and severity of TBE (based on the duration of hospitalisation) has been detected. Even though you suspected such an association in the beginning (and thus tested for it) and even though you think that it may be causal based on your DAGs and the control for confounding, there are more steps involved in establishing a causal relationship. We should follow the Bradford Hill Criteria to argue causality. For example, the biological basis for this effect needs to be established. Similar effects have been seen for other infections (e.g., SARS-CoV-2), which may have promoted the hypothesis in the beginning. You may also decide to look for a possible dose-response relationship in further analysis of our data. Furthermore, these results should be repeated independently to rule out a chance finding. Once the causal relationship between hypertension and TBE is further corroborated, vaccination against TBE for persons with hypertension could be recommended."
  },
  {
    "objectID": "pages/openxlsx2_tutorial-en_revised.html",
    "href": "pages/openxlsx2_tutorial-en_revised.html",
    "title": "Creating reports with R and MS Excel: a tutorial using the openxls2 package (EN)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\nName:\nopenxlsx2 tutorial\n\n\nLanguage:\nEnglish\n\n\nTools:\nR, MS Excel\n\n\nLocation:\nN/A\n\n\nScale:\nN/A\n\n\nDiseases:\nN/A\n\n\nKeywords:\nR, Excel, Report, Export, Format, openxls2, Tutorial\n\n\nTechnical complexity:\nIntermediate\n\n\nMethodological complexity:\nIntermediate\n\n\n\nAuthorship\nOriginal authors: Leonel Lerebours and Alberto Mateo Urdiales\nData source: None (Example data will be generated with R)\n\n\n\n\n\n\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\n\nHere is what the “helpers” look like:\n\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see the solution\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\n\n\n… description here about posting in Community… TO BE COMPLETED BY APPLIED EPI\n\n\n\n\nYou may use the tutorial to learn how to generate reports using R by creating tables and exporting them in MS Excel for visualization with the openxlsx2 package, for educational purposes, and to apply the learned techniques to your personal or professional projects. This tutorial might be freely translated, copied, or distributed. No warranty is made or implied for use of the software for any particular purpose.\n\n\n\n\n\nYou can write feedback and suggestions on this tutorial at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nJuly 2023\nFirst draft\n1.0\nLeonel Lerebours\n\n\nSeptember 2024\nRevision first draft\n1.1\nAlberto Mateo Urdiales\n\n\n\n\n\n\n\n\n\n\n\n\nThe main focus of the tutorial is to use the core functions of the openxlsx2 up to the version 1.8. You must have install MS Excel (or software equivalent like OpenOffice) to visualize the output tables.\nThe data for this tutorial will be generated randomly (any resemble with real data is totally coincidence).\n\n\n\n\n\n\n\n\n\nThe goal of this tutorial is to introduce you in the use of openxlsx2 to export formatted tables in MS Excel.\n\n\n\n\nIt is recommended to have intermediate R skills and have at least a basic knowledge of dplyr (from tidyverse package) like pipe operators and data wrangling. Here some reference.\nEpidemiological experience (e.g., knowledge of how to design outputs tables for reporting purpose)\n\n\n\n\n\nCreate a folder named “openxls2_tutorial” in your laptop\nCreate an Rstudio project in the folder openxls2_tutorial. If you are unsure on how to do that, read the EpiRhandbook on R projects\nYou must have installed MS Excel (or software equivalent like OpenOffice) in your laptop to visualize the output tables."
  },
  {
    "objectID": "pages/openxlsx2_tutorial-en_revised.html#overview",
    "href": "pages/openxlsx2_tutorial-en_revised.html#overview",
    "title": "Creating reports with R and MS Excel: a tutorial using the openxls2 package (EN)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\nName:\nopenxlsx2 tutorial\n\n\nLanguage:\nEnglish\n\n\nTools:\nR, MS Excel\n\n\nLocation:\nN/A\n\n\nScale:\nN/A\n\n\nDiseases:\nN/A\n\n\nKeywords:\nR, Excel, Report, Export, Format, openxls2, Tutorial\n\n\nTechnical complexity:\nIntermediate\n\n\nMethodological complexity:\nIntermediate\n\n\n\nAuthorship\nOriginal authors: Leonel Lerebours and Alberto Mateo Urdiales\nData source: None (Example data will be generated with R)"
  },
  {
    "objectID": "pages/openxlsx2_tutorial-en_revised.html#instructions",
    "href": "pages/openxlsx2_tutorial-en_revised.html#instructions",
    "title": "Creating reports with R and MS Excel: a tutorial using the openxls2 package (EN)",
    "section": "",
    "text": "There are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\n\nHere is what the “helpers” look like:\n\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see the solution\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\n\n\n… description here about posting in Community… TO BE COMPLETED BY APPLIED EPI\n\n\n\n\nYou may use the tutorial to learn how to generate reports using R by creating tables and exporting them in MS Excel for visualization with the openxlsx2 package, for educational purposes, and to apply the learned techniques to your personal or professional projects. This tutorial might be freely translated, copied, or distributed. No warranty is made or implied for use of the software for any particular purpose.\n\n\n\n\n\nYou can write feedback and suggestions on this tutorial at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nJuly 2023\nFirst draft\n1.0\nLeonel Lerebours\n\n\nSeptember 2024\nRevision first draft\n1.1\nAlberto Mateo Urdiales\n\n\n\n\n\n\n\n\n\n\n\n\nThe main focus of the tutorial is to use the core functions of the openxlsx2 up to the version 1.8. You must have install MS Excel (or software equivalent like OpenOffice) to visualize the output tables.\nThe data for this tutorial will be generated randomly (any resemble with real data is totally coincidence)."
  },
  {
    "objectID": "pages/openxlsx2_tutorial-en_revised.html#guidance",
    "href": "pages/openxlsx2_tutorial-en_revised.html#guidance",
    "title": "Creating reports with R and MS Excel: a tutorial using the openxls2 package (EN)",
    "section": "",
    "text": "The goal of this tutorial is to introduce you in the use of openxlsx2 to export formatted tables in MS Excel.\n\n\n\n\nIt is recommended to have intermediate R skills and have at least a basic knowledge of dplyr (from tidyverse package) like pipe operators and data wrangling. Here some reference.\nEpidemiological experience (e.g., knowledge of how to design outputs tables for reporting purpose)\n\n\n\n\n\nCreate a folder named “openxls2_tutorial” in your laptop\nCreate an Rstudio project in the folder openxls2_tutorial. If you are unsure on how to do that, read the EpiRhandbook on R projects\nYou must have installed MS Excel (or software equivalent like OpenOffice) in your laptop to visualize the output tables."
  },
  {
    "objectID": "pages/openxlsx2_tutorial-en_revised.html#why-use-ms-excel-for-reporting",
    "href": "pages/openxlsx2_tutorial-en_revised.html#why-use-ms-excel-for-reporting",
    "title": "Creating reports with R and MS Excel: a tutorial using the openxls2 package (EN)",
    "section": "Why use MS Excel for reporting ?",
    "text": "Why use MS Excel for reporting ?\nExcel is one of the most popular softwares for data analysis, data visualization and many other capabilities, since Excel’s formatting options allow users to adjust fonts, colors, borders, and alignment to create visually appealing reports. MS excel use is very common in many areas, including epidemiological tasks that involve creating reports.\nIn some ways, MS Excel -as other point-and-click tools- is easy to learn, since it lets you “interact” with the data. For example, if we want to do quick calculations and produce a summary table, or if we want to modify a graph and to compare it with other previous reports.\nIf you have experience working in routine reporting -such as working with epidemiological surveillance-, probably you or a co-worker use or have used at some point Excel or any other spreadsheet software like OpenOffice to present tables and summaries.\nHowever, even with all the great perks that Excel has, it is somewhat hard to automate a report with Excel even using a template with a pre-designed format. Is also time consuming to edit a spreadsheet every time you create a table or a graph (specially without knowledge of macros) and prone to errors."
  },
  {
    "objectID": "pages/openxlsx2_tutorial-en_revised.html#automating-a-report-in-excel-with-r-using-openxlsx2-package",
    "href": "pages/openxlsx2_tutorial-en_revised.html#automating-a-report-in-excel-with-r-using-openxlsx2-package",
    "title": "Creating reports with R and MS Excel: a tutorial using the openxls2 package (EN)",
    "section": "Automating a report in Excel with R using openxlsx2 package",
    "text": "Automating a report in Excel with R using openxlsx2 package\nAs described in the CRAN documentation of the openxlsx2 package the main purpose of this package is to simplify the creation of ‘xlsx’ files by providing a high level interface to writing, styling and editing worksheets.\nIn this short tutorial we are going to create and format a summary report from scratch in R without touching Excel or any other spreadsheet software."
  },
  {
    "objectID": "pages/openxlsx2_tutorial-en_revised.html#step-1-getting-ready",
    "href": "pages/openxlsx2_tutorial-en_revised.html#step-1-getting-ready",
    "title": "Creating reports with R and MS Excel: a tutorial using the openxls2 package (EN)",
    "section": "Step 1: Getting ready",
    "text": "Step 1: Getting ready\n\nStep 1.1: Create a new R script\nOnce you have created an Rproject inside the “openxls2_tutorial” folder (as specified in the second point of the section Preparation for the case study). Create a new script with the name openxls2_tutorial.R and save it in the subfolder “openxls2_tutorial”.\n\n\nStep 1.2: Install/load packages\nAs you probably know, the first part of our script (besides including -commented- some information about the aim, author, date last updated and contact details) is to install and load packages. Fortunately, there is a package that does this task very effectively: {pacman}. The function p_load() from this package will install any packages listed not already installed and will load them. If a listed package had already been installed, it will just load it. You can find more about installing/loading packages in the Packages section of the EpiRhandbook.\nUsing this approach, try to install and load the following packages: janitor, openxlsx2 and tidyverse.\n\n\n Click to read a hint\n\n\nYou may end up using a long list of packages. Unfortunately different packages have functions with the same name. For example, the package {dplyr} (already installed with {tidyverse}) has a function called select() which we frequently use to subset columns of a data frame. But other packages such as {MASS} do also have a function called select(). This could create headaches if you want to subset columns using dplyr’s select() but R thinks you’re calling MASS’s select() (we call this masking - dplyr’s select() is masked by MASS’s select()). Given that you are more likely to use functions from {tidyverse}, ensure that this is the last package in your p_load() list so that functions from {tidyverse} (including {dplyr} functions) will always “prevail”.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  janitor,    # data cleaning and tables\n  openxlsx2,  # create xlsx files \n  lubridate,  # to manage dates\n  tidyverse  # data management and visualization\n)"
  },
  {
    "objectID": "pages/openxlsx2_tutorial-en_revised.html#step-2-create-a-fake-dataset",
    "href": "pages/openxlsx2_tutorial-en_revised.html#step-2-create-a-fake-dataset",
    "title": "Creating reports with R and MS Excel: a tutorial using the openxls2 package (EN)",
    "section": "Step 2: Create a fake dataset",
    "text": "Step 2: Create a fake dataset\nBefore start using the functions of openxlsx2, we need to decide on what we want into the exported report (i.e., how many tables, what type of tables and which data inside.)\nFor this tutorial, the scenario is to do a summary of the microbiology laboratories’ production, including:\n\nhow many samples were received\nhow many were confirmed\nwhen the samples had a confirmed diagnosis\n\nWe will not be using real data for this tutorial, but we will create it with R. Feel free to create it with MS Excel if you feel more comfortable.\nTask: Generate a fake data frame of 1000 observations using the following variables:\n\ndate: from January 01, 2022 to December 31st, 2024.\nlaboratories: a categorical variable with five categories that have values from “A” to “E”.\nn_samples: The Number of samples received. a numerical variable (ramdon number from 0 to 100).\nn_confirmed: The Number of samples with positive results. A numerical variable calculated as a proportion of the previous variable, with a range that goes from 0.02 to 0.05.\npct_confirmed: The percentage of samples confirmed (n_samples/n_confirmed)\n\n\n\n Click to read a hint\n\n\nOne way to create the dataframe is to use the function tibble() which comes when you install {tidyverse}. Inside tibble() you can create the specified columns using the sample() function which will create values randomly once you have specified the date rage, the categories etc. If you are unsure on how to do this read the documentation of the tibble function or this post from R bloggers which may help you. If you still do not manage, have a look at the solution. Don’t worry, this may be the most difficult part of the case study!\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# we first use this function which will ensure that, even though the dataframe will be generated with random values, we will ALWAYS get the same values if we rerun the script. The number inside is not relevant\n\nset.seed(1300) \n\n# Create dataframe for the example using 1000 observations\n\ndb &lt;- tibble(\n  \n  # Random dates\n  \n   date=sample(seq(as.Date(\"2022-01-01\"),           # the begging of the period\n                  as.Date(\"2024-12-31\"),            # the end of the period\n                  by=\"day\"),                        # the time interval\n              replace = TRUE,                          # setting replace to true means that each date can be chosen to be in the sample more than once.\n              1000),                                # this is the number of observations\n  \n   # Random Labs (A to E)\n   \n   laboratories=sample(LETTERS[c(1:5)],             # we are saying that this columns should have letters from A (1) to E (5)       \n                      replace = TRUE, \n                      1000),\n  \n  # Random samples (by day and lab)\n  \n   n_samples=sample(c(1:100),                       \n                   replace = TRUE, \n                   1000)) %&gt;% \n  \n  #Random confirmed samples\n  mutate(\n    \n    n_confirmed=round(sample(seq(                  # the round function is used to round numbers. In this case the multiplication may mean that we have decimals\n      from=0.01, \n      to=0.05, \n      by=0.001), \n      replace=T,\n      1000)*n_samples,\n      digits = 0),                                 # setting digits to 0 is saying to round it to the nearest whole number\n    \n    # % positivity\n    pct_confirmed=n_confirmed/n_samples       \n    \n    )\n\n#take a look at the db created\nhead(db)\n\n# A tibble: 6 × 5\n  date       laboratories n_samples n_confirmed pct_confirmed\n  &lt;date&gt;     &lt;chr&gt;            &lt;int&gt;       &lt;dbl&gt;         &lt;dbl&gt;\n1 2024-09-04 B                   15           0        0     \n2 2023-02-27 C                   90           1        0.0111\n3 2023-06-02 A                   88           4        0.0455\n4 2023-02-19 B                    1           0        0     \n5 2024-06-15 D                   29           1        0.0345\n6 2022-06-24 C                   43           2        0.0465\n\n\n\n\n Note: If you want to create a dummy database with Excel, (or you want to use your data) you will have to import your file. To do that, you can use the function import() from the {rio} package or the function read_xlsx() from the openxlsx2 package. Read the dedicated EpiRhandbook Chapter for importing data if you have any doubts."
  },
  {
    "objectID": "pages/openxlsx2_tutorial-en_revised.html#step-3-transfoming-the-data-and-creating-the-summary-tables",
    "href": "pages/openxlsx2_tutorial-en_revised.html#step-3-transfoming-the-data-and-creating-the-summary-tables",
    "title": "Creating reports with R and MS Excel: a tutorial using the openxls2 package (EN)",
    "section": "Step 3: Transfoming the data and creating the summary tables",
    "text": "Step 3: Transfoming the data and creating the summary tables\nAs you can see, with this simple fake dataframe of 5 columns we may want to know :\n\nHow many samples were reported by month each year.\nWhat is the proportion of the confirmed samples by month.\nWhat is the proportion of samples reported by each laboratory.\nThe overall positivity rate by laboratory.\n\n\nStep 3.1: Summary table with number of samples received\nLet’s start by creating a table with the number of samples received by month each year. We want a table that has a nice formatting to put in a report, so we want a column with the year of reporting and one column for each calendar month. We also want to add the totals.\nWe will achieve this in to separate steps:\nTask 1: Aggregate the number of samples received (column n_samples) by month and year. Called the new column with the aggregated number tot_samples\n\n\n Click to read a hint\n\n\nThere are different ways to aggregate data. We suggest you use the function group_by() alongside summarise(), which is a {dplyr} approach. If you have never used this approach or if you have doubts, read the this section of the EpiRhandbook. In any case, you’ll need to create columns for the month and the year using the date column. You can do this using the functions month() and year().\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n#table for samples by year and months\n\n#table for samples by year and months\n\ntotal_sample_tab &lt;- db %&gt;% \n  \n  # we first create a column named months and years which are the respective months and years of the column \"date\"\n  \n  mutate(months = month(date,label=T), # the argument label = T ensures that months have the name of the month and not their number\n         years  = year(date)) %&gt;% \n  \n  # we group by the new columns\n  group_by(years, months) %&gt;% \n  \n  # and we create a new column by adding by each group the number of samples received\n  summarise(tot_samples = sum(n_samples), .groups = \"drop\") # the .groups = \"drop\" argument ungroup the data, which is always advisable after we finish aggregation\n\n\n\n#check the new data frame\nhead(total_sample_tab)\n\n# A tibble: 6 × 3\n  years months tot_samples\n  &lt;dbl&gt; &lt;ord&gt;        &lt;int&gt;\n1  2022 Jan           1587\n2  2022 Feb           1439\n3  2022 Mar           1099\n4  2022 Apr            906\n5  2022 May           1378\n6  2022 Jun           1646\n\n\n\n\nThe new dataframe has one column for years, one for months and one for the total number of samples received. We call this the long format. This format is useful for further analysis/visualisation (creating a plot), but here what we want is to export this into a nice formatted table, so we want to the months to go in the columns. In other words, we want our dataframe in a wide format.\nTask 2: Pivot your data from long to wide so that you have one column per month. Add the totals.\n\n\n Click to read a hint\n\n\nOne way to do this is to use the function pivot_wider(). You need to specify where the names of the columns will come from and where the values will come from. If you are not familiar with pivoting or if you have doubts, spend some time in this section of the EpiRhandbook\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# pivoting from long to wide\ntotal_sample_tab &lt;- total_sample_tab %&gt;% \n  pivot_wider(names_from = months,        # so the names of the columns will be the months\n              values_from = tot_samples,  # and the values the number of samples\n              values_fill = 0) %&gt;%        # if there were no data in a given month, it would fill it with 0\n  \n  adorn_totals(c(\"col\", \"row\"))           # we add the sum of the totals both by row and column\n\ntotal_sample_tab\n\n years  Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec Total\n  2022 1587 1439 1099  906 1378 1646 1640  799  955 1422  976 1550 15397\n  2023 1391 1488 1390 1870 1236 1488 1737 1097 1320 1642 1581 1647 17887\n  2024 1339 1156 1526 1188 1274 1609 1455 1342 1974 1226 1626 1974 17689\n Total 4317 4083 4015 3964 3888 4743 4832 3238 4249 4290 4183 5171 50973\n\n\n\n\n\n\nStep 3.2: Summary table with positivity percentage\nTask: Following a similar approach to the one we used in the previous step, create a table showing, by year and month, the positivity percentage of the samples\n\n\nClick to see a solution (try it yourself first!)\n\n\n\npositivity_tab &lt;- db %&gt;% \n  \n  # we first create a column named months and years which are the respective months and years of the column \"date\"\n  \n  mutate(months = month(date,label=T), # the argument label = T ensures that months have the name of the month and not their number\n         years  = year(date)) %&gt;% \n  \n  # we group by the new columns\n  group_by(years, months) %&gt;% \n  \n  # we create  new columns by adding by each group the number of samples received, the total confirmed and calcualte percentage\n  summarise(tot_samples = sum(n_samples),\n          tot_confirmed = sum(n_confirmed),\n          pct = round(tot_confirmed/tot_samples, digits = 5), .groups = \"drop\") %&gt;% # round can be use to round up numbers. in this case to only 1 decimal\n  \n  #we select the columns we're interested\n  select(years, months, pct) %&gt;% \n  \n  # we pivot them into wide format\n  pivot_wider(names_from = months,\n              values_from = pct, \n              values_fill = 0)\n\npositivity_tab\n\n# A tibble: 3 × 13\n  years    Jan    Feb    Mar    Apr    May    Jun    Jul    Aug    Sep    Oct\n  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1  2022 0.0309 0.0285 0.0319 0.0342 0.0268 0.0316 0.0287 0.0263 0.0304 0.0267\n2  2023 0.0367 0.0289 0.0295 0.0267 0.0235 0.0343 0.0311 0.0228 0.0296 0.0311\n3  2024 0.0261 0.0294 0.0242 0.0295 0.0330 0.0311 0.0261 0.0276 0.0314 0.0286\n# ℹ 2 more variables: Nov &lt;dbl&gt;, Dec &lt;dbl&gt;\n\n\n\n\n\n\nStep 3.3: Summary table by laboratory\nTask: Create a summary table for each year and laboratory with the total number of samples, the number of samples confirmed and the positivity percentage, as well as the total by rows.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlaboratory_summary &lt;- db %&gt;% \n  \n  # we first create a column named years which are the years of the column \"date\"\n  \n  mutate(years=year(date)) %&gt;% \n  \n  # we group by year and laboratory \n  group_by(years, laboratories) %&gt;% \n  \n  # we create new columns with the total number of samples received and the total number of samples confirmed\n  summarise(total_samples=sum(n_samples),\n          total_confirmed=sum(n_confirmed), .groups = \"drop\") %&gt;% \n  \n  # we arrange our table by laboratory and year\n  arrange(laboratories, years) %&gt;% \n  \n  # we add the totals by row\n  adorn_totals(\"row\") %&gt;% \n  \n  # we add a column with the positivity percentage by row\n  mutate(positivity_rate= round(total_confirmed/total_samples, digits = 5)) %&gt;% \n  \n  # we rename the columns\n  rename(\"Years of reporting\"=years,\n         \"Laboratories\"=laboratories,\n         \"Total Samples\"=total_samples,\n         \"Confirmed Samples\"=total_confirmed,\n         \"% of confirmed samples\"=positivity_rate)\n\nlaboratory_summary \n\n Years of reporting Laboratories Total Samples Confirmed Samples\n               2022            A          4202               135\n               2023            A          3638                98\n               2024            A          3997               110\n               2022            B          2795                76\n               2023            B          3759               104\n               2024            B          3800               119\n               2022            C          2441                68\n               2023            C          3425               111\n               2024            C          3045                90\n               2022            D          2730                75\n               2023            D          2863                83\n               2024            D          3553               106\n               2022            E          3229               102\n               2023            E          4202               127\n               2024            E          3294                93\n              Total            -         50973              1497\n % of confirmed samples\n                0.03213\n                0.02694\n                0.02752\n                0.02719\n                0.02767\n                0.03132\n                0.02786\n                0.03241\n                0.02956\n                0.02747\n                0.02899\n                0.02983\n                0.03159\n                0.03022\n                0.02823\n                0.02937"
  },
  {
    "objectID": "pages/openxlsx2_tutorial-en_revised.html#step-4-export-the-tables-to-excel",
    "href": "pages/openxlsx2_tutorial-en_revised.html#step-4-export-the-tables-to-excel",
    "title": "Creating reports with R and MS Excel: a tutorial using the openxls2 package (EN)",
    "section": "Step 4: Export the tables to excel",
    "text": "Step 4: Export the tables to excel\nNow that we have the tables for the summary report, lets do a overview of the main functions of openxlsx2 :\n\nMain functions\n\nwb_workbook(): to create a new workbook\nwb_add_worksheet(): to add worksheets (name, zoom level and gridlines)\nwb_add_data(): to add either a dataframe, a table, text string a single value\nwb_save(): to export the workbook to a file (Excel format)\nwb_open(): really handy to open right away the workbook in Excel (to see the results of the code)\n\n\n\nRelated to formating\n\nwb_add_font(): to specify font type for a region\nwb_add_border(): to add borders to a region\nwb_add_cell_style(): to add specific style to a region (wrap, vertical/horizontal/left/right alignment,\nwb_add_numfmt(): to add specific number style to a cells range\nwb_add_fill(): to add fill color to a region\nwb_set_col_widths(): to setup the width of specific columns\nwb_set_row_heights(): to setup the heights of specific rows\nwb_merge_cells(): to merge a range of cells\n\nSome of the functions use parameters to specify coordinates in the spreadsheet numbers (as columns and row) and others use dimensions, which are the combination of letters for columns and number for letters.\n\n\nRelated to location / dimension / coordenates\nThe following functions are really important to get the coordinates of where to apply specific formatting, since most of the functions to add format/style need a range (in row and columns). With these we can obtain Excel type coordinates of specify a region (such as A1:B30) based on the size of the tables and the location in the worksheet of the table that we want to export.\nrowcol_to_dims(): to create a vector with Excel’s coordinates from the rows and columns numbers you provide (example: rowcol_to_dims(col= c(1:3), row= c(1:3)) will result in “A1:C3”). You can combine the use of nrow() and ncol() to get the size of a table and get the Excel’s coordinates, depending where you want to place the table. Is important to know beforehand the position of a table (number of row and column) since the starting row and column so the format we want to apply fall in the range we want.\nwb_dims(): to get a dimension of an object (dataframe or matrix) for the spreadsheet. It start from coordinate A1 by default, for example if we use wb_dims(x=mtcars) will return the value of “A1:K33”. This helper function\n\n\n\nGeneral approach, you can create an example with all the formats in excel first too\n\n\nNow that we have some dataframes and see a quick overview of the main or most used functions from openxlsx, lets start to create the following output in excel:\n\nFirst lets see the “style” we want to add to the outputs and also the dimensions of the columns and rows where we want to apply a format. Like we do when we work in Excel directly.\nFor example in the picture above we can observe the title in the middle of each tables is at the center and the text is larger and bold. The first row with the column’s title has also bold text and has top and bottom borders. The last row, Total, has also bold text and has top bolder. In all of the cells the text is centered. In the top table the text of the body is in number format and the last row too. In the bottom table, the text of the body and last row are in percentage format.\nWe have to take into account these details to start creating the vectors with the ranges. There are formats that applies for the whole table, others for just part of the tables.\nAlso, it is very important to know where the tables are going to be located and if it is a table that is going to grow over time (from top to bottom or left to right).\n\n\nStep 4.1: Set the table positions\nThe first column and row of the top table (Table with the total samples received) in the exercise have the starting position at cell B3, whilst the bottom table (The positivity table) starts at cell B10.\nThe first row of the first table (Table with the total samples received) goes from cell B3 to cell O3, the last row range is B7 to O7. For the bottom table (The positivity table) the first row range is B10 to N10 and the bottom row is from B14 to N14.\nFor the vector with the ranges, we have to specify the columns as number instead of letters. the rowcol_to_dims() function will convert the numbers coordinates to the Excel range format (such as A1:B3). With the combination of the function ncol() and nrow() and the starting position we can get the range of the whole table.\nTask: Use the function rowcol_to_dims() to obtain the range of the columns for the Table with the total samples received (B3:07). Assign this range to the name tab1_dimres. Get also the range for the same table’s title (B2:B2)\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n#get the table 1 (Table with the total samples received) dimensions\n\ntab1_dimres &lt;- rowcol_to_dims(\n  # 1:ncol() will give us the a range for the number of columns of the table. By adding one we are specifying that we want the range to start in B instead of A\n  \n  col = 1:ncol(total_sample_tab) + 1, \n  \n  # similarly 3:nrow() will create a range that starts in 3 and will go until nrow() + 3, whic is 7\n  row = 3:(nrow(total_sample_tab) + 3))\n\ntab1_dimtitle &lt;- rowcol_to_dims(col = 2, row = 2)\n\n#get the first row and last row dimension of table 1 (Table with the total samples received)\ntab1_dimfirstrow&lt;- rowcol_to_dims(col = 1:ncol(total_sample_tab)+1, row=3)\n\ntab1_dimlastrow &lt;- rowcol_to_dims(col = 1:ncol(total_sample_tab)+1, row=nrow(total_sample_tab)+3)\n\n\n\nSince the table1 (Table with the total samples received) is a table that will grow over the time from top to bottom, the starting position of the table 2 (The positivity table) must depend on the starting position of the first table, if we want to dinamically setup the starting position of The positivity table.\nLets create a vector with the sequence of numbers of the rows where the The positivity table will be located based on the position of table 1 and the spaces between Table with the total samples received and The positivity table.\nTable with the total samples received has 7 rows nrow(total_sample_tab) and the starting position in the spreadsheet is row 3, and we want the second table starts two rows after the end of table 1. So, the starting position row of table 2 is the sum of the numbers of rows of table 1 + the starting position of table 1 + the rows after table 1 last row.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n#vector with the row for the starting position of table 2\n\ntab2_row_start &lt;- nrow(total_sample_tab)+3+3\n\ntab2_row_seq &lt;- seq(from= nrow(total_sample_tab)+3+3, \n                    to=nrow(positivity_tab)+nrow(total_sample_tab)+3+3, \n                    by=1)\n\n\ntab2_dimres &lt;- rowcol_to_dims(col = 1:ncol(positivity_tab)+1, #the columns are not affected\n                              row = tab2_row_seq)\n\n#get the first row and last row dimension of table 2 (The positivity table)\n\ntab2_dimtitle &lt;- rowcol_to_dims(\n  col = 2, \n  row = tab2_row_start - 1)\n\ntab2_dimfirstrow&lt;- rowcol_to_dims(\n  col =1:ncol(positivity_tab) + 1, \n  row=tab2_row_start)\n\ntab2_dimlastrow &lt;- rowcol_to_dims(\n  col = 1:ncol(positivity_tab) + 1, \n  row  =nrow(positivity_tab) + tab2_row_start)\n\ntab2_dimbody_pct &lt;- rowcol_to_dims(\n  col = 2:ncol(positivity_tab) + 1, \n  row = 1:nrow(positivity_tab) + tab2_row_start)\n\n\n\nWe are getting there!, now that we have the ranges where we just need to format it.\n\n\nStep 4.2: Creating the table in MS Excel\nThe next step now is to start using the {openxlsx2} functions to:\n\nAdd the tables\nAdd the formatting/styles\nSave the workbook into a Excel file\n\nTask: Looking at the {openxlsx2} functions described in the section Main functions have a go at:\n\nCreate a workbook object\nAdd at least one worksheet\n\nBelow you have one possible solution that we propose\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nwb_main &lt;- wb_workbook(\"Laboratory_Data\") %&gt;%                    #creating the workbook\n\nwb_add_worksheet(\"lab summary\",                                  #adding the first worksheet\n\ngridLines = FALSE,                                               #remove gridlines\n\ntabColor = \"red\") %&gt;%                                            #tab color in the spreadsheet\n\nwb_add_data(x=\"Samples reported by month and year (All laboratories)\", #adding the title of table 1\n\nstart_col = 2,                                                   #title starting in col 2 or \"B\" \n\nstart_row = 2) %&gt;%                                               #title starts in row 2 as well\n\nwb_merge_cells(rows=2,                                           #merging the row above Table 1\n\ncols = 1:ncol(total_sample_tab) + 1) %&gt;%                         #column range of Table 1            \n \nwb_add_data(x=total_sample_tab, start_col  = 2,                  #data starts in column 2 and row 3\n\nstart_row =3 ) %&gt;%\n\nwb_add_data(x=\"Sample positivity by month and year (All Laboratories)\", #add title of table 2\n            start_col = 2,\n            \n            start_row = tab2_row_start-1) %&gt;%\n  \nwb_merge_cells(rows= tab2_row_start - 1, #merging the row above Table 2\n\ncols = 1:ncol(positivity_tab)+1) %&gt;%\n\nwb_add_data(x=positivity_tab, start_col  = 2,\n\nstart_row =tab2_row_start, na.strings =\"-\" )\n\nwb_open(wb_main) # to see a preview\n\n\n\nWe can see so far what we have, almost done! \n\n\nStep 4.3: Formatting the table\nNo we just need to format the table.\nTask: Format the table using the {openxlsx2} functions described in the Related to formatting section.\nBelow is our proposed solution.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nwb_main_w_styles &lt;- wb_main %&gt;%\n  \n  wb_add_cell_style( 1, tab1_dimres,\n\n  vertical = \"center\",\n  \n  horizontal = \"center\",\n  \n  wrapText = 1) %&gt;%\n  \n  wb_add_cell_style(1 , tab1_dimtitle,\n  \n  vertical = \"center\",\n  \n  horizontal = \"center\") %&gt;% \n  \n  wb_add_border(1, tab1_dimfirstrow, \n                \n                top_border = \"thick\", \n                \n                top_color = wb_color(hex = \"000000\"),\n                \n                bottom_border = \"thick\", \n                \n                bottom_color = wb_color(hex = \"000000\"),\n                \n                inner_vgrid = \"none\",\n                \n                left_border=\"none\",\n                \n                right_border = \"none\") %&gt;% \n    \n  wb_add_font(dims = tab1_dimfirstrow,\n              \n              bold = \"double\") %&gt;% \n  \n  wb_add_font(dims = tab1_dimtitle,\n              \n              size=12,\n                \n              bold = \"double\") %&gt;% \n  \n  wb_add_font(dims = tab1_dimlastrow,\n              \n              size=11,\n              \n              bold=\"dobule\") %&gt;% \n  \n  wb_add_border(dims = tab1_dimlastrow,\n                \n                top_border = \"thick\",\n                \n                top_color = wb_color(hex = \"000000\"),\n                \n                inner_vgrid = \"none\",\n                \n                left_border=\"none\",\n                \n                right_border = \"none\",\n                \n                bottom_border = \"none\") %&gt;% \n\n  wb_add_numfmt(dims = tab1_dimlastrow,\n                \n                numfmt = \"#,0\") %&gt;% \n  \n  wb_add_numfmt(dims = rowcol_to_dims(row=1:nrow(total_sample_tab)+3,\n                                      col=ncol(total_sample_tab)+1),\n                \n                numfmt = \"#,0\") %&gt;% \n  \n wb_set_col_widths(cols = 2, widths = 20) %&gt;% \n  \n wb_set_row_heights(rows = c(2, 3,nrow(total_sample_tab)+3), heights = 30 )  %&gt;%\n  \n  wb_add_cell_style(1, tab2_dimres,\n\n  vertical = \"center\",\n\n  horizontal = \"center\",\n\n  wrapText = 1) %&gt;%\n\n  wb_add_cell_style(1, tab2_dimtitle,\n\n  vertical = \"center\",\n\n  horizontal = \"center\") %&gt;% \n\n  wb_add_border(1, tab2_dimfirstrow, \n              \n              top_border = \"thick\", \n              \n              top_color = wb_color(hex = \"000000\"),\n              \n              bottom_border = \"thick\", \n              \n              bottom_color = wb_color(hex = \"000000\"),\n              \n              inner_vgrid = \"none\",\n              \n              left_border=\"none\",\n              \n              right_border = \"none\") %&gt;% \n  \n  wb_add_font(dims=tab2_dimfirstrow,\n\n              bold=\"double\") %&gt;%\n\n  wb_add_font(dims=tab2_dimtitle,\n\n              size=12,\n\n              bold=\"double\") %&gt;%\n  \n  wb_add_border(dims = tab2_dimlastrow,\n\n                top_border = \"none\",\n\n                inner_vgrid = \"none\",\n\n                left_border=\"none\",\n\n                right_border = \"none\",\n\n                bottom_color = wb_color(hex = \"000000\"),\n\n                bottom_border = \"thick\") %&gt;%\n  \n\n   \n  wb_add_numfmt(dims = tab2_dimbody_pct,\n\n                numfmt = \"#.0%\") %&gt;%\n\n wb_set_col_widths(cols = 2, widths = 20) %&gt;%\n\n wb_set_row_heights(rows = c(tab2_row_start-1,tab2_row_start,nrow\n                             (positivity_tab)+tab2_row_start), heights = 30 ) %&gt;%\n \n  wb_open() # to open a temporary file \n\n\n\nIf all functions and commands are correct, you should see something like the following output:\n\n\n\nThe formated tables in Excel\n\n\n\n\nStep 4.4: Exporting the table\nThe last step is to export the table and save it in our computer.\nTask: Using the function wb_save(), export the tables into your local computer\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# save the output into an excel file\nwb_save(wb_main_w_styles, \"Lab_tables.xlsx\", overwrite = T) \n\n\n\n\nDepending on how complex your report is, you can add more worksheets. Iteration (like using map() from purrr) could help you to automate several reports from different provinces or geographical units. Have a look at the Iteration chapter of the EpiRhandbook if you want to explore this further.\n\nThere are other great functions to add more details or expand the format of the tables, for example adding conditional format, or sparklines. This tutorial covers just the main functions and what is the most common task to add formats. For more in depth formatting, please review the openxlsx2 following vignette\nThanks for reading this tutorial!"
  },
  {
    "objectID": "pages/under_construction.es.html",
    "href": "pages/under_construction.es.html",
    "title": "Sitio web en construcción",
    "section": "",
    "text": "Sitio web en construcción\n\n\n\n\n\n\nEN CONSTRUCCIÓN\n\n\n\nEsta página está en desarrollo. El contenido y la URL cambiarán.\n\n\nPara obtener instrucciones sobre cómo utilizar nuestros estudios de casos, consulte nuestra How-to Guide. Agradecemos sus comentarios y sugerencias en contact@appliedepi.org. También puede debatir sobre el estudio de caso o conceptos relacionados en la Applied Epi Community."
  },
  {
    "objectID": "pages/multi_disease_lab.html",
    "href": "pages/multi_disease_lab.html",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Tool: R | Technical complexity: Intermediate | Methodological complexity: Basic | Prior knowledge required: R basics (Using Rstudio; R packages, functions and arguments, using pipes) as well as key tidyverse functions and ggplots) | Source: Applied Epi, with technical support provided by the CDC Global Surveillance, Laboratory, and Data Systems Branch in collaboration with TEPHINET.\n\n\n\nFor instructions on how to use our case studies, see our How-to Guide. We welcome feedback and suggestions via contact@appliedepi.org. You can also discuss the case study or related concepts on the Applied Epi Community.\n\n\n\nYou are an epidemiologist working in the national surveillance office of Feveria, a very small tropical country. There are three districts within Feveria:\n\nFeveria Central: an over-populated urban area, with sometimes unreliable water and sanitation infrastructure.\nLake Minara: a lake area with good infrastructure but many mosquitoes in the warmer months of the year.\nKasara: a more sub-urban area on the other side of Feveria Central.\n\nMap of districts in the country Feveria\n\nIt is January 2025, and your supervisor would like you to transfer the routine processing of notifiable disease data from Excel into R, and to conduct some analyses on the data. She wants to know at least:\n\nHow many suspected cases of the different notifiable diseases were reported in 2024, and which was most common?\nWhat percentage of them ended up being confirmed?\nHow many confirmed cases of different notifiable diseases were reported in 2024, and which was most common?\nHow were confirmed cases geographically and temporally distributed in Feveria?\n\nShe asks that you write code to import, clean, link, and analyse the following linelists:\n\n2024 notifiable disease surveillance data: Referred to also as “notification data”, this is surveillance data on five notifiable diseases reported by clinics in Feveria: dengue, malaria, cholera, typhoid fever, and yellow fever. These are suspected cases, based on patients’ symptoms. Clinicians enter each notification into an online system every weekday.\n2024 laboratory test result data: This data comes from lab test results, from three major labs in Feveria. These results are for samples taken from those suspected notifiable disease cases mentioned above.\n\nLet’s go!\n\n\n\nIn this case study you will:\n\nUse key R functions to clean data, reshape datasets, link data sources, and create new columns using logical conditions to prepare data for analysis.\nConduct data inspections and data quality checks at multiple stages of the project and understand their importance for reliable analysis.\nPerform basic descriptive analyses to compare disease trends across different data sources, before and after linkage.\nInterpret differences in results across data sources and understand how these reflect the structure and design of the overall surveillance system.\n\n\n\n\n\n\nStart by setting up a reproducible and well-organized workflow. This will make it easy to rerun your analysis whenever needed.\nTasks:\n\nSet up an RStudio project\nSet up clear sub-folders where your code, data, and outputs will go\nCreate an R script, or an R Markdown file if you prefer. Make sure the script purpose, date, and author are written as comments at the top.\nExtra: Ensure your working language in RStudio is appropriate (e.g. English for this exercise)\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\n\nCreate a folder where all the work in this case study will go. For example, create ‘multi_disease_lab’ on your computer desktop. Create your RStudio project to be based in this folder.\nWe suggest creating the following sub-folders: scripts (for your code), data (for your data), and outputs (for your analytical outputs).\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nCreate a folder (e.g. ‘multi_disease_lab’ on your Desktop) for your work. To create an Rstudio project in your new folder, click New Project… in the top left of your R Studio, then Existing Directory, then Browse to select your new folder. For more information, look at the R projects section of the Epi R Handbook.\nStart a new R script by clicking New File… in the top left of your R Studio, then R Script. Save it immediately in the appropriate place, e.g. in a ‘scripts’ sub-folder of your R Project.\nAt the top of your new R script, write some essential information like your name, the purpose of the file, and the date.\nYour R locale determines the language and regional settings used for things like date formats and translations. If your locale is different from the language you want for your report (e.g., a French locale vs. an English report), you can change it to English by running Sys.setlocale(\"LC_ALL\", \"English\"). Include this in your script if needed, or skip it if your locale is usually appropriate. This is explained in more detail in the How-to Guide.\n\n\n\n\n\n\nNext in your R script, you need to install and load the necessary R packages. This ensures that the functions you need are available for your analysis.\nYou will need the following packages: {rio} (for importing data),{skimr} (for reviewing data), {janitor} (for cleaning data), {lubridate} (for cleaning dates), {epikit} (for epi-related tasks), {gtsummary} (for summary statistics/tests and regression), {apyramid} (for age-sex pyramids), {flextable} (for presentation-ready tables), {naniar} (for evaluating missing data), and {tidyverse} (for general data manipulation/science tasks). You will also need the {remotes} package to download the data - which we will explain in the download section.\nAs you start, your trusted colleague nudges you and whispers “I’ve heard that a great way to manage your packages is with the {pacman} package”.\nOver to you!\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse the function p_load() from pacman for this task. You provide the function with a list of packages that you want to use. The function will undertake two steps per package: 1) Check if the package is installed on your computer, and install it if necessary, then 2) Load the package so it can be used during this R session.\nIf you don’t already have pacman installed, you will need to install it the “traditional way” first, with install.packages().\nNote that the order of packages in your p_load function can be important. If two packages have the same function names (e.g. select() in the package MASS and select() in tidyverse, which do different things), then R will use the function from the most recently loaded package. To prioritize functions from tidyverse, which are commonly used for data manipulation and visualization, load tidyverse last.\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  flextable,  # Presentation ready tables\n  naniar,     # Evaluating missingness of data\n  remotes,    # Used to install package to download data\n  tidyverse   # data management and visualization\n)\n\n\n\n\n\n\n\n\n\n\nYour office provides you with two files for your analysis, both containing data for 2024 and updated as of 15th January 2025:\n\nA disease notification-level dataset (“multidisease_notifications.xlsx”) with case information from 5 health centers.\nA laboratory test-level dataset (“multidisease_tests.csv”) submitted by three laboratories conducting testing for the 5 health centers.\n\nFor this case study, you can download the data via Applied Epi’s very useful data repository, which you can access using the {appliedepidata} package. Follow these steps:\n\nInstall the {appliedepidata} package from GitHub using the install_github() function in the {remotes} package (which you installed previously)\n\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nSave the two datasets into a specific folder using the save_data() function from {appliedepidata}, by running the code below. The example below saves the data into a ‘data’ subfolder within the RStudio project. Note that if you do not specify a location within the ‘path’ argument of the function, a window will pop up asking you to manually select a folder.\n\n\n# Save down the two data files using the save_data() function from appliedepidata\nappliedepidata::save_data(\"multidisease_tests\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"multidisease_notifications\",\n                          path = \"data\")\n\n\n\n\nGreat! Thanks country office and Applied Epi! Now it’s time to import the data from that folder into RStudio, so you can analyse it.\n\n\nIdeally, you will use the same function for importing both datasets, despite one being a .csv and the other an .xlsx file. Note going forward we will simply say “environment” when we mean the environment pane in R Studio.\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nUse the import function from the {rio} package, which can recognize and import different file types. It replaces importing functions that are specific to the file type, such as read.csv() from {base} for .csv files and read_excel() from {readxl} to import .xlsx files.\nIf you feel you need to know more about importing functions, read the Import and export chapter of the Epi R Handbook.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nBelow we use the import function to bring in both files. Note how we are assigning the imported data to two objects, one called data_notif_raw, and one called data_lab_raw. We add the ‘raw’ suffix to distinguish this data from the cleaned versions we will make later.\n\n# Import data\n\n# Notification data\ndata_notif_raw &lt;- import(\"data/multidisease_notifications.xlsx\")\n\n# Lab data\ndata_lab_raw &lt;- import(\"data/multidisease_tests.csv\")\n\n\n\n\n\n\n\n\n\nThe data’s in, and now it’s time to see what story it tells. Take an initial look at your two raw data frames to check their contents and quality.\n\n\n\n\nUse skim() from the {skimr} package, names(), ncol(), and nrow() to inspect your data frame.\nskim() gives you a lot of information on data structure and content, whereas names() will show you the different column names in your data. The ncol() and nrow() functions to simply count the numbers of columns and rows in the data. Do you know what to put inside the parentheses?\nEasiest of all though, is to look at the environment. Remember the object in your environment for the notification data is called data_notif_raw.\nClick on the solution box underneath the questions if you need help.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many columns are there in the notification data?\n\n 10 11 12 13\n\nWhich of these columns are NOT in the data?\n\n Onset date Date reported by Health Facility/Community Date of outcome Date of test Date of birth\n\nWhat is the name of the column in the notification data that identifies each notification?\n\n Notification ID Test ID Health facility code Combination of Notification ID and Sex\n\nHow many rows are there in the notification data?\n\n 987 1314 950 778\n\nWhat type of information can you NOT see in the notification data?\n\n Laboratory test results District of residence Birthday and sex Health facility in which the case was diagnosed Outcome\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse skim() from the {skimr} package to look at a summary of the entire data frame, and View() to look at the whole data frame directly:\n\nskim(data_notif_raw)\n\nOr, you could use names() to print out just the column names. Through either skim() or names() you will be able to see the types of information including: the health facility of the case, birth-date, sex, a flag indicating pregnancy, district of residence, onset date, and date reported by the clinic, and outcome information. There is also a Notification ID which appears to be a unique identifier for a case, but we would want to double check duplicates before we are sure. Note that there are NO test results in this data, as these notifications are from clinics diagnosing notifiable diseases based on clinical case definitions.\n\nnames(data_notif_raw)\n\n [1] \"Organisation unit name\"                    \n [2] \"Health facility code\"                      \n [3] \"Notification ID\"                           \n [4] \"Date of Birth\"                             \n [5] \"Sex\"                                       \n [6] \"Pregnant\"                                  \n [7] \"Residential District\"                      \n [8] \"Disease notified\"                          \n [9] \"Onset date\"                                \n[10] \"Date reported by Health Facility/Community\"\n[11] \"Outcome\"                                   \n[12] \"Date of outcome\"                           \n\n\nUse ncol() and nrow() to print the number of columns and rows, like this:\n\nncol(data_notif_raw)\nnrow(data_notif_raw)\n\nThis will print the numbers of columns and rows in your console.\n\n\n[1] 12\n\n\n[1] 987\n\n\nOtherwise, when you look at the environment you can see that the number of observations (which is the same as rows) and columns are listed next to the name of the data frame.\n\n\n\n\n\n\nUse skim() from the {skimr} package or class() to inspect your column classes.\nDo you remember how to specify the column of interest inside the class() function? Alternatively, you can just look at the environment.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many columns in the notification data frame are recognised by R to be date columns?\n\n 0 2 4\n\nWhat is the class of most columns in the raw notification data frame?\n\n character numeric factor\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou can use class like the example below. The $ is an operator used to select a specific column from the data_notif_raw data frame. Note that the back-ticks are used around Date of Birth because the column name contains spaces.\n\nclass(data_notif_raw$`Date of Birth`)\n\nTo look at class via the environment, click on the blue arrow next to the data frame name. The column names will appear, with the class next to it (e.g. it says “chr” to show character class).\nYou can see the none of the columns that should be dates are recognized as dates. Instead, they are recognized as character values.\n\n\n\n\n\n\nUse the tabyl() function to inspect the values within categorical columns, specifying the data frame object in the first argument, and the column name in the second argument. For example, this code tabulates the values for the Sex column. The output shows that male and female are inconsistently spelled across the data. This column would need further cleaning before analysis.\n\ntabyl(data_notif_raw, Sex)\n\n    Sex   n    percent valid_percent\n      F  47 0.04761905    0.05452436\n FEMALE 146 0.14792300    0.16937355\n      M  40 0.04052685    0.04640371\n   MALE 172 0.17426545    0.19953596\n      f 154 0.15602837    0.17865429\n female  98 0.09929078    0.11368910\n      m 119 0.12056738    0.13805104\n   male  86 0.08713273    0.09976798\n   &lt;NA&gt; 125 0.12664640            NA\n\n\nTo inspect missingness, you can use the miss_var_summary() function from the {naniar} package:\n\nmiss_var_summary(data_notif_raw)\n\n# A tibble: 12 × 3\n   variable                                   n_miss pct_miss\n   &lt;chr&gt;                                       &lt;int&gt;    &lt;num&gt;\n 1 Onset date                                    691     70.0\n 2 Pregnant                                      510     51.7\n 3 Outcome                                       197     20.0\n 4 Date of outcome                               197     20.0\n 5 Date of Birth                                 168     17.0\n 6 Sex                                           125     12.7\n 7 Organisation unit name                          0      0  \n 8 Health facility code                            0      0  \n 9 Notification ID                                 0      0  \n10 Residential District                            0      0  \n11 Disease notified                                0      0  \n12 Date reported by Health Facility/Community      0      0  \n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nAre the values in the Residential District column standardized?\n\n No - they need cleaning They are standardized and are ready to be used for analysis\n\nAre the values in the Disease notified column standardized?\n\n No - they need cleaning They are standardized and are ready to be used for analysis\n\nWhat does R recognise as a missing value?\n\n Either no value, or just a space, or just a dot No value in a cell, represented with NA The words Unknown and Uncertain\n\nBased on the missingness of its values, is the Onset date column useful?\n\n Yes, the missingness is low so this column is useful Minimally, as the missingness is too high\n\nWhy might some columns in the notification data have different spellings and non-standardized categories?\n\n A bot scrambles the data so it becomes less identifiable Each clinic might use software that is configured slightly differently, or use free-text entries, so there are variations in spelling The surveillance system software used by the clinical settings has lots of bugs\n\nWhy might some columns in the notification data have high missingness?\n\n The clinician does not ask the patient the question during their consultation The patient might not know or want to share the answer The clinician might not have time to prioritise filling in that field in the data, even if they know the information All of the above, and many more reasons\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse the tabyl() function to tabulate the values within the Residential district column. Again, the first argument is the name of the data frame object, and the second argument is the name of the column.\n\ntabyl(data_notif_raw, `Residential District`)\n\n Residential District   n    percent\n            F Central  32 0.03242148\n            FEVERIA C  23 0.02330294\n      FEVERIA CENTRAL  85 0.08611955\n            Feveria C  24 0.02431611\n      Feveria Central  12 0.01215805\n               KASARA  64 0.06484296\n                  KSR  17 0.01722391\n               Kasara 109 0.11043566\n             L MINARA  50 0.05065856\n             L Minara 193 0.19554205\n          LAKE MINARA 185 0.18743668\n          Lake Minara  68 0.06889564\n             Lakeside 125 0.12664640\n\n\nYou can see that each of the three locations (Feveria Central, Lake Minara, and Kasara) are spelled in different ways and with different capitalization. This will need to be cleaned out if we want to analyse the geographic distribution of the notifiable diseases.\nSimilarly, use the tabyl() function to tabulate the values within the Disease notified column. You can see these are spelled out appropriately and consistently, so you can already see the distribution of rows by disease without further cleaning.\n\ntabyl(data_notif_raw, `Disease notified`)\n\n Disease notified   n    percent\n          cholera  46 0.04660588\n           dengue 273 0.27659574\n          malaria 533 0.54002026\n          typhoid  35 0.03546099\n     yellow_fever 100 0.10131712\n\n\nA different way of checking missingness is to tabulate the output of the function is.na(). In the example below, the function is.na() evaluates each cell within the column Onset date, returning TRUE for missing ones and FALSE for present ones. Running tabyl() on this TRUE/FALSE output then quickly gives you a clear count and percentage of both missing and non-missing values in that column. Remember, values like a space or the words “Unknown” or “Missing” will not be recognized by R as missing. R will only recognize true blanks as missing, represented by “NA”.\nFor Onset date, you can see that 70% of cases are missing onset date, suggesting that this column would not be particularly useful for analyzing trends in disease over time.\n\ntabyl(is.na(data_notif_raw$`Onset date`))\n\n is.na(data_notif_raw$`Onset date`)   n   percent\n                              FALSE 296 0.2998987\n                               TRUE 691 0.7001013\n\n\nMissing or non-standardized data can arise for many reasons, including the design of the data collection tool (e.g. whether questions are mandatory or use free text vs. drop-downs), the processes and standards in place (such as which fields staff are instructed to prioritise), and contextual factors (like whether staff have sufficient time to gather the information) — among many others.\n\n\n\n\n\n\n\n\n\nLike with the surveillance data, use skim(), ncol(), and nrow() functions or check the environment to inspect the lab data.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich linelist has more columns - the surveillance data or the laboratory data?\n\n Lab data Surveillance data They have the same number of columns\n\nWhich linelist has more rows?\n\n Lab data Surveillance data They have the same number of rows\n\nInspect the lab data with View(). Why might the lab data have more records?\n\n There may be several tests or targets per sample There are so many trial test results in the data Not all the notifications have test results yet\n\nWhich of these columns are NOT in the lab data?\n\n Notification ID Sample ID Test type Date of birth Test result\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nJust like in section 3.1, you can use skim() from the {skimr} package to look at the entire laboratory data frame with test results. This will also show you the different column names in the data, showing you that the lab data only contains information about the test and not about the patient. It does however also contain a notification ID, just like the notification data does.\n\nskim(data_lab_raw)\n\nUse ncol() and nrow() to print the number of columns and rows, like this:\n\nncol(data_lab_raw)\nnrow(data_lab_raw)\n\nThis will print the numbers of columns and rows in your console, showing you that the lab data has more rows than the notification data you inspected earlier.\n\n\n[1] 7\n\n\n[1] 1314\n\n\nThere are often more records in the lab data than in the clinical data. If you inspect the data with View(data_lab_raw) and then click on the arrow at the top of the notification_id column to sort it alphabetically, you’ll see that several rows share the same notification_id. This can happen when multiple targets are tested from the same sample (same sample ID), or when a case is retested (resulting in a different sample ID).\n\nView(data_lab_raw)\n\n\n\nlaboratory_namenotification_idsample_iddate_testtesttargetvalueFeveria General Hospitalf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue NS.1NFeveria General Hospitalf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgGNFeveria General Hospitalf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgMPFeveria General Hospital6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue NS.1NFeveria General Hospital6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgGNFeveria General Hospital6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgMP\n\n\n\n\n\n\n\n\nAs above, use the class(), skim(), or tabyl() functions, or inspect the environment, to look at your columns in more detail.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many columns in the laboratory data frame are recognised by R to be date columns?\n\n 0 1 2\n\nHow many columns in the laboratory data frame have complete data?\n\n 1 3 7 (all of them!)\n\nWhich test detects multiple targets (and therefore has multiple rows per sample)?\n\n Malaria Dengue Yellow Fever Cholera Typhoid Fever\n\nHow many possible test result values are there in the column value?\n\n 5 3 4\n\nWhat is NOT a possible test result for the stool culture test which detects V. cholerae bacteria’?)\n\n P P01 P0139 N I\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nThe laboratory data has one date column, recognized by R as an “IDate” class. This is a date class used by {rio}’s import() when reading csv files. Like base R’s Date class, it allows sorting by date and analyzing trends over time.\n\nclass(data_lab_raw$date_test)\n\n[1] \"IDate\" \"Date\" \n\n\nUse of the miss_var_summary() function from the {naniar} package demonstrates that all columns in the laboratory data are actually complete. This may be because the laboratory systems use automated processes, so are much less likely to have human error.\n(Important point: Note that in real life, the lab data would probably have some issues too!)\n\nmiss_var_summary(data_lab_raw)\n\n# A tibble: 7 × 3\n  variable        n_miss pct_miss\n  &lt;chr&gt;            &lt;int&gt;    &lt;num&gt;\n1 laboratory_name      0        0\n2 notification_id      0        0\n3 sample_id            0        0\n4 date_test            0        0\n5 test                 0        0\n6 target               0        0\n7 value                0        0\n\n\nTo see how many targets are detected by each test, you can cross-tabulate test and target columns with tabyl(). Write the column names into the function as two separate arguments. The output shows that each test clearly aligns with one or more targets, and only the dengue assay detects more than one target (IgG, IgM, and NS.1).\nTip: Experiment with changing the order of the column names in the function to see the impact on the table.\n\ntabyl(data_lab_raw, target, test)\n\n               target Blood culture Dengue NS1/IgG/IgM IgM ELISA Stool Culture\n           Dengue IgG             0                215         0             0\n           Dengue IgM             0                215         0             0\n          Dengue NS.1             0                215         0             0\n           Plasmodium             0                  0         0             0\n    S. Typhi bacteria            33                  0         0             0\n V. cholerae bacteria             0                  0         0            45\n     Yellow Fever IgM             0                  0        88             0\n Whole Blood Microscopy\n                      0\n                      0\n                      0\n                    503\n                      0\n                      0\n                      0\n\n\nFinally, you can inspect the different test result values in the column value, again using tabyl(). You can see that there are six possible results, including N for negative, P for positive, and I for indeterminate. Cholera specifically does not show P, but can show P01 and P0139, which in this case represent being positive for serogroups O1 or O139.\n\ntabyl(data_lab_raw, test, value)\n\n                   test  I   N   P PO1 PO139\n          Blood culture  2  24   7   0     0\n     Dengue NS1/IgG/IgM  0 354 291   0     0\n              IgM ELISA 10  45  33   0     0\n          Stool Culture  5   2   0  22    16\n Whole Blood Microscopy 56 257 190   0     0\n\n\n\n\n\n\n\n\n\n\nYou now know that the notification data (data_notif_raw) contains information about suspected cases, alongside basic demographic information (age, sex, pregnancy, district of residence), and information about their onset date, date reported by the health facility, and outcome. Some columns need cleaning before further analysis, due to variations in spelling of categorical values and some date columns not being recognized as dates.\nYou will now start writing longer chunks of code to clean data, using various {dplyr} functions chained together with pipes (which look like this: |&gt;).\nNOTE ON PIPES: Pipes allow you to perform several operations in one smooth sequence, by “chaining” different functions together. The output from one function becomes the input for the next. If you need more information on piping, please refer to the Epi R Handbook. Note that this exercise uses the base pipe (|&gt;) rather than the magrittr pipe (%&gt;%), as it is faster and does not require package installation. Use the magrittr pipe if you prefer it.\n\n\n\n\nDue to quality and data storage issues, your team recommends that you create a clean linelist that only contains information on the unique identifier, location of the case, disease, and the date the notification was reported to the surveillance system.\nWrite R code to produce a new clean data frame called data_notif, applying the following cleaning tasks:\n\nRename columns to be more machine readable (remove spaces and capitalization) using clean_names() from the {janitor} package\nUse the rename() function from {dplyr} so that the column with the date the case was reported is changed to a more concise date_report.\n\nSelect relevant columns for analysis with the select() function from the {dplyr} package.\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nStart your code with the name of the new data frame, the assignment arrow, and the name of the raw data object. This shows that the outcome of the raw data processing will be assigned to a new object called data_notif.\n\ndata_notif &lt;- data_notif_raw\n\nThen build on this code by adding in additional functions, chained together with a pipe. This lets you perform several operations in one smooth sequence. First, you’ll use clean_names() to standardize all your column names. It automatically replaces spaces and special characters with underscores and converts everything to lowercase, making names easier to work with. Then, you can use rename() to give a column a new name. Just remember, when you use rename(), the column will already have its clean_names() version.\n\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(NEW_NAME = OLD_NAME) |&gt; \n  select(VAR_NAMES)\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the code to clean column names and select the right columns for analysis:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report)\n\n\n\n\n\n\n\nYou already know from your data inspection that the values for district are not standardized.\nAdd a mutate() function to clean the residential_district column, to:\n\nStandardize the capitalization of the column\nReplace the existing residential_district column with a clean column that only contains these district values: “Lake Minara”, “Feveria Central”, and “Kasara”.\n\nSee the hint to see what functions you can use.\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTry using str_to_title() from {stringr} package so that the first letter of each word is upper case and all other letters are lower case. You can also use case_match() to specify different specific typos.\nUse the ‘help’ functionality of RStudio to see how to use these functions. For example, type ?case_match in your console to get the help page. NOTE on case_match() - this is a very useful function for replacing or correcting values, and supersedes recode().\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYour cleaning code should now look like this:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = str_to_title(residential_district)) |&gt; \n  mutate(residential_district = case_match(residential_district,\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\"))\n\nYou could also wrap the str_to_title function into the case_match() for shorter code, as follows:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = case_match(str_to_title(residential_district),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\"))\n\n\n\n\n\n\n\nThe column for report date needs to be transformed so that it is recognized as a date in R. This will allow you to analyse trends over time, including over weeks and months.\nReview the values within the date_report column. Then, add a line to your cleaning code to change date_report into a date class.\nKnowing the structure will allow you to use the correct function to convert the column into a date class. We recommend you use one of the functions from the {lubridate} package: either ymd() (for converting dates written as year-month-date), mdy() (for dates written as month-day-year), or dmy() (for dates written as day-month-year). These functions will recognize any way of writing the date as long as it is the correct order, for example “21st August 2025” and “21-08-2024” would both be recognized by dmy().\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow are the dates currently formatted?\n\n day-month-year year-month-day month-day-year year-day-month\n\nWhich mutate() function should you use to convert the date_report column into a date class?\n\n mutate(date_report = ymd(date_report)) mutate(date_report = dmy(date_report)) mutate(date_report = mdy(date_report))\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou can use the head() function to view the first six rows of data for the date_report column. You can see that they are written with the year first, then the month, then the date.\n\nhead(data_notif$date_report)\n\n[1] \"2024-03-08\" \"2024-03-11\" \"2024-03-11\" \"2024-03-18\" \"2024-03-14\"\n[6] \"2024-03-12\"\n\n\nYou can use the ymd() function inside mutate() to convert the class of the date_report function. You can double-check that the class is correct by running a class() function afterwards.\nYour cleaning code should now look like this:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = case_match(str_to_title(residential_district),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\")) |&gt; \n  mutate(date_report = ymd(date_report)) \n\nAnd you can double check the class with this:\n\nclass(data_notif$date_report)\n\n[1] \"Date\"\n\n\n\n\n\n\n\n\nYour colleagues tell you that each notification_id represents one suspected case. You now want to create a table to check if notification_id is duplicated across rows in you data.\n\n\n\n\n\n\nQuestions\n\n\n\n\nDoes one row in the notification data equate to one case?\n\n Yes No\n\nDo you need to deduplicate your data for epidemiological analysis of cases?\n\n Yes No\n\n\n\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nThere are many ways to do this, but try using count() function from {dplyr}. It will create a table that counts the number of rows per unique value of the column that you specify inside the function. Then, use tabyl() to look at the distribution of these counts.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFirst, pipe from the surveillance data into the count() function, giving the notification_id column as the only argument. This creates a table that counts the number of rows per unique value of sample_id, shown in a new column n. You can see for example in this excerpt that there is only one row per each of these 6 notification_ids.\n\ndata_notif |&gt; \n  count(notification_id) \n\n\n\n  notification_id n\n1          00399b 1\n2          005c85 1\n3          006f52 1\n4          00cbbb 1\n5          01830d 1\n6          019045 1\n\n\nThen tabulate the new column n with the tabyl(), which shows that there is only one row per unique notification_id. This means that one row equates to one case, and no further deduplication is needed.\n\ndata_notif |&gt; \n  count(notification_id) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 987       1\n\n\n\n\n\n\n\n\n\nYou can now comfortably proceed with descriptive analyses of cases, as your data is clean and you know that one row equals one case. Use the tabyl() function for the following tasks.\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich disease was most commonly diagnosed by clinics in Feveria in 2024?\n\n Cholera Malaria Dengue Typhoid Fever Yellow Fever\n\nWhich disease was least commonly diagnosed by clinics in Feveria in 2024?\n\n Cholera Malaria Dengue Typhoid Fever Yellow Fever\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see that there were 533 suspected cases of malaria in Feveria in 2024, and only 35 suspected cases of typhoid fever.\n\ntabyl(data_notif, disease_notified)\n\n disease_notified   n    percent\n          cholera  46 0.04660588\n           dengue 273 0.27659574\n          malaria 533 0.54002026\n          typhoid  35 0.03546099\n     yellow_fever 100 0.10131712\n\n\n\n\n\n\n\n\nUse tabyl() to cross-tabulate the disease and district of residence columns.\nBuild on your table by adding various adorn functions from the {janitor} package, to see percentage distributions, e.g. adorn_percentages(), adorn_pct_formatting(), and adorn_ns()\nType the name of the function after a ? in your console (e.g. ?adorn_ns) to see the relevant Help pages. You can also look at the section about {janitor} in the Epi R Handbook for more explanation of adorn_xxx() functions.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich district reported the most vector-borne disease in 2024 (malaria, dengue, yellow fever)?\n\n Lake Minara Feveria Central Kasara\n\nWhich district reported the most diarrhoeal disease in 2024 (cholera, typhoid fever)?\n\n Lake Minara Feveria Central Kasara\n\nWhat factors contribute to increased diarrhoeal disease in this specific district (selected in previous question)?\n\n Unreliable water and sanitation infrastructure Overcrowding of mosquitoes We don't know\n\n\n\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nHere is some code to get you started. It cross-tabulates disease_notified and residential_district with tabyl(), then adding adorn_percentages() converts these numbers to percentages with many decimals. You then need to pipe into adorn_pct_formatting() to convert into actual percentage formatting, and then adorn_ns() to add numbers back in in parentheses. Note that adorn_xxx() functions need to be applied in a specific order!\n\ntabyl(data_notif, disease_notified, residential_district) |&gt;\n  adorn_percentages()\n\nFor factors contributing to more diarrhea - scroll up to earlier in the case study when the districts were first introduced!\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see that most suspected cases of dengue, malaria, and yellow fever were located in Lake Minara - the lake area with higher density of mosquitoes and therefore vector-borne disease. Meanwhile the majority of cholera and typhoid fever were in Feveria Central, the over-populated urban area with water and sanitation infrastructure issues that result in higher risk of flooding and drinking water contamination during rainy weather.\n\ntabyl(data_notif, disease_notified, residential_district) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n disease_notified Feveria Central      Kasara Lake Minara\n          cholera      91.3% (42)  8.7%   (4)  0.0%   (0)\n           dengue       9.5% (26) 17.6%  (48) 72.9% (199)\n          malaria      13.7% (73) 19.9% (106) 66.4% (354)\n          typhoid      68.6% (24) 31.4%  (11)  0.0%   (0)\n     yellow_fever      11.0% (11) 21.0%  (21) 68.0%  (68)\n\n\n\n\n\n\n\n\n\n\nFrom your earlier work in step 3, you have found that the laboratory data contains only testing data, and no patient information. The data is already very clean, so we only need to standardize one column. We will also want to process the laboratory data frame to be one row per notification, so that it can be neatly linked to the notification data frame.\n\n\n\n\nCreate a new object data_lab. This will allow a more straight-forward analysis and interpretation of results.\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse case_match() to turn the different original values into “Positive”, “Negative”, or “Indeterminate”:\n\ndata_lab &lt;- data_lab_raw |&gt; \n  mutate(value = case_match(value, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positive\",\n                            \"N\" ~ \"Negative\",\n                            \"I\" ~ \"Indeterminate\"))\n\nYou can then double-check that the new values look correct by tabulating and comparing the values in the original data frame and the clean one. Make sure that you used the letter ‘O’ and not the number ‘0’!\n\ntabyl(data_lab_raw, value)\n\n value   n    percent\n     I  73 0.05555556\n     N 682 0.51902588\n     P 521 0.39649924\n   PO1  22 0.01674277\n PO139  16 0.01217656\n\n\n\ntabyl(data_lab, value)\n\n         value   n    percent\n Indeterminate  73 0.05555556\n      Negative 682 0.51902588\n      Positive 559 0.42541857\n\n\n\n\n\n\n\n\n\n\n\nWe already know that some samples have multiple rows, and that this is because the dengue assay has three targets, with one row per target result.\nNow find the number of samples with multiple rows.\nDo this as you did with the notification data, using the data_lab object: first count the number of rows per sample, then create a table to show the distribution of row numbers. Keep in mind that each sample is identified by a sample ID.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many samples (unique sample_ids) are repeated across three rows?\n\n 200 215 230\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFirst, pipe from the lab data into the count() function, giving the sample_id column as the only argument. This creates a table that counts the number of rows per unique value of sample_id, shown in a new column n. You can see for example that the sample_id “000e8eee” has three rows, whereas the sample_id “001e1878” is only seen on one row.\n\ndata_lab |&gt; \n  count(sample_id) \n\n\n\n  sample_id n\n1  000e8eee 3\n2  001e1878 1\n3  005f39af 1\n4  00b30781 3\n5  00b56d18 1\n6  0110abcd 3\n\n\nThen tabulate the new column n with the tabyl().\n\ndata_lab |&gt; \n  count(sample_id) |&gt; \n  tabyl(n)\n\n n n_n   percent\n 1 669 0.7567873\n 3 215 0.2432127\n\n\nYou can even double-check that this only applies to the dengue assay by adding in the disease column to the calculation. You can see that it is only the dengue test that has 3 rows per sample.\n\ndata_lab |&gt; \n  count(test, sample_id) |&gt; \n  tabyl(test, n)\n\n                   test   1   3\n          Blood culture  33   0\n     Dengue NS1/IgG/IgM   0 215\n              IgM ELISA  88   0\n          Stool Culture  45   0\n Whole Blood Microscopy 503   0\n\n\n\n\n\n\n\n\nAs you saw in section 3.2, your dengue test provides results for three different targets: IgG, IgM, and NS.1. The results for each of these targets can be either negative or positive. However, to simplify and consolidate your data, you want to assign a single negative or positive label to each sample, to indicate if the sample represents current infection.\n\n\ntargetNegativePositiveDengue IgG110105Dengue IgM105110Dengue NS.113976\n\n\nYour colleague Ben, who works in the lab, advises you on the cleaning as follows:\n\nA sample can be considered positive if NS.1 or IgM are positive (as both can represent acute infection)\nYou can ignore IgG (because a positive result in the absence of positive NS.1 or IgM is indicative of immunity after a past resolved infection)\n\nNow you need to consolidate the dengue test results to one row per test, with one result value. Use filter(), arrange(), and slice(), making sure any sample positive for NS.1 or IgM is considered positive for dengue. Create a new object called data_lab_tests\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTry to apply the following to consolidate according to Ben’s recommendation:\n\nRemove IgG Results: filter out rows where the target is “IgG” using filter() from {dplyr}.\nPrioritize positive IgM/NS1results: Group by sample_id and arrange rows with arrange() so any ‘P’ (positive) result appears first\nFilter to final status: Keep only the first row using slice(1) to get the positive or negative result for the sample.\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the code to filter out the dengue IgG results, and then consolidate the test result within each group of rows with the same sample_id, prioritizing positive results. You need to specify desc within arrange(), as this means that the results will be in reverse alphabetical order, meaning P will be at the top. Also, add the ungroup() function at the end so that the new data is not grouped, which could confuse further analyses.\n\ndata_lab_tests &lt;- data_lab |&gt; \n  filter(target != \"Dengue IgG\") |&gt; \n  group_by(sample_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\nYou can then double-check that the new object data_lab_tests has only one row per test, using the combination of count() and tabyl() like you did in Task A. This table shows you that all unique sample IDs are only present in one row each:\n\ndata_lab_tests |&gt; \n  count(sample_id) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 884       1\n\n\n\n\n\n\n\n\nNext, you check the number of tests per notification ID in your new consolidated data. You can see that there are 26 rows with the same notification id as another row, but only among cases tested with whole blood microscopy for malaria.\n\ndata_lab_tests |&gt; \n  count(test, notification_id) |&gt; \n  tabyl(test, n)\n\n                   test   1  2\n          Blood culture  33  0\n     Dengue NS1/IgG/IgM 215  0\n              IgM ELISA  88  0\n          Stool Culture  45  0\n Whole Blood Microscopy 451 26\n\n\nYou investigate further, looking at one example case with notification_id “043228”. This shows you that this one case was tested twice, with two different samples, one week apart. The first result was positive, and the second result was negative.\n\ndata_lab_tests |&gt; \n  filter(notification_id == \"043228\")\n\n# A tibble: 2 × 7\n  laboratory_name        notification_id sample_id date_test  test  target value\n  &lt;chr&gt;                  &lt;chr&gt;           &lt;chr&gt;     &lt;IDate&gt;    &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;\n1 Kasara University Hos… 043228          27c37cd8  2024-06-18 Whol… Plasm… Posi…\n2 Kasara University Hos… 043228          d2271be0  2024-06-25 Whol… Plasm… Nega…\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich statement about the lab data is correct?\n\n All cases of different diseases get retested Some malaria cases get retested All malaria cases get retested\n\nWill you need to deduplicate the lab data, to link with the notification data?\n\n Yes - we need one row representing the lab result per notification No - the data is sufficiently deduplicated\n\n\n\n\nIf you answered that you need to deduplicate, you are correct!\nDeduplicate your data to have one row per notification ID, prioritizing positive results, so that you can link to the notification data.\nTo do this, follow a similar process as you did in Task B, using the data frame produced by task B: - Group by notification_id - Arrange by the test result value so that values starting with P are prioritized in the top row, followed by N (negative), and then I (indeterminate). - Then keep the first row within each group of notification_ids, using slice(). - When doing this, create a new object called data_lab_cases.\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the code to deduplicate rows within each group of rows with the same notification_id, prioritizing positive results. Once again you need to specify desc within arrange(). This works perfectly because the desired priority order for results — positive, then negative, then indeterminate — happens to align with reverse alphabetical order (P comes before N, which comes before I, when sorted descending).\nIf your priority order was more complex or didn’t match alphabetical sorting (e.g., if “indeterminate” needed to come before “negative”), you’d have to convert the result column into a factor and explicitly define the desired order of its levels. Don’t forget to ungroup again at the end.\n\ndata_lab_cases &lt;- data_lab_tests |&gt; \n  group_by(notification_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt;\n  ungroup()\n\nYou can then double-check that the new object data_lab_cases has only one row per test, using the combination of count() and tabyl() like you did in Task A. This table shows you that all unique sample IDs are only present in one row each:\n\ndata_lab_cases |&gt; \n  count(notification_id) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 858       1\n\n\n\n\n\n\n\n\n\nNow we have two objects that we can use for analysis of laboratory data: data_lab_tests and data_lab_cases.\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich object should you use to analyse tests?\n\n data_lab_tests data_lab_cases neither\n\nHow many tests were conducted to test for malaria (via whole blood microscopy)?\n\n 215 503 88 190\n\nWhat percentage of tests for cholera (via stool culture) were positive?\n\n 21% 11% 84% 87%\n\nWhich test had the highest percentage of indeterminate results?\n\n IgM ELISA (for yellow fever detection) Stool Culture (for cholera detection) Blood culture (for typhoid fever detection)\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see the number of positive, negative, and indeterminate results per test. You can add a series of adorn() functions to show percentages and totals.\n\ntabyl(data_lab_tests, test, value) |&gt; \n  adorn_totals(where = \"col\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n                   test Indeterminate    Negative    Positive        Total\n          Blood culture     6.1%  (2) 72.7%  (24) 21.2%   (7) 100.0%  (33)\n     Dengue NS1/IgG/IgM     0.0%  (0) 13.5%  (29) 86.5% (186) 100.0% (215)\n              IgM ELISA    11.4% (10) 51.1%  (45) 37.5%  (33) 100.0%  (88)\n          Stool Culture    11.1%  (5)  4.4%   (2) 84.4%  (38) 100.0%  (45)\n Whole Blood Microscopy    11.1% (56) 51.1% (257) 37.8% (190) 100.0% (503)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich lab data frame should you use to count the number of suspected cases tested?\n\n data_lab_raw data_lab_cases data_lab_tests data_lab\n\nHow many suspected cases were tested in the 2024 lab data?\n\n 858 1314 884\n\nAre there more suspected cases in the notification data or the lab data?\n\n Notification data Lab data\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou can simply look at the number of rows in the data_lab_cases data frame to see the number of suspected cases who were tested.\n\nnrow(data_lab_cases)\n\n[1] 858\n\n\nThis is less than the number of suspected cases that were in the clean notifiable disease surveillance data (data_notif) - which suggests that not all suspected cases in 2024 were tested by the time this data was available.\n\nnrow(data_notif)\n\n[1] 987\n\n\n\n\n\n\n\n\n\n\nNow that both linelists are clean and have one row per suspected case, you can link them to enable the full analysis requested by your boss.\n\n\n\n\nCreate a new object called data_linked, using a xxx_join() function from {dplyr}. You want to keep all notifications, but add on test results where available for each suspected case.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich function is the correct approach if you want to retain all rows from your notification data and bring in results from your lab data?\n\n left_join(data_notif, data_lab_cases… full_join(data_notif, data_lab_cases… right_join(data_notif, data_lab_cases…\n\nWhat identifier should be used to link the two linelists?\n\n sample_id notification_id sample_id and date of report notification_id and date of report\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nLink the data using the left_join() function, with notification data as the main data frame on the left. This will keep all the rows from this data frame, and will just bring in the test results from the lab data specified on the “right” of the function.\n\ndata_linked &lt;- left_join(data_notif, data_lab_cases, \n                         by = \"notification_id\")\n\nYou are linking on the notification_id column, which is present, complete, and clean in both linelists.\nNote: You are lucky to work with such a straight-forward example of linkage! Usually you would need to really clean and check the ID column, or link on other columns like name and date fo birth. In Feveria, clinic staff are fantastic at consistently allocating notification IDs to each patient, including on the sample forms sent to the lab, and then the lab staff are equally brilliant at recording the notification ID in their lab systems so that the results can be linked back to the case.\n\n\n\n\n\n\nNow check your data and review a few things.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many rows are in your new data_linked data frame?\n\n 987 884 858\n\nHow does this compare to your original notification data?\n\n more rows than the original same number of rows fewer rows\n\nWhat term best describes the linkage you just did?\n\n many-to-one one-to-one many-to-many\n\nHow many lab results were NOT linked (hint: use anti-join())?\n\n 30 19 0\n\nHow fortunate are you that your linkage is so successful?\n\n What? Isn't all linkage this simple?? Very! Usually some records don't match\n\nWhat are typical reasons that lab data doesn’t match to the notifiable diseases data?\n\n There are typos in the columns used for linkage, so they are not recognised as matching The lab data may contain additional cases from other clinics or countries The lab data may include test samples Notifications may have been accidentally missed in the surveillance data even though the sample was tested in the lab All of the above\n\nHow many suspected cases do not have a result?\n\n 83 100 129\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nCheck the number of rows in each data frame with the nrow() function, or by checking the object information in your environment. You can see that this was simply a one-to-one merge, because each row had a unique notification_id, so one row in the notification data linked directly to one row in the lab data.\nNumber of rows in notification data\n\nnrow(data_notif)\n\n[1] 987\n\n\nNumber of rows in linked data\n\nnrow(data_linked)\n\n[1] 987\n\n\nTo check if there were any lab result that were not linked to the notification data, you can use anti_join(). This time the data_lab_cases object is on the left, as the function assess how many rows from the left data frame were not found in the right data frame, matching by notification_id. Here you do not need to generate a new data frame, you can simply pipe into an nrow() to count the number of rows. The output is 0, which shows there were no unlinked results - amazing!\n\nanti_join(data_lab_cases, data_notif, \n          by = \"notification_id\") |&gt; nrow()\n\n[1] 0\n\n\nFinally, to check the number of notifications without a result, you can either conduct an anti_join in putting data_notif first:\n\nanti_join(data_notif, data_lab_cases, \n          by = \"notification_id\") |&gt; nrow()\n\n[1] 129\n\n\nOr, you can simply tabulate the number of missing values in the value column in data_linked (as the value column comes from the lab data).\n\ntabyl(is.na(data_linked$value)) \n\n is.na(data_linked$value)   n   percent\n                    FALSE 858 0.8693009\n                     TRUE 129 0.1306991\n\n\nBoth of these approaches show that 129 suspected cases do not have a lab test result.\n\n\n\n\n\n\n\n\n\nUse mutate() to create a new column case_category, updating the label of suspected cases according to their lab result. The categories should be as follows:\n\nIf the result was positive: Confirmed\nIf the result was negative: Discarded\nIf the result was indeterminate or missing: Suspected\n\nThis means that all cases in the notification data are initially suspected when reported, and then remain suspected if there is no conclusive test result.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich is the most appropriate function for creating this new column?\n\n case_when() if_else() case_match()\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou should use case_when() to create the new column. This function is ideal for applying multiple logical conditions to create multiple values, whereas case_match() is better for replacing specific values, and if_else() is better if there are only two possible values.\n\ndata_linked &lt;- data_linked |&gt; \n  mutate(case_category = case_when(value==\"Positive\" ~ \"Confirmed\",\n                                   value==\"Negative\" ~ \"Discarded\",\n                                   value==\"Indeterminate\" | is.na(value) ~ \"Suspected\"))\n\n\n\n\n\n\n\n\n\n\nUse tabyl() overall, and also cross-tabulate by disease to answer the questions below.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many cases in the linked notification data did not have a positive or negative result?\n\n 202 347 250\n\nWhat percentage of cases in the notification data DID have a positive or negative result?\n\n 60.1% 79.5% 92.2%\n\nWhy are there more remaining suspected cases than there are unlinked notifications?\n\n Suspected cases include notifications without a lab result and with an indeterminate lab result There are additional suspected cases being brought in from the lab There is an issue with the data\n\nWhich disease had the highest percentage of cases that remained suspected after linkage?\n\n Cholera Malaria Dengue Yellow fever\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nOnce again you can use tabyl() to see the distribution of case categories across notifications. The total number of suspected cases, i.e. those with either no lab result at all or with an indeterminate result, is 202. This means 785 cases, i.e. 79.5%, did have a definitive laboratory result.\n\ntabyl(data_linked, case_category) \n\n case_category   n   percent\n     Confirmed 438 0.4437690\n     Discarded 347 0.3515704\n     Suspected 202 0.2046606\n\n\nYou can also cross-tabulate the original results (indeterminate/negative/positive) in the value column with the new case_category column, firstly to check your logic worked, and to see how the original values map to the new column values. This shows that in addition to the 129 notifications that were not linked (with NA in the value column), 73 had indeterminate results, so were categorized as suspected cases.\n\ntabyl(data_linked, case_category, value) \n\n case_category Indeterminate Negative Positive NA_\n     Confirmed             0        0      438   0\n     Discarded             0      347        0   0\n     Suspected            73        0        0 129\n\n\nFinally, you can also cross-tabulate with the disease name to see the case categories by disease. Add additional adorn_xxx() functions for percentage formatting. The table shows you that 22% of yellow fever cases remained suspected, which was the highest percentage compared to the other diseases.\n\ntabyl(data_linked, disease_notified, case_category) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n disease_notified   Confirmed   Discarded   Suspected        Total\n          cholera 82.6%  (38)  4.3%   (2) 13.0%   (6) 100.0%  (46)\n           dengue 68.1% (186) 10.6%  (29) 21.2%  (58) 100.0% (273)\n          malaria 32.6% (174) 46.3% (247) 21.0% (112) 100.0% (533)\n          typhoid 20.0%   (7) 68.6%  (24) 11.4%   (4) 100.0%  (35)\n     yellow_fever 33.0%  (33) 45.0%  (45) 22.0%  (22) 100.0% (100)\n            Total 44.4% (438) 35.2% (347) 20.5% (202) 100.0% (987)\n\n\n\n\n\n\n\n\nUse tabyl() for this once again, looking at the results by disease. Think about the correct denominator!\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhat percentage of suspected cases reported in 2024 were true cases, according to their test results?\n\n 44% 56% 59%\n\nWhat percentage of suspected malaria cases were really malaria?\n\n 86% 41% 23%\n\nWhat percentage of suspected dengue cases were really dengue?\n\n 87% 41% 23%\n\n\n\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nDivide the number of confirmed cases (i.e. those with a positive result) by the number of confirmed plus discarded cases (i.e. those with either a positive or negative result). This gives a positivity rate, which approximates the percentage of suspected cases that were truly cases. Indeterminate results are excluded because they don’t provide a clear outcome and would skew the positivity rate.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFilter out suspected cases and then cross-tabulate, to see the percentage of originally suspected cases that become confirmed or discarded, among those with valid test results.\nBecause there is a totals row, you can see that 56% of suspected cases overall became confirmed, among those with a valid result. You can also see that 41% and 87% of malaria and dengue cases respectively were confirmed.\n\ndata_linked |&gt; \n  filter(case_category != \"Suspected\") |&gt; \n  tabyl(disease_notified, case_category) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n disease_notified   Confirmed   Discarded        Total\n          cholera 95.0%  (38)  5.0%   (2) 100.0%  (40)\n           dengue 86.5% (186) 13.5%  (29) 100.0% (215)\n          malaria 41.3% (174) 58.7% (247) 100.0% (421)\n          typhoid 22.6%   (7) 77.4%  (24) 100.0%  (31)\n     yellow_fever 42.3%  (33) 57.7%  (45) 100.0%  (78)\n            Total 55.8% (438) 44.2% (347) 100.0% (785)\n\n\n\n\n\n\n\n\n\nTask A: Create a new linelist called data_linked_confirmed.\nThis is what you will use in official surveillance reporting.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhy are we opting to report only confirmed cases in our surveillance data?\n\n Reporting confirmed cases can be more reliable and accurate when the percentage testing positive is low and lab testing is routine, thereby helping prevent over-estimation of disease burden Reporting confirmed cases is slower, which gives us more time to be sure of what we are reporting Because we want to hide the true number of cases\n\nWhat function is important for creating the new linelist?\n\n filter() arrange() mutate()\n\nHow many rows are in this new data frame?\n\n 389 438 858\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYour surveillance unit wants to focus on confirmed cases in reporting. This is because lab testing is routine in Feveria, and so reporting suspected cases would be unnecessarily inaccurate, with a high percentage of suspected cases getting discarded.\nThe decision to publish suspected cases may be different in other contexts. For example, if the positivity rate is high (most cases are true cases if tested), and testing itself is not common, or testing takes a long time and would result in delayed reporting, this would suggest that suspected case trends are sufficiently accurate and also more timely than waiting for laboratory confirmation.\nCreate the new linelist with the filter() function:\ndata_linked_confirmed &lt;- data_linked |&gt; \n  filter(case_category==\"Confirmed\")\nAnd check the number of rows by looking at the information in your environment, or with nrow():\nnrow(data_linked_confirmed)\n[1] 438\n\n\n\n\n\n\n\nNow that you have your linelist of confirmed notifiable disease cases reported in Feveria in 2024, you are ready to conduct the final part of your surveillance analysis! Namely, this is to summarize the five notifiable diseases by geography and time.\nTip: Typically surveillance analysis would also include analysis by person. You could expand on this case study by also analyzing by demographic variables.\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich notifiable disease was most commonly reported in 2024, when restricting to only confirmed cases?\n\n Dengue Malaria Yellow Fever\n\nWhy is the most commonly reported disease different when looking at confirmed and suspected cases?\n\n The sensitivity and specificity of the clinical diagnosis may differ by disease The performance of the tests used in the lab may differ by disease There may be reporting biases All of the above!\n\nWhich district reported the most confirmed cholera cases in 2024?\n\n Lake Minara Feveria Central Kasara\n\nHow many confirmed cases of cholera reported in 2024 were among residents of Feveria Central?\n\n 35 42 4\n\nWhich district reported the most confirmed malaria cases in 2024?\n\n Lake Minara Feveria Central Kasara\n\nDoes this data confirm that dengue is the most common infectious disease in Feveria?\n\n No - a different disease may be under-reported and/or not notifiable Yes - if it's most reported then it must be most common\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see that dengue was the most commonly reported disease in Feveria in 2024 when restricting to confirmed cases, with 186 cases.\n\ndata_linked_confirmed |&gt; \n  tabyl(disease_notified) \n\n disease_notified   n    percent\n          cholera  38 0.08675799\n           dengue 186 0.42465753\n          malaria 174 0.39726027\n          typhoid   7 0.01598174\n     yellow_fever  33 0.07534247\n\n\nNote that this is different from the suspected cases, where malaria was most commonly reported (with 533 suspected cases)! This was hinted at previously, when you saw that the positivity rate for suspected dengue cases was higher than for suspected malaria cases. This can be for different reasons, for instance the clinical diagnosis method used for malaria may be less specific (so many of the suspected cases are actually other diseases), or the test used for dengue may be more sensitive.\nTo cross-tabulate with residential district, add the relevant adorn_xxx() functions.\n\ndata_linked_confirmed |&gt; \n  tabyl(disease_notified, residential_district) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n disease_notified Feveria Central     Kasara Lake Minara        Total\n          cholera      92.1% (35)  7.9%  (3)  0.0%   (0) 100.0%  (38)\n           dengue       8.6% (16) 17.2% (32) 74.2% (138) 100.0% (186)\n          malaria      14.9% (26) 22.4% (39) 62.6% (109) 100.0% (174)\n          typhoid      71.4%  (5) 28.6%  (2)  0.0%   (0) 100.0%   (7)\n     yellow_fever       0.0%  (0) 18.2%  (6) 81.8%  (27) 100.0%  (33)\n            Total      18.7% (82) 18.7% (82) 62.6% (274) 100.0% (438)\n\n\nLike with the suspected cases, we can see that most confirmed cases of dengue, malaria, and yellow fever were located in Lake Minara - the lake area with higher density of mosquitoes and therefore vector-borne disease. The majority of confirmed cholera and typhoid fever cases were in Feveria Central, where there are water and sanitation issues.\nThe data suggests that vector-borne disease (dengue and malaria) are a particular concern in this tropical country. However, we don’t know for sure which is the most common disease and what the underlying patterns are - only five diseases are notifiable, and typically the reported cases only represent a fraction of true cases in the community.\n\n\n\n\n\n\n\nYou are going to work towards producing this epicurve, over the various tasks below.\n\n\n\n\n\n\n\n\n\n\n\nMake sure you specify the argument binwidth=7 so that each bar in the histogram represents the number of cases within a 7 day period.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhen was the first case of typhoid fever reported in Feveria in 2024?\n\n January 2024 May 2024 October 2024\n\nAccording to this graph, what was the highest number of dengue cases reported in a single week in 2024?\n\n 10 20 30 It's very hard to tell from this stacked graph!\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is some simple code to produce the epicurve. Note that you are not controlling the colors just yet, or specifying what day of the week each 7-day period starts on.\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = disease_notified)), binwidth=7)\n\n\n\n\n\n\n\n\nRefer to the dates chapter in the Epi R Handbook if you want more specific date formatting, for instance so that each bar represents a Monday-Sunday week, or the x axis labels the week number (weeks 1 - 52).\nImportantly - it is not straight forward to see the trends per disease when stacked this way! To see such temporal trends, you should produce one histogram per disease.\n\n\n\n\n\n\nUse facet_wrap() to easily create several mini-plots, one per disease. To understand this further, you can look at the facet section of the ggplot2 chapter in the Epi R Handbook\n\n\n\n\n\n\nQuestions\n\n\n\n\nAccording to this faceted graph, what was the highest number of dengue cases reported in a single week in 2024?\n\n 11 15 29 I still can't tell!\n\nAmong the dengue cases reported that week, what districts did they live in?\n\n All three districts Feveria Central Kasara Lake Minara This graph does not show this information\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nNow you can see an epicurve per disease! And you can see that during one week in July, 15 cases of dengue were reported. However, this graph does not show any geographical information yet.\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report)), binwidth=7) + \n  facet_wrap(.~disease_notified)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nAmong the 15 dengue cases reported in one week in July 2024, what districts did they live in?\n\n All three districts Feveria Central Kasara Lake Minara\n\nIn what district was the first typhoid fever case reported in 2024?\n\n Kasara Feveria Central Lake Minara I still can't tell!\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nNow you can see an epicurve per disease, with the coloring reflecting the district the case is a resident of.\nYou can see that among the 15 dengue cases reported in a single week, they lived across the three different districts. You can also see that the first case of typhoid was reported in Feveria Central.\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = residential_district)), binwidth=7) + \n  facet_wrap(.~disease_notified)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can specify:\n\nThe theme/appearance of the overall graph (e.g. background color, appearance of grid lines)\nThe title and labels\nThe colors of the bars (with scale_fill_manual())\nThe formatting and spacing of dates along the x-axis (with scale_x_date)\nMany other things!\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nDo cholera and typhoid fever appear endemic?\n\n No - the data suggests smaller occasional outbreaks Yes they are both endemic\n\nIs there a particular time of the year when malaria peaked in 2024?\n\n Yes - around November/December time Yes - around July/August (summer) time No, it is consistently high\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the fully formatted code. Note some other changes include specifying that we only want two columns of mini-plots within facet_wrap(), and that the date label along the x axis should only show day and month (not year, since all cases are in 2024 anyway).\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = residential_district)), binwidth=7) +\n  facet_wrap(.~disease_notified, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"District of residence\",\n       x = \"Date reported by clinic\",\n       y = \"Count\",\n       subtitle = \"Number of confirmed cholera, dengue, malaria, typhoid fever, and yellow fever cases by week in Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n\n\n\n\n\n\nWe can also see from the epicurve that cholera and typhoid appear to be occurring as isolated outbreaks, rather than showing endemicity. Malaria and dengue however were present in Feveria throughout the year, with malaria more obviously peaking in the summer months.\n\n\n\n\n\n\nThis time, use group_by() and summarize() to produce a table by district showing the earliest and latest report dates.\nYou can adjust your table with a filter() function to create this table for one district at a time.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhen was the first dengue case reported in Feveria in 2024?\n\n 18th January 2024 17th January 2024 12th February 2024\n\nWhen was the last dengue case reported in Feveria Central in 2024?\n\n 22nd August 2024 18th November 2024 25th December 2024\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nGroup the data by disease and then summarize the first and last date to look at the overall timeline of each disease in Feveria.\n\ndata_linked_confirmed |&gt; \n  group_by(disease_notified) |&gt; \n  summarize(first_reported = min(date_report), \n            last_reported = max(date_report)) |&gt;\n  ungroup()\n\n# A tibble: 5 × 3\n  disease_notified first_reported last_reported\n  &lt;chr&gt;            &lt;date&gt;         &lt;date&gt;       \n1 cholera          2024-06-03     2024-09-23   \n2 dengue           2024-01-17     2024-11-18   \n3 malaria          2024-01-08     2024-12-25   \n4 typhoid          2024-05-02     2024-11-07   \n5 yellow_fever     2024-03-08     2024-08-23   \n\n\nAdd a filter() to the code to look at first and most recent report dates for the district you’re interested in.\n\ndata_linked_confirmed |&gt; \n  filter(residential_district == \"Feveria Central\") |&gt; \n  group_by(disease_notified) |&gt; \n  summarize(first_reported = min(date_report), \n            recent_reported = max(date_report)) |&gt;\n  ungroup()\n\n# A tibble: 4 × 3\n  disease_notified first_reported recent_reported\n  &lt;chr&gt;            &lt;date&gt;         &lt;date&gt;         \n1 cholera          2024-06-03     2024-09-23     \n2 dengue           2024-01-29     2024-08-22     \n3 malaria          2024-01-29     2024-12-17     \n4 typhoid          2024-05-02     2024-11-07     \n\n\n\n\n\n\n\n\n\n\nWow! In line with the objectives for this case study, you have done the following:\n\nYou used key R functions to clean, reshape, and link data frames, plus created new columns using logical conditions.\nTo inform the data processing, you conducted data inspections and checks along the way\nYou conducted a thorough descriptive analysis to understand the testing and notification data, before and after linkage. In response to your supervisor’s original four questions, you can say:\n\nHow many suspected cases of the different notifiable diseases were reported in 2024, and which was most common? Malaria was the most common notifiable disease in Feveria in 2024, reported through the notifiable disease surveillance system: There were 533 suspected cases of malaria reported, 273 suspected cases of dengue, 100 yellow fever, 46 cholera, and 35 typhoid.\nWhat percentage of them ended up being confirmed? Almost 80% of notifiable cases reported in 2024 had a laboratory test result by the time the linked dataset was created, with some variation by disease. In total, 56% of notified cases were eventually confirmed, but this ranged from only 23% for typhoid fever (7 confirmed of 31 suspected cases with test results), to 95% for cholera (38 confirmed of 40 suspected cases with rest results). Additionally, the positivity rate was higher for suspected dengue than for suspected malaria (87% vs 41%).\nHow many confirmed cases of different notifiable diseases were reported in 2024, and which was most common? Confirmed cases followed a slightly different trend to suspected cases: the most commonly reported infection was dengue with 186 cases, followed by malaria (174), then cholera (38), yellow fever (33), and typhoid fever (7).\nHow are confirmed cases geographically and temporally distributed in Feveria? Feveria experienced dengue and malaria transmission throughout the year, peaking in the summer, and concentrated in the Laka Minara district. Feveria also experienced small and infrequent outbreaks of diarrhoeal disease, e.g. cholera and typhoid fever, particularly in the urban Feveria Central where there can be issues with water and sanitation.\n\nFinally, you have reflected on how the processes involved in notifiable disease surveillance systems and lab testing, for instance the transfer of data between clinics to labs, can affect data quality and completeness, and therefore your results.\n\nThere is so much more potential ahead. You can explore disease patterns by age or sex, calculate disease rates with population data, and even analyze reporting delays by examining the different dates in your datasets.\nYou have built a strong foundation and are well equipped to take your analysis to the next level. Keep going — exciting discoveries await!\nTo learn more, check out the other case studies or dive into the Epi R Handbook.\n\n\n\nSee below a script of all data cleaning steps and descriptive analyses. Note how the analyses are combined at the end rather than interspersed in between cleaning steps. This is a tidier way to organize your script.\nFor brevity, the code below does not include all inspections and checks made along the way, but you may decide to create a sections with such checks.\nThe top of your script should also contain information to help the reader understand what the script is for, as well as comments throughout. You will thank yourself later for adding these comments!\n\n\n\n\n\n\nCode to clean and analyse notification data and lab data from Feveria, 2024\n\n\n\n\n\n\n# Code to clean and analyse notification data and lab data from Feveria, 2024\n# Date:\n# Author:\n\n# Install packages -------------------------------------------------\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  flextable,  # Presentation ready tables\n  naniar,     # Evaluating missingness of data\n  remotes,    # Used to install package to download data\n  tidyverse   # data management and visualization\n)\n\n# Import data --------------------------------------------\n\n# Notification data\ndata_notif_raw &lt;- import(\"data/multidisease_notifications.xlsx\")\n\n# Lab data\ndata_lab_raw &lt;- import(\"data/multidisease_tests.csv\")\n\n# Clean notification data --------------------------------\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = case_match(str_to_title(residential_district),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\")) |&gt; \n  mutate(date_report = ymd(date_report)) \n\n\n# Clean and consolidate lab data  ---------------------------------------\n# Clean values\ndata_lab &lt;- data_lab_raw |&gt; \n  mutate(value = case_match(value, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positive\",\n                            \"N\" ~ \"Negative\",\n                            \"I\" ~ \"Indeterminate\"))\n\n# Create test-level lab data\ndata_lab_tests &lt;- data_lab |&gt; \n  filter(target != \"Dengue IgG\") |&gt; \n  group_by(sample_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Create case-level lab data\ndata_lab_cases &lt;- data_lab_tests |&gt; \n  group_by(notification_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Link notification and lab data  ---------------------------------------\ndata_linked &lt;- left_join(data_notif, data_lab_cases, by = \"notification_id\")\n\n# Clean data--------------------------------------------------------------\ndata_linked &lt;- data_linked |&gt; \n  mutate(case_category = case_when(value==\"Positive\" ~ \"Confirmed\",\n                                   value==\"Negative\" ~ \"Discarded\",\n                                   value==\"Indeterminate\" | is.na(value) ~ \"Suspected\"))\n\ndata_linked_confirmed &lt;- data_linked |&gt; \n  filter(case_category==\"Confirmed\")\n\n# ANALYSIS ---------------------------------------------------------\n# Number of suspected cases in Feveria\ntabyl(data_notif, disease_notified)\n\n# Distribution of suspected cases by district\ntabyl(data_notif, disease_notified, residential_district) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n# Distribution of results per disease-specific test\ntabyl(data_lab_tests, test, value) |&gt; \n    adorn_totals(where = \"col\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution of case category, in linked data: all cases\ntabyl(data_linked, case_category) \n\n# Distribution of case category by diseases, in linked data: all cases\ntabyl(data_linked, disease_notified, case_category) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution of case category by disease, in linked data: only cases with a valid result\ndata_linked |&gt; \n    filter(case_category != \"Suspected\") |&gt; \n    tabyl(disease_notified, case_category) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution of confirmed cases by district\ndata_linked_confirmed |&gt; \n  tabyl(disease_notified, residential_district) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n\n# Visualize confirmed cases over time\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = residential_district)), binwidth=7) +\n  facet_wrap(.~disease_notified, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"District of residence\",\n       x = \"Date reported by clinic\",\n       y = \"Count\",\n       subtitle = \"Number of confirmed cholera, dengue, malaria, typhoid fever, and yellow fever cases by week in Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n# First and last report date per disease\ndata_linked_confirmed |&gt; \n  group_by(disease_notified) |&gt; \n  summarize(first_reported = min(date_report), \n            last_reported = max(date_report)) |&gt;\n  ungroup()\n\n\n\n\n\n\n\n\n\n\n\n\n\nOriginal authors: Paula Blomquist and Alanah Jansen, with technical support provided by the CDC Global Surveillance, Laboratory, and Data Systems Branch in collaboration with TEPHINET.\nData source: Fictional data provided by Applied Epi.\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nJuly 2025\nFirst draft\n1\nPaula Blomquist and Alanah Jansen, Applied Epi, with technical support by the CDC Global Surveillance, Laboratory, and Data Systems Branch in collaboration with TEPHINET\n\n\n\n\n\n\nDisclaimer: The information presented in this exercise and the associated data files have been developed to help learners achieve the intended learning objectives. The contents are those of the author(s) and do not necessarily represent the official views of CDC, the US Department of Health and Human Services, or TEPHINET.\nLicense: This case study is under a CC BY-NC-SA 4.0 license. For more information about sharing and adapting this case study, see the associated deed.\nFunding: This case study was 100% supported by Cooperative Agreement number NU2HGH000044 funded by the US Centers for Disease Control and Prevention (CDC)."
  },
  {
    "objectID": "pages/multi_disease_lab.html#scenario",
    "href": "pages/multi_disease_lab.html#scenario",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "You are an epidemiologist working in the national surveillance office of Feveria, a very small tropical country. There are three districts within Feveria:\n\nFeveria Central: an over-populated urban area, with sometimes unreliable water and sanitation infrastructure.\nLake Minara: a lake area with good infrastructure but many mosquitoes in the warmer months of the year.\nKasara: a more sub-urban area on the other side of Feveria Central.\n\nMap of districts in the country Feveria\n\nIt is January 2025, and your supervisor would like you to transfer the routine processing of notifiable disease data from Excel into R, and to conduct some analyses on the data. She wants to know at least:\n\nHow many suspected cases of the different notifiable diseases were reported in 2024, and which was most common?\nWhat percentage of them ended up being confirmed?\nHow many confirmed cases of different notifiable diseases were reported in 2024, and which was most common?\nHow were confirmed cases geographically and temporally distributed in Feveria?\n\nShe asks that you write code to import, clean, link, and analyse the following linelists:\n\n2024 notifiable disease surveillance data: Referred to also as “notification data”, this is surveillance data on five notifiable diseases reported by clinics in Feveria: dengue, malaria, cholera, typhoid fever, and yellow fever. These are suspected cases, based on patients’ symptoms. Clinicians enter each notification into an online system every weekday.\n2024 laboratory test result data: This data comes from lab test results, from three major labs in Feveria. These results are for samples taken from those suspected notifiable disease cases mentioned above.\n\nLet’s go!"
  },
  {
    "objectID": "pages/multi_disease_lab.html#objectives",
    "href": "pages/multi_disease_lab.html#objectives",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "In this case study you will:\n\nUse key R functions to clean data, reshape datasets, link data sources, and create new columns using logical conditions to prepare data for analysis.\nConduct data inspections and data quality checks at multiple stages of the project and understand their importance for reliable analysis.\nPerform basic descriptive analyses to compare disease trends across different data sources, before and after linkage.\nInterpret differences in results across data sources and understand how these reflect the structure and design of the overall surveillance system."
  },
  {
    "objectID": "pages/multi_disease_lab.html#step-1.-set-up",
    "href": "pages/multi_disease_lab.html#step-1.-set-up",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Start by setting up a reproducible and well-organized workflow. This will make it easy to rerun your analysis whenever needed.\nTasks:\n\nSet up an RStudio project\nSet up clear sub-folders where your code, data, and outputs will go\nCreate an R script, or an R Markdown file if you prefer. Make sure the script purpose, date, and author are written as comments at the top.\nExtra: Ensure your working language in RStudio is appropriate (e.g. English for this exercise)\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\n\nCreate a folder where all the work in this case study will go. For example, create ‘multi_disease_lab’ on your computer desktop. Create your RStudio project to be based in this folder.\nWe suggest creating the following sub-folders: scripts (for your code), data (for your data), and outputs (for your analytical outputs).\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nCreate a folder (e.g. ‘multi_disease_lab’ on your Desktop) for your work. To create an Rstudio project in your new folder, click New Project… in the top left of your R Studio, then Existing Directory, then Browse to select your new folder. For more information, look at the R projects section of the Epi R Handbook.\nStart a new R script by clicking New File… in the top left of your R Studio, then R Script. Save it immediately in the appropriate place, e.g. in a ‘scripts’ sub-folder of your R Project.\nAt the top of your new R script, write some essential information like your name, the purpose of the file, and the date.\nYour R locale determines the language and regional settings used for things like date formats and translations. If your locale is different from the language you want for your report (e.g., a French locale vs. an English report), you can change it to English by running Sys.setlocale(\"LC_ALL\", \"English\"). Include this in your script if needed, or skip it if your locale is usually appropriate. This is explained in more detail in the How-to Guide.\n\n\n\n\n\n\nNext in your R script, you need to install and load the necessary R packages. This ensures that the functions you need are available for your analysis.\nYou will need the following packages: {rio} (for importing data),{skimr} (for reviewing data), {janitor} (for cleaning data), {lubridate} (for cleaning dates), {epikit} (for epi-related tasks), {gtsummary} (for summary statistics/tests and regression), {apyramid} (for age-sex pyramids), {flextable} (for presentation-ready tables), {naniar} (for evaluating missing data), and {tidyverse} (for general data manipulation/science tasks). You will also need the {remotes} package to download the data - which we will explain in the download section.\nAs you start, your trusted colleague nudges you and whispers “I’ve heard that a great way to manage your packages is with the {pacman} package”.\nOver to you!\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse the function p_load() from pacman for this task. You provide the function with a list of packages that you want to use. The function will undertake two steps per package: 1) Check if the package is installed on your computer, and install it if necessary, then 2) Load the package so it can be used during this R session.\nIf you don’t already have pacman installed, you will need to install it the “traditional way” first, with install.packages().\nNote that the order of packages in your p_load function can be important. If two packages have the same function names (e.g. select() in the package MASS and select() in tidyverse, which do different things), then R will use the function from the most recently loaded package. To prioritize functions from tidyverse, which are commonly used for data manipulation and visualization, load tidyverse last.\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  flextable,  # Presentation ready tables\n  naniar,     # Evaluating missingness of data\n  remotes,    # Used to install package to download data\n  tidyverse   # data management and visualization\n)"
  },
  {
    "objectID": "pages/multi_disease_lab.html#step-2-download-and-import-the-data",
    "href": "pages/multi_disease_lab.html#step-2-download-and-import-the-data",
    "title": "Linking and analysing notifiable disease surveillance data and laboratory data in R",
    "section": "",
    "text": "Your office provides you with two files for your analysis, both containing data for 2024 and updated as of 15th January 2025:\n\nA notification-level data (“notification_data.xlsx”) with case information from 5 health centers\nTest-level data (“lab_data.csv”) submitted by three laboratories conducting testing for the 5 health centres\n\nFor this case study, you can access the data via Applied Epi’s very useful data repository, which you can access using the {appliedepidata} package. So first you need to download these two files to your own computer, as follows:\n\nInstall the {appliedepidata} package from GitHub using the install_github() function in the {remotes} package. Install {remotes} if you need to first.\n\n\n# Install remotes if you need to (so you can install a package from GitHub)\npacman::p_load(\"remotes\")\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nSave the two datasets into a specific folder using the save_data() function from {appliedepidata}, by running the code below. The example below saves the data into a ‘data’ subfolder within the RStudio project. Note that if you do not specify a location within the ‘path’ argument of the function, a window will pop up asking you to manually select a folder.\n\n\n# Save down the two data files using the save_data() function from appliedepidata\nappliedepidata::save_data(\"notification_data\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"lab_data\",\n                          path = \"data\")\n\n\n\n\nGreat! Thanks country office and Applied Epi! Now it’s time to import the data from that folder into RStudio, so you can analyse it.\n\n\nIdeally you want to use one function for both datasets, despite one being a .csv and the other an .xlsx file.\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nUse the import function from the {rio} package, which can recognize and import different file types. It replaces importing functions that are specific to the file type, such as read.csv() from {base} for .csv files and read_excel() from {readxl} to import .xlsx files.\nIf you feel you need to know more about importing functions, read the Import and export chapter of the Epi R Handbook.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nBelow we use the import function to bring in both files. Note how we are assigning the imported data to two objects, one called notification_data_raw, and one called lab_data_raw. We add the ‘raw’ suffix to distinguish this data from the cleaned versions we will make later.\n\n# Import data\n\n# Notification data\ndata_notif_raw &lt;- import(\"data/notification_data.xlsx\")\n\n# Lab data\ndata_lab_raw &lt;- import(\"data/lab_data.csv\")"
  },
  {
    "objectID": "pages/multi_disease_lab.html#step-3-inspect-the-data",
    "href": "pages/multi_disease_lab.html#step-3-inspect-the-data",
    "title": "Linking and analysing notifiable disease surveillance data and laboratory data in R",
    "section": "",
    "text": "The data’s in, and now it’s time to see what story it tells. Take an initial look at your two datasets to check their contents and quality.\n\n\n\n\nUse skim() from the {skimr} package, names(), ncol(), and nrow() to inspect your dataset.\nskim() gives you a lot of information on data structure and content, whereas names() will show you the different column names in your data. The ncol() and nrow() functions to simply count the numbers of columns and rows in the data. Do you know what to put inside the brackets?\nEasiest of all though, is to look at the RStudio environment. Remember the object in your environment for the notification data is called data_notif_raw.\nClick on the solution box underneath the questions if you need help.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many columns are there in the notification data?\n\n 10 11 12 13\n\nTick which of these columns are NOT in the data:\n\n Onset date Date seen at Health Facility/Community Date of outcome Date of test Date of birth\n\nWhat is the name of the column that probably identifies a case?\n\n Notification ID Test ID Health facility code Combination of Notification ID and Sex\n\nHow many are rows are there?\n\n 987 1314 950 778\n\nWhat type of information can you NOT see in this data?\n\n Laboratory test results District of residence Birthday and sex Health facility in which the case was diagnosed Outcome\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse skim() from the {skimr} package to look at a summary of the entire dataframe, and View() to look at the whole dataframe directly:\n\nskim(data_notif_raw)\n\nOr, you could use names() to print out just the column names. Through either skim() or names() you will be able to see the types of information included: the health facility of the case, onset date, birthdate, sex, a flag indicating pregnancy, district of residence, onset and report dates, and outcome information. There is also a Notification ID which appears to be a unique identifier for a case, but we would want to double check duplicates before we are sure. Note that there are NO test results in this data, as these notifications are from clinics diagnosing notifiable diseases based on clinical case definitions.\n\nnames(data_notif_raw)\n\n [1] \"Organisation unit name\"                \n [2] \"Health facility code\"                  \n [3] \"Notification ID\"                       \n [4] \"Date of Birth\"                         \n [5] \"Sex\"                                   \n [6] \"Pregnant\"                              \n [7] \"Residential District\"                  \n [8] \"Disease notified\"                      \n [9] \"Onset date\"                            \n[10] \"Date seen at Health Facility/Community\"\n[11] \"Outcome\"                               \n[12] \"Date of outcome\"                       \n\n\nUse ncol() and nrow() to print the number of columns and rows, like this:\n\nncol(data_notif_raw)\nnrow(data_notif_raw)\n\nThis will print the numbers of columns and rows in your console.\n\n\n[1] 12\n\n\n[1] 987\n\n\nOtherwise, when you look at the RStudio environment you can see that the number of observations (which is the same as rows) and columns are listed next to the name of the dataframe.\n\n\n\n\n\n\nUse skim() from the {skimr} package or class() to inspect your column classes.\nDo you remember how to specify the column of interest inside the class() function? Alternatively, you can just look at the RStudio Environment.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many columns are recognised by R to be date columns?\n\n 0 2 4\n\nWhat is the class of most columns in the raw notification data?\n\n character numeric factor\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou can use class like the example below. The $ is an operator used to select a specific column from the data_notif_raw dataframe. Note that the backticks are used around Date of Birth because the column name contains spaces.\n\nclass(data_notif_raw$`Date of Birth`)\n\nTo look at class via the RStudio environment, click on the blue arrow next to the dataframe name. The column names will appear, with the class next to it (e.g. it says “chr” to show character class).\n\n\n\n\n\n\nUse the tabyl() function to inspect the values within categorical columns, specifying the dataset object in the first argument, and the column name in the second argument. For example, this code tabulates the values for the Sex column. The output shows that male and female are inconsistently spelled across the data. This column would need further cleaning before analysis.\n\ntabyl(data_notif_raw, Sex)\n\n    Sex   n    percent valid_percent\n      F  47 0.04761905    0.05452436\n FEMALE 146 0.14792300    0.16937355\n      M  40 0.04052685    0.04640371\n   MALE 172 0.17426545    0.19953596\n      f 154 0.15602837    0.17865429\n female  98 0.09929078    0.11368910\n      m 119 0.12056738    0.13805104\n   male  86 0.08713273    0.09976798\n   &lt;NA&gt; 125 0.12664640            NA\n\n\nTo inspect missingness, you can use the miss_var_summary() function from the {naniar} package:\n\nmiss_var_summary(data_notif_raw)\n\n# A tibble: 12 × 3\n   variable                               n_miss pct_miss\n   &lt;chr&gt;                                   &lt;int&gt;    &lt;num&gt;\n 1 Onset date                                691     70.0\n 2 Pregnant                                  510     51.7\n 3 Outcome                                   197     20.0\n 4 Date of outcome                           197     20.0\n 5 Date of Birth                             168     17.0\n 6 Sex                                       125     12.7\n 7 Organisation unit name                      0      0  \n 8 Health facility code                        0      0  \n 9 Notification ID                             0      0  \n10 Residential District                        0      0  \n11 Disease notified                            0      0  \n12 Date seen at Health Facility/Community      0      0  \n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nAre the values in the Residential District column standardised?\n\n No - they need cleaning They are standardised and are ready to be used for analysis\n\nAre the values in the Disease notified column standardised?\n\n No - they need cleaning They are standardised and are ready to be used for analysis\n\nWhat does R recognise as a missing value?\n\n Either no value, or just a space, or just a dot No value in a cell, represented with NA The words Unknown and Uncertain\n\nBased on the missingness of its values, is the Onset date column useful?\n\n Yes, the missingness is low so this column is useful Minimally, as the missingness is too high\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse the tabyl() function to tabulate the values within the Residential district column. Again, the first argument is the name of the dataframe object, and the second argument is the name of the column.\n\ntabyl(data_notif_raw, `Residential District`)\n\n Residential District   n    percent\n            F Central  32 0.03242148\n            FEVERIA C  23 0.02330294\n      FEVERIA CENTRAL  85 0.08611955\n            Feveria C  24 0.02431611\n      Feveria Central  12 0.01215805\n               KASARA  64 0.06484296\n                  KSR  17 0.01722391\n               Kasara 109 0.11043566\n             L MINARA  50 0.05065856\n             L Minara 193 0.19554205\n          LAKE MINARA 185 0.18743668\n          Lake Minara  68 0.06889564\n             Lakeside 125 0.12664640\n\n\nYou can see that each of the three locations (Feveria Central, Lake Minara, and Kasara) are spelled in different ways and with different capitalisation. This will need to be cleaned out if we want to analyse the geographic distribution of the notifiable diseases.\nSimilarly, use the tabyl() function to tabulate the values within the Disease notified column. You can see these are spelled out appropriately and consistently, so you can already see the distribution of rows by disease without further cleaning.\n\ntabyl(data_notif_raw, `Disease notified`)\n\n Disease notified   n    percent\n          cholera  46 0.04660588\n           dengue 273 0.27659574\n          malaria 533 0.54002026\n    typhoid fever  35 0.03546099\n     yellow fever 100 0.10131712\n\n\nA different way of checking missingness is to tabulate the the output of the function is.na(). In the example below, the function is.na() evaluates each value within the column Onset date, returning TRUE for missing ones and FALSE for present ones. Running tabyl() on this TRUE/FALSE output then quickly gives you a clear count and percentage of both missing and non-missing values in that column. Remember, values like a space or the words “Unknown” or “Missing” will not be recognised by R as missing. R will only recognise true blanks as missing, represented by “NA”.\nFor Onset date, you can see that 70% of cases are missing onset date, suggesting that this column would not be particularly useful for analysing trends in disease over time.\n\ntabyl(is.na(data_notif_raw$`Onset date`))\n\n is.na(data_notif_raw$`Onset date`)   n   percent\n                              FALSE 296 0.2998987\n                               TRUE 691 0.7001013\n\n\n\n\n\n\n\n\n\n\n\nLike with the surveillance data, use skim(), ncol(), and nrow() functions or check the environment to inspect the lab data.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich linelist has more columns - the surveillance data or the laboratory data?\n\n Lab data Surveillance data They have the same number of columns\n\nWhich linelist has more rows?\n\n Lab data Surveillance data They have the same number of rows\n\nInspect the lab data with View(). Why might the lab data have more records?\n\n There may be several tests or targets per sample There are so many trial test results in the data Not all the notifications have test results yet\n\nWhich of these columns are NOT in the lab data?\n\n Notification ID Sample ID Test type Date of birth Test result\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nJust like in section 3.1, you can use skim() from the {skimr} package to look at the entire surveillance dataset with clinical notifications. This will also show you the different column names in the data, showing you that the lab data only contains information about the test and not about the patient. It does however also contain a notification ID, just like the notifiable disease surveillance data does.\n\nskim(data_lab_raw)\n\nUse ncol() and nrow() to print the number of columns and rows, like this:\n\nncol(data_lab_raw)\nnrow(data_lab_raw)\n\nThis will print the numbers of columns and rows in your console.\n\n\n[1] 6\n\n\n[1] 1314\n\n\nThere are often more records in the lab data than in the clinical data. If you inspect the data with View(data_notif_raw) and then click on the arrow at the top of each column to sort, you’ll see that several rows share the same notification_id. This can happen when multiple targets are tested from the same sample (same sample ID), or when a case is retested (resulting in a different sample ID).\n\nView(data_lab_raw)\n\n\n\nnotification_idsample_iddate_testtesttargetvaluef2170848b003132024-06-07 00:00:00Dengue NS1/IgG/IgM RDTDengue NS.1Nf2170848b003132024-06-07 00:00:00Dengue NS1/IgG/IgM RDTDengue IgGNf2170848b003132024-06-07 00:00:00Dengue NS1/IgG/IgM RDTDengue IgMP6a47a3ca5e865b2024-06-15 20:33:47Dengue NS1/IgG/IgM RDTDengue NS.1N6a47a3ca5e865b2024-06-15 20:33:47Dengue NS1/IgG/IgM RDTDengue IgGN6a47a3ca5e865b2024-06-15 20:33:47Dengue NS1/IgG/IgM RDTDengue IgMP\n\n\n\n\n\n\n\n\nAs above, use the class(), skim(), or tabyl() functions, or inspect the Environment, to look at your columns in more detail.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many columns are recognised by R to be date columns?\n\n 0 1 2\n\nHow many columns have complete data?\n\n 1 3 6 (all of them!)\n\nAre the values within the test, and target columns standardised? (Tip: produce a cross-tabulation!)\n\n Yes - they are ready for analysis No - the need standardisation Cannot tell\n\nWhich test targets multiple targets (and therefore has multiple rows per sample)?\n\n Malaria Dengue Yellow Fever Cholera Typhoid Fever\n\nHow many possible results are there for value?)\n\n 6 3 4\n\nWhat is NOT a possible test result for the stool culture test which targets V. cholera bacteria’?)\n\n P P2 P01 P0139 N I\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse class() with the one date column in the data - you will see that R does recognise it as a date. This means R understands the order of values in this column (e.g. from oldest to newest) and trends over time could be inspected with this column.\n\nclass(data_lab_raw$date_test)\n\nUse of the miss_var_summary() function from the {naniar} package demonstrates that this data is actually complete. This may be because the laboratory systems use automated processes, so are much less likely to have human error. However note, in real life the lab data would probably have some issues too!\n\nmiss_var_summary(data_lab_raw)\n\n# A tibble: 6 × 3\n  variable        n_miss pct_miss\n  &lt;chr&gt;            &lt;int&gt;    &lt;num&gt;\n1 notification_id      0        0\n2 sample_id            0        0\n3 date_test            0        0\n4 test                 0        0\n5 target               0        0\n6 value                0        0\n\n\nYou can inspect the different values within columns using tabyl(). In this example, we suggest you cross-tabulate test and target columns, by writing them the column names into the function as two separate arguments. The output shows that each test clearly aligns with one or more targets, and that it is only the gengue test which targets more than one target (IgG, IgM, and NS.1). Tip: Experiment with changing the order of the column names to see the impact on the table.\n\ntabyl(data_lab_raw, target, test)\n\n               target Blood culture Dengue NS1/IgG/IgM RDT IgM ELISA\n           Dengue IgG             0                    215         0\n           Dengue IgM             0                    215         0\n          Dengue NS.1             0                    215         0\n           Plasmodium             0                      0         0\n    S. Typhi bacteria            33                      0         0\n V. cholerae bacteria             0                      0         0\n     Yellow Fever IgM             0                      0        88\n Stool Culture Whole Blood Microscopy\n             0                      0\n             0                      0\n             0                      0\n             0                    503\n             0                      0\n            45                      0\n             0                      0\n\n\nFinally, you can inspect the different values for the column value, which shows the results per test. You can see that there are six positive results, including N for negative, P for positive, and I for indeterminate. Cholera specifically does not show P, but can show P2, P01, and P0139, which in this case represent being positive for specific serogroups/subtypes.\n\ntabyl(data_lab_raw, test, value)\n\n                   test  I   N   P P2 PO1 PO139\n          Blood culture  2  24   7  0   0     0\n Dengue NS1/IgG/IgM RDT  0 354 291  0   0     0\n              IgM ELISA 10  45  33  0   0     0\n          Stool Culture  5   2   0  5  17    16\n Whole Blood Microscopy 56 257 190  0   0     0"
  },
  {
    "objectID": "pages/multi_disease_lab.html#step-4-clean-and-describe-the-notifiable-disease-surveillance-data",
    "href": "pages/multi_disease_lab.html#step-4-clean-and-describe-the-notifiable-disease-surveillance-data",
    "title": "Linking and analysing notifiable disease surveillance data and laboratory data in R",
    "section": "",
    "text": "You now know that the notifiable disease surveillance data (data_notif_raw) contains information about suspected cases, alongside basic demographic information (age, sex, pregnancy, district of residence), and information about their onset date, report data at the health facility, and outcome. Some columns need cleaning before further analysis, due to variations in spelling of categorical values and some date columns not being recognised as dates.\nYou will now start writing longer chunks of code to clean data, using various {dplyr} functions chained together with pipes (which look like this: |&gt;).\n\n\n\n\nDue to quality and data storage issues, your team recommends that you create a clean linelist that only contains information on the unique identifier, location of the case, disease, and the date of report.\nWrite R code to produce a new clean dataframe called data_notif, applying the following cleaning tasks:\n\nRename columns to be more machine readable (remove spaces and capitalisation) using clean_names() from the {janitor} package\nUse the rename() function from {dplyr} so that the column with the date of diagnosis (and therefore date of reporting by the clinic) is changed to a more conscise date_report.\n\nSelect relevant columns for analysis with the select() function from the {dplyr} package.\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nStart your code with the name of the new dataframe, the assignment arrow, and the name of the raw data object. This shows that the outcome of the raw data processing will be assigned to a new object called data_notif.\n\ndata_notif &lt;- data_notif_raw\n\nThen build on this code by adding in additional functions, chained together with a pipe. This lets you perform several operations in one smooth sequence. First, you’ll use clean_names() to standardize all your column names. It automatically replaces spaces and special characters with underscores and converts everything to lowercase, making names easier to work with. Then, you can use rename() to give a column a new name. Just remember, when you use rename(), the column will already have its clean_names() version.\n\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(NEW_NAME = OLD_NAME)\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the code to clean column names and select the right columns for analysis:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_seen_at_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report)\n\n\n\n\n\n\n\nYou already know from your data inspection that the values for district are not standardised.\nAdd a mutate() function to clean the residential_district column, to:\n\nStandardise the capitalisation of the column\nReplace the existing residential_district column with a clean column that only contains these district values: “Lake Minara”, “Feveria Central”, and “Kasara”.\n\nSee the hint to see what functions you can use.\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTry using str_to_title() from {stringr} package so that the first letter of each word is upper case and all other letters are lower case. You can also use case_match() to specify different specific typos\nUse the ‘help’ functionality of RStudio to see how to use these functions. For example, type ?case_match in your console to get the help page.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYour cleaning code should now look like this:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_seen_at_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = str_to_title(residential_district)) |&gt; \n  mutate(residential_district = case_match(residential_district,\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\"))\n\nYou could also wrap the str_to_title function into the case_match() for shorter code, as follows:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_seen_at_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = case_match(str_to_title(residential_district),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\"))\n\n\n\n\n\n\n\nThe column for report date needs to be transformed so that it is recognized as a date in R. This will allow you to analyse trends over time, including over weeks and months.\nReview the values within the date_report column. Then, add a line to your cleaning code to change date_report into a date class.\nKnowing the structure will allow you to use the correct function to convert the column into a date class. We recommend you use one of the functions from the {lubridate} package: either ymd() (for converting dates written as year-month-date), mdy() (for dates written as month-day-year), or dmy() (for dates written as day-month-year). These functions will recognise any way of writing the date as long as it is the correct order, for example “21st August 2025” and “21-08-2024” would both be recognised by dmy().\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow are the dates formatted?\n\n day-month-year year-month-day month-day-year year-day-month\n\nWhich mutate() function should you use to convert the date_report column into a date class?\n\n mutate(date_report = ymd(date_report)) mutate(date_report = dmy(date_report)) mutate(date_report = mdy(date_report))\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou can use the head() function to view the first six rows of data for the date_report column. You can see that they are written with the year first, then the month, then the date.\n\nhead(data_notif$date_report)\n\n[1] \"2024-03-08\" \"2024-03-11\" \"2024-03-11\" \"2024-03-18\" \"2024-03-14\"\n[6] \"2024-03-12\"\n\n\nYou can use the ymd() function inside mutate() to convert the class of the date_report function. You can double-check that the class is correct by running a class() function afterwards.\nYour cleaning code should now look like this:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_seen_at_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = case_match(str_to_title(residential_district),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\")) |&gt; \n  mutate(date_report = ymd(date_report)) \n\nAnd you can double check the class with this:\n\nclass(data_notif$date_report)\n\n[1] \"Date\"\n\n\n\n\n\n\n\n\nYour colleagues tell you that each notification_id represents one suspected case. You now want to create a table to check if notification_id is duplicated across rows in you data.\n\n\n\n\n\n\nQuestions\n\n\n\n\nDoes one row in the notifiable disease surveillance data equate to one case?\n\n Yes No\n\nDo you need to deduplicate your data for epidemiological analysis of cases?\n\n Yes No\n\n\n\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nThere are many ways to do this, but try using count() function from {dplyr}. It will create a table that counts the number of rows per unique value of the column that you specify inside the function. Then, use tabyl() to look at the distribution of these counts.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFirst, pipe from the surveillance data into the count() function, giving the notification_id column as the only argument. This creates a table that counts the number of rows per unique value of sample_id, shown in a new column n. You can see for example in this excerpt that there is only one row per each of these 6 notification_ids.\n\ndata_notif |&gt; \n  count(notification_id) \n\n\n\n# A tibble: 6 × 2\n  notification_id     n\n  &lt;chr&gt;           &lt;int&gt;\n1 00399b              1\n2 005c85              1\n3 006f52              1\n4 00cbbb              1\n5 01830d              1\n6 019045              1\n\n\nThen tabulate the new column n with the tabyl(), which shows that there is only one row per unique notification_id. This means that one row equates to one case, and no further deduplication is needed.\n\ndata_notif |&gt; \n  count(notification_id) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 987       1\n\n\n\n\n\n\n\n\n\nYou can now comfortably proceed with descriptive analyses of cases, as your data is clean and you know that one row equals one case. Use the tabyl() function for the following tasks.\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich disease was most commonly diagnosed by clinics in Feveria Central in 2024?\n\n Cholera Malaria Dengue Typhoid Fever Yellow Fever\n\nWhich disease was least commonly diagnosed by clinics in Feveria Central in 2024?\n\n Cholera Malaria Dengue Typhoid Fever Yellow Fever\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see that there were 533 suspected cases of malaria in Feveria Centra in 2024, and only 25 suspected cases of typhoid fever.\n\ntabyl(data_notif, disease_notified)\n\n disease_notified   n    percent\n          cholera  46 0.04660588\n           dengue 273 0.27659574\n          malaria 533 0.54002026\n    typhoid fever  35 0.03546099\n     yellow fever 100 0.10131712\n\n\n\n\n\n\n\n\nUse tabyl() to cross-tabulate the disease and district of residence columns.\nYou can also add various adorn functions from the {janitor} package to build on your table to see percentage distributions, e.g. adorn_percentages(), adorn_pct_formatting(), and adorn_ns()\nType the name of the function after a ? in your console (e.g. ?adorn_ns) to see the relevant Help pages.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich district reported the most vector-borne disease in 2024 (malaria, dengue, yellow fever)?\n\n Lake Minara Feveria Central Kasara\n\nWhich district reported the most diarrhoeal disease in 2024 (cholera, typhoid fever)?\n\n Lake Minara Feveria Central Kasara\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see that most cases of dengue, malaria, and yellow fever were located in Lake Minara - the lake area with higher density of mosquitoes and therefore vector-borne disease. Meanwhile the majority of cholera and typhoid fever were in Feveria Central, the over-populated urban area with water and sanitation infrastructure issues that result in higher risk of flooding and drinking water contamination during rainy weather.\n\ntabyl(data_notif, disease_notified, residential_district) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n disease_notified Feveria Central      Kasara Lake Minara\n          cholera      91.3% (42)  8.7%   (4)  0.0%   (0)\n           dengue       9.5% (26) 17.6%  (48) 72.9% (199)\n          malaria      13.7% (73) 19.9% (106) 66.4% (354)\n    typhoid fever      68.6% (24) 31.4%  (11)  0.0%   (0)\n     yellow fever      11.0% (11) 21.0%  (21) 68.0%  (68)"
  },
  {
    "objectID": "pages/multi_disease_lab.html#step-5.-clean-deduplicate-and-describe-the-laboratory-data",
    "href": "pages/multi_disease_lab.html#step-5.-clean-deduplicate-and-describe-the-laboratory-data",
    "title": "Linking and analysing notifiable disease surveillance data and laboratory data in R",
    "section": "",
    "text": "From your earlier work in step 3, you have found that the laboratory data contains only testing data, and no patient information. The data is already very clean, so we will only standardise one column.\n\n\n\n\nCreate a new object data_lab. This will allow a more straight forward analysis and interpretation of results.\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse case_match() to turn the different original values into “Positive”, “Negative”, or “Indeterminate”:\n\ndata_lab &lt;- data_lab_raw |&gt; \n  mutate(value = case_match(value, \n                            c(\"P\", \"PO1\", \"PO139\", \"P2\") ~ \"Positive\",\n                            \"N\" ~ \"Negative\",\n                            \"I\" ~ \"Indeterminate\"))\n\nYou can then double-check that the new values look correct by tabulating and comparing the values in the original dataset and the clean one. Make sure that you used ‘O’ and not ‘0’!\n\ntabyl(data_lab_raw, value)\n\n value   n     percent\n     I  73 0.055555556\n     N 682 0.519025875\n     P 521 0.396499239\n    P2   5 0.003805175\n   PO1  17 0.012937595\n PO139  16 0.012176560\n\n\n\ntabyl(data_lab, value)\n\n         value   n    percent\n Indeterminate  73 0.05555556\n      Negative 682 0.51902588\n      Positive 559 0.42541857\n\n\n\n\n\n\n\n\n\n\n\nWe already know that some samples have multiple rows, and that this is because the dengue test has three targets, with one row per target result.\nNow find the number of samples with multiple rows.\nDo this as you did with the notifiable disease surveillance data, using the data_lab object: first count the number of rows per sample, then create a table to show the distribution of row numbers. Keep in mind that each sample is identified by a sample ID.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many samples (unique sample_ids) are repeated across three rows?\n\n 200 215 230\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFirst, pipe from the lab data into the count() function, giving the sample_id column as the only argument. This creates a table that counts the number of rows per unique value of sample_id, shown in a new column n. You can see for example that the sample_id “000e8eee” has three rows, whereas the sample_id “001e1878” is only seen on one row.\n\ndata_lab |&gt; \n  count(sample_id) \n\n\n\n# A tibble: 6 × 2\n  sample_id     n\n  &lt;chr&gt;     &lt;int&gt;\n1 000e8eee      3\n2 001e1878      1\n3 005f39af      1\n4 00b30781      3\n5 00b56d18      1\n6 0110abcd      3\n\n\nThen tabulate the new column n with the tabyl().\n\ndata_lab |&gt; \n  count(sample_id) |&gt; \n  tabyl(n)\n\n n n_n   percent\n 1 669 0.7567873\n 3 215 0.2432127\n\n\nYou can even double-check that this only applies to the dengue tests by adding in the disease column to the calculation. You can see that it is only the dengue test that has 3 rows per sample.\n\ndata_lab |&gt; \n  count(test, sample_id) |&gt; \n  tabyl(test, n)\n\n                   test   1   3\n          Blood culture  33   0\n Dengue NS1/IgG/IgM RDT   0 215\n              IgM ELISA  88   0\n          Stool Culture  45   0\n Whole Blood Microscopy 503   0\n\n\n\n\n\n\n\n\nAs you saw in section 3.2, your dengue PCR test provides results for three different markers: IgG, IgM, and NS.1. Each of these can be either Negative or Positive. However, to simplify and deduplicate your data, you want to assign a single Negative or Positive label to each sample, to indicate if the sample represents current infection.\n\n\ntargetNegativePositiveDengue IgG110105Dengue IgM105110Dengue NS.113976\n\n\nYou ask your colleague Ben to help you. He says:\n\nA positive NS.1 result is a strong indicator of active viral replication\nA positive IgM result suggests a primary infection that is either acute (past early NS.1 window) or very recent/resolving\nA positive IgG result is either strongly indicative of acute or recently resolved re-infection (in combination with positive IgM), or indicative of immunity after a past resolved infection.\n\nBen suggests to keep your code simple, and identify if a person is currently infected using only NS.1 and IgM, and to ignore the IgG results. You might accidentally identify some recently infected people as currently infected this way (as some IgM positives can be recent infections), but this is still acceptable to capture them as a case.\nNow you need to deduplicate the dengue test results to one row per test. Use filter(), arrange(), and slice(), making sure any sample positive for NS.1 and IgM is considered positive for dengue. Create a new object called data_lab_tests\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTry to apply the following to deduplicate according to his recommendation:\n\nRemove IgG Results: filter out rows where the target is “IgG” using filter() from {dplyr}.\nPrioritize positive IgM/NS1results: Group by sample_id and arrange rows with arrange() so any ‘P’ (Positive) result appears first\nFilter to final status: Keep only the first row using slice(1) to get the Positive or Negative result for the sample.\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the code to filter out the Dengue IgG results, and then deduplicate rows within each group of rows with the same sample_id, prioritising positive results. You need to specify desc within arrange(), as this means that the results will be in reverse alphabetical order, meaning P will be at the top. Also, add the ungroup() function at the end so that the new data is not grouped, which could confuse further analyses.\n\ndata_lab_tests &lt;- data_lab |&gt; \n  filter(target != \"Dengue IgG\") |&gt; \n  group_by(sample_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\nYou can then double-check that the new object data_lab_tests has only one row per test, using the combination of count() and tabyl() like you did in Task A. This table shows you that all unique sample IDs are only present in one row each:\n\ndata_lab_tests |&gt; \n  count(sample_id) |&gt; \n  tabyl(n)\n\n\n\n\n\n\n\nNext, you check the number of tests per notification ID in your new deduplicated data. You can see that there are some rows with the same notification id, but only among cases tested with whole blood microscopy for malaria.\n\ndata_lab_tests |&gt; \n  count(test, notification_id) |&gt; \n  tabyl(test, n)\n\n                   test   1  2\n          Blood culture  33  0\n Dengue NS1/IgG/IgM RDT 215  0\n              IgM ELISA  88  0\n          Stool Culture  45  0\n Whole Blood Microscopy 451 26\n\n\nYou investigate further, looking at one example case with notification_id “043228”. This shows you that this one case was tested twice, with two different samples, one week apart. The first result was positive, and the second result was negative.\n\ndata_lab_tests |&gt; \n  filter(notification_id == \"043228\")\n\n# A tibble: 2 × 6\n  notification_id sample_id date_test           test                target value\n  &lt;chr&gt;           &lt;chr&gt;     &lt;dttm&gt;              &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt;\n1 043228          27c37cd8  2024-06-18 20:36:35 Whole Blood Micros… Plasm… Posi…\n2 043228          d2271be0  2024-06-25 20:36:35 Whole Blood Micros… Plasm… Nega…\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich statement about the lab data is correct?\n\n All cases of different diseases get retested Some malaria cases get retested All malaria cases get retested\n\nWill you need to deduplicate the lab data again, to link with the notifiable disease surveillance data?\n\n Yes - we need one row representing the lab result per case No - the data is sufficiently deduplicated\n\n\n\n\nIf you answered that you need to deduplicate, you are correct!\nDeduplicate your data to have one row per notification ID, so that you can link to the notifiable disease surveillance data.\nTo do this, follow a similar process as you did in Task B: group by notification_id, arrange by the test result value so that values starting with P are prioritised in the top row, followed by N (negative), and then I (indeterminate). Then keep the first row within each group of notification_ids, using slice(). Create a new object called data_lab_cases.\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the code to deduplicate rows within each group of rows with the same notification_id, prioritising positive results. Once again you need to specify desc within arrange(). This works perfectly because the desired priority order for results — Positive, then Negative, then Inconclusive — happens to align with reverse alphabetical order (P comes before N, which comes before I, when sorted descending).\nIf your priority order was more complex or didn’t match alphabetical sorting (e.g., if “Inconclusive” needed to come before “Negative”), you’d have to convert the result column into a factor and explicitly define the desired order of its levels.\n\ndata_lab_cases &lt;- data_lab_tests |&gt; \n  group_by(notification_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1)\n\nYou can then double-check that the new object data_lab_cases has only one row per test, using the combination of count() and tabyl() like you did in Task A. This table shows you that all unique sample IDs are only present in one row each:\n\ndata_lab_cases |&gt; \n  count(notification_id) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 858       1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many tests were conducted to test for malaria (via whole blood microscopy)?\n\n 215 503 88 190\n\nWhat proportion of tests for cholera (via stool culture) were positive?\n\n 21% 11% 84% 87%\n\nWhich test had the highest proportion of indeterminate results?\n\n IgM ELISA (for yellow fever detection) Stool Culture (for cholera detection) Blood culture (for typhoid fever detection)\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see the number of positive, negative, and indeterminate results per test. You can add a series of adorn() functions to show percentages and totals.\n\ntabyl(data_lab_tests, test, value) |&gt; \n  adorn_totals(where = \"col\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n                   test Indeterminate    Negative    Positive        Total\n          Blood culture     6.1%  (2) 72.7%  (24) 21.2%   (7) 100.0%  (33)\n Dengue NS1/IgG/IgM RDT     0.0%  (0) 13.5%  (29) 86.5% (186) 100.0% (215)\n              IgM ELISA    11.4% (10) 51.1%  (45) 37.5%  (33) 100.0%  (88)\n          Stool Culture    11.1%  (5)  4.4%   (2) 84.4%  (38) 100.0%  (45)\n Whole Blood Microscopy    11.1% (56) 51.1% (257) 37.8% (190) 100.0% (503)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich dataset should you use to count the number of cases tested?\n\n data_lab_raw data_lab_cases data_lab_tests data_lab\n\nHow many suspected cases were tested in the 2024 lab data?\n\n 858 1314 884\n\nAre there more suspected cases in the notifiable disease surveillance data or the lab data?\n\n Notifiable disease surveillance data Lab data\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou can simply look at the number of rows in the data_lab_cases dataset to see the number of suspected cases who were tested. This is less than the number of suspected cases that were in the notifiable disease surveillance data (858 vs 987) - which suggests that not all suspected cases have been tested.\n\nnrow(data_lab_cases)\n\n[1] 858"
  },
  {
    "objectID": "pages/multi_disease_lab.html#step-6.-linkage-and-final-processing",
    "href": "pages/multi_disease_lab.html#step-6.-linkage-and-final-processing",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Now that both linelists are clean and have one row per suspected case, you can link them to enable the full analysis requested by your boss.\n\n\n\n\nCreate a new object called data_linked, using a xxx_join() function from {dplyr}. You want to keep all notifications, but add on test results where available for each suspected case.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich function is the correct approach if you want to retain all rows from your notification data and bring in results from your lab data?\n\n left_join(data_notif, data_lab_cases… full_join(data_notif, data_lab_cases… right_join(data_notif, data_lab_cases…\n\nWhat identifier should be used to link the two linelists?\n\n sample_id notification_id sample_id and date of report notification_id and date of report\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nLink the data using the left_join() function, with notification data as the main data frame on the left. This will keep all the rows from this data frame, and will just bring in the test results from the lab data specified on the “right” of the function.\n\ndata_linked &lt;- left_join(data_notif, data_lab_cases, \n                         by = \"notification_id\")\n\nYou are linking on the notification_id column, which is present, complete, and clean in both linelists.\nNote: You are lucky to work with such a straight-forward example of linkage! Usually you would need to really clean and check the ID column, or link on other columns like name and date fo birth. In Feveria, clinic staff are fantastic at consistently allocating notification IDs to each patient, including on the sample forms sent to the lab, and then the lab staff are equally brilliant at recording the notification ID in their lab systems so that the results can be linked back to the case.\n\n\n\n\n\n\nNow check your data and review a few things.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many rows are in your new data_linked data frame?\n\n 987 884 858\n\nHow does this compare to your original notification data?\n\n more rows than the original same number of rows fewer rows\n\nWhat term best describes the linkage you just did?\n\n many-to-one one-to-one many-to-many\n\nHow many lab results were NOT linked (hint: use anti-join())?\n\n 30 19 0\n\nHow fortunate are you that your linkage is so successful?\n\n What? Isn't all linkage this simple?? Very! Usually some records don't match\n\nWhat are typical reasons that lab data doesn’t match to the notifiable diseases data?\n\n There are typos in the columns used for linkage, so they are not recognised as matching The lab data may contain additional cases from other clinics or countries The lab data may include test samples Notifications may have been accidentally missed in the surveillance data even though the sample was tested in the lab All of the above\n\nHow many suspected cases do not have a result?\n\n 83 100 129\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nCheck the number of rows in each data frame with the nrow() function, or by checking the object information in your environment. You can see that this was simply a one-to-one merge, because each row had a unique notification_id, so one row in the notification data linked directly to one row in the lab data.\nNumber of rows in notification data\n\nnrow(data_notif)\n\n[1] 987\n\n\nNumber of rows in linked data\n\nnrow(data_linked)\n\n[1] 987\n\n\nTo check if there were any lab result that were not linked to the notification data, you can use anti_join(). This time the data_lab_cases object is on the left, as the function assess how many rows from the left data frame were not found in the right data frame, matching by notification_id. Here you do not need to generate a new data frame, you can simply pipe into an nrow() to count the number of rows. The output is 0, which shows there were no unlinked results - amazing!\n\nanti_join(data_lab_cases, data_notif, \n          by = \"notification_id\") |&gt; nrow()\n\n[1] 0\n\n\nFinally, to check the number of notifications without a result, you can either conduct an anti_join in putting data_notif first:\n\nanti_join(data_notif, data_lab_cases, \n          by = \"notification_id\") |&gt; nrow()\n\n[1] 129\n\n\nOr, you can simply tabulate the number of missing values in the value column in data_linked (as the value column comes from the lab data).\n\ntabyl(is.na(data_linked$value)) \n\n is.na(data_linked$value)   n   percent\n                    FALSE 858 0.8693009\n                     TRUE 129 0.1306991\n\n\nBoth of these approaches show that 129 suspected cases do not have a lab test result.\n\n\n\n\n\n\n\n\n\nUse mutate() to create a new column case_category, updating the label of suspected cases according to their lab result. The categories should be as follows:\n\nIf the result was positive: Confirmed\nIf the result was negative: Discarded\nIf the result was indeterminate or missing: Suspected\n\nThis means that all cases in the notification data are initially suspected when reported, and then remain suspected if there is no conclusive test result.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich is the most appropriate function for creating this new column?\n\n case_when() if_else() case_match()\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou should use case_when() to create the new column. This function is ideal for applying multiple logical conditions to create multiple values, whereas case_match() is better for replacing specific values, and if_else() is better if there are only two possible values.\n\ndata_linked &lt;- data_linked |&gt; \n  mutate(case_category = case_when(value==\"Positive\" ~ \"Confirmed\",\n                                   value==\"Negative\" ~ \"Discarded\",\n                                   value==\"Indeterminate\" | is.na(value) ~ \"Suspected\"))\n\n\n\n\n\n\n\n\n\n\nUse tabyl() overall, and also cross-tabulate by disease to answer the questions below.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many cases in the linked notification data did not have a positive or negative result?\n\n 202 347 250\n\nWhat percentage of cases in the notification data DID have a positive or negative result?\n\n 60.1% 79.5% 92.2%\n\nWhy are there more remaining suspected cases than there are unlinked notifications?\n\n Suspected cases include notifications without a lab result and with an indeterminate lab result There are additional suspected cases being brought in from the lab There is an issue with the data\n\nWhich disease had the highest percentage of cases that remained suspected after linkage?\n\n Cholera Malaria Dengue Yellow fever\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nOnce again you can use tabyl() to see the distribution of case categories across notifications. The total number of suspected cases, i.e. those with either no lab result at all or with an indeterminate result, is 202. This means 785 cases, i.e. 79.5%, did have a definitive laboratory result.\n\ntabyl(data_linked, case_category) \n\n case_category   n   percent\n     Confirmed 438 0.4437690\n     Discarded 347 0.3515704\n     Suspected 202 0.2046606\n\n\nYou can also cross-tabulate the original results (indeterminate/negative/positive) in the value column with the new case_category column, firstly to check your logic worked, and to see how the original values map to the new column values. This shows that in addition to the 129 notifications that were not linked (with NA in the value column), 73 had indeterminate results, so were categorized as suspected cases.\n\ntabyl(data_linked, case_category, value) \n\n case_category Indeterminate Negative Positive NA_\n     Confirmed             0        0      438   0\n     Discarded             0      347        0   0\n     Suspected            73        0        0 129\n\n\nFinally, you can also cross-tabulate with the disease name to see the case categories by disease. Add additional adorn_xxx() functions for percentage formatting. The table shows you that 22% of yellow fever cases remained suspected, which was the highest percentage compared to the other diseases.\n\ntabyl(data_linked, disease_notified, case_category) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n disease_notified   Confirmed   Discarded   Suspected        Total\n          cholera 82.6%  (38)  4.3%   (2) 13.0%   (6) 100.0%  (46)\n           dengue 68.1% (186) 10.6%  (29) 21.2%  (58) 100.0% (273)\n          malaria 32.6% (174) 46.3% (247) 21.0% (112) 100.0% (533)\n          typhoid 20.0%   (7) 68.6%  (24) 11.4%   (4) 100.0%  (35)\n     yellow_fever 33.0%  (33) 45.0%  (45) 22.0%  (22) 100.0% (100)\n            Total 44.4% (438) 35.2% (347) 20.5% (202) 100.0% (987)\n\n\n\n\n\n\n\n\nUse tabyl() for this once again, looking at the results by disease. Think about the correct denominator!\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhat percentage of suspected cases reported in 2024 were true cases, according to their test results?\n\n 44% 56% 59%\n\nWhat percentage of suspected malaria cases were really malaria?\n\n 86% 41% 23%\n\nWhat percentage of suspected dengue cases were really dengue?\n\n 87% 41% 23%\n\n\n\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nDivide the number of confirmed cases (i.e. those with a positive result) by the number of confirmed plus discarded cases (i.e. those with either a positive or negative result). This gives a positivity rate, which approximates the percentage of suspected cases that were truly cases. Indeterminate results are excluded because they don’t provide a clear outcome and would skew the positivity rate.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFilter out suspected cases and then cross-tabulate, to see the percentage of originally suspected cases that become confirmed or discarded, among those with valid test results.\nBecause there is a totals row, you can see that 56% of suspected cases overall became confirmed, among those with a valid result. You can also see that 41% and 87% of malaria and dengue cases respectively were confirmed.\n\ndata_linked |&gt; \n  filter(case_category != \"Suspected\") |&gt; \n  tabyl(disease_notified, case_category) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n disease_notified   Confirmed   Discarded        Total\n          cholera 95.0%  (38)  5.0%   (2) 100.0%  (40)\n           dengue 86.5% (186) 13.5%  (29) 100.0% (215)\n          malaria 41.3% (174) 58.7% (247) 100.0% (421)\n          typhoid 22.6%   (7) 77.4%  (24) 100.0%  (31)\n     yellow_fever 42.3%  (33) 57.7%  (45) 100.0%  (78)\n            Total 55.8% (438) 44.2% (347) 100.0% (785)\n\n\n\n\n\n\n\n\n\nTask A: Create a new linelist called data_linked_confirmed.\nThis is what you will use in official surveillance reporting.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhy are we opting to report only confirmed cases in our surveillance data?\n\n Reporting confirmed cases can be more reliable and accurate when the percentage testing positive is low and lab testing is routine, thereby helping prevent over-estimation of disease burden Reporting confirmed cases is slower, which gives us more time to be sure of what we are reporting Because we want to hide the true number of cases\n\nWhat function is important for creating the new linelist?\n\n filter() arrange() mutate()\n\nHow many rows are in this new data frame?\n\n 389 438 858\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYour surveillance unit wants to focus on confirmed cases in reporting. This is because lab testing is routine in Feveria, and so reporting suspected cases would be unnecessarily inaccurate, with a high percentage of suspected cases getting discarded.\nThe decision to publish suspected cases may be different in other contexts. For example, if the positivity rate is high (most cases are true cases if tested), and testing itself is not common, or testing takes a long time and would result in delayed reporting, this would suggest that suspected case trends are sufficiently accurate and also more timely than waiting for laboratory confirmation.\nCreate the new linelist with the filter() function:\ndata_linked_confirmed &lt;- data_linked |&gt; \n  filter(case_category==\"Confirmed\")\nAnd check the number of rows by looking at the information in your environment, or with nrow():\nnrow(data_linked_confirmed)\n[1] 438"
  },
  {
    "objectID": "pages/multi_disease_lab.html#step-7.-descriptive-analysis-of-confirmed-cases",
    "href": "pages/multi_disease_lab.html#step-7.-descriptive-analysis-of-confirmed-cases",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Now that you have your linelist of confirmed notifiable disease cases reported in Feveria in 2024, you are ready to conduct the final part of your surveillance analysis! Namely, this is to summarize the five notifiable diseases by geography and time.\nTip: Typically surveillance analysis would also include analysis by person. You could expand on this case study by also analyzing by demographic variables.\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich notifiable disease was most commonly reported in 2024, when restricting to only confirmed cases?\n\n Dengue Malaria Yellow Fever\n\nWhy is the most commonly reported disease different when looking at confirmed and suspected cases?\n\n The sensitivity and specificity of the clinical diagnosis may differ by disease The performance of the tests used in the lab may differ by disease There may be reporting biases All of the above!\n\nWhich district reported the most confirmed cholera cases in 2024?\n\n Lake Minara Feveria Central Kasara\n\nHow many confirmed cases of cholera reported in 2024 were among residents of Feveria Central?\n\n 35 42 4\n\nWhich district reported the most confirmed malaria cases in 2024?\n\n Lake Minara Feveria Central Kasara\n\nDoes this data confirm that dengue is the most common infectious disease in Feveria?\n\n No - a different disease may be under-reported and/or not notifiable Yes - if it's most reported then it must be most common\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see that dengue was the most commonly reported disease in Feveria in 2024 when restricting to confirmed cases, with 186 cases.\n\ndata_linked_confirmed |&gt; \n  tabyl(disease_notified) \n\n disease_notified   n    percent\n          cholera  38 0.08675799\n           dengue 186 0.42465753\n          malaria 174 0.39726027\n          typhoid   7 0.01598174\n     yellow_fever  33 0.07534247\n\n\nNote that this is different from the suspected cases, where malaria was most commonly reported (with 533 suspected cases)! This was hinted at previously, when you saw that the positivity rate for suspected dengue cases was higher than for suspected malaria cases. This can be for different reasons, for instance the clinical diagnosis method used for malaria may be less specific (so many of the suspected cases are actually other diseases), or the test used for dengue may be more sensitive.\nTo cross-tabulate with residential district, add the relevant adorn_xxx() functions.\n\ndata_linked_confirmed |&gt; \n  tabyl(disease_notified, residential_district) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n disease_notified Feveria Central     Kasara Lake Minara        Total\n          cholera      92.1% (35)  7.9%  (3)  0.0%   (0) 100.0%  (38)\n           dengue       8.6% (16) 17.2% (32) 74.2% (138) 100.0% (186)\n          malaria      14.9% (26) 22.4% (39) 62.6% (109) 100.0% (174)\n          typhoid      71.4%  (5) 28.6%  (2)  0.0%   (0) 100.0%   (7)\n     yellow_fever       0.0%  (0) 18.2%  (6) 81.8%  (27) 100.0%  (33)\n            Total      18.7% (82) 18.7% (82) 62.6% (274) 100.0% (438)\n\n\nLike with the suspected cases, we can see that most confirmed cases of dengue, malaria, and yellow fever were located in Lake Minara - the lake area with higher density of mosquitoes and therefore vector-borne disease. The majority of confirmed cholera and typhoid fever cases were in Feveria Central, where there are water and sanitation issues.\nThe data suggests that vector-borne disease (dengue and malaria) are a particular concern in this tropical country. However, we don’t know for sure which is the most common disease and what the underlying patterns are - only five diseases are notifiable, and typically the reported cases only represent a fraction of true cases in the community.\n\n\n\n\n\n\n\nYou are going to work towards producing this epicurve, over the various tasks below.\n\n\n\n\n\n\n\n\n\n\n\nMake sure you specify the argument binwidth=7 so that each bar in the histogram represents the number of cases within a 7 day period.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhen was the first case of typhoid fever reported in Feveria in 2024?\n\n January 2024 May 2024 October 2024\n\nAccording to this graph, what was the highest number of dengue cases reported in a single week in 2024?\n\n 10 20 30 It's very hard to tell from this stacked graph!\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is some simple code to produce the epicurve. Note that you are not controlling the colors just yet, or specifying what day of the week each 7-day period starts on.\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = disease_notified)), binwidth=7)\n\n\n\n\n\n\n\n\nRefer to the dates chapter in the Epi R Handbook if you want more specific date formatting, for instance so that each bar represents a Monday-Sunday week, or the x axis labels the week number (weeks 1 - 52).\nImportantly - it is not straight forward to see the trends per disease when stacked this way! To see such temporal trends, you should produce one histogram per disease.\n\n\n\n\n\n\nUse facet_wrap() to easily create several mini-plots, one per disease. To understand this further, you can look at the facet section of the ggplot2 chapter in the Epi R Handbook\n\n\n\n\n\n\nQuestions\n\n\n\n\nAccording to this faceted graph, what was the highest number of dengue cases reported in a single week in 2024?\n\n 11 15 29 I still can't tell!\n\nAmong the dengue cases reported that week, what districts did they live in?\n\n All three districts Feveria Central Kasara Lake Minara This graph does not show this information\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nNow you can see an epicurve per disease! And you can see that during one week in July, 15 cases of dengue were reported. However, this graph does not show any geographical information yet.\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report)), binwidth=7) + \n  facet_wrap(.~disease_notified)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nAmong the 15 dengue cases reported in one week in July 2024, what districts did they live in?\n\n All three districts Feveria Central Kasara Lake Minara\n\nIn what district was the first typhoid fever case reported in 2024?\n\n Kasara Feveria Central Lake Minara I still can't tell!\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nNow you can see an epicurve per disease, with the coloring reflecting the district the case is a resident of.\nYou can see that among the 15 dengue cases reported in a single week, they lived across the three different districts. You can also see that the first case of typhoid was reported in Feveria Central.\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = residential_district)), binwidth=7) + \n  facet_wrap(.~disease_notified)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can specify:\n\nThe theme/appearance of the overall graph (e.g. background color, appearance of grid lines)\nThe title and labels\nThe colors of the bars (with scale_fill_manual())\nThe formatting and spacing of dates along the x-axis (with scale_x_date)\nMany other things!\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nDo cholera and typhoid fever appear endemic?\n\n No - the data suggests smaller occasional outbreaks Yes they are both endemic\n\nIs there a particular time of the year when malaria peaked in 2024?\n\n Yes - around November/December time Yes - around July/August (summer) time No, it is consistently high\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the fully formatted code. Note some other changes include specifying that we only want two columns of mini-plots within facet_wrap(), and that the date label along the x axis should only show day and month (not year, since all cases are in 2024 anyway).\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = residential_district)), binwidth=7) +\n  facet_wrap(.~disease_notified, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"District of residence\",\n       x = \"Date reported by clinic\",\n       y = \"Count\",\n       subtitle = \"Number of confirmed cholera, dengue, malaria, typhoid fever, and yellow fever cases by week in Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n\n\n\n\n\n\nWe can also see from the epicurve that cholera and typhoid appear to be occurring as isolated outbreaks, rather than showing endemicity. Malaria and dengue however were present in Feveria throughout the year, with malaria more obviously peaking in the summer months.\n\n\n\n\n\n\nThis time, use group_by() and summarize() to produce a table by district showing the earliest and latest report dates.\nYou can adjust your table with a filter() function to create this table for one district at a time.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhen was the first dengue case reported in Feveria in 2024?\n\n 18th January 2024 17th January 2024 12th February 2024\n\nWhen was the last dengue case reported in Feveria Central in 2024?\n\n 22nd August 2024 18th November 2024 25th December 2024\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nGroup the data by disease and then summarize the first and last date to look at the overall timeline of each disease in Feveria.\n\ndata_linked_confirmed |&gt; \n  group_by(disease_notified) |&gt; \n  summarize(first_reported = min(date_report), \n            last_reported = max(date_report)) |&gt;\n  ungroup()\n\n# A tibble: 5 × 3\n  disease_notified first_reported last_reported\n  &lt;chr&gt;            &lt;date&gt;         &lt;date&gt;       \n1 cholera          2024-06-03     2024-09-23   \n2 dengue           2024-01-17     2024-11-18   \n3 malaria          2024-01-08     2024-12-25   \n4 typhoid          2024-05-02     2024-11-07   \n5 yellow_fever     2024-03-08     2024-08-23   \n\n\nAdd a filter() to the code to look at first and most recent report dates for the district you’re interested in.\n\ndata_linked_confirmed |&gt; \n  filter(residential_district == \"Feveria Central\") |&gt; \n  group_by(disease_notified) |&gt; \n  summarize(first_reported = min(date_report), \n            recent_reported = max(date_report)) |&gt;\n  ungroup()\n\n# A tibble: 4 × 3\n  disease_notified first_reported recent_reported\n  &lt;chr&gt;            &lt;date&gt;         &lt;date&gt;         \n1 cholera          2024-06-03     2024-09-23     \n2 dengue           2024-01-29     2024-08-22     \n3 malaria          2024-01-29     2024-12-17     \n4 typhoid          2024-05-02     2024-11-07"
  },
  {
    "objectID": "pages/multi_disease_lab.html#conclusion",
    "href": "pages/multi_disease_lab.html#conclusion",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Wow! In line with the objectives for this case study, you have done the following:\n\nYou used key R functions to clean, reshape, and link data frames, plus created new columns using logical conditions.\nTo inform the data processing, you conducted data inspections and checks along the way\nYou conducted a thorough descriptive analysis to understand the testing and notification data, before and after linkage. In response to your supervisor’s original four questions, you can say:\n\nHow many suspected cases of the different notifiable diseases were reported in 2024, and which was most common? Malaria was the most common notifiable disease in Feveria in 2024, reported through the notifiable disease surveillance system: There were 533 suspected cases of malaria reported, 273 suspected cases of dengue, 100 yellow fever, 46 cholera, and 35 typhoid.\nWhat percentage of them ended up being confirmed? Almost 80% of notifiable cases reported in 2024 had a laboratory test result by the time the linked dataset was created, with some variation by disease. In total, 56% of notified cases were eventually confirmed, but this ranged from only 23% for typhoid fever (7 confirmed of 31 suspected cases with test results), to 95% for cholera (38 confirmed of 40 suspected cases with rest results). Additionally, the positivity rate was higher for suspected dengue than for suspected malaria (87% vs 41%).\nHow many confirmed cases of different notifiable diseases were reported in 2024, and which was most common? Confirmed cases followed a slightly different trend to suspected cases: the most commonly reported infection was dengue with 186 cases, followed by malaria (174), then cholera (38), yellow fever (33), and typhoid fever (7).\nHow are confirmed cases geographically and temporally distributed in Feveria? Feveria experienced dengue and malaria transmission throughout the year, peaking in the summer, and concentrated in the Laka Minara district. Feveria also experienced small and infrequent outbreaks of diarrhoeal disease, e.g. cholera and typhoid fever, particularly in the urban Feveria Central where there can be issues with water and sanitation.\n\nFinally, you have reflected on how the processes involved in notifiable disease surveillance systems and lab testing, for instance the transfer of data between clinics to labs, can affect data quality and completeness, and therefore your results.\n\nThere is so much more potential ahead. You can explore disease patterns by age or sex, calculate disease rates with population data, and even analyze reporting delays by examining the different dates in your datasets.\nYou have built a strong foundation and are well equipped to take your analysis to the next level. Keep going — exciting discoveries await!\nTo learn more, check out the other case studies or dive into the Epi R Handbook."
  },
  {
    "objectID": "pages/multi_disease_lab.html#case-study-information",
    "href": "pages/multi_disease_lab.html#case-study-information",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Original authors: Paula Blomquist and Alanah Jansen, with technical support provided by the CDC Global Surveillance, Laboratory, and Data Systems Branch in collaboration with TEPHINET.\nData source: Fictional data provided by Applied Epi.\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nJuly 2025\nFirst draft\n1\nPaula Blomquist and Alanah Jansen, Applied Epi, with technical support by the CDC Global Surveillance, Laboratory, and Data Systems Branch in collaboration with TEPHINET"
  },
  {
    "objectID": "pages/multi_disease_lab.html#terms-of-use",
    "href": "pages/multi_disease_lab.html#terms-of-use",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Disclaimer: The information presented in this exercise and the associated data files have been developed to help learners achieve the intended learning objectives. The contents are those of the author(s) and do not necessarily represent the official views of CDC, the US Department of Health and Human Services, or TEPHINET.\nLicense: This case study is under a CC BY-NC-SA 4.0 license. For more information about sharing and adapting this case study, see the associated deed.\nFunding: This case study was 100% supported by Cooperative Agreement number NU2HGH000044 funded by the US Centers for Disease Control and Prevention (CDC)."
  },
  {
    "objectID": "pages/multi_disease_lab.html#step-2.-download-and-import-the-data",
    "href": "pages/multi_disease_lab.html#step-2.-download-and-import-the-data",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Your office provides you with two files for your analysis, both containing data for 2024 and updated as of 15th January 2025:\n\nA disease notification-level dataset (“multidisease_notifications.xlsx”) with case information from 5 health centers.\nA laboratory test-level dataset (“multidisease_tests.csv”) submitted by three laboratories conducting testing for the 5 health centers.\n\nFor this case study, you can download the data via Applied Epi’s very useful data repository, which you can access using the {appliedepidata} package. Follow these steps:\n\nInstall the {appliedepidata} package from GitHub using the install_github() function in the {remotes} package (which you installed previously)\n\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nSave the two datasets into a specific folder using the save_data() function from {appliedepidata}, by running the code below. The example below saves the data into a ‘data’ subfolder within the RStudio project. Note that if you do not specify a location within the ‘path’ argument of the function, a window will pop up asking you to manually select a folder.\n\n\n# Save down the two data files using the save_data() function from appliedepidata\nappliedepidata::save_data(\"multidisease_tests\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"multidisease_notifications\",\n                          path = \"data\")\n\n\n\n\nGreat! Thanks country office and Applied Epi! Now it’s time to import the data from that folder into RStudio, so you can analyse it.\n\n\nIdeally, you will use the same function for importing both datasets, despite one being a .csv and the other an .xlsx file. Note going forward we will simply say “environment” when we mean the environment pane in R Studio.\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nUse the import function from the {rio} package, which can recognize and import different file types. It replaces importing functions that are specific to the file type, such as read.csv() from {base} for .csv files and read_excel() from {readxl} to import .xlsx files.\nIf you feel you need to know more about importing functions, read the Import and export chapter of the Epi R Handbook.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nBelow we use the import function to bring in both files. Note how we are assigning the imported data to two objects, one called data_notif_raw, and one called data_lab_raw. We add the ‘raw’ suffix to distinguish this data from the cleaned versions we will make later.\n\n# Import data\n\n# Notification data\ndata_notif_raw &lt;- import(\"data/multidisease_notifications.xlsx\")\n\n# Lab data\ndata_lab_raw &lt;- import(\"data/multidisease_tests.csv\")"
  },
  {
    "objectID": "pages/multi_disease_lab.html#step-3.-inspect-the-data",
    "href": "pages/multi_disease_lab.html#step-3.-inspect-the-data",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "The data’s in, and now it’s time to see what story it tells. Take an initial look at your two raw data frames to check their contents and quality.\n\n\n\n\nUse skim() from the {skimr} package, names(), ncol(), and nrow() to inspect your data frame.\nskim() gives you a lot of information on data structure and content, whereas names() will show you the different column names in your data. The ncol() and nrow() functions to simply count the numbers of columns and rows in the data. Do you know what to put inside the parentheses?\nEasiest of all though, is to look at the environment. Remember the object in your environment for the notification data is called data_notif_raw.\nClick on the solution box underneath the questions if you need help.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many columns are there in the notification data?\n\n 10 11 12 13\n\nWhich of these columns are NOT in the data?\n\n Onset date Date reported by Health Facility/Community Date of outcome Date of test Date of birth\n\nWhat is the name of the column in the notification data that identifies each notification?\n\n Notification ID Test ID Health facility code Combination of Notification ID and Sex\n\nHow many rows are there in the notification data?\n\n 987 1314 950 778\n\nWhat type of information can you NOT see in the notification data?\n\n Laboratory test results District of residence Birthday and sex Health facility in which the case was diagnosed Outcome\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse skim() from the {skimr} package to look at a summary of the entire data frame, and View() to look at the whole data frame directly:\n\nskim(data_notif_raw)\n\nOr, you could use names() to print out just the column names. Through either skim() or names() you will be able to see the types of information including: the health facility of the case, birth-date, sex, a flag indicating pregnancy, district of residence, onset date, and date reported by the clinic, and outcome information. There is also a Notification ID which appears to be a unique identifier for a case, but we would want to double check duplicates before we are sure. Note that there are NO test results in this data, as these notifications are from clinics diagnosing notifiable diseases based on clinical case definitions.\n\nnames(data_notif_raw)\n\n [1] \"Organisation unit name\"                    \n [2] \"Health facility code\"                      \n [3] \"Notification ID\"                           \n [4] \"Date of Birth\"                             \n [5] \"Sex\"                                       \n [6] \"Pregnant\"                                  \n [7] \"Residential District\"                      \n [8] \"Disease notified\"                          \n [9] \"Onset date\"                                \n[10] \"Date reported by Health Facility/Community\"\n[11] \"Outcome\"                                   \n[12] \"Date of outcome\"                           \n\n\nUse ncol() and nrow() to print the number of columns and rows, like this:\n\nncol(data_notif_raw)\nnrow(data_notif_raw)\n\nThis will print the numbers of columns and rows in your console.\n\n\n[1] 12\n\n\n[1] 987\n\n\nOtherwise, when you look at the environment you can see that the number of observations (which is the same as rows) and columns are listed next to the name of the data frame.\n\n\n\n\n\n\nUse skim() from the {skimr} package or class() to inspect your column classes.\nDo you remember how to specify the column of interest inside the class() function? Alternatively, you can just look at the environment.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many columns in the notification data frame are recognised by R to be date columns?\n\n 0 2 4\n\nWhat is the class of most columns in the raw notification data frame?\n\n character numeric factor\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou can use class like the example below. The $ is an operator used to select a specific column from the data_notif_raw data frame. Note that the back-ticks are used around Date of Birth because the column name contains spaces.\n\nclass(data_notif_raw$`Date of Birth`)\n\nTo look at class via the environment, click on the blue arrow next to the data frame name. The column names will appear, with the class next to it (e.g. it says “chr” to show character class).\nYou can see the none of the columns that should be dates are recognized as dates. Instead, they are recognized as character values.\n\n\n\n\n\n\nUse the tabyl() function to inspect the values within categorical columns, specifying the data frame object in the first argument, and the column name in the second argument. For example, this code tabulates the values for the Sex column. The output shows that male and female are inconsistently spelled across the data. This column would need further cleaning before analysis.\n\ntabyl(data_notif_raw, Sex)\n\n    Sex   n    percent valid_percent\n      F  47 0.04761905    0.05452436\n FEMALE 146 0.14792300    0.16937355\n      M  40 0.04052685    0.04640371\n   MALE 172 0.17426545    0.19953596\n      f 154 0.15602837    0.17865429\n female  98 0.09929078    0.11368910\n      m 119 0.12056738    0.13805104\n   male  86 0.08713273    0.09976798\n   &lt;NA&gt; 125 0.12664640            NA\n\n\nTo inspect missingness, you can use the miss_var_summary() function from the {naniar} package:\n\nmiss_var_summary(data_notif_raw)\n\n# A tibble: 12 × 3\n   variable                                   n_miss pct_miss\n   &lt;chr&gt;                                       &lt;int&gt;    &lt;num&gt;\n 1 Onset date                                    691     70.0\n 2 Pregnant                                      510     51.7\n 3 Outcome                                       197     20.0\n 4 Date of outcome                               197     20.0\n 5 Date of Birth                                 168     17.0\n 6 Sex                                           125     12.7\n 7 Organisation unit name                          0      0  \n 8 Health facility code                            0      0  \n 9 Notification ID                                 0      0  \n10 Residential District                            0      0  \n11 Disease notified                                0      0  \n12 Date reported by Health Facility/Community      0      0  \n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nAre the values in the Residential District column standardized?\n\n No - they need cleaning They are standardized and are ready to be used for analysis\n\nAre the values in the Disease notified column standardized?\n\n No - they need cleaning They are standardized and are ready to be used for analysis\n\nWhat does R recognise as a missing value?\n\n Either no value, or just a space, or just a dot No value in a cell, represented with NA The words Unknown and Uncertain\n\nBased on the missingness of its values, is the Onset date column useful?\n\n Yes, the missingness is low so this column is useful Minimally, as the missingness is too high\n\nWhy might some columns in the notification data have different spellings and non-standardized categories?\n\n A bot scrambles the data so it becomes less identifiable Each clinic might use software that is configured slightly differently, or use free-text entries, so there are variations in spelling The surveillance system software used by the clinical settings has lots of bugs\n\nWhy might some columns in the notification data have high missingness?\n\n The clinician does not ask the patient the question during their consultation The patient might not know or want to share the answer The clinician might not have time to prioritise filling in that field in the data, even if they know the information All of the above, and many more reasons\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse the tabyl() function to tabulate the values within the Residential district column. Again, the first argument is the name of the data frame object, and the second argument is the name of the column.\n\ntabyl(data_notif_raw, `Residential District`)\n\n Residential District   n    percent\n            F Central  32 0.03242148\n            FEVERIA C  23 0.02330294\n      FEVERIA CENTRAL  85 0.08611955\n            Feveria C  24 0.02431611\n      Feveria Central  12 0.01215805\n               KASARA  64 0.06484296\n                  KSR  17 0.01722391\n               Kasara 109 0.11043566\n             L MINARA  50 0.05065856\n             L Minara 193 0.19554205\n          LAKE MINARA 185 0.18743668\n          Lake Minara  68 0.06889564\n             Lakeside 125 0.12664640\n\n\nYou can see that each of the three locations (Feveria Central, Lake Minara, and Kasara) are spelled in different ways and with different capitalization. This will need to be cleaned out if we want to analyse the geographic distribution of the notifiable diseases.\nSimilarly, use the tabyl() function to tabulate the values within the Disease notified column. You can see these are spelled out appropriately and consistently, so you can already see the distribution of rows by disease without further cleaning.\n\ntabyl(data_notif_raw, `Disease notified`)\n\n Disease notified   n    percent\n          cholera  46 0.04660588\n           dengue 273 0.27659574\n          malaria 533 0.54002026\n          typhoid  35 0.03546099\n     yellow_fever 100 0.10131712\n\n\nA different way of checking missingness is to tabulate the output of the function is.na(). In the example below, the function is.na() evaluates each cell within the column Onset date, returning TRUE for missing ones and FALSE for present ones. Running tabyl() on this TRUE/FALSE output then quickly gives you a clear count and percentage of both missing and non-missing values in that column. Remember, values like a space or the words “Unknown” or “Missing” will not be recognized by R as missing. R will only recognize true blanks as missing, represented by “NA”.\nFor Onset date, you can see that 70% of cases are missing onset date, suggesting that this column would not be particularly useful for analyzing trends in disease over time.\n\ntabyl(is.na(data_notif_raw$`Onset date`))\n\n is.na(data_notif_raw$`Onset date`)   n   percent\n                              FALSE 296 0.2998987\n                               TRUE 691 0.7001013\n\n\nMissing or non-standardized data can arise for many reasons, including the design of the data collection tool (e.g. whether questions are mandatory or use free text vs. drop-downs), the processes and standards in place (such as which fields staff are instructed to prioritise), and contextual factors (like whether staff have sufficient time to gather the information) — among many others.\n\n\n\n\n\n\n\n\n\nLike with the surveillance data, use skim(), ncol(), and nrow() functions or check the environment to inspect the lab data.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich linelist has more columns - the surveillance data or the laboratory data?\n\n Lab data Surveillance data They have the same number of columns\n\nWhich linelist has more rows?\n\n Lab data Surveillance data They have the same number of rows\n\nInspect the lab data with View(). Why might the lab data have more records?\n\n There may be several tests or targets per sample There are so many trial test results in the data Not all the notifications have test results yet\n\nWhich of these columns are NOT in the lab data?\n\n Notification ID Sample ID Test type Date of birth Test result\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nJust like in section 3.1, you can use skim() from the {skimr} package to look at the entire laboratory data frame with test results. This will also show you the different column names in the data, showing you that the lab data only contains information about the test and not about the patient. It does however also contain a notification ID, just like the notification data does.\n\nskim(data_lab_raw)\n\nUse ncol() and nrow() to print the number of columns and rows, like this:\n\nncol(data_lab_raw)\nnrow(data_lab_raw)\n\nThis will print the numbers of columns and rows in your console, showing you that the lab data has more rows than the notification data you inspected earlier.\n\n\n[1] 7\n\n\n[1] 1314\n\n\nThere are often more records in the lab data than in the clinical data. If you inspect the data with View(data_lab_raw) and then click on the arrow at the top of the notification_id column to sort it alphabetically, you’ll see that several rows share the same notification_id. This can happen when multiple targets are tested from the same sample (same sample ID), or when a case is retested (resulting in a different sample ID).\n\nView(data_lab_raw)\n\n\n\nlaboratory_namenotification_idsample_iddate_testtesttargetvalueFeveria General Hospitalf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue NS.1NFeveria General Hospitalf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgGNFeveria General Hospitalf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgMPFeveria General Hospital6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue NS.1NFeveria General Hospital6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgGNFeveria General Hospital6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgMP\n\n\n\n\n\n\n\n\nAs above, use the class(), skim(), or tabyl() functions, or inspect the environment, to look at your columns in more detail.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many columns in the laboratory data frame are recognised by R to be date columns?\n\n 0 1 2\n\nHow many columns in the laboratory data frame have complete data?\n\n 1 3 7 (all of them!)\n\nWhich test detects multiple targets (and therefore has multiple rows per sample)?\n\n Malaria Dengue Yellow Fever Cholera Typhoid Fever\n\nHow many possible test result values are there in the column value?\n\n 5 3 4\n\nWhat is NOT a possible test result for the stool culture test which detects V. cholerae bacteria’?)\n\n P P01 P0139 N I\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nThe laboratory data has one date column, recognized by R as an “IDate” class. This is a date class used by {rio}’s import() when reading csv files. Like base R’s Date class, it allows sorting by date and analyzing trends over time.\n\nclass(data_lab_raw$date_test)\n\n[1] \"IDate\" \"Date\" \n\n\nUse of the miss_var_summary() function from the {naniar} package demonstrates that all columns in the laboratory data are actually complete. This may be because the laboratory systems use automated processes, so are much less likely to have human error.\n(Important point: Note that in real life, the lab data would probably have some issues too!)\n\nmiss_var_summary(data_lab_raw)\n\n# A tibble: 7 × 3\n  variable        n_miss pct_miss\n  &lt;chr&gt;            &lt;int&gt;    &lt;num&gt;\n1 laboratory_name      0        0\n2 notification_id      0        0\n3 sample_id            0        0\n4 date_test            0        0\n5 test                 0        0\n6 target               0        0\n7 value                0        0\n\n\nTo see how many targets are detected by each test, you can cross-tabulate test and target columns with tabyl(). Write the column names into the function as two separate arguments. The output shows that each test clearly aligns with one or more targets, and only the dengue assay detects more than one target (IgG, IgM, and NS.1).\nTip: Experiment with changing the order of the column names in the function to see the impact on the table.\n\ntabyl(data_lab_raw, target, test)\n\n               target Blood culture Dengue NS1/IgG/IgM IgM ELISA Stool Culture\n           Dengue IgG             0                215         0             0\n           Dengue IgM             0                215         0             0\n          Dengue NS.1             0                215         0             0\n           Plasmodium             0                  0         0             0\n    S. Typhi bacteria            33                  0         0             0\n V. cholerae bacteria             0                  0         0            45\n     Yellow Fever IgM             0                  0        88             0\n Whole Blood Microscopy\n                      0\n                      0\n                      0\n                    503\n                      0\n                      0\n                      0\n\n\nFinally, you can inspect the different test result values in the column value, again using tabyl(). You can see that there are six possible results, including N for negative, P for positive, and I for indeterminate. Cholera specifically does not show P, but can show P01 and P0139, which in this case represent being positive for serogroups O1 or O139.\n\ntabyl(data_lab_raw, test, value)\n\n                   test  I   N   P PO1 PO139\n          Blood culture  2  24   7   0     0\n     Dengue NS1/IgG/IgM  0 354 291   0     0\n              IgM ELISA 10  45  33   0     0\n          Stool Culture  5   2   0  22    16\n Whole Blood Microscopy 56 257 190   0     0"
  },
  {
    "objectID": "pages/multi_disease_lab.html#step-4.-clean-and-describe-the-notification-data",
    "href": "pages/multi_disease_lab.html#step-4.-clean-and-describe-the-notification-data",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "You now know that the notification data (data_notif_raw) contains information about suspected cases, alongside basic demographic information (age, sex, pregnancy, district of residence), and information about their onset date, date reported by the health facility, and outcome. Some columns need cleaning before further analysis, due to variations in spelling of categorical values and some date columns not being recognized as dates.\nYou will now start writing longer chunks of code to clean data, using various {dplyr} functions chained together with pipes (which look like this: |&gt;).\nNOTE ON PIPES: Pipes allow you to perform several operations in one smooth sequence, by “chaining” different functions together. The output from one function becomes the input for the next. If you need more information on piping, please refer to the Epi R Handbook. Note that this exercise uses the base pipe (|&gt;) rather than the magrittr pipe (%&gt;%), as it is faster and does not require package installation. Use the magrittr pipe if you prefer it.\n\n\n\n\nDue to quality and data storage issues, your team recommends that you create a clean linelist that only contains information on the unique identifier, location of the case, disease, and the date the notification was reported to the surveillance system.\nWrite R code to produce a new clean data frame called data_notif, applying the following cleaning tasks:\n\nRename columns to be more machine readable (remove spaces and capitalization) using clean_names() from the {janitor} package\nUse the rename() function from {dplyr} so that the column with the date the case was reported is changed to a more concise date_report.\n\nSelect relevant columns for analysis with the select() function from the {dplyr} package.\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nStart your code with the name of the new data frame, the assignment arrow, and the name of the raw data object. This shows that the outcome of the raw data processing will be assigned to a new object called data_notif.\n\ndata_notif &lt;- data_notif_raw\n\nThen build on this code by adding in additional functions, chained together with a pipe. This lets you perform several operations in one smooth sequence. First, you’ll use clean_names() to standardize all your column names. It automatically replaces spaces and special characters with underscores and converts everything to lowercase, making names easier to work with. Then, you can use rename() to give a column a new name. Just remember, when you use rename(), the column will already have its clean_names() version.\n\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(NEW_NAME = OLD_NAME) |&gt; \n  select(VAR_NAMES)\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the code to clean column names and select the right columns for analysis:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report)\n\n\n\n\n\n\n\nYou already know from your data inspection that the values for district are not standardized.\nAdd a mutate() function to clean the residential_district column, to:\n\nStandardize the capitalization of the column\nReplace the existing residential_district column with a clean column that only contains these district values: “Lake Minara”, “Feveria Central”, and “Kasara”.\n\nSee the hint to see what functions you can use.\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTry using str_to_title() from {stringr} package so that the first letter of each word is upper case and all other letters are lower case. You can also use case_match() to specify different specific typos.\nUse the ‘help’ functionality of RStudio to see how to use these functions. For example, type ?case_match in your console to get the help page. NOTE on case_match() - this is a very useful function for replacing or correcting values, and supersedes recode().\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYour cleaning code should now look like this:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = str_to_title(residential_district)) |&gt; \n  mutate(residential_district = case_match(residential_district,\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\"))\n\nYou could also wrap the str_to_title function into the case_match() for shorter code, as follows:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = case_match(str_to_title(residential_district),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\"))\n\n\n\n\n\n\n\nThe column for report date needs to be transformed so that it is recognized as a date in R. This will allow you to analyse trends over time, including over weeks and months.\nReview the values within the date_report column. Then, add a line to your cleaning code to change date_report into a date class.\nKnowing the structure will allow you to use the correct function to convert the column into a date class. We recommend you use one of the functions from the {lubridate} package: either ymd() (for converting dates written as year-month-date), mdy() (for dates written as month-day-year), or dmy() (for dates written as day-month-year). These functions will recognize any way of writing the date as long as it is the correct order, for example “21st August 2025” and “21-08-2024” would both be recognized by dmy().\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow are the dates currently formatted?\n\n day-month-year year-month-day month-day-year year-day-month\n\nWhich mutate() function should you use to convert the date_report column into a date class?\n\n mutate(date_report = ymd(date_report)) mutate(date_report = dmy(date_report)) mutate(date_report = mdy(date_report))\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou can use the head() function to view the first six rows of data for the date_report column. You can see that they are written with the year first, then the month, then the date.\n\nhead(data_notif$date_report)\n\n[1] \"2024-03-08\" \"2024-03-11\" \"2024-03-11\" \"2024-03-18\" \"2024-03-14\"\n[6] \"2024-03-12\"\n\n\nYou can use the ymd() function inside mutate() to convert the class of the date_report function. You can double-check that the class is correct by running a class() function afterwards.\nYour cleaning code should now look like this:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = case_match(str_to_title(residential_district),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\")) |&gt; \n  mutate(date_report = ymd(date_report)) \n\nAnd you can double check the class with this:\n\nclass(data_notif$date_report)\n\n[1] \"Date\"\n\n\n\n\n\n\n\n\nYour colleagues tell you that each notification_id represents one suspected case. You now want to create a table to check if notification_id is duplicated across rows in you data.\n\n\n\n\n\n\nQuestions\n\n\n\n\nDoes one row in the notification data equate to one case?\n\n Yes No\n\nDo you need to deduplicate your data for epidemiological analysis of cases?\n\n Yes No\n\n\n\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nThere are many ways to do this, but try using count() function from {dplyr}. It will create a table that counts the number of rows per unique value of the column that you specify inside the function. Then, use tabyl() to look at the distribution of these counts.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFirst, pipe from the surveillance data into the count() function, giving the notification_id column as the only argument. This creates a table that counts the number of rows per unique value of sample_id, shown in a new column n. You can see for example in this excerpt that there is only one row per each of these 6 notification_ids.\n\ndata_notif |&gt; \n  count(notification_id) \n\n\n\n  notification_id n\n1          00399b 1\n2          005c85 1\n3          006f52 1\n4          00cbbb 1\n5          01830d 1\n6          019045 1\n\n\nThen tabulate the new column n with the tabyl(), which shows that there is only one row per unique notification_id. This means that one row equates to one case, and no further deduplication is needed.\n\ndata_notif |&gt; \n  count(notification_id) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 987       1\n\n\n\n\n\n\n\n\n\nYou can now comfortably proceed with descriptive analyses of cases, as your data is clean and you know that one row equals one case. Use the tabyl() function for the following tasks.\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich disease was most commonly diagnosed by clinics in Feveria in 2024?\n\n Cholera Malaria Dengue Typhoid Fever Yellow Fever\n\nWhich disease was least commonly diagnosed by clinics in Feveria in 2024?\n\n Cholera Malaria Dengue Typhoid Fever Yellow Fever\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see that there were 533 suspected cases of malaria in Feveria in 2024, and only 35 suspected cases of typhoid fever.\n\ntabyl(data_notif, disease_notified)\n\n disease_notified   n    percent\n          cholera  46 0.04660588\n           dengue 273 0.27659574\n          malaria 533 0.54002026\n          typhoid  35 0.03546099\n     yellow_fever 100 0.10131712\n\n\n\n\n\n\n\n\nUse tabyl() to cross-tabulate the disease and district of residence columns.\nBuild on your table by adding various adorn functions from the {janitor} package, to see percentage distributions, e.g. adorn_percentages(), adorn_pct_formatting(), and adorn_ns()\nType the name of the function after a ? in your console (e.g. ?adorn_ns) to see the relevant Help pages. You can also look at the section about {janitor} in the Epi R Handbook for more explanation of adorn_xxx() functions.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich district reported the most vector-borne disease in 2024 (malaria, dengue, yellow fever)?\n\n Lake Minara Feveria Central Kasara\n\nWhich district reported the most diarrhoeal disease in 2024 (cholera, typhoid fever)?\n\n Lake Minara Feveria Central Kasara\n\nWhat factors contribute to increased diarrhoeal disease in this specific district (selected in previous question)?\n\n Unreliable water and sanitation infrastructure Overcrowding of mosquitoes We don't know\n\n\n\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nHere is some code to get you started. It cross-tabulates disease_notified and residential_district with tabyl(), then adding adorn_percentages() converts these numbers to percentages with many decimals. You then need to pipe into adorn_pct_formatting() to convert into actual percentage formatting, and then adorn_ns() to add numbers back in in parentheses. Note that adorn_xxx() functions need to be applied in a specific order!\n\ntabyl(data_notif, disease_notified, residential_district) |&gt;\n  adorn_percentages()\n\nFor factors contributing to more diarrhea - scroll up to earlier in the case study when the districts were first introduced!\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see that most suspected cases of dengue, malaria, and yellow fever were located in Lake Minara - the lake area with higher density of mosquitoes and therefore vector-borne disease. Meanwhile the majority of cholera and typhoid fever were in Feveria Central, the over-populated urban area with water and sanitation infrastructure issues that result in higher risk of flooding and drinking water contamination during rainy weather.\n\ntabyl(data_notif, disease_notified, residential_district) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n disease_notified Feveria Central      Kasara Lake Minara\n          cholera      91.3% (42)  8.7%   (4)  0.0%   (0)\n           dengue       9.5% (26) 17.6%  (48) 72.9% (199)\n          malaria      13.7% (73) 19.9% (106) 66.4% (354)\n          typhoid      68.6% (24) 31.4%  (11)  0.0%   (0)\n     yellow_fever      11.0% (11) 21.0%  (21) 68.0%  (68)"
  },
  {
    "objectID": "pages/multi_disease_lab.html#step-5.-clean-consolidate-and-describe-the-laboratory-data",
    "href": "pages/multi_disease_lab.html#step-5.-clean-consolidate-and-describe-the-laboratory-data",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "From your earlier work in step 3, you have found that the laboratory data contains only testing data, and no patient information. The data is already very clean, so we only need to standardize one column. We will also want to process the laboratory data frame to be one row per notification, so that it can be neatly linked to the notification data frame.\n\n\n\n\nCreate a new object data_lab. This will allow a more straight-forward analysis and interpretation of results.\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse case_match() to turn the different original values into “Positive”, “Negative”, or “Indeterminate”:\n\ndata_lab &lt;- data_lab_raw |&gt; \n  mutate(value = case_match(value, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positive\",\n                            \"N\" ~ \"Negative\",\n                            \"I\" ~ \"Indeterminate\"))\n\nYou can then double-check that the new values look correct by tabulating and comparing the values in the original data frame and the clean one. Make sure that you used the letter ‘O’ and not the number ‘0’!\n\ntabyl(data_lab_raw, value)\n\n value   n    percent\n     I  73 0.05555556\n     N 682 0.51902588\n     P 521 0.39649924\n   PO1  22 0.01674277\n PO139  16 0.01217656\n\n\n\ntabyl(data_lab, value)\n\n         value   n    percent\n Indeterminate  73 0.05555556\n      Negative 682 0.51902588\n      Positive 559 0.42541857\n\n\n\n\n\n\n\n\n\n\n\nWe already know that some samples have multiple rows, and that this is because the dengue assay has three targets, with one row per target result.\nNow find the number of samples with multiple rows.\nDo this as you did with the notification data, using the data_lab object: first count the number of rows per sample, then create a table to show the distribution of row numbers. Keep in mind that each sample is identified by a sample ID.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many samples (unique sample_ids) are repeated across three rows?\n\n 200 215 230\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFirst, pipe from the lab data into the count() function, giving the sample_id column as the only argument. This creates a table that counts the number of rows per unique value of sample_id, shown in a new column n. You can see for example that the sample_id “000e8eee” has three rows, whereas the sample_id “001e1878” is only seen on one row.\n\ndata_lab |&gt; \n  count(sample_id) \n\n\n\n  sample_id n\n1  000e8eee 3\n2  001e1878 1\n3  005f39af 1\n4  00b30781 3\n5  00b56d18 1\n6  0110abcd 3\n\n\nThen tabulate the new column n with the tabyl().\n\ndata_lab |&gt; \n  count(sample_id) |&gt; \n  tabyl(n)\n\n n n_n   percent\n 1 669 0.7567873\n 3 215 0.2432127\n\n\nYou can even double-check that this only applies to the dengue assay by adding in the disease column to the calculation. You can see that it is only the dengue test that has 3 rows per sample.\n\ndata_lab |&gt; \n  count(test, sample_id) |&gt; \n  tabyl(test, n)\n\n                   test   1   3\n          Blood culture  33   0\n     Dengue NS1/IgG/IgM   0 215\n              IgM ELISA  88   0\n          Stool Culture  45   0\n Whole Blood Microscopy 503   0\n\n\n\n\n\n\n\n\nAs you saw in section 3.2, your dengue test provides results for three different targets: IgG, IgM, and NS.1. The results for each of these targets can be either negative or positive. However, to simplify and consolidate your data, you want to assign a single negative or positive label to each sample, to indicate if the sample represents current infection.\n\n\ntargetNegativePositiveDengue IgG110105Dengue IgM105110Dengue NS.113976\n\n\nYour colleague Ben, who works in the lab, advises you on the cleaning as follows:\n\nA sample can be considered positive if NS.1 or IgM are positive (as both can represent acute infection)\nYou can ignore IgG (because a positive result in the absence of positive NS.1 or IgM is indicative of immunity after a past resolved infection)\n\nNow you need to consolidate the dengue test results to one row per test, with one result value. Use filter(), arrange(), and slice(), making sure any sample positive for NS.1 or IgM is considered positive for dengue. Create a new object called data_lab_tests\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTry to apply the following to consolidate according to Ben’s recommendation:\n\nRemove IgG Results: filter out rows where the target is “IgG” using filter() from {dplyr}.\nPrioritize positive IgM/NS1results: Group by sample_id and arrange rows with arrange() so any ‘P’ (positive) result appears first\nFilter to final status: Keep only the first row using slice(1) to get the positive or negative result for the sample.\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the code to filter out the dengue IgG results, and then consolidate the test result within each group of rows with the same sample_id, prioritizing positive results. You need to specify desc within arrange(), as this means that the results will be in reverse alphabetical order, meaning P will be at the top. Also, add the ungroup() function at the end so that the new data is not grouped, which could confuse further analyses.\n\ndata_lab_tests &lt;- data_lab |&gt; \n  filter(target != \"Dengue IgG\") |&gt; \n  group_by(sample_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\nYou can then double-check that the new object data_lab_tests has only one row per test, using the combination of count() and tabyl() like you did in Task A. This table shows you that all unique sample IDs are only present in one row each:\n\ndata_lab_tests |&gt; \n  count(sample_id) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 884       1\n\n\n\n\n\n\n\n\nNext, you check the number of tests per notification ID in your new consolidated data. You can see that there are 26 rows with the same notification id as another row, but only among cases tested with whole blood microscopy for malaria.\n\ndata_lab_tests |&gt; \n  count(test, notification_id) |&gt; \n  tabyl(test, n)\n\n                   test   1  2\n          Blood culture  33  0\n     Dengue NS1/IgG/IgM 215  0\n              IgM ELISA  88  0\n          Stool Culture  45  0\n Whole Blood Microscopy 451 26\n\n\nYou investigate further, looking at one example case with notification_id “043228”. This shows you that this one case was tested twice, with two different samples, one week apart. The first result was positive, and the second result was negative.\n\ndata_lab_tests |&gt; \n  filter(notification_id == \"043228\")\n\n# A tibble: 2 × 7\n  laboratory_name        notification_id sample_id date_test  test  target value\n  &lt;chr&gt;                  &lt;chr&gt;           &lt;chr&gt;     &lt;IDate&gt;    &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;\n1 Kasara University Hos… 043228          27c37cd8  2024-06-18 Whol… Plasm… Posi…\n2 Kasara University Hos… 043228          d2271be0  2024-06-25 Whol… Plasm… Nega…\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich statement about the lab data is correct?\n\n All cases of different diseases get retested Some malaria cases get retested All malaria cases get retested\n\nWill you need to deduplicate the lab data, to link with the notification data?\n\n Yes - we need one row representing the lab result per notification No - the data is sufficiently deduplicated\n\n\n\n\nIf you answered that you need to deduplicate, you are correct!\nDeduplicate your data to have one row per notification ID, prioritizing positive results, so that you can link to the notification data.\nTo do this, follow a similar process as you did in Task B, using the data frame produced by task B: - Group by notification_id - Arrange by the test result value so that values starting with P are prioritized in the top row, followed by N (negative), and then I (indeterminate). - Then keep the first row within each group of notification_ids, using slice(). - When doing this, create a new object called data_lab_cases.\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the code to deduplicate rows within each group of rows with the same notification_id, prioritizing positive results. Once again you need to specify desc within arrange(). This works perfectly because the desired priority order for results — positive, then negative, then indeterminate — happens to align with reverse alphabetical order (P comes before N, which comes before I, when sorted descending).\nIf your priority order was more complex or didn’t match alphabetical sorting (e.g., if “indeterminate” needed to come before “negative”), you’d have to convert the result column into a factor and explicitly define the desired order of its levels. Don’t forget to ungroup again at the end.\n\ndata_lab_cases &lt;- data_lab_tests |&gt; \n  group_by(notification_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt;\n  ungroup()\n\nYou can then double-check that the new object data_lab_cases has only one row per test, using the combination of count() and tabyl() like you did in Task A. This table shows you that all unique sample IDs are only present in one row each:\n\ndata_lab_cases |&gt; \n  count(notification_id) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 858       1\n\n\n\n\n\n\n\n\n\nNow we have two objects that we can use for analysis of laboratory data: data_lab_tests and data_lab_cases.\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich object should you use to analyse tests?\n\n data_lab_tests data_lab_cases neither\n\nHow many tests were conducted to test for malaria (via whole blood microscopy)?\n\n 215 503 88 190\n\nWhat percentage of tests for cholera (via stool culture) were positive?\n\n 21% 11% 84% 87%\n\nWhich test had the highest percentage of indeterminate results?\n\n IgM ELISA (for yellow fever detection) Stool Culture (for cholera detection) Blood culture (for typhoid fever detection)\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see the number of positive, negative, and indeterminate results per test. You can add a series of adorn() functions to show percentages and totals.\n\ntabyl(data_lab_tests, test, value) |&gt; \n  adorn_totals(where = \"col\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n                   test Indeterminate    Negative    Positive        Total\n          Blood culture     6.1%  (2) 72.7%  (24) 21.2%   (7) 100.0%  (33)\n     Dengue NS1/IgG/IgM     0.0%  (0) 13.5%  (29) 86.5% (186) 100.0% (215)\n              IgM ELISA    11.4% (10) 51.1%  (45) 37.5%  (33) 100.0%  (88)\n          Stool Culture    11.1%  (5)  4.4%   (2) 84.4%  (38) 100.0%  (45)\n Whole Blood Microscopy    11.1% (56) 51.1% (257) 37.8% (190) 100.0% (503)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich lab data frame should you use to count the number of suspected cases tested?\n\n data_lab_raw data_lab_cases data_lab_tests data_lab\n\nHow many suspected cases were tested in the 2024 lab data?\n\n 858 1314 884\n\nAre there more suspected cases in the notification data or the lab data?\n\n Notification data Lab data\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou can simply look at the number of rows in the data_lab_cases data frame to see the number of suspected cases who were tested.\n\nnrow(data_lab_cases)\n\n[1] 858\n\n\nThis is less than the number of suspected cases that were in the clean notifiable disease surveillance data (data_notif) - which suggests that not all suspected cases in 2024 were tested by the time this data was available.\n\nnrow(data_notif)\n\n[1] 987"
  },
  {
    "objectID": "pages/multi_disease_lab.html#data-cleaning-and-analysis-code",
    "href": "pages/multi_disease_lab.html#data-cleaning-and-analysis-code",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "See below a script of all data cleaning steps and descriptive analyses. Note how the analyses are combined at the end rather than interspersed in between cleaning steps. This is a tidier way to organize your script.\nFor brevity, the code below does not include all inspections and checks made along the way, but you may decide to create a sections with such checks.\nThe top of your script should also contain information to help the reader understand what the script is for, as well as comments throughout. You will thank yourself later for adding these comments!\n\n\n\n\n\n\nCode to clean and analyse notification data and lab data from Feveria, 2024\n\n\n\n\n\n\n# Code to clean and analyse notification data and lab data from Feveria, 2024\n# Date:\n# Author:\n\n# Install packages -------------------------------------------------\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  flextable,  # Presentation ready tables\n  naniar,     # Evaluating missingness of data\n  remotes,    # Used to install package to download data\n  tidyverse   # data management and visualization\n)\n\n# Import data --------------------------------------------\n\n# Notification data\ndata_notif_raw &lt;- import(\"data/multidisease_notifications.xlsx\")\n\n# Lab data\ndata_lab_raw &lt;- import(\"data/multidisease_tests.csv\")\n\n# Clean notification data --------------------------------\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = case_match(str_to_title(residential_district),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\")) |&gt; \n  mutate(date_report = ymd(date_report)) \n\n\n# Clean and consolidate lab data  ---------------------------------------\n# Clean values\ndata_lab &lt;- data_lab_raw |&gt; \n  mutate(value = case_match(value, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positive\",\n                            \"N\" ~ \"Negative\",\n                            \"I\" ~ \"Indeterminate\"))\n\n# Create test-level lab data\ndata_lab_tests &lt;- data_lab |&gt; \n  filter(target != \"Dengue IgG\") |&gt; \n  group_by(sample_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Create case-level lab data\ndata_lab_cases &lt;- data_lab_tests |&gt; \n  group_by(notification_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Link notification and lab data  ---------------------------------------\ndata_linked &lt;- left_join(data_notif, data_lab_cases, by = \"notification_id\")\n\n# Clean data--------------------------------------------------------------\ndata_linked &lt;- data_linked |&gt; \n  mutate(case_category = case_when(value==\"Positive\" ~ \"Confirmed\",\n                                   value==\"Negative\" ~ \"Discarded\",\n                                   value==\"Indeterminate\" | is.na(value) ~ \"Suspected\"))\n\ndata_linked_confirmed &lt;- data_linked |&gt; \n  filter(case_category==\"Confirmed\")\n\n# ANALYSIS ---------------------------------------------------------\n# Number of suspected cases in Feveria\ntabyl(data_notif, disease_notified)\n\n# Distribution of suspected cases by district\ntabyl(data_notif, disease_notified, residential_district) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n# Distribution of results per disease-specific test\ntabyl(data_lab_tests, test, value) |&gt; \n    adorn_totals(where = \"col\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution of case category, in linked data: all cases\ntabyl(data_linked, case_category) \n\n# Distribution of case category by diseases, in linked data: all cases\ntabyl(data_linked, disease_notified, case_category) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution of case category by disease, in linked data: only cases with a valid result\ndata_linked |&gt; \n    filter(case_category != \"Suspected\") |&gt; \n    tabyl(disease_notified, case_category) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution of confirmed cases by district\ndata_linked_confirmed |&gt; \n  tabyl(disease_notified, residential_district) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n\n# Visualize confirmed cases over time\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = residential_district)), binwidth=7) +\n  facet_wrap(.~disease_notified, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"District of residence\",\n       x = \"Date reported by clinic\",\n       y = \"Count\",\n       subtitle = \"Number of confirmed cholera, dengue, malaria, typhoid fever, and yellow fever cases by week in Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n# First and last report date per disease\ndata_linked_confirmed |&gt; \n  group_by(disease_notified) |&gt; \n  summarize(first_reported = min(date_report), \n            last_reported = max(date_report)) |&gt;\n  ungroup()"
  },
  {
    "objectID": "pages/multidisease_surveillance.pt.html",
    "href": "pages/multidisease_surveillance.pt.html",
    "title": "Ligação e análise de dados de notificação e de dados laboratoriais em R",
    "section": "",
    "text": "Ferramenta: R Complexidade técnica: Intermédiaria Complexidade metodológica: Básica\nConhecimentos prévios necessários: Noções básicas de R (Utilizando Rstudio; pacotes R, funções e argumentos, utilização de pipes), bem como as principais funções tidyverse e ggplots)\nFonte: Applied Epi, com apoio técnico fornecido pelo CDC Global Surveillance, Laboratory, and Data Systems Branch em colaboração com a TEPHINET.\n\n\n\nPara obter instruções sobre como utilizar os nossos estudos de caso, consulte o nosso guia. Agradecemos comentários e sugestões via contact@appliedepi.org. Também pode discutir o estudo de caso ou conceitos relacionados na Comunidade Applied Epi.\n\n\nVocê é um epidemiologista que trabalha no serviço nacional de vigilância de Feveria, um país tropical muito pequeno. Existem três distritos em Feveria:\n\nFeveria Central:uma área urbana superpovoada, com infraestrutura de água e saneamento às vezes precária.\nLago Minara: uma zona lacustre com boa infra-estrutura mas muitos mosquitos nos meses mais quentes do ano.\nKasara: uma zona mais suburbana do outro lado de Feveria Central.\n\nMapa dos distritos do país Feveria\n\nÉ janeiro de 2025, e sua supervisora gostaria que você transferisse o processamento rotineiro dos dados de doenças de notificação compulsória do Excel para o R e realizasse algumas análises com os dados. Ela quer saber pelo menos:\n\nQuantos casos suspeitos das diferentes doenças de notificação compulsória foram notificados em 2024 e qual foi a mais comum?\nQual porcentagem deles acabou sendo confirmada?\nQuantos casos confirmados das diferentes doenças de notificação compulsória foram notificados em 2024 e qual foi a mais comum?\nComo é que os casos confirmados foram distribuídos geográfica e temporalmente em Feveria?\n\nEla pede que você escreva código para importar, limpar, relacionar e analisar as seguintes listas de casos (linelists):\n\nDados de vigilância de doenças notificáveis de 2024: Também designados por “dados de notificação”, estes são dados de vigilância de cinco doenças notificáveis comunicadas pelas clínicas do Feveria: dengue, malária, cólera, febre tifoide e febre amarela. Trata-se de casos suspeitos, baseados nos sintomas dos pacientes. Os médicos introduzem cada notificação num sistema em linha todos os dias da semana.\n2024 dados de resultados de testes laboratoriais: Estes dados provêm de resultados de análises laboratoriais de três grandes laboratórios de Feveria. Estes resultados referem-se a amostras colhidas dos casos suspeitos de doenças notificáveis mencionados acima.\n\nVamos lá!\n\n\n\nNeste estudo de caso, você vai:\n\nUsar funções-chave do R para limpar os dados, reorganizar os conjuntos de dados, relacionar fontes de dados e criar novas colunas usando condições lógicas, a fim de preparar os dados para análise.\nRealizar inspecções de dados e verificações da qualidade dos dados em várias fases do projeto e compreender a sua importância para uma análise confiável.\nRealizar análises descritivas básicas para comparar as tendências das doenças entre diferentes fontes de dados, antes e depois do linkage.\nInterpretar as diferenças nos resultados entre as fontes de dados e compreender como elas refletem a estrutura e o desenho do sistema de vigilância como um todo.\n\n\n\n\n\n\nComece por estabelecer um fluxo de trabalho reproduzível e bem organizado. Este facilitará a repetição da sua análise sempre que necessário.\nTarefas:\n\nConfigurar um projeto RStudio\nConfigurar subpastas claras onde o seu código, dados e resultados serão colocados\nCrie um script R, ou um arquivo R Markdown, se preferir. Certifique-se de que que o objetivo do script, a data e o autor estão escritos como comentários no topo.\nExtra: Certifique-se de que a sua linguagem de trabalho no RStudio é apropriada (por exemplo, inglês para este exercício)\n\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\n\nCrie uma pasta para onde irá todo o trabalho deste estudo de caso. Por exemplo, crie a pasta ‘multidoencas_lab’ no ambiente de trabalho do seu computador. Crie o seu projeto RStudio para ser baseado nesta pasta.\nSugerimos que crie as seguintes subpastas: scripts (para os códigos), data (para os seus dados), e outputs (para os resultados da análise).\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nCrie uma pasta (por exemplo, ‘multidoencas_lab’ no seu ambiente de trabalho) para o seu trabalho. Para criar um projeto Rstudio na sua nova pasta, clique em New Project… no canto superior esquerdo do seu R Studio e, em seguida Existing Directory e, em seguida Browse para selecionar a sua nova pasta. Para mais informações, consulte a secção Projetos R do Manual de R para Epidemiologistas\nInicie um novo script R clicando em New File… no canto superior esquerdo do seu R Studio e, em seguida R Script. Salve-o imediatamente no local apropriado, por exemplo, em uma subpasta ‘scripts’ dentro da pasta que contém seu projeto RStudio.\nNo topo do seu novo script R, escreva algumas informações essenciais como o seu nome, o objetivo do script e a data.\nO locale do R determina o idioma e as definições regionais utilizadas para o coisas como formatos de data e traduções. Se a sua localidade for diferente do idioma que pretende para o seu relatório (por exemplo, uma localidade francesa vs. uma localidade em inglês), pode alterá-la para inglês executando Sys.setlocale(\"LC_ALL\", \"English\"). Inclua isto no seu script se necessário, ou ignore-o se a sua localidade for normalmente apropriada. Isto é explicado em mais detalhes na seção Guia de instruções.\n\n\n\n\n\n\nA seguir, no seu script R, você precisa instalar e carregar os pacotes R necessários. Isto garante que as funções necessárias estarão disponíveis para sua análise.\nSão necessários os seguintes pacotes: {rio} (para importação de dados),{skimr} (para explroar os dados), {janitor} (para limpeza de dados), {lubridate} (para limpeza de datas), {epikit} (para tarefas relacionadas com epidemiologia), {gtsummary} (para estatísticas resumidas/testes e regressão), {apyramid} (para pirâmides etárias), {flextable} (para tabelas prontas para apresentação), {naniar} (para avaliar dados faltantes), e {tidyverse} (para tarefas gerais de manipulação de dados). Também vai precisar do {remotes} para baixar os dados - o que explicaremos na seção de download.\nAo começar, seu colega de confiança te cutuca e sussurra: “Ouvi dizer que uma ótima forma de gerenciar seus pacotes é com o pacote {pacman}”.\nAgora é com você!\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUtilize a função p_load() do pacote pacman para esta tarefa. Você fornece uma lista de pacotes que deseja utilizar. A função executará dois passos por pacote: 1) Verificar se o pacote está instalado no seu computador, e instalá-lo se necessário, depois 2) Carregar o pacote para que ele possa ser usado durante esta sessão do R.\nSe ainda não tem pacman instalado, será necessário instalar ele da “maneira tradicional”, com install.packages().\nNote que a ordem dos pacotes na sua função p_load pode ser importante. Se dois pacotes tiverem os mesmos nomes de função (por exemplo select() no pacote MASS e select() na tidyverse, que fazem diferentes coisas), então o R utilizará a função do pacote mais recentemente carregado. Para dar prioridade às funções do tidyverse, que são normalmente utilizadas para manipulação e visualização de dados, carregue sempre tidyverse por último.\n\n# Garante que o pacote \"pacman\" está instalado\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\")\n}\n\n# Instala (se necessário) a partir do CRAN e carrega os pacotes a serem usados\npacman::p_load(\n  rio,        # importar dados\n  skimr,      # obter visão geral dos dados\n  janitor,    # limpeza de dados e criação de tabelas\n  lubridate,  # trabalhar com datas\n  epikit,     # criar categorias de idade\n  gtsummary,  # estatísticas resumidas, testes e regressões\n  apyramid,   # plotar pirâmides etárias\n  flextable,  # tabelas prontas para apresentação\n  naniar,     # avaliar dados ausentes\n  remotes,    # usado para instalar pacotes para baixar dados\n  tidyverse   # gestão de dados e visualização\n)\n\n\n\n\n\n\n\n\n\n\nO seu escritório fornece-lhe dois arquivos para a sua análise, ambos com dados relativos a 2024 e atualizados a partir de 15 de janeiro de 2025:\n\nUm conjunto de dados no nível de notificação de doenças (“notificacoes_multidoencas.xlsx”) com informações de casos de 5 centros de saúde.\nUm conjunto de dados a nível de exames laboratoriais (“testes_multidoencas.csv”) apresentado por três laboratórios que efetuam exames para os 5 centros de saúde.\n\nPara este estudo de caso, você pode baixar os dados através do repositório de dados muito útil do Applied Epi, que pode ser acessado usando o pacote {appliedepidata}.\nSiga estes passos:\n\nInstale o pacote {appliedepidata} do GitHub usando a função install_github() do pacote {remotes} (que você instalou anteriormente).\n\n\n# Use a função install_github do pacote remotes para instalar o appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nSalve os dois conjuntos de dados numa pasta específica utilizando a função save_data() do pacote {appliedepidata}. Execute o código abaixo. O exemplo abaixo salva os dados em uma subpasta data dentro do projeto do RStudio. Observe que, se você não especificar um local no argumento path da função, uma janela será exibida pedindo para selecionar manualmente uma pasta.\n\n\n# Salva os dois arquivos de dados usando a função save_data() do pacote appliedepidata\nappliedepidata::save_data(\"testes_multidoencas\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"notificacoes_multidoencas\",\n                          path = \"data\")\n\n\n\n\nÓtimo! Obrigado ao escritório do país e à Applied Epi! Agora é hora de importar os dados dessa pasta para o RStudio, para que você possa analisá-los.\n\n\nIdealmente, utilizará a mesma função para importar ambos os conjuntos de dados, apesar de uma ser um arquivo .csv e o outro um arquivo .xlsx. Nota: daqui para a frente, diremos simplesmente “ambiente” quando nos referirmos ao painel ambiente (Environment) no R Studio.\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\nUse a função import do pacote {rio} que consegue reconhecer e importar diferentes tipos de arquivos. Ela substitui funções de importação específicas para cada tipo de arquivo, como read.csv() do {base} para arquivos .csv e read_excel() do {readxl} para importar arquivos .xlsx.\nSe achar que precisa de saber mais sobre funções de importação, leia o capítulo Importar e exportar do Manual de R para Epidemiologistas\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAbaixo usamos a função import para carregar os dois arquivos. Note que estamos atribuindo os dados importados a dois objetos: um chamado dados_notif_bruto e outro chamado dados_lab_bruto. Adicionamos o sufixo ‘bruto’ para diferenciar esses dados das versões limpas que criaremos posteriormente.\n\n# Importar dados\n\n# Dados de notificação\ndados_notif_bruto &lt;- import(\"data/notificacoes_multidoencas.xlsx\")\n\n# Dados laboratoriais\ndados_lab_bruto &lt;- import(\"data/testes_multidoencas.csv\")\n\n\n\n\n\n\n\n\n\nOs dados foram importados e agora é hora de ver que história eles contam. Faça uma análise inicial dos dois data frames brutos para verificar seu conteúdo e qualidade.\n\n\n\n\nUse as funções skim() do pacote {skimr}, names(), ncol() e nrow() para inspecionar seu conjunto de dados.\nA função skim() fornece muitas informações sobre a estrutura e o conteúdo dos dados, enquanto names() mostra os diferentes nomes das colunas. As funções ncol() e nrow() contam, respectivamente, o número de colunas e linhas do conjunto de dados. Você sabe o que colocar dentro dos parênteses?\nO jeito mais fácil, no entanto, é olhar diretamente o ambiente do RStudio.\nLembre-se: o objeto no seu ambiente referente às notificações se chama dados_notif_bruto.\nClique na caixa de solução abaixo das perguntas se precisar de ajuda.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuantas colunas existem nos dados de notificações?\n\n 10 11 12 13\n\nQuais dessas colunas NÃO estão nos dados?\n\n Data de início dos sintomas Data comunicada pela unidade de saúde/comunidade Data do Resultado Data do teste Data de nascimento\n\nQual é o nome da coluna nos dados de notificação que identifica cada notificação?\n\n ID notificacao ID do teste Codigo da unidade de saude Combinação de ID notificacao e Sexo\n\nQuantas linhas existem nos dados de notificação?\n\n 987 1314 950 778\n\nQue tipo de informação você NÃO consegue ver nos dados de notificação?\n\n Resultados de exames laboratoriais Distrito de residência Data de nascimento e Sexo Unidade de saúde em que o caso foi diagnosticado Desfecho\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUse a função skim() do pacote {skimr} para ver um resumo de todo o data frame, e View() para visualizar diretamente o data frame completo:\n\nskim(dados_notif_bruto)\n\nOu você pode usar names() para exibir apenas os nomes das colunas. Com skim() ou names() você poderá ver os tipos de informação, incluindo: a unidade de saúde do caso, data de nascimento, sexo, um indicador de gravidez, distrito de residência, data de início dos sintomas, data comunicada pela clínica e informações sobre o desfecho.\nTambém existe um ID notificacao, que parece ser um identificador único para cada caso, mas é recomendável verificar duplicatas antes de ter certeza.\nObserve que NÃO há resultados de testes nesses dados, pois essas notificações são de clínicas que diagnosticam doenças de notificação compulsória com base em definições clínicas de caso.\n\nnames(dados_notif_bruto)\n\n [1] \"Nome da unidade organizacional\"                  \n [2] \"Codigo da unidade de saude\"                      \n [3] \"ID notificacao\"                                  \n [4] \"Data de nascimento\"                              \n [5] \"Sexo\"                                            \n [6] \"Gestante\"                                        \n [7] \"Distrito de residencia\"                          \n [8] \"Doenca notificada\"                               \n [9] \"Data de inicio dos sintomas\"                     \n[10] \"Data comunicada pela unidade de saude/comunidade\"\n[11] \"Resultado\"                                       \n[12] \"Data do resultado\"                               \n\n\nUse ncol() e nrow() para exibir o número de colunas e linhas, assim:\n\nncol(dados_notif_bruto)\nnrow(dados_notif_bruto)\n\nIsso exibirá o número de colunas e linhas no console.\n\n\n[1] 12\n\n\n[1] 987\n\n\nDe outro modo, ao olhar para o ambiente, você pode ver que o número de observações (que é o mesmo que o número de linhas) e o número de colunas estão listados ao lado do nome do data frame.\n\n\n\n\n\n\nUse a função skim() do pacote {skimr} ou class() para inspecionar as classes das colunas.\nVocê se lembra de como especificar a coluna de interesse dentro da função class()?\nComo alternativa, você pode simplesmente olhar para o ambiente.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuantas colunas do data frame de notificações são reconhecidas pelo R como colunas de data?\n\n 0 2 4\n\nQual é a classe da maioria das colunas no data frame bruto de notificações?\n\n character numeric factor\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nVocê pode usar a função class() como no exemplo abaixo. O $ é um operador usado para selecionar uma coluna específica do data frame dados_notif_bruto.\nObserve que os acentos graves (`) são usados em torno de Data de nascimento porque o nome da coluna contém espaços.\n\nclass(dados_notif_bruto$`Data de nascimento`)\n\nPara verificar a classe pelo ambiente, clique na seta azul ao lado do nome do data frame.\nOs nomes das colunas aparecerão, com a classe ao lado (por exemplo, aparece “chr” para indicar que é do tipo character).\nVocê pode ver que nenhuma das colunas que deveriam ser datas é reconhecida como tal.\nEm vez disso, elas são reconhecidas como valores do tipo character.\n\n\n\n\n\n\nUse a função tabyl() para inspecionar os valores dentro de colunas categóricas, especificando o objeto do data frame no primeiro argumento e o nome da coluna no segundo argumento.\nPor exemplo, este código tabula os valores da coluna Sexo. A saída mostra que “masculino” e “feminino” estão escritos de forma inconsistente nos dados. Essa coluna precisará de limpeza adicional antes da análise.\n\ntabyl(dados_notif_bruto, Sexo)\n\n      Sexo   n    percent valid_percent\n         F  47 0.04761905    0.05452436\n  FEMININO 146 0.14792300    0.16937355\n         M  40 0.04052685    0.04640371\n MASCULINO 172 0.17426545    0.19953596\n         f 154 0.15602837    0.17865429\n  feminino  98 0.09929078    0.11368910\n         m 119 0.12056738    0.13805104\n masculino  86 0.08713273    0.09976798\n      &lt;NA&gt; 125 0.12664640            NA\n\n\nPara inspecionar dados ausentes, você pode usar a função miss_var_summary() do pacote {naniar}:\n\nmiss_var_summary(dados_notif_bruto)\n\n# A tibble: 12 × 3\n   variable                                         n_miss pct_miss\n   &lt;chr&gt;                                             &lt;int&gt;    &lt;num&gt;\n 1 Data de inicio dos sintomas                         691     70.0\n 2 Gestante                                            510     51.7\n 3 Resultado                                           197     20.0\n 4 Data do resultado                                   197     20.0\n 5 Data de nascimento                                  168     17.0\n 6 Sexo                                                125     12.7\n 7 Nome da unidade organizacional                        0      0  \n 8 Codigo da unidade de saude                            0      0  \n 9 ID notificacao                                        0      0  \n10 Distrito de residencia                                0      0  \n11 Doenca notificada                                     0      0  \n12 Data comunicada pela unidade de saude/comunidade      0      0  \n\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nOs valores na coluna Distrito de residência estão padronizados?\n\n Não - precisam ser limpas Estão padronizadas e prontas para análise\n\nOs valores na coluna Doença notificada estão padronizados?\n\n Não - precisam ser limpas Estão padronizadas e prontas para análise\n\nO que o R reconhece como valor ausente?\n\n Ou nenhum valor, ou apenas um espaço, ou apenas um ponto Nenhum valor em uma célula, representado por NA As palavras Desconhecido e Incerto\n\nCom base na quantidade de valores ausentes, a coluna Data de início dos sintomas é útil?\n\n Sim, o índice de ausentes é baixo, então esta coluna é útil Minimamente, pois o índice de ausentes é muito alto\n\nPor que algumas colunas nos dados de notificação podem ter diferentes grafias e categorias não padronizadas?\n\n Um robô embaralha os dados para que fiquem menos identificáveis Cada clínica pode usar softwares configurados de forma ligeiramente diferente ou permitir entradas em texto livre, gerando variações na escrita O software do sistema de vigilância usado pelas unidades clínicas possui muitos erros\n\nPor que algumas colunas nos dados de notificação podem apresentar grande quantidade de valores ausentes?\n\n O clínico não faz a pergunta ao paciente durante a consulta O paciente pode não saber ou não querer informar a resposta O clínico pode não ter tempo de priorizar o preenchimento desse campo, mesmo sabendo a informação Todas as alternativas acima, e muitos outros motivos\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUse a função tabyl() para tabular os valores da coluna Distrito de residencia.\nNovamente, o primeiro argumento é o nome do objeto do data frame e o segundo argumento é o nome da coluna.\n\ntabyl(dados_notif_bruto, `Distrito de residencia`)\n\n Distrito de residencia   n    percent\n              F Central  32 0.03242148\n              FEVERIA C  23 0.02330294\n        FEVERIA CENTRAL  85 0.08611955\n              Feveria C  24 0.02431611\n        Feveria Central  12 0.01215805\n                 KASARA  64 0.06484296\n                    KSR  17 0.01722391\n                 Kasara 109 0.11043566\n               L MINARA  50 0.05065856\n               L Minara 193 0.19554205\n            LAGO MINARA 185 0.18743668\n            Lago Minara  68 0.06889564\n               Lakeside 125 0.12664640\n\n\nVocê pode ver que cada uma das três localidades (Feveria Central, Lago Minara e Kasara) está escrita de maneiras diferentes e com capitalização diferente. Será necessário corrigir isso se quisermos analisar a distribuição geográfica das doenças de notificação compulsória.\nDe forma semelhante, use a função tabyl() para tabular os valores da coluna Doença notificada.\nVocê pode ver que os nomes estão escritos de forma adequada e consistente, permitindo visualizar a distribuição de linhas por doença sem necessidade de limpeza adicional.\n\ntabyl(dados_notif_bruto, `Doenca notificada`)\n\n Doenca notificada   n    percent\n            colera  46 0.04660588\n            dengue 273 0.27659574\n     febre amarela 100 0.10131712\n     febre tifoide  35 0.03546099\n           malaria 533 0.54002026\n\n\nUma forma diferente de verificar dados ausentes é tabular o resultado da função is.na(). No exemplo abaixo, a função is.na() avalia cada célula da coluna Data de início dos sintomas, retornando TRUE para as ausentes e FALSE para as presentes.\nExecutar tabyl() sobre essa saída TRUE/FALSE fornece rapidamente a contagem e o percentual de valores ausentes e não ausentes nessa coluna. Lembre-se: valores como um espaço ou as palavras “Desconhecido” ou “Ausente” não serão reconhecidos pelo R como ausentes. O R reconhece apenas espaços verdadeiramente em branco como ausentes, representados por NA.\nPara a coluna Data de início dos sintomas, você pode ver que 70% dos casos estão sem essa informação, sugerindo que essa coluna não seria particularmente útil para analisar tendências de doenças ao longo do tempo.\n\ntabyl(is.na(dados_notif_bruto$`Data de inicio dos sintomas`))\n\n is.na(dados_notif_bruto$`Data de inicio dos sintomas`)   n   percent\n                                                  FALSE 296 0.2998987\n                                                   TRUE 691 0.7001013\n\n\nDados ausentes ou não padronizados podem ocorrer por diversos motivos, incluindo o design da ferramenta de coleta de dados (por exemplo, se as perguntas são obrigatórias ou permitem texto livre versus listas suspensas), os processos e padrões estabelecidos (como quais campos a equipe é instruída a priorizar) e fatores contextuais (como se a equipe dispõe de tempo suficiente para coletar a informação) — entre muitos outros.\n\n\n\n\n\n\n\n\n\nDa mesma forma como acontece com os dados de notificação, utilize as funções skim(), ncol(), e nrow() ou verifique o objeto no ambiente para inspecionar os dados laboratoriais.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQual data frame tem mais colunas - os dados de notificação ou os dados laboratoriais?\n\n Dados laboratoriais Dados de notificação Eles têm o mesmo número de colunas\n\nQual data frame tem mais linhas?\n\n Dados laboratoriais Dados de notificação Eles têm o mesmo número de linhas\n\nInspecione os dados laboratoriais com View(). Por que pode haver mais registros nos dados laboratoriais?\n\n Pode haver vários testes ou alvos por amostra Existem muitos resultados de testes de ensaio nos dados Nem todas as notificações têm resultados de testes ainda\n\nQual destas colunas NÃO está nos dados laboratoriais?\n\n ID notificação ID da amostra Tipo de teste Data de nascimento Resultado do teste\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (experimente primeiro!)\n\n\n\n\n\nAssim como na seção 3.1, você pode usar a função skim() do pacote {skimr} para visualizar todos os dado laboratoriais com os resultados dos testes. Isso também mostrará os diferentes nomes de colunas nos dados, evidenciando que os dados laboratoriais contém apenas informações sobre o teste e não sobre o paciente. No entanto, ele também contém um ID notificação, assim como os dados das notificações.\n\nskim(dados_lab_bruto)\n\nUtilizar ncol() e nrow() para exibir o número de colunas e linhas, assim:\n\nncol(dados_lab_bruto)\nnrow(dados_lab_bruto)\n\nIsto exibirá os números de colunas e linhas no painel console, mostrando que os dados do laboratório têm mais linhas do que os dados da notificação inspecionados anteriormente.\n\n\n[1] 7\n\n\n[1] 1314\n\n\nFrequentemente há mais registros nos dados laboratoriais do que nos dados de notificação. Se você inspecionar os dados com View(dados_lab_bruto) e, em seguida, clicar na seta no topo da coluna id_notificacao para ordená-la alfabeticamente, verá que várias linhas compartilham o mesmo id_notificacao.\nIsso pode acontecer quando múltiplos alvos são testados a partir da mesma amostra (mesmo ID de amostra) ou quando um caso é retestado (resultando em um ID de amostra diferente).\n\nView(dados_lab_bruto)\n\n\n\nnome_laboratorioid_notificacaoid_amostradata_exameexamealvoresultadoHospital Geral de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue NS.1NHospital Geral de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgGNHospital Geral de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgMPHospital Geral de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue NS.1NHospital Geral de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgGNHospital Geral de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgMP\n\n\n\n\n\n\n\n\nComo acima, utilize as funções class(), skim(), ou tabyl(), ou inspecione o objeto direto no ambiente RStudio, para analisar as suas colunas com mais detalhes.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuantas colunas dos dados laboratoriais são reconhecidas pelo R como colunas de data?\n\n 0 1 2\n\nQuantas colunas nos dados laboratoriais possuem dados completos?\n\n 1 3 7 (todas elas!)\n\nQual teste detecta múltiplos alvos (e, portanto, possui múltiplas linhas por amostra)?\n\n Malária Dengue Febre Amarela Cólera Febre Tifoide\n\nQuantos valores possíveis de resultado de teste existem na coluna resultado?\n\n 5 3 4\n\nQual NÃO é um resultado possível para o teste de cultura de fezes que detecta a bactéria V. cholerae?\n\n P P01 P0139 N I\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nOs dados laboratoriais têm uma coluna de data, reconhecida pelo R como uma classe “IDate”. Esta é uma classe de data utilizada pela função import() do pacote {rio} ao importar arquivos csv. Da mesma forma como a classe Data do R base, ela permite ordenar pela data e analisar tendências ao longo do tempo.\n\nclass(dados_lab_bruto$data_exame)\n\n[1] \"IDate\" \"Date\" \n\n\nO uso da função miss_var_summary() do pacote {naniar} demonstra que todas as colunas dos dados laboratoriais estão efetivamente completas. Isto talvez se deva ao fato de os sistemas laboratoriais utilizarem processos automatizados, por isso é muito menos provável que haja erro humano.\n(Ponto importante: Nota-se que, na vida real, os dados laboratoriais provavelmente teriam alguns problemas!)\n\nmiss_var_summary(dados_lab_bruto)\n\n# A tibble: 7 × 3\n  variable         n_miss pct_miss\n  &lt;chr&gt;             &lt;int&gt;    &lt;num&gt;\n1 nome_laboratorio      0        0\n2 id_notificacao        0        0\n3 id_amostra            0        0\n4 data_exame            0        0\n5 exame                 0        0\n6 alvo                  0        0\n7 resultado             0        0\n\n\nPara ver quantos alvos são detectados por cada tipo de exame, faça uma tabulação cruzada das colunas exame e alvo com tabyl(). Escreva os nomes das colunas na função como dois argumentos separados. O resultado mostra que cada exame está claramente alinhado com um ou mais alvos, e apenas o teste da dengue detecta mais do que um alvo (IgG, IgM e NS.1).\nDica: Experimente alterar a ordem dos nomes das colunas na função para ver o impacto na tabela.\n\ntabyl(dados_lab_bruto, alvo, exame)\n\n                 alvo Cultura de fezes Dengue NS1/IgG/IgM Hemocultura IgM ELISA\n    Bacteria S. Typhi                0                  0          33         0\n Bacteria V. cholerae               45                  0           0         0\n           Dengue IgG                0                215           0         0\n           Dengue IgM                0                215           0         0\n          Dengue NS.1                0                215           0         0\n    Febre Amarela IgM                0                  0           0        88\n           Plasmodium                0                  0           0         0\n Microscopia de sangue total\n                           0\n                           0\n                           0\n                           0\n                           0\n                           0\n                         503\n\n\nFinalmente, inspecione os diferentes valores dos resultados do teste na coluna resultado usando tabyl(). Pode ver que existem seis resultados possíveis, incluindo N para negativo, P para positivo e I para indeterminado. A cólera, especificamente, não apresenta P, mas pode apresentar P01 e P0139, o que, neste caso, significa ser positivo para os serogrupos O1 ou O139.\n\ntabyl(dados_lab_bruto, exame, resultado)\n\n                       exame  I   N   P PO1 PO139\n            Cultura de fezes  5   2   0  22    16\n          Dengue NS1/IgG/IgM  0 354 291   0     0\n                 Hemocultura  2  24   7   0     0\n                   IgM ELISA 10  45  33   0     0\n Microscopia de sangue total 56 257 190   0     0\n\n\n\n\n\n\n\n\n\n\nAgora já sabemos que os dados de notificação (dados_notif_bruto) contêm informações sobre casos suspeitos, além de variáveis demográficas básicas (idade, sexo, gravidez, distrito de residência), bem como dados sobre a data de início dos sintomas, a dados de notificação pela unidade de saúde e o desfecho. Algumas dessas colunas precisam ser limpas antes da análise, seja por variações na ortografia de valores categóricos, seja porque algumas datas não foram corretamente reconhecidas como tal.\nA partir deste ponto, você começará a escrever trechos mais longos de código para realizar a limpeza, utilizando várias funções do {dplyr} encadeadas com pipes (que se parecem com isso: |&gt;).\nNOTA SOBRE PIPES Os pipes permitem realizar várias operações em sequência, “encadeando” diferentes funções. O resultado de uma função passa a ser a entrada como primeiro argumento da seguinte.\nCaso queira mais detalhes sobre o uso de pipes, veja a seção do Manual de R para Epidemiologistas.\nNeste exercício será utilizado o pipe nativo do R (|&gt;), que é mais rápido e não exige instalação de pacotes adicionais. Se preferir, você também pode usar o pipe do pacote magrittr (%&gt;%).\n\n\n\n\nDevido a questões de qualidade e armazenamento de dados, a sua equipe recomenda que seja criado um data frame limpo, contendo apenas as seguintes variáveis: identificador único, localização do caso, doença e a data em que a notificação foi registrada no sistema de vigilância.\nEscreva um código em R para produzir um novo data frame limpo chamado dados_notif, aplicando as seguintes tarefas de limpeza:\n\nRenomear as colunas para serem mais legíveis pela máquina (remover espaços e capitalização) usando a função clean_names() do pacote {janitor}.\n\nUsar a função rename() do pacote {dplyr} para que a coluna com a data em que o caso foi notificado seja alterada para o nome mais conciso data_notificacao.\nSelecionar colunas relevantes para análise com a função select() do pacote {dplyr}.\n\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\nComece seu código com o nome do novo data frame, a seta do operador de atribuição e o nome do objeto de dados brutos. Isso indica que o resultado do processamento dos dados brutos será atribuído a um novo objeto chamado dados_notif. .\n\ndados_notif &lt;- dados_notif_bruto\n\nEm seguida, desenvolva este código adicionando funções adicionais, encadeadas com um pipe. Isto permite executar várias operações em uma sequência contínua. Primeiro, utilize clean_names() para padronizar todos os nomes das suas colunas. Essa função substitui automaticamente espaços e caracteres especiais por sublinhados e converte tudo para minúsculas, tornando os nomes mais fáceis de trabalhar. Depois, você pode usar rename() para atribuir um novo nome a uma coluna. Lembre-se de que, ao utilizar rename(), a coluna já possui a versão de seu nome gerada pelo clean_names().\n\ndados_notif &lt;- dados_notif_bruto |&gt; \n  clean_names() |&gt; \n  rename(NOVO_NOME = ANTIGO_NOME) |&gt; \n  select(VAR_NOMES)\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAqui está o código para limpar os nomes das colunas e selecionar as colunas certas para análise:\n\n# Limpeza dos dados\ndados_notif &lt;- dados_notif_bruto |&gt; \n  clean_names() |&gt; \n  rename(data_notificacao =  data_comunicada_pela_unidade_de_saude_comunidade) |&gt; \n  select(id_notificacao, distrito_de_residencia, doenca_notificada, data_notificacao)\n\n\n\n\n\n\n\nA partir da inspeção dos dados, já se sabe que os valores para distritonão estão padronizados.\nAdicione um mutate() para limpar a coluna distrito_de_residencia da seguinte maneira:\n\nNormalizar a capitalização dos valores dessa coluna\nSubstituir a coluna existente distrito_de_residencia existente por uma coluna limpa que contenha apenas estes valores de distrito: “Lago Minara”, “Feveria Central” e “Kasara”.\n\nVeja a dica para saber quais funções utilizar.\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\nTente usar str_to_title() do pacote {stringr} para que a primeira letra de cada palavra seja maiúscula e todas as outras letras sejam minúsculas. Também pode utilizar case_match() para corrigir erros tipográficos específicos.\nUse a funcionalidade de ajuda do RStudio para aprender a utilizar essas funções. Por exemplo, digite ?case_match no console para abrir a página de ajuda e a documentação da função. Nota: case_match() é uma função muito útil para substituir ou corrigir valores, e pode substituir recode().\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nO seu código de limpeza deve agora ter o seguinte aspecto:\n\n# Limpeza dos dados\ndados_notif &lt;- dados_notif_bruto |&gt; \n  clean_names() |&gt; \n  rename(data_notificacao =  data_comunicada_pela_unidade_de_saude_comunidade) |&gt; \n  select(id_notificacao, distrito_de_residencia, doenca_notificada, data_notificacao) |&gt;\n  mutate(distrito_de_residencia = str_to_title(distrito_de_residencia)) |&gt; \n  mutate(distrito_de_residencia = case_match(distrito_de_residencia,\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\"))\n\nTambém pode envolver o str_to_title na função case_match() para um código mais curto, como se segue:\n\n# Limpeza dos dados\ndados_notif &lt;- dados_notif_bruto |&gt; \n  clean_names() |&gt; \n  rename(data_notificacao =  data_comunicada_pela_unidade_de_saude_comunidade) |&gt; \n  select(id_notificacao, distrito_de_residencia, doenca_notificada, data_notificacao) |&gt;\n  mutate(distrito_de_residencia = case_match(str_to_title(distrito_de_residencia),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\"))\n\n\n\n\n\n\n\nA coluna data_notificacao precisa ser transformada para que seja reconhecida como uma data no R. Isso permitirá analisar tendências ao longo do tempo, incluindo semanas e meses.\nReveja os valores da coluna data_notificacao. Em seguida, adicione uma linha ao seu código de limpeza para converter data_notificacao em uma classe de data.\nConhecer a estrutura dos dados permitirá utilizar a função correta para a conversão.\nRecomendamos o uso de funções do pacote {lubridate}, como ymd() (para datas no formato ano-mês-dia), mdy() (para datas no formato mês-dia-ano) ou dmy() (para datas no formato dia-mês-ano). Essas funções reconhecerão qualquer forma de escrever a data, desde que a ordem esteja correta; por exemplo, “21 de agosto de 2025” e “21-08-2024” seriam reconhecidas por dmy().\n\n\n\n\n\n\nPerguntas\n\n\n\n\nComo as datas estão atualmente formatadas?\n\n dia-mês-ano ano-mês-dia mês-dia-ano ano-dia-mês\n\nQual função mutate() deve ser usada para converter a coluna data_notificacao para a classe de data?\n\n mutate(data_notificacao = ymd(data_notificacao)) mutate(data_notificacao = dmy(data_notificacao)) mutate(data_notificacao = mdy(data_notificacao))\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUtilize a função head() para ver as primeiras seis linhas dos dados da coluna data_notificacao. É possível ver que elas são escritas no formato: ano primeiro, depois o mês e depois o dia.\n\nhead(dados_notif$data_notificacao)\n\n[1] \"2024-03-08\" \"2024-03-11\" \"2024-03-11\" \"2024-03-18\" \"2024-03-14\"\n[6] \"2024-03-12\"\n\n\nÉ possível utilizar a função ymd() dentro de mutate() para converter a coluna data_notificacao para a classe de data. Você pode verificar se a conversão foi correta executando class() em seguida.\nO seu código de limpeza deve agora ter o seguinte aspecto:\n\n# Limpeza dos dados\ndados_notif &lt;- dados_notif_bruto |&gt; \n  clean_names() |&gt; \n  rename(data_notificacao =  data_comunicada_pela_unidade_de_saude_comunidade) |&gt; \n  select(id_notificacao, distrito_de_residencia, doenca_notificada, data_notificacao) |&gt;\n  mutate(distrito_de_residencia = case_match(str_to_title(distrito_de_residencia),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\"))|&gt; \n  mutate(data_notificacao = ymd(data_notificacao)) \n\nE pode verificar novamente a classe assim:\n\nclass(dados_notif$data_notificacao)\n\n[1] \"Date\"\n\n\n\n\n\n\n\n\nOs seus colegas dizem-lhe que cada id_notificacao representa um caso suspeito. Agora você pretende criar uma tabela para verificar se id_notificacao está duplicado nas linhas dos seus dados.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nUma linha nos dados de notificação equivale a um caso?\n\n Sim Não\n\nÉ necessário deduplicar seus dados para análise epidemiológica dos casos?\n\n Sim Não\n\n\n\n\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\nHá várias formas de fazer isso, mas tente utilizar a função count() do pacote {dplyr}. Ela cria uma tabela que conta o número de linhas para cada valor único da coluna que você especificar. Em seguida, utilize tabyl() para visualizar a distribuição dessas contagens.\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nPrimeiro, passe os dados de notificação para a função count(), usando id_notificacao como único argumento. Isso cria uma contagem do número de linhas para cada valor único de id_notificacao, apresentada em uma nova coluna chamada n. Por exemplo, neste excerto é possível ver que existe apenas uma linha para cada um desses 6 id_notificacao.\n\ndados_notif |&gt; \n  count(id_notificacao) \n\n\n\n  id_notificacao n\n1         00399b 1\n2         005c85 1\n3         006f52 1\n4         00cbbb 1\n5         01830d 1\n6         019045 1\n\n\nEm seguida, tabule a nova coluna n com a função tabyl(), que mostrará que existe apenas uma linha por id_notificacao único. Isso significa que cada linha equivale a um caso e não é necessária nenhuma deduplicação adicional.\n\ndados_notif |&gt; \n  count(id_notificacao) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 987       1\n\n\n\n\n\n\n\n\n\nVocê pode agora proceder confortavelmente às análises descritivas dos casos, pois os dados estão limpos e cada linha equivale a um caso. Use a função tabyl() para realizar as tarefas seguintes.\n\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQual doença foi mais frequentemente diagnosticada pelas clínicas em Feveria em 2024?\n\n Cólera Malária Dengue Febre Tifoide Febre Amarela\n\nQual doença foi menos frequentemente diagnosticada pelas clínicas em Feveria em 2024?\n\n Cólera Malária Dengue Febre Tifoide Febre Amarela\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUsando a função tabyl() podemos ver que houve 533 casos suspeitos de malária em Feveria em 2024, e apenas 35 casos suspeitos de febre tifoide.\n\ntabyl(dados_notif, doenca_notificada)\n\n doenca_notificada   n    percent\n            colera  46 0.04660588\n            dengue 273 0.27659574\n     febre amarela 100 0.10131712\n     febre tifoide  35 0.03546099\n           malaria 533 0.54002026\n\n\n\n\n\n\n\n\nUtilize tabyl() para fazer uma tabulação cruzada das colunas da doença notificada e do distrito de residência.\nDesenvolva a tabulação adicionando várias funções adorn() do pacote {janitor} para visualizar as distribuições percentuais, como por exemplo adorn_percentages(), adorn_pct_formatting() e adorn_ns().\nDigite o nome da função precedido de ? no console (por exemplo, ?adorn_ns) para acessar as páginas de ajuda relevantes. Você também pode consultar a seção sobre {janitor} no Manual de R para Epidemiologistas para mais explicações sobre as funções adorn_xxx().\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQual distrito reportou o maior número de doenças transmitidas por vetores em 2024 (malária, dengue, febre amarela)?\n\n Lago Minara Feveria Central Kasara\n\nQual distrito reportou o maior número de doenças diarreicas em 2024 (cólera, febre tifoide)?\n\n Lago Minara Feveria Central Kasara\n\nQuais fatores contribuem para o aumento de doenças diarreicas neste distrito específico (selecionado na pergunta anterior)?\n\n Infraestrutura de água e saneamento pouco confiável Superlotação de mosquitos Não sabemos\n\n\n\n\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\nAqui está um código para ajudá-lo a começar. Ele cria tabelas cruzadas entre doenca_notificada e distrito_de_residencia usando tabyl() e, em seguida, aplica adorn_percentages() para converter os números em percentagens com muitas casas decimais. Depois, é necessário passar para adorn_pct_formatting() para formatar as percentagens corretamente, e então usar adorn_ns() para adicionar os números originais entre parênteses.\nNote que as funções adorn_xxx() devem ser aplicadas em uma ordem específica!\n\ntabyl(dados_notif, doenca_notificada, distrito_de_residencia) |&gt;\n  adorn_percentages()\n\nPara entender os fatores que contribuem para o aumento de casos de diarreia, volte ao início do estudo de caso, quando os distritos foram apresentados pela primeira vez.\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUsando a função tabyl() podemos ver que a maioria dos casos suspeitos de dengue, malária e febre amarela ocorreu no Lago Minara, a área do lago com maior densidade de mosquitos e, portanto, maior transmissão de doenças por vetores. Por outro lado, cólera e febre tifoide foram predominantemente registradas em Feveria Central, uma zona urbana superlotada com problemas de infraestrutura de água e saneamento, que aumentam o risco de inundações e contaminação da água potável durante o período chuvoso.\n\ntabyl(dados_notif, doenca_notificada, distrito_de_residencia) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n doenca_notificada Feveria Central      Kasara Lago Minara\n            colera      91.3% (42)  8.7%   (4)  0.0%   (0)\n            dengue       9.5% (26) 17.6%  (48) 72.9% (199)\n     febre amarela      11.0% (11) 21.0%  (21) 68.0%  (68)\n     febre tifoide      68.6% (24) 31.4%  (11)  0.0%   (0)\n           malaria      13.7% (73) 19.9% (106) 66.4% (354)\n\n\n\n\n\n\n\n\n\n\nCom base no seu trabalho anterior, na Etapa 3, você verificou que os dados laboratoriais contêm apenas informações sobre os testes e nenhuma informação sobre o paciente. Os dados já estão bastante limpos, então só precisamos padronizar uma coluna. Também queremos processar o data frame do laboratório para que haja uma linha por notificação, permitindo que ele seja corretamente vinculado ao data frame de notificações.\n\n\n\n\nCriar um novo objeto dados_lab. Isto permitirá uma abordagem e análise mais direta bem como facilitará a interpretação dos resultados.\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUtilize case_match() para transformar os diferentes valores originais em “Positivo”, “Negativo” ou “Indeterminado”:\n\ndados_lab &lt;- dados_lab_bruto |&gt; \n  mutate(resultado = case_match(resultado, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positivo\",\n                            \"N\" ~ \"Negativo\",\n                            \"I\" ~ \"Indeterminado\"))\n\nVocê pode então verificar novamente se os novos valores estão corretos, tabulando e comparando os valores no data frame original e no data frame limpo. Certifique-se de que utilizou a letra ‘O’ e não o número ‘0’!\n\ntabyl(dados_lab_bruto, resultado)\n\n resultado   n    percent\n         I  73 0.05555556\n         N 682 0.51902588\n         P 521 0.39649924\n       PO1  22 0.01674277\n     PO139  16 0.01217656\n\n\n\ntabyl(dados_lab, resultado)\n\n     resultado   n    percent\n Indeterminado  73 0.05555556\n      Negativo 682 0.51902588\n      Positivo 559 0.42541857\n\n\n\n\n\n\n\n\n\n\n\nJá sabemos que algumas amostras possuem várias linhas, porque o teste de dengue possui três alvos, gerando uma linha por resultado de alvo.\nAgora, identifique o número de amostras com várias linhas.\nFaça isso da mesma forma que fez com os dados de notificação: use dados_lab para primeiro contar o número de linhas por amostra e, em seguida, crie uma tabela para mostrar a distribuição desses números de linhas. Lembre-se de que cada amostra é identificada por um id_amostra.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuantas amostras (valores únicos de id_amostra) estão sendo repetidos em três linhas?\n\n 200 215 230\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nPrimeiro, passe os dados laboratoriais para a função count(), usando id_amostra como único argumento.\nIsso cria uma tabela que conta o número de linhas por valor único de id_amostra, apresentado em uma nova coluna n.\nPor exemplo, pode-se ver que o id_amostra “000e8eee” possui três linhas, enquanto o id_amostra “001e1878” aparece em apenas uma linha.\n\ndados_lab |&gt; \n  count(id_amostra) \n\n\n\n  id_amostra n\n1   000e8eee 3\n2   001e1878 1\n3   005f39af 1\n4   00b30781 3\n5   00b56d18 1\n6   0110abcd 3\n\n\nEm seguida, tabule a nova coluna n com o tabyl().\n\ndados_lab |&gt; \n  count(id_amostra) |&gt; \n  tabyl(n)\n\n n n_n   percent\n 1 669 0.7567873\n 3 215 0.2432127\n\n\nPode até verificar se isto se aplica apenas ao exame de dengue adicionando a exame ao cálculo. Pode ver que é apenas o teste da dengue que tem 3 linhas por amostra.\n\ndados_lab |&gt; \n  count(exame, id_amostra) |&gt; \n  tabyl(exame, n)\n\n                       exame   1   3\n            Cultura de fezes  45   0\n          Dengue NS1/IgG/IgM   0 215\n                 Hemocultura  33   0\n                   IgM ELISA  88   0\n Microscopia de sangue total 503   0\n\n\n\n\n\n\n\n\nComo você viu na Seção 3.2, o teste de dengue fornece resultados para três alvos diferentes: IgG, IgM e NS1. Os resultados para cada um desses alvos podem ser negativos ou positivos. No entanto, para simplificar e consolidar os dados, deseja-se atribuir um único valor, negativo ou positivo, para cada amostra, indicando se a amostra representa uma infecção ativa.\n\n\nalvoNegativoPositivoDengue IgG110105Dengue IgM105110Dengue NS.113976\n\n\nO seu colega Ben, que trabalha no laboratório, aconselha sobre a limpeza da seguinte forma:\n\nUma amostra pode ser considerada positiva se NS1 ou IgM forem positivos (já que ambos podem indicar uma infecção aguda).\n\nO IgG pode ser ignorado (porque um resultado positivo, na ausência de NS1 ou IgM positivos, indica imunidade de uma infecção passada resolvida).\n\nAgora, você precisa consolidar os resultados dos testes de dengue em uma linha por teste, com um valor de resultado. Utilize filter(), arrange() e slice(), garantindo que qualquer amostra positiva para NS1 ou IgM seja considerada positiva para dengue.\nCrie um novo objeto chamado dados_lab_testes.\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\nTente aplicar o seguinte para consolidar os resultados de acordo com a recomendação do Ben:\n\nRemover resultados de IgG: filtre as linhas em que o alvo é \"IgG\" usando filter() do {dplyr}.\n\nPriorizar resultados positivos de IgM/NS1: agrupe por id_amostra e organize as linhas com arrange() para que qualquer resultado \"P\" (positivo) apareça primeiro.\n\nFiltrar para o status final: mantenha apenas a primeira linha usando slice(1) para obter o resultado positivo ou negativo da amostra.\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (experimente primeiro!)\n\n\n\n\n\nAqui está o código para filtrar os resultados de IgG da dengue e, em seguida, consolidar o resultado do teste dentro de cada grupo de linhas com o mesmo id_amostra, dando prioridade aos resultados positivos.\nÉ necessário especificar desc dentro de arrange(), pois isso faz com que os resultados sejam ordenados em ordem alfabética inversa, colocando \"P\" no topo.\nAlém disso, adicione ungroup() no final para que os novos dados não permaneçam agrupados, o que poderia interferir em análises posteriores.\n\ndados_lab_testes &lt;- dados_lab |&gt; \n  filter(alvo != \"Dengue IgG\") |&gt; \n  group_by(id_amostra) |&gt; \n  arrange(desc(resultado)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\nEm seguida, é possível verificar novamente se o novo objeto dados_lab_testes contém apenas uma linha por teste, utilizando a combinação de count() e tabyl() como feito na Tarefa A.\nEsta tabela mostra que todos os IDs de amostra únicos estão presentes em apenas uma linha cada:\n\ndados_lab_testes |&gt; \n  count(id_amostra) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 884       1\n\n\n\n\n\n\n\n\nEm seguida, verifique o número de testes por ID de notificação nos novos dados consolidados.\nPode-se observar que existem 26 linhas com o mesmo id_notificacao que outra linha, mas apenas entre os casos testados com microscopia de sangue total para malária.\n\ndados_lab_testes |&gt; \n  count(exame, id_notificacao) |&gt; \n  tabyl(exame, n)\n\n                       exame   1  2\n            Cultura de fezes  45  0\n          Dengue NS1/IgG/IgM 215  0\n                 Hemocultura  33  0\n                   IgM ELISA  88  0\n Microscopia de sangue total 451 26\n\n\nInvestiga-se mais detalhadamente analisando um caso de exemplo com id_notificacao “043228”.\nIsso mostra que este caso foi testado duas vezes, com duas amostras diferentes, com uma semana de intervalo. O primeiro resultado foi positivo e o segundo resultado foi negativo.\n\ndados_lab_testes |&gt; \n  filter(id_notificacao == \"043228\")\n\n# A tibble: 2 × 7\n  nome_laboratorio    id_notificacao id_amostra data_exame exame alvo  resultado\n  &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;      &lt;IDate&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;    \n1 Hospital Universit… 043228         27c37cd8   2024-06-18 Micr… Plas… Positivo \n2 Hospital Universit… 043228         d2271be0   2024-06-25 Micr… Plas… Negativo \n\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQual afirmação sobre os dados laboratoriais está correta?\n\n Todos os casos de diferentes doenças são retestados Alguns casos de malária são retestados Todos os casos de malária são retestados\n\nSerá necessário deduplicar os dados laboratoriais para ligar com os dados de notificação?\n\n Sim - precisamos de uma linha representando o resultado do laboratório por notificação Não - os dados já estão suficientemente deduplicados\n\n\n\n\nSe respondeu que precisa deduplicar, está correto!\nDeduplicar os dados para ter uma linha por ID de notificação priorizando os resultados positivos, para que seja possível fazer a vinculação com os dados da notificação.\nPara fazer isso, siga um processo semelhante ao da tarefa B, utilizando a estrutura de dados produzida pela tarefa B:\n\nAgrupar por id_notificacao\nOrdenar pelo valor do resultado do exame, de modo a que os valores que começam por P tenham prioridade na linha superior, seguidos por N (negativo) e depois I (indeterminado).\nEm seguida, mantenha a primeira linha dentro de cada grupo de id_notificacaos, utilizando slice().\nAo fazer isto, crie um novo objeto chamado dados_lab_casos.\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAqui está o código para deduplicar as linhas dentro de cada grupo de linhas com o mesmo id_notificacao dando prioridade aos resultados positivos. Mais uma vez, você precisa especificar desc dentro de arrange(). Isto funciona perfeitamente porque a ordem de prioridade desejada para os resultados — positivos, depois negativos, depois indeterminados — alinha-se com a ordem alfabética inversa (P vem antes de N, que vem antes de I, quando ordenado de forma descendente).\nSe a sua ordem de prioridades fosse mais complexa ou não correspondesse à ordem alfabética (por exemplo, se “indeterminado” precisasse de vir antes de “negativo”), teria de converter a coluna de resultados num fator e explicitamente definir a ordem desejada dos seus níveis. Não se esqueça de desagrupar novamente no final.\n\ndados_lab_casos &lt;- dados_lab_testes |&gt; \n  group_by(id_notificacao) |&gt; \n  arrange(desc(resultado)) |&gt; \n  slice(1) |&gt;\n  ungroup()\n\nVocê pode então verificar novamente se o novo objeto dados_lab_casos tem apenas uma linha por exame, usando a combinação de count() e tabyl() como fez na Tarefa A. Esta tabela lhe mostra que todos os IDs de amostra únicos estão presentes em apenas uma linha cada:\n\ndados_lab_casos |&gt; \n  count(id_notificacao) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 858       1\n\n\n\n\n\n\n\n\n\nAgora temos dois objetos que podemos utilizar para a análise de dados laboratoriais: dados_lab_testes e dados_lab_casos.\n\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQue objeto você deve utilizar para analisar os exames?\n\n dados_lab_testes dados_lab_casos nenhum destes\n\nQuantos exames foram conduzidos para examinar para malária (através da microscopia de sangue total)?\n\n 215 503 88 190\n\nQue porcentagem dos exames para cólera (através da cultura de fezes) foi positiva?\n\n 21% 11% 84% 87%\n\nQuais exames tiveram a maior porcentagem de resultados indeterminados?\n\n IgM ELISA (para detecção de febre amarela) Cultura de fezes (para detecção de cólera) Hemocultura (para detecção de febre tifóide)\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUtilizando tabyl() podemos ver o número de resultados positivos, negativos e indeterminados por exame. Você pode adicionar uma série de funções adorn() para mostrar porcentagens e totais.\n\ntabyl(dados_lab_testes, exame, resultado) |&gt; \n  adorn_totals(where = \"col\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n                       exame Indeterminado    Negativo    Positivo        Total\n            Cultura de fezes    11.1%  (5)  4.4%   (2) 84.4%  (38) 100.0%  (45)\n          Dengue NS1/IgG/IgM     0.0%  (0) 13.5%  (29) 86.5% (186) 100.0% (215)\n                 Hemocultura     6.1%  (2) 72.7%  (24) 21.2%   (7) 100.0%  (33)\n                   IgM ELISA    11.4% (10) 51.1%  (45) 37.5%  (33) 100.0%  (88)\n Microscopia de sangue total    11.1% (56) 51.1% (257) 37.8% (190) 100.0% (503)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQue data frame de dados laboratoriais você deve usar para contar o número de casos supeitos examinados?\n\n dados_lab_bruto dados_lab_casos dados_lab_testes dados_lab\n\nQuantos casos suspeitos foram examinados nos dados laboratoriais de 2024?\n\n 858 1314 884\n\nExistem mais casos suspeitos nos dados de notificação ou nos dados laboratoriais?\n\n dados de notificação Dados laboratoriais\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (experimente primeiro!)\n\n\n\n\n\nVocê pode simplesmente analisar o número de linhas no data frame dados_lab_casos para ver o número de casos suspeitos que foram examinados.\n\nnrow(dados_lab_casos)\n\n[1] 858\n\n\nEste número é inferior ao número de casos suspeitos que estavam nos dados limpos de vigilância de doenças de notificação compulsória (dados_notif) - o que sugere que nem todos os casos suspeitos em 2024 foram examinados quando estes dados estavam disponíveis.\n\nnrow(dados_notif)\n\n[1] 987\n\n\n\n\n\n\n\n\n\n\nAgora que ambas as listas de casos estão limpas e têm uma linha por caso suspeito, você pode vinculá-las para permitir a análise completa solicitada pelo seu chefe.\n\n\n\n\nCriar um novo objeto chamado dados_vinculados, utilizando uma função xxx_join() do {dplyr}. Pretende-se manter todas as notificações, mas adicionar resultados de exames, quando disponíveis, para cada caso suspeito.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQue função traz a abordagem correta se você quiser manter todas as linhas dos seus dados de notificação e trazer os resultados dos dados laboratoriais?\n\n left_join(dados_notif, dados_lab_casos… full_join(dados_notif, dados_lab_casos… right_join(dados_notif, dados_lab_casos…\n\nQue identificador deve ser utilizado para vincular as duas listas de casos?\n\n id_amostra id_notificacao id_amostra e data de notificação id_notificacao e data de notificação\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (experimente primeiro!)\n\n\n\n\n\nLigue os dados utilizando o left_join() com os dados de notificação como data frame principal à esquerda. Isto manterá todas as linhas deste data frame e apenas introduzirá os resultados dos exames nos dados laboratoriais especificados à “direita” da função.\n\ndados_vinculados &lt;- left_join(dados_notif, dados_lab_casos, \n                         by = \"id_notificacao\")\n\nVocê está ligando através da coluna id_notificacao, que está presente, completa e limpa em ambas as listas de casos.\nNota: Você tem sorte de trabalhar com um exemplo de ligação tão simples! Normalmente, seria necessário limpar e verificar a coluna de ID, ou vincular a outras colunas como o nome e a data de nascimento. Em Feveria, os clínicos são fantásticos em atribuir consistentemente IDs de notificação a cada doente, incluindo nos formulários de amostra enviados para o laboratório, e ainda o pessoal do laboratório é igualmente brilhante em registrar o ID de notificação nos seus sistemas de laboratório, para que os resultados possam ser associados ao caso.\n\n\n\n\n\n\nAgora, verifique os seus dados e revise algumas coisas.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuantas linhas tem o seu novo data frame dados_vinculados?\n\n 987 884 858\n\nComo este resultado se compara aos seus dados de notificação originais?\n\n mais linhas que o original o mesmo número de linhas menos linhas\n\nQue termo melhor descreve a vinculação que você acabou de realizar?\n\n muitos-para-um um-para-um muitos-para-muitos\n\nQuantos resultados de laboratório NÃO foram vinculados? (dica: use anti-join())?\n\n 30 19 0\n\nQuão sortudo você foi por sua vinculação de dados ter sido tão bem-sucedida?\n\n O quê? Nem toda vinculação de dados é simples assim?? Bastante! Normalmente alguns registros não têm correspondência.\n\nQuais são razões típicas para os dados laboratoriais não possuírem correspondência entre os dados de notificação?\n\n Existem erros de digitação nas colunas utilizadas para a vinculação, e por isso elas não são reconhecidas como correspondências Os dados laboratoriais podem conter casos adicionais de outras clínicas ou países Os dados laboratoriais podem incluir amostras de exames Notificações podem ter sido acidentalmente perdidas nos dados de notificação apesar da amostra ter sido examinada em laboratório Todas as opções acima\n\nQuantos casos supeitos não possuem um resultado?\n\n 83 100 129\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nVerifique o número de linhas em cada quadro de dados com o comando nrow() ou olhando as informações do objeto no seu ambiente. É possível ver que esta foi simplesmente uma vinculação de um para um, porque cada linha tinha um único id_notificacao, então uma linha nos dados de notificação se vinculou exatamente a uma linha dos dados laboratoriais.\nNúmero de linhas nos dados de notificação\n\nnrow(dados_notif)\n\n[1] 987\n\n\nNúmero de linhas nos dados vinculados\n\nnrow(dados_vinculados)\n\n[1] 987\n\n\nPara verificar se houve algum resultado de laboratório que não estava ligado aos dados de notificação, é possível usar anti_join(). Desta vez, o objeto dados_lab_casos está à esquerda, pois a função avalia quantas linhas do data frame da esquerda não foram encontradas no data frame da direita, ao realizar a correspondência por id_notificacao. Aqui não é necessário gerar um novo data frame, você pode simplesmente passar, através de um pipe, o resultado para nrow() para contar o número de linhas. A saída é 0, o que mostra que não houve resultados sem vínculo - incrível!\n\nanti_join(dados_lab_casos, dados_notif, \n          by = \"id_notificacao\") |&gt; nrow()\n\n[1] 0\n\n\nFinalmente, para verificar o número de notificações sem um resultado, você pode efetuar um anti_join ao colocar dados_notif primeiro:\n\nanti_join(dados_notif, dados_lab_casos, \n          by = \"id_notificacao\") |&gt; nrow()\n\n[1] 129\n\n\nOu, pode simplesmente tabular o número de valores em falta na coluna resultado em dados_vinculados (já que a coluna resultado provém dos dados laboratoriais).\n\ntabyl(is.na(dados_vinculados$resultado)) \n\n is.na(dados_vinculados$resultado)   n   percent\n                             FALSE 858 0.8693009\n                              TRUE 129 0.1306991\n\n\nAmbas as abordagens mostram que 129 casos suspeitos não têm um resultado de exame laboratorial.\n\n\n\n\n\n\n\n\n\nUtilize mutate() para criar uma nova coluna categoria_caso atualizando o rótulo dos casos suspeitos de acordo com o seu resultado laboratorial. As categorias devem ser as seguintes:\n\nSe o resultado for positivo: Confirmado\nSe o resultado for negativo: Descartado\nSe o resultado for indeterminado ou inexistente: Suspeito\n\nIsto significa que todos os casos nos dados de notificação são inicialmente suspeitos quando notificados, e permanecem suspeitos se não houver um resultado conclusivo no exame.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQual é a função mais apropriada para criar essa nova coluna?\n\n case_when() if_else() case_match()\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nVocê deve utilizar o case_when() para criar a nova coluna. Esta função é ideal para aplicar múltiplas condições lógicas para criar múltiplos valores, enquanto que case_match() é melhor para substituir valores específicos, e if_else() é melhor se houver apenas dois valores possíveis.\n\ndados_vinculados &lt;- dados_vinculados |&gt; \n  mutate(categoria_caso = case_when(resultado==\"Positivo\" ~ \"Confirmado\",\n                                   resultado==\"Negativo\" ~ \"Descartado\",\n                                   resultado==\"Indeterminado\" | is.na(resultado) ~ \"Suspeito\"))\n\n\n\n\n\n\n\n\n\n\nUtilizar tabyl() em geral, e também a tabulação cruzada por doença para responder às perguntas abaixo.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuantos casos nos dados de notificação vinculados não possuem um resultado positivo ou negativo?\n\n 202 347 250\n\nQue porcentagem dos casos nos dados de notificação POSSUEM um resultado positivo ou negativo?\n\n 60.1% 79.5% 92.2%\n\nPor que existem mais casos suspeitos remanescentes do que notificações sem vinculação?\n\n Casos suspeitos incluem notificações sem um resulado laboratorial e com um resultado indeterminado Existem casos suspeitos adicionais sendo trazidos dos laboratórios Existe algum problema com os dados\n\nQuais doenças possuíram a maior porcentagem de casos que permaneceram suspeitos após a vinculação?\n\n Cólera Malária Dengue Febre amarela\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nMais uma vez, você pode utilizar tabyl() para ver a distribuição das categorias de casos pelas notificações. O número total de casos suspeitos, ou seja, os que não têm qualquer resultado laboratorial ou têm um resultado indeterminado, é de 202. Isto significa que 785 casos, ou seja, 79,5%, tiveram um resultado laboratorial definitivo.\n\ntabyl(dados_vinculados, categoria_caso) \n\n categoria_caso   n   percent\n     Confirmado 438 0.4437690\n     Descartado 347 0.3515704\n       Suspeito 202 0.2046606\n\n\nPode também fazer uma tabela cruzada dos resultados originais (indeterminado/negativo/positivo) na coluna resultado com os novos resultados categoria_caso, primeiro para verificar se a sua lógica funcionou, e para ver como os valores originais se relacionam com os valores da nova coluna. Isto mostra que, além das 129 notificações que não foram vinculadas (com NA na coluna resultado), 73 tiveram resultados indeterminados, e assim foram classificadas como casos suspeitos.\n\ntabyl(dados_vinculados, categoria_caso, resultado) \n\n categoria_caso Indeterminado Negativo Positivo NA_\n     Confirmado             0        0      438   0\n     Descartado             0      347        0   0\n       Suspeito            73        0        0 129\n\n\nFinalmente, você pode também fazer uma tabela cruzada com o nome da doença para ver as categorias de casos por doença. Adicione adorn_xxx() para formatar as porcentagens. A tabela mostra que 22% dos casos de febre amarela permaneceram suspeitos, e que essa porcentagem foi a mais elevada em comparação com as outras doenças.\n\ntabyl(dados_vinculados, doenca_notificada, categoria_caso) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n doenca_notificada  Confirmado  Descartado    Suspeito        Total\n            colera 82.6%  (38)  4.3%   (2) 13.0%   (6) 100.0%  (46)\n            dengue 68.1% (186) 10.6%  (29) 21.2%  (58) 100.0% (273)\n     febre amarela 33.0%  (33) 45.0%  (45) 22.0%  (22) 100.0% (100)\n     febre tifoide 20.0%   (7) 68.6%  (24) 11.4%   (4) 100.0%  (35)\n           malaria 32.6% (174) 46.3% (247) 21.0% (112) 100.0% (533)\n             Total 44.4% (438) 35.2% (347) 20.5% (202) 100.0% (987)\n\n\n\n\n\n\n\n\nUtilize tabyl() mais uma vez para esta tarefa, analisando os resultados por doença. Pense no denominador correto!\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQue porcentagem de casos suspeitos repotados em em 2024 eram casos verdadeiros, de acordo com os resultados dos exames?\n\n 44% 56% 59%\n\nQue porcentagem dos casos suspeitos de malária eram realmente malária?\n\n 86% 41% 23%\n\nQue porcentagem de casos suspeitos de dengue eram realmente dengue?\n\n 87% 41% 23%\n\n\n\n\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\nDividir o número de casos confirmados (ou seja, aqueles com um resultado positivo) pelo número de casos confirmados e descartados (ou seja, aqueles com um resultado positivo ou negativo). Obtém-se assim uma taxa de positivos, que se aproxima da porcentagem de casos suspeitos que eram efetivamente casos. Os resultados indeterminados são excluídos porque não fornecem um resultado claro e distorceriam a taxa de positivos.\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nFiltre os casos suspeitos e, em seguida, faça uma tabela cruzada para ver a porcentagem de casos originalmente suspeitos que foram confirmados ou descartados, entre aqueles com resultados de exame válidos.\nUma vez que existe uma linha de totais, pode ver-se que 56% dos casos suspeitos em geral foram confirmados, entre os que tinham um resultado válido. Também se pode ver que 41% e 87% dos casos de malária e dengue, respetivamente, foram confirmados.\n\ndados_vinculados |&gt; \n  filter(categoria_caso != \"Suspeito\") |&gt; \n  tabyl(doenca_notificada, categoria_caso) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n doenca_notificada  Confirmado  Descartado        Total\n            colera 95.0%  (38)  5.0%   (2) 100.0%  (40)\n            dengue 86.5% (186) 13.5%  (29) 100.0% (215)\n     febre amarela 42.3%  (33) 57.7%  (45) 100.0%  (78)\n     febre tifoide 22.6%   (7) 77.4%  (24) 100.0%  (31)\n           malaria 41.3% (174) 58.7% (247) 100.0% (421)\n             Total 55.8% (438) 44.2% (347) 100.0% (785)\n\n\n\n\n\n\n\n\n\nTarefa A: Criar uma nova lista de casos chamada dados_vinculados_confirmados.\nEsta é a que você utilizará nos relatórios oficiais de vigilância.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nPor que estamos optando por relatar apenas casos confirmados em nossos dados de vigilância?\n\n Relatar casos confirmados pode ser mais confiável e preciso quando a porcentagem de resultados positivos é baixa e os exames laboratoriais são rotineiros, ajudando assim a evitar a superestimação da carga da doença Relatar casos confirmados é mais lento, o que nos dá mais tempo para ter certeza do que estamos relatando Porque queremos esconder o número real de casos\n\nQual função é importante para criar a nova lista de linhas (linelist)?\n\n filter() arrange() mutate()\n\nQuantas linhas há neste novo data frame?\n\n 389 438 858\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nA sua unidade de vigilância quer concentrar-se em notificar os casos confirmados. Isto deve-se ao fato de os exames laboratoriais serem rotina em Feveria, tendo em vista que a notificação de casos suspeitos seria desnecessariamente imprecisa, com uma elevada porcentagem de casos suspeitos sendo descartados.\nA decisão de publicar casos suspeitos pode ser diferente em outros contextos. Por exemplo, se a taxa de positivos for elevada (a maioria dos casos são casos confirmados se examinados) e os exames em si não forem comuns, ou se os exames demorarem muito tempo e resultarem numa notificação tardia, isso sugeriria que as tendências de casos suspeitos são suficientemente precisas e também mais oportunas do que esperar pela confirmação laboratorial.\nCriar a nova lista de casos com a função filter():\ndados_vinculados_confirmados &lt;- dados_vinculados |&gt; \n  filter(categoria_caso==\"Confirmado\")\nE verifique o número de linhas consultando as informações no seu ambiente ou com nrow():\nnrow(dados_vinculados_confirmados)\n[1] 438\n\n\n\n\n\n\n\nAgora que você tem sua lista de casos confirmados de doenças de notificação compulsória registrados em Feveria em 2024, você está pronto para conduzir a parte final da sua análise de vigilância! Especificamente, isso significa resumir as cinco doenças de notificação compulsória por área geográfica e tempo.\nDica: Normalmente, a análise de vigilância incluiria também uma análise por pessoa. Você pode expandir este estudo de caso, analisando também por variáveis demográficas.\n\n\n\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQual doença de notificação compulsória foi mais comumente relatada em 2024, quando restringimos apenas os casos confirmados?\n\n Dengue Malária Febre Amarela\n\nPor que a doença mais notificada muda quando olhamos os casos confirmados e suspeitos?\n\n A sensibilidade e especificidade do diagnóstico clínico pode variar por doença O desempenho dos exames utilizados nos laboratórios pode variar por doença Pode existir vieses de notificação Todas as opções acima!\n\nQual distrito relatou o maior número de casos confirmados de cólera em 2024?\n\n Lago Minara Feveria Central Kasara\n\nQuantos casos confirmados de cólera relatados em 2024 foram entre moradores de Feveria Central?\n\n 35 42 4\n\nQual distrito relatou mais casos confirmados de malária em 2024?\n\n Lago Minara Feveria Central Kasara\n\nEstes dados confirmam que a dengue é a doença infecciosa mais comum em Feveria?\n\n Não - uma doença diferente pode estar sendo subnotificada e/ou não ser de notificação compulsória Sim - se é a mais notificada então deve ser a mais comum\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUtilizando tabyl() podemos ver que a dengue foi a doença mais frequentemente notificada em Feveria em 2024 quando consideramos apenas os casos confirmados, com 186 casos.\n\ndados_vinculados_confirmados |&gt; \n  tabyl(doenca_notificada) \n\n doenca_notificada   n    percent\n            colera  38 0.08675799\n            dengue 186 0.42465753\n     febre amarela  33 0.07534247\n     febre tifoide   7 0.01598174\n           malaria 174 0.39726027\n\n\nNote que isto é diferente dos casos suspeitos, em que a malária foi a doença mais notificada (com 533 casos suspeitos)! Isto foi sugerido anteriormente, quando se viu que a taxa de positivos para casos suspeitos de dengue era mais elevada do que para casos suspeitos de malária. Isto pode dever-se a diferentes razões, por exemplo, o método de diagnóstico clínico utilizado para a malária pode ser menos específico (então muitos dos casos suspeitos são, na realidade, outras doenças), ou o exame utilizado para a dengue pode ser mais sensível.\nPara fazer uma tabela cruzada com o distrito de residência, adicione as funções adorn_xxx() relevantes.\n\ndados_vinculados_confirmados |&gt; \n  tabyl(doenca_notificada, distrito_de_residencia) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n doenca_notificada Feveria Central     Kasara Lago Minara        Total\n            colera      92.1% (35)  7.9%  (3)  0.0%   (0) 100.0%  (38)\n            dengue       8.6% (16) 17.2% (32) 74.2% (138) 100.0% (186)\n     febre amarela       0.0%  (0) 18.2%  (6) 81.8%  (27) 100.0%  (33)\n     febre tifoide      71.4%  (5) 28.6%  (2)  0.0%   (0) 100.0%   (7)\n           malaria      14.9% (26) 22.4% (39) 62.6% (109) 100.0% (174)\n             Total      18.7% (82) 18.7% (82) 62.6% (274) 100.0% (438)\n\n\nTal como acontece com os casos suspeitos, podemos ver que a maioria dos casos confirmados de dengue, malária e febre amarela se localizaram em Lago Minara - a zona do lago com maior densidade de mosquitos e, por conseguinte, de doenças transmitidas por vetores. A maioria dos casos confirmados de cólera e febre tifoide registou-se em Feveria Central, onde existem problemas de água e saneamento.\nOs dados sugerem que as doenças transmitidas por vetores (dengue e malária) constituem uma preocupação especial neste país tropical. No entanto, não sabemos ao certo qual é a doença mais comum e quais são os padrões subjacentes - apenas cinco doenças são de notificação compulsória e, normalmente, os casos notificados representam apenas uma fração dos casos reais na comunidade.\n\n\n\n\n\n\n\nVocê irá trabalhar na construção desta curva epidêmica, ao longo das várias tarefas abaixo.\n\n\n\n\n\n\n\n\n\n\n\nCertifique-se de especificar o argumento binwidth=7 para que cada barra no histograma represente o número de casos dentro de um período de 7 dias.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuando foi notificado o primeiro caso de febre tifoide em Feveria em 2024?\n\n Janeiro de 2024 Maio de 2024 Outubro de 2024\n\nDe acordo com este gráfico, qual foi o maior número de casos de dengue notificados em uma única semana em 2024?\n\n 10 20 30 É muito difícil responder isto a partir do gráfico empilhado!\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAqui está um código simples para construir a curva epidêmica. Note que ainda não está controlando as cores, nem especificando em que dia da semana começa cada período de 7 dias.\n\ndados_vinculados_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = data_notificacao, fill = doenca_notificada)), binwidth=7)\n\n\n\n\n\n\n\n\nConsulte o capítulo sobre datas do Manual de R para Epidemiologistas caso queira uma formatação de data mais específica, por exemplo, de modo que cada barra represente uma semana de segunda a domingo, ou o eixo x indique o número da semana (semanas 1 - 52).\nImportante - não é simples visualizar as tendências por doença quando os dados estão empilhados dessa forma! Para ver essas tendências temporais, você deve produzir um histograma para cada doença.\n\n\n\n\n\n\nUtilize facet_wrap() para criar facilmente vários mini-plots, um por doença. Para entender isto melhor, você pode consultar a seção seção de facetas do capítulo sobre ggplot2 no Manual de R para Epidemiologistas\n\n\n\n\n\n\nPerguntas\n\n\n\n\nDe acordo com este gráfico facetado, qual foi o maior número de casos de dengue notificados em uma mesma semana em 2024?\n\n 11 15 29 Ainda não consigo responder!\n\nDentre os casos de dengue notificados naquela semana, em que distrito moravam?\n\n Todos os três distritos Feveria Central Kasara Lago Minara Este gráfico não mostra esta informação\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAgora você pode ver uma curva epidêmica por doença! E pode ver que, durante uma semana de julho, foram notificados 15 casos de dengue. No entanto, este gráfico ainda não apresenta qualquer informação geográfica.\n\ndados_vinculados_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = data_notificacao)), binwidth=7) + \n  facet_wrap(.~doenca_notificada)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nDentre os 15 casos de dengue notificados na mesma semana de julho de 2024, em que distritos moravam?\n\n Todos os três distritos Feveria Central Kasara Lago Minara\n\nEm qual distrito foi notificado o primeiro caso de febre tifoide de 2024?\n\n Kasara Feveria Central Lago Minara Ainda não consigo responder!\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAgora você pode ver uma curva epidêmica por doença, com a coloração refletindo o distrito de residência de onde é o caso\nPode-se ver que entre os 15 casos de dengue notificados na mesma semana, estes residiam em três distritos diferentes. Você também pode ver que o primeiro caso de febre tifoide foi notificado em Feveria Central.\n\ndados_vinculados_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = data_notificacao, fill = distrito_de_residencia)), binwidth=7) + \n  facet_wrap(.~doenca_notificada)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVocê pode especificar:\n\nO tema/aparência geral do gráfico (por exemplo, cor de fundo, aparência das linhas de grade)\nO título e os rótulos\nAs cores das barras (com scale_fill_manual())\nA formatação e o espaçamento das datas ao longo do eixo x (com scale_x_date)\nMuitas outras coisas!\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nA cólera e a febre tifoide aparentam ser endêmicas?\n\n Não - os dados sugerem pequenos surtos ocasionais Sim, ambas são endêmicas\n\nHouve alguma época específica do ano em que a malária atingiu o pico em 2024?\n\n Sim - por volta de novembro/dezembro Sim - por volta de julho/agosto (verão) Não, é consistentemente alta\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAqui está o código totalmente formatado. Observe que algumas outras alterações incluem especificar que queremos apenas duas colunas de mini gráficos dentro do facet_wrap() e que a etiqueta de data ao longo do eixo x deve apenas mostrar o dia e o mês (não o ano, uma vez que todos os casos são em 2024).\n\ndados_vinculados_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = data_notificacao, fill = distrito_de_residencia)), binwidth=7) +\n  facet_wrap(.~doenca_notificada, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"Distrito de residência\",\n       x = \"Data comunicada pela clínica\",\n       y = \"Contagem\",\n       subtitle = \"Número de casos confirmados de cólera, dengue, malária, febre tifoide e febre amarela por semana em Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n\n\n\n\n\n\nTambém podemos ver na curva epidêmica que a cólera e a febre tifoide parecem estar ocorrendo como surtos isolados, em vez de mostrarem endemicidade. No entanto, a malária e a dengue estiveram presentes em Feveria durante todo o ano, com a malária atingindo um pico mais evidente nos meses de verão.\n\n\n\n\n\n\nDesta vez, utilize group_by() e summarize() para produzir uma tabela por distrito com as datas mais antigas e mais recentes dos relatórios.\nVocê pode modificar a sua tabela com um filter() para criar esta tabela para um distrito de cada vez.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuando foi notificado o primeiro caso de dengue de 2024 em Feveria?\n\n 18 de janeiro de 2024 17 de janeiro de 2024 12 de fevereiro de 2024\n\nQuando foi notificado o último caso de dengue em Feveria Central de 2024?\n\n 22 de agosto de 2024 18 de novembro de 2024 25 de dezembro de 2024\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAgrupe os dados por doença e, em seguida, resuma a primeira e a última data para ver a cronologia geral de cada doença em Feveria.\n\ndados_vinculados_confirmados |&gt; \n  group_by(doenca_notificada) |&gt; \n  summarize(primeira_notificacao = min(data_notificacao), \n            ultima_notificacao = max(data_notificacao)) |&gt;\n  ungroup()\n\n# A tibble: 5 × 3\n  doenca_notificada primeira_notificacao ultima_notificacao\n  &lt;chr&gt;             &lt;date&gt;               &lt;date&gt;            \n1 colera            2024-06-03           2024-09-23        \n2 dengue            2024-01-17           2024-11-18        \n3 febre amarela     2024-03-08           2024-08-23        \n4 febre tifoide     2024-05-02           2024-11-07        \n5 malaria           2024-01-08           2024-12-25        \n\n\nAdicione um filter() ao código para ver as datas da primeira e da última notificações no distrito em que está interessado.\n\ndados_vinculados_confirmados |&gt; \n  filter(distrito_de_residencia == \"Feveria Central\") |&gt; \n  group_by(doenca_notificada) |&gt; \n  summarize(primeira_notificacao = min(data_notificacao), \n            ultima_notificacao = max(data_notificacao)) |&gt;\n  ungroup()\n\n# A tibble: 4 × 3\n  doenca_notificada primeira_notificacao ultima_notificacao\n  &lt;chr&gt;             &lt;date&gt;               &lt;date&gt;            \n1 colera            2024-06-03           2024-09-23        \n2 dengue            2024-01-29           2024-08-22        \n3 febre tifoide     2024-05-02           2024-11-07        \n4 malaria           2024-01-29           2024-12-17        \n\n\n\n\n\n\n\n\n\n\nUau! De acordo com os objetivos deste estudo de caso, você conseguiu fazer o seguinte:\n\nUtilizar funções-chave do R para limpar, remodelar e vincular data frames, além de criar novas colunas utilizando condições lógicas.\nPara orientar o processamento dos dados, você realizou inspeções e verificações de dados ao longo do caminho\nVocê conduziu uma análise descritiva detalhada para compreender os dados dos exames e notificações, antes e depois da vinculação. Em resposta às quatro perguntas iniciais do seu supervisor, você pode dizer:\n\nQuantos casos suspeitos das diferentes doenças de notificação compulsória foram notificados em 2024, e qual foi o mais comum? A malária foi a doença de notificação compulsória mais comum em Feveria em 2024, notificada através do sistema de vigilância de doenças de notificação compulsória: Foram notificados 533 casos suspeitos de malária, 273 casos suspeitos de dengue, 100 de febre amarela, 46 de cólera e 35 de febre tifoide.\nQual a porcentagem de casos acabaram sendo confirmados? Quase 80% dos casos notificáveis notificados em 2024 tinham um resultado de exame laboratorial no momento em que o conjunto de dados vinculados foi criado, com alguma variação por doença. No total, 56% dos casos notificados acabaram por ser confirmados, mas esta percentagem variou entre 23% para a febre tifoide (7 casos confirmados de 31 casos suspeitos com resultados de exames) e 95% para a cólera (38 casos confirmados de 40 casos suspeitos com resultados de exames). Além disso, a taxa de positivos foi mais elevada para a suspeita de dengue do que para a suspeita de malária (87% contra 41%).\nQuantos casos confirmados das diferentes doenças de notificação compulsória foram notificados em 2024 e qual foi o mais comum? Os casos confirmados seguiram uma tendência ligeiramente diferente da dos casos suspeitos: a infecção mais notificada foi a dengue, com 186 casos, seguida da malária (174), da cólera (38), da febre amarela (33) e da febre tifoide (7).\nComo é que os casos confirmados se distribuem geográfica e temporalmente em Feveria? Feveria registrou transmissão de dengue e malária ao longo do ano, com picos no verão, e concentrados no distrito de Lago Minara. Feveria também registrou surtos pequenos e pouco frequentes de doenças diarreicas, por exemplo, cólera e febre tifoide, particularmente na área urbana de Feveria Central, onde pode haver problemas com água e saneamento.\n\nPor último, você refletiu sobre a forma como os processos envolvidos nos sistemas de vigilância de doenças de notificação compulsória e nos exames laboratoriais, por exemplo, a transferência de dados entre clínicas e laboratórios, podem afetar a qualidade e a integridade dos dados e, como consequência, os seus resultados.\n\nHá muito mais potencial pela frente. Você pode explorar padrões de doença por idade ou sexo, calcular taxas de doença com dados populacionais e até analisar atrasos na notificação, examinando as diferentes datas nos seus conjuntos de dados.\nVocê construiu uma base sólida e está bem equipado para levar a sua análise para o nível seguinte. Continue firme - descobertas emocionantes o aguardam!\nPara saber mais, consulte os outros estudos de caso ou mergulhe no Manual de R para Epidemiologistas.\n\n\n\nVeja abaixo um script de todas as etapas de limpeza de dados e análises descritivas. Repare como as análises são combinadas no final ao invés de intercaladas entre os passos de limpeza. Esta é uma forma mais organizada de estruturar o seu script.\nPara simplificar, o código abaixo não inclui todas as inspeções e verificações realizadas ao longo do processo, mas você pode optar por criar uma seção específica para esses verificações.\nO início do seu script também deve trazer informações que ajudem o leitor a entender para que ele serve, além de comentários ao longo do código. Você mesmo vai agradecer por ter incluído esses comentários no futuro!\n\n\n\n\n\n\nCódigo para limpar e analisar dados de notificação e dados laboratoriais de Feveria, 2024\n\n\n\n\n\n\n# Código para limpar e analisar dados de notificação e dados laboratoriais de Feveria, 2024\n# Data:\n# Autor:\n\n# Instalar os pacotes ----------------------------------------------\n# Verificar se o pacote \"pacman\" está instalado\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# Instala (se necessário) a partir do CRAN e carrega os pacotes a serem usados\npacman::p_load(\n  rio,        # importação de dados\n  skimr,      # visão geral dos dados\n  janitor,    # limpeza de dados e tabelas\n  lubridate,  # manipulação de datas\n  epikit,     # criação de categorias de idade\n  gtsummary,  # estatísticas descritivas, testes e regressão\n  apyramid,   # gráficos de pirâmides etárias\n  flextable,  # tabelas prontas para apresentação\n  naniar,     # análise de dados faltantes\n  remotes,    # instalação de pacotes para baixar dados\n  tidyverse   # manipulação e visualização de dados\n)\n\n# Importar os dados ------------------------------------------------\n\n# dados de notificação\ndados_notif_bruto &lt;- import(\"data/notificacoes_multidoencas.xlsx\")\n\n# Dados laboratoriais\ndados_lab_bruto &lt;- import(\"data/testes_multidoencas.csv\")\n\n# Limpar os dados de notificação -----------------------------------\ndados_notif &lt;- dados_notif_bruto |&gt; \n  clean_names() |&gt; \n  rename(data_notificacao = data_comunicada_pela_unidade_de_saude_comunidade) |&gt; \n  select(id_notificacao, distrito_de_residencia, doenca_notificada, data_notificacao) |&gt; \n  mutate(distrito_de_residencia = case_match(str_to_title(distrito_de_residencia),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\")) |&gt; \n  mutate(data_notificacao = ymd(data_notificacao)) \n\n\n# Limpar e consolidar os dados laboratoriais -----------------------\n# Padronizar valores\ndados_lab &lt;- dados_lab_bruto |&gt; \n  mutate(resultado = case_match(resultado, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positivo\",\n                            \"N\" ~ \"Negativo\",\n                            \"I\" ~ \"Indeterminado\"))\n\n# Criar base em nível de exame laboratorial\ndados_lab_testes &lt;- dados_lab |&gt; \n  filter(alvo != \"Dengue IgG\") |&gt; \n  group_by(id_amostra) |&gt; \n  arrange(desc(resultado)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Criar base em nível de caso\ndados_lab_casos &lt;- dados_lab_testes |&gt; \n  group_by(id_notificacao) |&gt; \n  arrange(desc(resultado)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Vincular dados de notificação e dados laboratoriais --------------\ndados_vinculados &lt;- left_join(dados_notif, dados_lab_casos, by = \"id_notificacao\")\n\n# Limpar os dados --------------------------------------------------\ndados_vinculados &lt;- dados_vinculados |&gt; \n  mutate(categoria_caso = case_when(resultado==\"Positivo\" ~ \"Confirmado\",\n                                   resultado==\"Negativo\" ~ \"Descartado\",\n                                   resultado==\"Indeterminado\" | is.na(resultado) ~ \"Suspeito\"))\n\ndados_vinculados_confirmados &lt;- dados_vinculados |&gt; \n  filter(categoria_caso==\"Confirmado\")\n\n# ANÁLISE ----------------------------------------------------------\n# Número de casos suspeitos em Feveria\ntabyl(dados_notif, doenca_notificada)\n\n# Distribuição de casos suspeitos por distrito\ntabyl(dados_notif, doenca_notificada, distrito_de_residencia) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n# Distribuição de resultados por exames específicos\ntabyl(dados_lab_testes, exame, resultado) |&gt; \n    adorn_totals(where = \"col\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribuição da categoria de caso, nos dados vinculados: todos os casos\ntabyl(dados_vinculados, categoria_caso) \n\n# Distribuição da categoria de caso por doença, nos dados vinculados: todos os casos\ntabyl(dados_vinculados, doenca_notificada, categoria_caso) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribuição da categoria de caso por doença, nos dados vinculados: apenas casos com um resultado válido\ndados_vinculados |&gt; \n    filter(categoria_caso != \"Suspeito\") |&gt; \n    tabyl(doenca_notificada, categoria_caso) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribuição de casos confirmados por distrito\ndados_vinculados_confirmados |&gt; \n  tabyl(doenca_notificada, distrito_de_residencia) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n\n# Visualizar casos confirmados ao longo do tempo\ndados_vinculados_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = data_notificacao, fill = distrito_de_residencia)), binwidth=7) +\n  facet_wrap(.~doenca_notificada, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"Distrito de residência\",\n       x = \"Data comunicada pela clínica\",\n       y = \"Contagem\",\n       subtitle = \"Número de casos confirmados de cólera, dengue, malária, febre tifoide e febre amarela por semana em Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n# Primeira e última notificações por doença\ndados_vinculados_confirmados |&gt; \n  group_by(doenca_notificada) |&gt; \n  summarize(primeira_notificacao = min(data_notificacao), \n            ultima_notificacao = max(data_notificacao)) |&gt;\n  ungroup()\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutores originais: Paula Blomquist e Alanah Jansen, com apoio técnico fornecido pelo CDC Global Surveillance, Laboratory, and Data Systems Branch em colaboração com a TEPHINET.\nFonte de dados: Dados fictícios fornecidos pela Applied Epi.\n\n\n\n\n\n\n\n\n\n\n\n\nData\nAlterações efetuadas\nVersão\nAutor\n\n\n\n\nJulho de 2025\nPrimeiro rascunho\n1\nPaula Blomquist e Alanah Jansen, Applied Epi, com o apoio técnico do CDC Global Surveillance, Laboratory, and Data Systems Branch em colaboração com a TEPHINET\n\n\nAgosto de 2025\nTradução para o português\n1\nLucca Nielsen e Pedro Menezes\n\n\n\n\n\n\nAviso legal: A informação apresentada neste exercício e os arquivos de dados associados foram desenvolvidos para ajudar os alunos a atingir os objetivos de aprendizagem pretendidos. Os conteúdos são da responsabilidade do(s) autor(es) e não representam necessariamente as opiniões oficiais do CDC, do Departamento de Saúde e Serviços Humanos dos EUA ou da TEPHINET.\nLicença: Este estudo de caso está sob uma licença CC BY-NC-SA 4.0. Para mais informações sobre o compartilhamento e adaptação deste estudo de caso, consulte a escritura associada.\nFinanciamento Este estudo de caso foi 100% apoiado pelo Acordo de Cooperação número NU2HGH000044 financiado pelos Centros de Controle e Prevenção de Doenças (CDC) dos EUA."
  },
  {
    "objectID": "pages/multidisease_surveillance.pt.html#cenário",
    "href": "pages/multidisease_surveillance.pt.html#cenário",
    "title": "Ligação e análise de dados de notificação e de dados laboratoriais em R",
    "section": "",
    "text": "Você é um epidemiologista que trabalha no serviço nacional de vigilância de Feveria, um país tropical muito pequeno. Existem três distritos em Feveria:\n\nFeveria Central:uma área urbana superpovoada, com infraestrutura de água e saneamento às vezes precária.\nLago Minara: uma zona lacustre com boa infra-estrutura mas muitos mosquitos nos meses mais quentes do ano.\nKasara: uma zona mais suburbana do outro lado de Feveria Central.\n\nMapa dos distritos do país Feveria\n\nÉ janeiro de 2025, e sua supervisora gostaria que você transferisse o processamento rotineiro dos dados de doenças de notificação compulsória do Excel para o R e realizasse algumas análises com os dados. Ela quer saber pelo menos:\n\nQuantos casos suspeitos das diferentes doenças de notificação compulsória foram notificados em 2024 e qual foi a mais comum?\nQual porcentagem deles acabou sendo confirmada?\nQuantos casos confirmados das diferentes doenças de notificação compulsória foram notificados em 2024 e qual foi a mais comum?\nComo é que os casos confirmados foram distribuídos geográfica e temporalmente em Feveria?\n\nEla pede que você escreva código para importar, limpar, relacionar e analisar as seguintes listas de casos (linelists):\n\nDados de vigilância de doenças notificáveis de 2024: Também designados por “dados de notificação”, estes são dados de vigilância de cinco doenças notificáveis comunicadas pelas clínicas do Feveria: dengue, malária, cólera, febre tifoide e febre amarela. Trata-se de casos suspeitos, baseados nos sintomas dos pacientes. Os médicos introduzem cada notificação num sistema em linha todos os dias da semana.\n2024 dados de resultados de testes laboratoriais: Estes dados provêm de resultados de análises laboratoriais de três grandes laboratórios de Feveria. Estes resultados referem-se a amostras colhidas dos casos suspeitos de doenças notificáveis mencionados acima.\n\nVamos lá!"
  },
  {
    "objectID": "pages/multidisease_surveillance.pt.html#objetivos",
    "href": "pages/multidisease_surveillance.pt.html#objetivos",
    "title": "Ligação e análise de dados de notificação e de dados laboratoriais em R",
    "section": "",
    "text": "Neste estudo de caso, você vai:\n\nUsar funções-chave do R para limpar os dados, reorganizar os conjuntos de dados, relacionar fontes de dados e criar novas colunas usando condições lógicas, a fim de preparar os dados para análise.\nRealizar inspecções de dados e verificações da qualidade dos dados em várias fases do projeto e compreender a sua importância para uma análise confiável.\nRealizar análises descritivas básicas para comparar as tendências das doenças entre diferentes fontes de dados, antes e depois do linkage.\nInterpretar as diferenças nos resultados entre as fontes de dados e compreender como elas refletem a estrutura e o desenho do sistema de vigilância como um todo."
  },
  {
    "objectID": "pages/multidisease_surveillance.pt.html#passo-1.-configuração",
    "href": "pages/multidisease_surveillance.pt.html#passo-1.-configuração",
    "title": "Ligação e análise de dados de notificação e de dados laboratoriais em R",
    "section": "",
    "text": "Comece por estabelecer um fluxo de trabalho reproduzível e bem organizado. Este facilitará a repetição da sua análise sempre que necessário.\nTarefas:\n\nConfigurar um projeto RStudio\nConfigurar subpastas claras onde o seu código, dados e resultados serão colocados\nCrie um script R, ou um arquivo R Markdown, se preferir. Certifique-se de que que o objetivo do script, a data e o autor estão escritos como comentários no topo.\nExtra: Certifique-se de que a sua linguagem de trabalho no RStudio é apropriada (por exemplo, inglês para este exercício)\n\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\n\nCrie uma pasta para onde irá todo o trabalho deste estudo de caso. Por exemplo, crie a pasta ‘multidoencas_lab’ no ambiente de trabalho do seu computador. Crie o seu projeto RStudio para ser baseado nesta pasta.\nSugerimos que crie as seguintes subpastas: scripts (para os códigos), data (para os seus dados), e outputs (para os resultados da análise).\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nCrie uma pasta (por exemplo, ‘multidoencas_lab’ no seu ambiente de trabalho) para o seu trabalho. Para criar um projeto Rstudio na sua nova pasta, clique em New Project… no canto superior esquerdo do seu R Studio e, em seguida Existing Directory e, em seguida Browse para selecionar a sua nova pasta. Para mais informações, consulte a secção Projetos R do Manual de R para Epidemiologistas\nInicie um novo script R clicando em New File… no canto superior esquerdo do seu R Studio e, em seguida R Script. Salve-o imediatamente no local apropriado, por exemplo, em uma subpasta ‘scripts’ dentro da pasta que contém seu projeto RStudio.\nNo topo do seu novo script R, escreva algumas informações essenciais como o seu nome, o objetivo do script e a data.\nO locale do R determina o idioma e as definições regionais utilizadas para o coisas como formatos de data e traduções. Se a sua localidade for diferente do idioma que pretende para o seu relatório (por exemplo, uma localidade francesa vs. uma localidade em inglês), pode alterá-la para inglês executando Sys.setlocale(\"LC_ALL\", \"English\"). Inclua isto no seu script se necessário, ou ignore-o se a sua localidade for normalmente apropriada. Isto é explicado em mais detalhes na seção Guia de instruções.\n\n\n\n\n\n\nA seguir, no seu script R, você precisa instalar e carregar os pacotes R necessários. Isto garante que as funções necessárias estarão disponíveis para sua análise.\nSão necessários os seguintes pacotes: {rio} (para importação de dados),{skimr} (para explroar os dados), {janitor} (para limpeza de dados), {lubridate} (para limpeza de datas), {epikit} (para tarefas relacionadas com epidemiologia), {gtsummary} (para estatísticas resumidas/testes e regressão), {apyramid} (para pirâmides etárias), {flextable} (para tabelas prontas para apresentação), {naniar} (para avaliar dados faltantes), e {tidyverse} (para tarefas gerais de manipulação de dados). Também vai precisar do {remotes} para baixar os dados - o que explicaremos na seção de download.\nAo começar, seu colega de confiança te cutuca e sussurra: “Ouvi dizer que uma ótima forma de gerenciar seus pacotes é com o pacote {pacman}”.\nAgora é com você!\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUtilize a função p_load() do pacote pacman para esta tarefa. Você fornece uma lista de pacotes que deseja utilizar. A função executará dois passos por pacote: 1) Verificar se o pacote está instalado no seu computador, e instalá-lo se necessário, depois 2) Carregar o pacote para que ele possa ser usado durante esta sessão do R.\nSe ainda não tem pacman instalado, será necessário instalar ele da “maneira tradicional”, com install.packages().\nNote que a ordem dos pacotes na sua função p_load pode ser importante. Se dois pacotes tiverem os mesmos nomes de função (por exemplo select() no pacote MASS e select() na tidyverse, que fazem diferentes coisas), então o R utilizará a função do pacote mais recentemente carregado. Para dar prioridade às funções do tidyverse, que são normalmente utilizadas para manipulação e visualização de dados, carregue sempre tidyverse por último.\n\n# Garante que o pacote \"pacman\" está instalado\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\")\n}\n\n# Instala (se necessário) a partir do CRAN e carrega os pacotes a serem usados\npacman::p_load(\n  rio,        # importar dados\n  skimr,      # obter visão geral dos dados\n  janitor,    # limpeza de dados e criação de tabelas\n  lubridate,  # trabalhar com datas\n  epikit,     # criar categorias de idade\n  gtsummary,  # estatísticas resumidas, testes e regressões\n  apyramid,   # plotar pirâmides etárias\n  flextable,  # tabelas prontas para apresentação\n  naniar,     # avaliar dados ausentes\n  remotes,    # usado para instalar pacotes para baixar dados\n  tidyverse   # gestão de dados e visualização\n)"
  },
  {
    "objectID": "pages/multidisease_surveillance.pt.html#passo-2.-baixar-e-importar-os-dados",
    "href": "pages/multidisease_surveillance.pt.html#passo-2.-baixar-e-importar-os-dados",
    "title": "Ligação e análise de dados de notificação e de dados laboratoriais em R",
    "section": "",
    "text": "O seu escritório fornece-lhe dois arquivos para a sua análise, ambos com dados relativos a 2024 e atualizados a partir de 15 de janeiro de 2025:\n\nUm conjunto de dados no nível de notificação de doenças (“notificacoes_multidoencas.xlsx”) com informações de casos de 5 centros de saúde.\nUm conjunto de dados a nível de exames laboratoriais (“testes_multidoencas.csv”) apresentado por três laboratórios que efetuam exames para os 5 centros de saúde.\n\nPara este estudo de caso, você pode baixar os dados através do repositório de dados muito útil do Applied Epi, que pode ser acessado usando o pacote {appliedepidata}.\nSiga estes passos:\n\nInstale o pacote {appliedepidata} do GitHub usando a função install_github() do pacote {remotes} (que você instalou anteriormente).\n\n\n# Use a função install_github do pacote remotes para instalar o appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nSalve os dois conjuntos de dados numa pasta específica utilizando a função save_data() do pacote {appliedepidata}. Execute o código abaixo. O exemplo abaixo salva os dados em uma subpasta data dentro do projeto do RStudio. Observe que, se você não especificar um local no argumento path da função, uma janela será exibida pedindo para selecionar manualmente uma pasta.\n\n\n# Salva os dois arquivos de dados usando a função save_data() do pacote appliedepidata\nappliedepidata::save_data(\"testes_multidoencas\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"notificacoes_multidoencas\",\n                          path = \"data\")\n\n\n\n\nÓtimo! Obrigado ao escritório do país e à Applied Epi! Agora é hora de importar os dados dessa pasta para o RStudio, para que você possa analisá-los.\n\n\nIdealmente, utilizará a mesma função para importar ambos os conjuntos de dados, apesar de uma ser um arquivo .csv e o outro um arquivo .xlsx. Nota: daqui para a frente, diremos simplesmente “ambiente” quando nos referirmos ao painel ambiente (Environment) no R Studio.\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\nUse a função import do pacote {rio} que consegue reconhecer e importar diferentes tipos de arquivos. Ela substitui funções de importação específicas para cada tipo de arquivo, como read.csv() do {base} para arquivos .csv e read_excel() do {readxl} para importar arquivos .xlsx.\nSe achar que precisa de saber mais sobre funções de importação, leia o capítulo Importar e exportar do Manual de R para Epidemiologistas\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAbaixo usamos a função import para carregar os dois arquivos. Note que estamos atribuindo os dados importados a dois objetos: um chamado dados_notif_bruto e outro chamado dados_lab_bruto. Adicionamos o sufixo ‘bruto’ para diferenciar esses dados das versões limpas que criaremos posteriormente.\n\n# Importar dados\n\n# Dados de notificação\ndados_notif_bruto &lt;- import(\"data/notificacoes_multidoencas.xlsx\")\n\n# Dados laboratoriais\ndados_lab_bruto &lt;- import(\"data/testes_multidoencas.csv\")"
  },
  {
    "objectID": "pages/multidisease_surveillance.pt.html#passo-3.-inspecionar-os-dados",
    "href": "pages/multidisease_surveillance.pt.html#passo-3.-inspecionar-os-dados",
    "title": "Ligação e análise de dados de notificação e de dados laboratoriais em R",
    "section": "",
    "text": "Os dados foram importados e agora é hora de ver que história eles contam. Faça uma análise inicial dos dois data frames brutos para verificar seu conteúdo e qualidade.\n\n\n\n\nUse as funções skim() do pacote {skimr}, names(), ncol() e nrow() para inspecionar seu conjunto de dados.\nA função skim() fornece muitas informações sobre a estrutura e o conteúdo dos dados, enquanto names() mostra os diferentes nomes das colunas. As funções ncol() e nrow() contam, respectivamente, o número de colunas e linhas do conjunto de dados. Você sabe o que colocar dentro dos parênteses?\nO jeito mais fácil, no entanto, é olhar diretamente o ambiente do RStudio.\nLembre-se: o objeto no seu ambiente referente às notificações se chama dados_notif_bruto.\nClique na caixa de solução abaixo das perguntas se precisar de ajuda.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuantas colunas existem nos dados de notificações?\n\n 10 11 12 13\n\nQuais dessas colunas NÃO estão nos dados?\n\n Data de início dos sintomas Data comunicada pela unidade de saúde/comunidade Data do Resultado Data do teste Data de nascimento\n\nQual é o nome da coluna nos dados de notificação que identifica cada notificação?\n\n ID notificacao ID do teste Codigo da unidade de saude Combinação de ID notificacao e Sexo\n\nQuantas linhas existem nos dados de notificação?\n\n 987 1314 950 778\n\nQue tipo de informação você NÃO consegue ver nos dados de notificação?\n\n Resultados de exames laboratoriais Distrito de residência Data de nascimento e Sexo Unidade de saúde em que o caso foi diagnosticado Desfecho\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUse a função skim() do pacote {skimr} para ver um resumo de todo o data frame, e View() para visualizar diretamente o data frame completo:\n\nskim(dados_notif_bruto)\n\nOu você pode usar names() para exibir apenas os nomes das colunas. Com skim() ou names() você poderá ver os tipos de informação, incluindo: a unidade de saúde do caso, data de nascimento, sexo, um indicador de gravidez, distrito de residência, data de início dos sintomas, data comunicada pela clínica e informações sobre o desfecho.\nTambém existe um ID notificacao, que parece ser um identificador único para cada caso, mas é recomendável verificar duplicatas antes de ter certeza.\nObserve que NÃO há resultados de testes nesses dados, pois essas notificações são de clínicas que diagnosticam doenças de notificação compulsória com base em definições clínicas de caso.\n\nnames(dados_notif_bruto)\n\n [1] \"Nome da unidade organizacional\"                  \n [2] \"Codigo da unidade de saude\"                      \n [3] \"ID notificacao\"                                  \n [4] \"Data de nascimento\"                              \n [5] \"Sexo\"                                            \n [6] \"Gestante\"                                        \n [7] \"Distrito de residencia\"                          \n [8] \"Doenca notificada\"                               \n [9] \"Data de inicio dos sintomas\"                     \n[10] \"Data comunicada pela unidade de saude/comunidade\"\n[11] \"Resultado\"                                       \n[12] \"Data do resultado\"                               \n\n\nUse ncol() e nrow() para exibir o número de colunas e linhas, assim:\n\nncol(dados_notif_bruto)\nnrow(dados_notif_bruto)\n\nIsso exibirá o número de colunas e linhas no console.\n\n\n[1] 12\n\n\n[1] 987\n\n\nDe outro modo, ao olhar para o ambiente, você pode ver que o número de observações (que é o mesmo que o número de linhas) e o número de colunas estão listados ao lado do nome do data frame.\n\n\n\n\n\n\nUse a função skim() do pacote {skimr} ou class() para inspecionar as classes das colunas.\nVocê se lembra de como especificar a coluna de interesse dentro da função class()?\nComo alternativa, você pode simplesmente olhar para o ambiente.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuantas colunas do data frame de notificações são reconhecidas pelo R como colunas de data?\n\n 0 2 4\n\nQual é a classe da maioria das colunas no data frame bruto de notificações?\n\n character numeric factor\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nVocê pode usar a função class() como no exemplo abaixo. O $ é um operador usado para selecionar uma coluna específica do data frame dados_notif_bruto.\nObserve que os acentos graves (`) são usados em torno de Data de nascimento porque o nome da coluna contém espaços.\n\nclass(dados_notif_bruto$`Data de nascimento`)\n\nPara verificar a classe pelo ambiente, clique na seta azul ao lado do nome do data frame.\nOs nomes das colunas aparecerão, com a classe ao lado (por exemplo, aparece “chr” para indicar que é do tipo character).\nVocê pode ver que nenhuma das colunas que deveriam ser datas é reconhecida como tal.\nEm vez disso, elas são reconhecidas como valores do tipo character.\n\n\n\n\n\n\nUse a função tabyl() para inspecionar os valores dentro de colunas categóricas, especificando o objeto do data frame no primeiro argumento e o nome da coluna no segundo argumento.\nPor exemplo, este código tabula os valores da coluna Sexo. A saída mostra que “masculino” e “feminino” estão escritos de forma inconsistente nos dados. Essa coluna precisará de limpeza adicional antes da análise.\n\ntabyl(dados_notif_bruto, Sexo)\n\n      Sexo   n    percent valid_percent\n         F  47 0.04761905    0.05452436\n  FEMININO 146 0.14792300    0.16937355\n         M  40 0.04052685    0.04640371\n MASCULINO 172 0.17426545    0.19953596\n         f 154 0.15602837    0.17865429\n  feminino  98 0.09929078    0.11368910\n         m 119 0.12056738    0.13805104\n masculino  86 0.08713273    0.09976798\n      &lt;NA&gt; 125 0.12664640            NA\n\n\nPara inspecionar dados ausentes, você pode usar a função miss_var_summary() do pacote {naniar}:\n\nmiss_var_summary(dados_notif_bruto)\n\n# A tibble: 12 × 3\n   variable                                         n_miss pct_miss\n   &lt;chr&gt;                                             &lt;int&gt;    &lt;num&gt;\n 1 Data de inicio dos sintomas                         691     70.0\n 2 Gestante                                            510     51.7\n 3 Resultado                                           197     20.0\n 4 Data do resultado                                   197     20.0\n 5 Data de nascimento                                  168     17.0\n 6 Sexo                                                125     12.7\n 7 Nome da unidade organizacional                        0      0  \n 8 Codigo da unidade de saude                            0      0  \n 9 ID notificacao                                        0      0  \n10 Distrito de residencia                                0      0  \n11 Doenca notificada                                     0      0  \n12 Data comunicada pela unidade de saude/comunidade      0      0  \n\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nOs valores na coluna Distrito de residência estão padronizados?\n\n Não - precisam ser limpas Estão padronizadas e prontas para análise\n\nOs valores na coluna Doença notificada estão padronizados?\n\n Não - precisam ser limpas Estão padronizadas e prontas para análise\n\nO que o R reconhece como valor ausente?\n\n Ou nenhum valor, ou apenas um espaço, ou apenas um ponto Nenhum valor em uma célula, representado por NA As palavras Desconhecido e Incerto\n\nCom base na quantidade de valores ausentes, a coluna Data de início dos sintomas é útil?\n\n Sim, o índice de ausentes é baixo, então esta coluna é útil Minimamente, pois o índice de ausentes é muito alto\n\nPor que algumas colunas nos dados de notificação podem ter diferentes grafias e categorias não padronizadas?\n\n Um robô embaralha os dados para que fiquem menos identificáveis Cada clínica pode usar softwares configurados de forma ligeiramente diferente ou permitir entradas em texto livre, gerando variações na escrita O software do sistema de vigilância usado pelas unidades clínicas possui muitos erros\n\nPor que algumas colunas nos dados de notificação podem apresentar grande quantidade de valores ausentes?\n\n O clínico não faz a pergunta ao paciente durante a consulta O paciente pode não saber ou não querer informar a resposta O clínico pode não ter tempo de priorizar o preenchimento desse campo, mesmo sabendo a informação Todas as alternativas acima, e muitos outros motivos\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUse a função tabyl() para tabular os valores da coluna Distrito de residencia.\nNovamente, o primeiro argumento é o nome do objeto do data frame e o segundo argumento é o nome da coluna.\n\ntabyl(dados_notif_bruto, `Distrito de residencia`)\n\n Distrito de residencia   n    percent\n              F Central  32 0.03242148\n              FEVERIA C  23 0.02330294\n        FEVERIA CENTRAL  85 0.08611955\n              Feveria C  24 0.02431611\n        Feveria Central  12 0.01215805\n                 KASARA  64 0.06484296\n                    KSR  17 0.01722391\n                 Kasara 109 0.11043566\n               L MINARA  50 0.05065856\n               L Minara 193 0.19554205\n            LAGO MINARA 185 0.18743668\n            Lago Minara  68 0.06889564\n               Lakeside 125 0.12664640\n\n\nVocê pode ver que cada uma das três localidades (Feveria Central, Lago Minara e Kasara) está escrita de maneiras diferentes e com capitalização diferente. Será necessário corrigir isso se quisermos analisar a distribuição geográfica das doenças de notificação compulsória.\nDe forma semelhante, use a função tabyl() para tabular os valores da coluna Doença notificada.\nVocê pode ver que os nomes estão escritos de forma adequada e consistente, permitindo visualizar a distribuição de linhas por doença sem necessidade de limpeza adicional.\n\ntabyl(dados_notif_bruto, `Doenca notificada`)\n\n Doenca notificada   n    percent\n            colera  46 0.04660588\n            dengue 273 0.27659574\n     febre amarela 100 0.10131712\n     febre tifoide  35 0.03546099\n           malaria 533 0.54002026\n\n\nUma forma diferente de verificar dados ausentes é tabular o resultado da função is.na(). No exemplo abaixo, a função is.na() avalia cada célula da coluna Data de início dos sintomas, retornando TRUE para as ausentes e FALSE para as presentes.\nExecutar tabyl() sobre essa saída TRUE/FALSE fornece rapidamente a contagem e o percentual de valores ausentes e não ausentes nessa coluna. Lembre-se: valores como um espaço ou as palavras “Desconhecido” ou “Ausente” não serão reconhecidos pelo R como ausentes. O R reconhece apenas espaços verdadeiramente em branco como ausentes, representados por NA.\nPara a coluna Data de início dos sintomas, você pode ver que 70% dos casos estão sem essa informação, sugerindo que essa coluna não seria particularmente útil para analisar tendências de doenças ao longo do tempo.\n\ntabyl(is.na(dados_notif_bruto$`Data de inicio dos sintomas`))\n\n is.na(dados_notif_bruto$`Data de inicio dos sintomas`)   n   percent\n                                                  FALSE 296 0.2998987\n                                                   TRUE 691 0.7001013\n\n\nDados ausentes ou não padronizados podem ocorrer por diversos motivos, incluindo o design da ferramenta de coleta de dados (por exemplo, se as perguntas são obrigatórias ou permitem texto livre versus listas suspensas), os processos e padrões estabelecidos (como quais campos a equipe é instruída a priorizar) e fatores contextuais (como se a equipe dispõe de tempo suficiente para coletar a informação) — entre muitos outros.\n\n\n\n\n\n\n\n\n\nDa mesma forma como acontece com os dados de notificação, utilize as funções skim(), ncol(), e nrow() ou verifique o objeto no ambiente para inspecionar os dados laboratoriais.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQual data frame tem mais colunas - os dados de notificação ou os dados laboratoriais?\n\n Dados laboratoriais Dados de notificação Eles têm o mesmo número de colunas\n\nQual data frame tem mais linhas?\n\n Dados laboratoriais Dados de notificação Eles têm o mesmo número de linhas\n\nInspecione os dados laboratoriais com View(). Por que pode haver mais registros nos dados laboratoriais?\n\n Pode haver vários testes ou alvos por amostra Existem muitos resultados de testes de ensaio nos dados Nem todas as notificações têm resultados de testes ainda\n\nQual destas colunas NÃO está nos dados laboratoriais?\n\n ID notificação ID da amostra Tipo de teste Data de nascimento Resultado do teste\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (experimente primeiro!)\n\n\n\n\n\nAssim como na seção 3.1, você pode usar a função skim() do pacote {skimr} para visualizar todos os dado laboratoriais com os resultados dos testes. Isso também mostrará os diferentes nomes de colunas nos dados, evidenciando que os dados laboratoriais contém apenas informações sobre o teste e não sobre o paciente. No entanto, ele também contém um ID notificação, assim como os dados das notificações.\n\nskim(dados_lab_bruto)\n\nUtilizar ncol() e nrow() para exibir o número de colunas e linhas, assim:\n\nncol(dados_lab_bruto)\nnrow(dados_lab_bruto)\n\nIsto exibirá os números de colunas e linhas no painel console, mostrando que os dados do laboratório têm mais linhas do que os dados da notificação inspecionados anteriormente.\n\n\n[1] 7\n\n\n[1] 1314\n\n\nFrequentemente há mais registros nos dados laboratoriais do que nos dados de notificação. Se você inspecionar os dados com View(dados_lab_bruto) e, em seguida, clicar na seta no topo da coluna id_notificacao para ordená-la alfabeticamente, verá que várias linhas compartilham o mesmo id_notificacao.\nIsso pode acontecer quando múltiplos alvos são testados a partir da mesma amostra (mesmo ID de amostra) ou quando um caso é retestado (resultando em um ID de amostra diferente).\n\nView(dados_lab_bruto)\n\n\n\nnome_laboratorioid_notificacaoid_amostradata_exameexamealvoresultadoHospital Geral de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue NS.1NHospital Geral de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgGNHospital Geral de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgMPHospital Geral de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue NS.1NHospital Geral de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgGNHospital Geral de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgMP\n\n\n\n\n\n\n\n\nComo acima, utilize as funções class(), skim(), ou tabyl(), ou inspecione o objeto direto no ambiente RStudio, para analisar as suas colunas com mais detalhes.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuantas colunas dos dados laboratoriais são reconhecidas pelo R como colunas de data?\n\n 0 1 2\n\nQuantas colunas nos dados laboratoriais possuem dados completos?\n\n 1 3 7 (todas elas!)\n\nQual teste detecta múltiplos alvos (e, portanto, possui múltiplas linhas por amostra)?\n\n Malária Dengue Febre Amarela Cólera Febre Tifoide\n\nQuantos valores possíveis de resultado de teste existem na coluna resultado?\n\n 5 3 4\n\nQual NÃO é um resultado possível para o teste de cultura de fezes que detecta a bactéria V. cholerae?\n\n P P01 P0139 N I\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nOs dados laboratoriais têm uma coluna de data, reconhecida pelo R como uma classe “IDate”. Esta é uma classe de data utilizada pela função import() do pacote {rio} ao importar arquivos csv. Da mesma forma como a classe Data do R base, ela permite ordenar pela data e analisar tendências ao longo do tempo.\n\nclass(dados_lab_bruto$data_exame)\n\n[1] \"IDate\" \"Date\" \n\n\nO uso da função miss_var_summary() do pacote {naniar} demonstra que todas as colunas dos dados laboratoriais estão efetivamente completas. Isto talvez se deva ao fato de os sistemas laboratoriais utilizarem processos automatizados, por isso é muito menos provável que haja erro humano.\n(Ponto importante: Nota-se que, na vida real, os dados laboratoriais provavelmente teriam alguns problemas!)\n\nmiss_var_summary(dados_lab_bruto)\n\n# A tibble: 7 × 3\n  variable         n_miss pct_miss\n  &lt;chr&gt;             &lt;int&gt;    &lt;num&gt;\n1 nome_laboratorio      0        0\n2 id_notificacao        0        0\n3 id_amostra            0        0\n4 data_exame            0        0\n5 exame                 0        0\n6 alvo                  0        0\n7 resultado             0        0\n\n\nPara ver quantos alvos são detectados por cada tipo de exame, faça uma tabulação cruzada das colunas exame e alvo com tabyl(). Escreva os nomes das colunas na função como dois argumentos separados. O resultado mostra que cada exame está claramente alinhado com um ou mais alvos, e apenas o teste da dengue detecta mais do que um alvo (IgG, IgM e NS.1).\nDica: Experimente alterar a ordem dos nomes das colunas na função para ver o impacto na tabela.\n\ntabyl(dados_lab_bruto, alvo, exame)\n\n                 alvo Cultura de fezes Dengue NS1/IgG/IgM Hemocultura IgM ELISA\n    Bacteria S. Typhi                0                  0          33         0\n Bacteria V. cholerae               45                  0           0         0\n           Dengue IgG                0                215           0         0\n           Dengue IgM                0                215           0         0\n          Dengue NS.1                0                215           0         0\n    Febre Amarela IgM                0                  0           0        88\n           Plasmodium                0                  0           0         0\n Microscopia de sangue total\n                           0\n                           0\n                           0\n                           0\n                           0\n                           0\n                         503\n\n\nFinalmente, inspecione os diferentes valores dos resultados do teste na coluna resultado usando tabyl(). Pode ver que existem seis resultados possíveis, incluindo N para negativo, P para positivo e I para indeterminado. A cólera, especificamente, não apresenta P, mas pode apresentar P01 e P0139, o que, neste caso, significa ser positivo para os serogrupos O1 ou O139.\n\ntabyl(dados_lab_bruto, exame, resultado)\n\n                       exame  I   N   P PO1 PO139\n            Cultura de fezes  5   2   0  22    16\n          Dengue NS1/IgG/IgM  0 354 291   0     0\n                 Hemocultura  2  24   7   0     0\n                   IgM ELISA 10  45  33   0     0\n Microscopia de sangue total 56 257 190   0     0"
  },
  {
    "objectID": "pages/multidisease_surveillance.pt.html#passo-4.-limpar-e-descrever-os-dados-de-notificação",
    "href": "pages/multidisease_surveillance.pt.html#passo-4.-limpar-e-descrever-os-dados-de-notificação",
    "title": "Ligação e análise de dados de notificação e de dados laboratoriais em R",
    "section": "",
    "text": "Agora já sabemos que os dados de notificação (dados_notif_bruto) contêm informações sobre casos suspeitos, além de variáveis demográficas básicas (idade, sexo, gravidez, distrito de residência), bem como dados sobre a data de início dos sintomas, a dados de notificação pela unidade de saúde e o desfecho. Algumas dessas colunas precisam ser limpas antes da análise, seja por variações na ortografia de valores categóricos, seja porque algumas datas não foram corretamente reconhecidas como tal.\nA partir deste ponto, você começará a escrever trechos mais longos de código para realizar a limpeza, utilizando várias funções do {dplyr} encadeadas com pipes (que se parecem com isso: |&gt;).\nNOTA SOBRE PIPES Os pipes permitem realizar várias operações em sequência, “encadeando” diferentes funções. O resultado de uma função passa a ser a entrada como primeiro argumento da seguinte.\nCaso queira mais detalhes sobre o uso de pipes, veja a seção do Manual de R para Epidemiologistas.\nNeste exercício será utilizado o pipe nativo do R (|&gt;), que é mais rápido e não exige instalação de pacotes adicionais. Se preferir, você também pode usar o pipe do pacote magrittr (%&gt;%).\n\n\n\n\nDevido a questões de qualidade e armazenamento de dados, a sua equipe recomenda que seja criado um data frame limpo, contendo apenas as seguintes variáveis: identificador único, localização do caso, doença e a data em que a notificação foi registrada no sistema de vigilância.\nEscreva um código em R para produzir um novo data frame limpo chamado dados_notif, aplicando as seguintes tarefas de limpeza:\n\nRenomear as colunas para serem mais legíveis pela máquina (remover espaços e capitalização) usando a função clean_names() do pacote {janitor}.\n\nUsar a função rename() do pacote {dplyr} para que a coluna com a data em que o caso foi notificado seja alterada para o nome mais conciso data_notificacao.\nSelecionar colunas relevantes para análise com a função select() do pacote {dplyr}.\n\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\nComece seu código com o nome do novo data frame, a seta do operador de atribuição e o nome do objeto de dados brutos. Isso indica que o resultado do processamento dos dados brutos será atribuído a um novo objeto chamado dados_notif. .\n\ndados_notif &lt;- dados_notif_bruto\n\nEm seguida, desenvolva este código adicionando funções adicionais, encadeadas com um pipe. Isto permite executar várias operações em uma sequência contínua. Primeiro, utilize clean_names() para padronizar todos os nomes das suas colunas. Essa função substitui automaticamente espaços e caracteres especiais por sublinhados e converte tudo para minúsculas, tornando os nomes mais fáceis de trabalhar. Depois, você pode usar rename() para atribuir um novo nome a uma coluna. Lembre-se de que, ao utilizar rename(), a coluna já possui a versão de seu nome gerada pelo clean_names().\n\ndados_notif &lt;- dados_notif_bruto |&gt; \n  clean_names() |&gt; \n  rename(NOVO_NOME = ANTIGO_NOME) |&gt; \n  select(VAR_NOMES)\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAqui está o código para limpar os nomes das colunas e selecionar as colunas certas para análise:\n\n# Limpeza dos dados\ndados_notif &lt;- dados_notif_bruto |&gt; \n  clean_names() |&gt; \n  rename(data_notificacao =  data_comunicada_pela_unidade_de_saude_comunidade) |&gt; \n  select(id_notificacao, distrito_de_residencia, doenca_notificada, data_notificacao)\n\n\n\n\n\n\n\nA partir da inspeção dos dados, já se sabe que os valores para distritonão estão padronizados.\nAdicione um mutate() para limpar a coluna distrito_de_residencia da seguinte maneira:\n\nNormalizar a capitalização dos valores dessa coluna\nSubstituir a coluna existente distrito_de_residencia existente por uma coluna limpa que contenha apenas estes valores de distrito: “Lago Minara”, “Feveria Central” e “Kasara”.\n\nVeja a dica para saber quais funções utilizar.\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\nTente usar str_to_title() do pacote {stringr} para que a primeira letra de cada palavra seja maiúscula e todas as outras letras sejam minúsculas. Também pode utilizar case_match() para corrigir erros tipográficos específicos.\nUse a funcionalidade de ajuda do RStudio para aprender a utilizar essas funções. Por exemplo, digite ?case_match no console para abrir a página de ajuda e a documentação da função. Nota: case_match() é uma função muito útil para substituir ou corrigir valores, e pode substituir recode().\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nO seu código de limpeza deve agora ter o seguinte aspecto:\n\n# Limpeza dos dados\ndados_notif &lt;- dados_notif_bruto |&gt; \n  clean_names() |&gt; \n  rename(data_notificacao =  data_comunicada_pela_unidade_de_saude_comunidade) |&gt; \n  select(id_notificacao, distrito_de_residencia, doenca_notificada, data_notificacao) |&gt;\n  mutate(distrito_de_residencia = str_to_title(distrito_de_residencia)) |&gt; \n  mutate(distrito_de_residencia = case_match(distrito_de_residencia,\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\"))\n\nTambém pode envolver o str_to_title na função case_match() para um código mais curto, como se segue:\n\n# Limpeza dos dados\ndados_notif &lt;- dados_notif_bruto |&gt; \n  clean_names() |&gt; \n  rename(data_notificacao =  data_comunicada_pela_unidade_de_saude_comunidade) |&gt; \n  select(id_notificacao, distrito_de_residencia, doenca_notificada, data_notificacao) |&gt;\n  mutate(distrito_de_residencia = case_match(str_to_title(distrito_de_residencia),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\"))\n\n\n\n\n\n\n\nA coluna data_notificacao precisa ser transformada para que seja reconhecida como uma data no R. Isso permitirá analisar tendências ao longo do tempo, incluindo semanas e meses.\nReveja os valores da coluna data_notificacao. Em seguida, adicione uma linha ao seu código de limpeza para converter data_notificacao em uma classe de data.\nConhecer a estrutura dos dados permitirá utilizar a função correta para a conversão.\nRecomendamos o uso de funções do pacote {lubridate}, como ymd() (para datas no formato ano-mês-dia), mdy() (para datas no formato mês-dia-ano) ou dmy() (para datas no formato dia-mês-ano). Essas funções reconhecerão qualquer forma de escrever a data, desde que a ordem esteja correta; por exemplo, “21 de agosto de 2025” e “21-08-2024” seriam reconhecidas por dmy().\n\n\n\n\n\n\nPerguntas\n\n\n\n\nComo as datas estão atualmente formatadas?\n\n dia-mês-ano ano-mês-dia mês-dia-ano ano-dia-mês\n\nQual função mutate() deve ser usada para converter a coluna data_notificacao para a classe de data?\n\n mutate(data_notificacao = ymd(data_notificacao)) mutate(data_notificacao = dmy(data_notificacao)) mutate(data_notificacao = mdy(data_notificacao))\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUtilize a função head() para ver as primeiras seis linhas dos dados da coluna data_notificacao. É possível ver que elas são escritas no formato: ano primeiro, depois o mês e depois o dia.\n\nhead(dados_notif$data_notificacao)\n\n[1] \"2024-03-08\" \"2024-03-11\" \"2024-03-11\" \"2024-03-18\" \"2024-03-14\"\n[6] \"2024-03-12\"\n\n\nÉ possível utilizar a função ymd() dentro de mutate() para converter a coluna data_notificacao para a classe de data. Você pode verificar se a conversão foi correta executando class() em seguida.\nO seu código de limpeza deve agora ter o seguinte aspecto:\n\n# Limpeza dos dados\ndados_notif &lt;- dados_notif_bruto |&gt; \n  clean_names() |&gt; \n  rename(data_notificacao =  data_comunicada_pela_unidade_de_saude_comunidade) |&gt; \n  select(id_notificacao, distrito_de_residencia, doenca_notificada, data_notificacao) |&gt;\n  mutate(distrito_de_residencia = case_match(str_to_title(distrito_de_residencia),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\"))|&gt; \n  mutate(data_notificacao = ymd(data_notificacao)) \n\nE pode verificar novamente a classe assim:\n\nclass(dados_notif$data_notificacao)\n\n[1] \"Date\"\n\n\n\n\n\n\n\n\nOs seus colegas dizem-lhe que cada id_notificacao representa um caso suspeito. Agora você pretende criar uma tabela para verificar se id_notificacao está duplicado nas linhas dos seus dados.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nUma linha nos dados de notificação equivale a um caso?\n\n Sim Não\n\nÉ necessário deduplicar seus dados para análise epidemiológica dos casos?\n\n Sim Não\n\n\n\n\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\nHá várias formas de fazer isso, mas tente utilizar a função count() do pacote {dplyr}. Ela cria uma tabela que conta o número de linhas para cada valor único da coluna que você especificar. Em seguida, utilize tabyl() para visualizar a distribuição dessas contagens.\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nPrimeiro, passe os dados de notificação para a função count(), usando id_notificacao como único argumento. Isso cria uma contagem do número de linhas para cada valor único de id_notificacao, apresentada em uma nova coluna chamada n. Por exemplo, neste excerto é possível ver que existe apenas uma linha para cada um desses 6 id_notificacao.\n\ndados_notif |&gt; \n  count(id_notificacao) \n\n\n\n  id_notificacao n\n1         00399b 1\n2         005c85 1\n3         006f52 1\n4         00cbbb 1\n5         01830d 1\n6         019045 1\n\n\nEm seguida, tabule a nova coluna n com a função tabyl(), que mostrará que existe apenas uma linha por id_notificacao único. Isso significa que cada linha equivale a um caso e não é necessária nenhuma deduplicação adicional.\n\ndados_notif |&gt; \n  count(id_notificacao) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 987       1\n\n\n\n\n\n\n\n\n\nVocê pode agora proceder confortavelmente às análises descritivas dos casos, pois os dados estão limpos e cada linha equivale a um caso. Use a função tabyl() para realizar as tarefas seguintes.\n\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQual doença foi mais frequentemente diagnosticada pelas clínicas em Feveria em 2024?\n\n Cólera Malária Dengue Febre Tifoide Febre Amarela\n\nQual doença foi menos frequentemente diagnosticada pelas clínicas em Feveria em 2024?\n\n Cólera Malária Dengue Febre Tifoide Febre Amarela\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUsando a função tabyl() podemos ver que houve 533 casos suspeitos de malária em Feveria em 2024, e apenas 35 casos suspeitos de febre tifoide.\n\ntabyl(dados_notif, doenca_notificada)\n\n doenca_notificada   n    percent\n            colera  46 0.04660588\n            dengue 273 0.27659574\n     febre amarela 100 0.10131712\n     febre tifoide  35 0.03546099\n           malaria 533 0.54002026\n\n\n\n\n\n\n\n\nUtilize tabyl() para fazer uma tabulação cruzada das colunas da doença notificada e do distrito de residência.\nDesenvolva a tabulação adicionando várias funções adorn() do pacote {janitor} para visualizar as distribuições percentuais, como por exemplo adorn_percentages(), adorn_pct_formatting() e adorn_ns().\nDigite o nome da função precedido de ? no console (por exemplo, ?adorn_ns) para acessar as páginas de ajuda relevantes. Você também pode consultar a seção sobre {janitor} no Manual de R para Epidemiologistas para mais explicações sobre as funções adorn_xxx().\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQual distrito reportou o maior número de doenças transmitidas por vetores em 2024 (malária, dengue, febre amarela)?\n\n Lago Minara Feveria Central Kasara\n\nQual distrito reportou o maior número de doenças diarreicas em 2024 (cólera, febre tifoide)?\n\n Lago Minara Feveria Central Kasara\n\nQuais fatores contribuem para o aumento de doenças diarreicas neste distrito específico (selecionado na pergunta anterior)?\n\n Infraestrutura de água e saneamento pouco confiável Superlotação de mosquitos Não sabemos\n\n\n\n\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\nAqui está um código para ajudá-lo a começar. Ele cria tabelas cruzadas entre doenca_notificada e distrito_de_residencia usando tabyl() e, em seguida, aplica adorn_percentages() para converter os números em percentagens com muitas casas decimais. Depois, é necessário passar para adorn_pct_formatting() para formatar as percentagens corretamente, e então usar adorn_ns() para adicionar os números originais entre parênteses.\nNote que as funções adorn_xxx() devem ser aplicadas em uma ordem específica!\n\ntabyl(dados_notif, doenca_notificada, distrito_de_residencia) |&gt;\n  adorn_percentages()\n\nPara entender os fatores que contribuem para o aumento de casos de diarreia, volte ao início do estudo de caso, quando os distritos foram apresentados pela primeira vez.\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUsando a função tabyl() podemos ver que a maioria dos casos suspeitos de dengue, malária e febre amarela ocorreu no Lago Minara, a área do lago com maior densidade de mosquitos e, portanto, maior transmissão de doenças por vetores. Por outro lado, cólera e febre tifoide foram predominantemente registradas em Feveria Central, uma zona urbana superlotada com problemas de infraestrutura de água e saneamento, que aumentam o risco de inundações e contaminação da água potável durante o período chuvoso.\n\ntabyl(dados_notif, doenca_notificada, distrito_de_residencia) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n doenca_notificada Feveria Central      Kasara Lago Minara\n            colera      91.3% (42)  8.7%   (4)  0.0%   (0)\n            dengue       9.5% (26) 17.6%  (48) 72.9% (199)\n     febre amarela      11.0% (11) 21.0%  (21) 68.0%  (68)\n     febre tifoide      68.6% (24) 31.4%  (11)  0.0%   (0)\n           malaria      13.7% (73) 19.9% (106) 66.4% (354)"
  },
  {
    "objectID": "pages/multidisease_surveillance.pt.html#passo-5.-limpar-consolidar-e-descrever-os-dados-laboratoriais",
    "href": "pages/multidisease_surveillance.pt.html#passo-5.-limpar-consolidar-e-descrever-os-dados-laboratoriais",
    "title": "Ligação e análise de dados de notificação e de dados laboratoriais em R",
    "section": "",
    "text": "Com base no seu trabalho anterior, na Etapa 3, você verificou que os dados laboratoriais contêm apenas informações sobre os testes e nenhuma informação sobre o paciente. Os dados já estão bastante limpos, então só precisamos padronizar uma coluna. Também queremos processar o data frame do laboratório para que haja uma linha por notificação, permitindo que ele seja corretamente vinculado ao data frame de notificações.\n\n\n\n\nCriar um novo objeto dados_lab. Isto permitirá uma abordagem e análise mais direta bem como facilitará a interpretação dos resultados.\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUtilize case_match() para transformar os diferentes valores originais em “Positivo”, “Negativo” ou “Indeterminado”:\n\ndados_lab &lt;- dados_lab_bruto |&gt; \n  mutate(resultado = case_match(resultado, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positivo\",\n                            \"N\" ~ \"Negativo\",\n                            \"I\" ~ \"Indeterminado\"))\n\nVocê pode então verificar novamente se os novos valores estão corretos, tabulando e comparando os valores no data frame original e no data frame limpo. Certifique-se de que utilizou a letra ‘O’ e não o número ‘0’!\n\ntabyl(dados_lab_bruto, resultado)\n\n resultado   n    percent\n         I  73 0.05555556\n         N 682 0.51902588\n         P 521 0.39649924\n       PO1  22 0.01674277\n     PO139  16 0.01217656\n\n\n\ntabyl(dados_lab, resultado)\n\n     resultado   n    percent\n Indeterminado  73 0.05555556\n      Negativo 682 0.51902588\n      Positivo 559 0.42541857\n\n\n\n\n\n\n\n\n\n\n\nJá sabemos que algumas amostras possuem várias linhas, porque o teste de dengue possui três alvos, gerando uma linha por resultado de alvo.\nAgora, identifique o número de amostras com várias linhas.\nFaça isso da mesma forma que fez com os dados de notificação: use dados_lab para primeiro contar o número de linhas por amostra e, em seguida, crie uma tabela para mostrar a distribuição desses números de linhas. Lembre-se de que cada amostra é identificada por um id_amostra.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuantas amostras (valores únicos de id_amostra) estão sendo repetidos em três linhas?\n\n 200 215 230\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nPrimeiro, passe os dados laboratoriais para a função count(), usando id_amostra como único argumento.\nIsso cria uma tabela que conta o número de linhas por valor único de id_amostra, apresentado em uma nova coluna n.\nPor exemplo, pode-se ver que o id_amostra “000e8eee” possui três linhas, enquanto o id_amostra “001e1878” aparece em apenas uma linha.\n\ndados_lab |&gt; \n  count(id_amostra) \n\n\n\n  id_amostra n\n1   000e8eee 3\n2   001e1878 1\n3   005f39af 1\n4   00b30781 3\n5   00b56d18 1\n6   0110abcd 3\n\n\nEm seguida, tabule a nova coluna n com o tabyl().\n\ndados_lab |&gt; \n  count(id_amostra) |&gt; \n  tabyl(n)\n\n n n_n   percent\n 1 669 0.7567873\n 3 215 0.2432127\n\n\nPode até verificar se isto se aplica apenas ao exame de dengue adicionando a exame ao cálculo. Pode ver que é apenas o teste da dengue que tem 3 linhas por amostra.\n\ndados_lab |&gt; \n  count(exame, id_amostra) |&gt; \n  tabyl(exame, n)\n\n                       exame   1   3\n            Cultura de fezes  45   0\n          Dengue NS1/IgG/IgM   0 215\n                 Hemocultura  33   0\n                   IgM ELISA  88   0\n Microscopia de sangue total 503   0\n\n\n\n\n\n\n\n\nComo você viu na Seção 3.2, o teste de dengue fornece resultados para três alvos diferentes: IgG, IgM e NS1. Os resultados para cada um desses alvos podem ser negativos ou positivos. No entanto, para simplificar e consolidar os dados, deseja-se atribuir um único valor, negativo ou positivo, para cada amostra, indicando se a amostra representa uma infecção ativa.\n\n\nalvoNegativoPositivoDengue IgG110105Dengue IgM105110Dengue NS.113976\n\n\nO seu colega Ben, que trabalha no laboratório, aconselha sobre a limpeza da seguinte forma:\n\nUma amostra pode ser considerada positiva se NS1 ou IgM forem positivos (já que ambos podem indicar uma infecção aguda).\n\nO IgG pode ser ignorado (porque um resultado positivo, na ausência de NS1 ou IgM positivos, indica imunidade de uma infecção passada resolvida).\n\nAgora, você precisa consolidar os resultados dos testes de dengue em uma linha por teste, com um valor de resultado. Utilize filter(), arrange() e slice(), garantindo que qualquer amostra positiva para NS1 ou IgM seja considerada positiva para dengue.\nCrie um novo objeto chamado dados_lab_testes.\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\nTente aplicar o seguinte para consolidar os resultados de acordo com a recomendação do Ben:\n\nRemover resultados de IgG: filtre as linhas em que o alvo é \"IgG\" usando filter() do {dplyr}.\n\nPriorizar resultados positivos de IgM/NS1: agrupe por id_amostra e organize as linhas com arrange() para que qualquer resultado \"P\" (positivo) apareça primeiro.\n\nFiltrar para o status final: mantenha apenas a primeira linha usando slice(1) para obter o resultado positivo ou negativo da amostra.\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (experimente primeiro!)\n\n\n\n\n\nAqui está o código para filtrar os resultados de IgG da dengue e, em seguida, consolidar o resultado do teste dentro de cada grupo de linhas com o mesmo id_amostra, dando prioridade aos resultados positivos.\nÉ necessário especificar desc dentro de arrange(), pois isso faz com que os resultados sejam ordenados em ordem alfabética inversa, colocando \"P\" no topo.\nAlém disso, adicione ungroup() no final para que os novos dados não permaneçam agrupados, o que poderia interferir em análises posteriores.\n\ndados_lab_testes &lt;- dados_lab |&gt; \n  filter(alvo != \"Dengue IgG\") |&gt; \n  group_by(id_amostra) |&gt; \n  arrange(desc(resultado)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\nEm seguida, é possível verificar novamente se o novo objeto dados_lab_testes contém apenas uma linha por teste, utilizando a combinação de count() e tabyl() como feito na Tarefa A.\nEsta tabela mostra que todos os IDs de amostra únicos estão presentes em apenas uma linha cada:\n\ndados_lab_testes |&gt; \n  count(id_amostra) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 884       1\n\n\n\n\n\n\n\n\nEm seguida, verifique o número de testes por ID de notificação nos novos dados consolidados.\nPode-se observar que existem 26 linhas com o mesmo id_notificacao que outra linha, mas apenas entre os casos testados com microscopia de sangue total para malária.\n\ndados_lab_testes |&gt; \n  count(exame, id_notificacao) |&gt; \n  tabyl(exame, n)\n\n                       exame   1  2\n            Cultura de fezes  45  0\n          Dengue NS1/IgG/IgM 215  0\n                 Hemocultura  33  0\n                   IgM ELISA  88  0\n Microscopia de sangue total 451 26\n\n\nInvestiga-se mais detalhadamente analisando um caso de exemplo com id_notificacao “043228”.\nIsso mostra que este caso foi testado duas vezes, com duas amostras diferentes, com uma semana de intervalo. O primeiro resultado foi positivo e o segundo resultado foi negativo.\n\ndados_lab_testes |&gt; \n  filter(id_notificacao == \"043228\")\n\n# A tibble: 2 × 7\n  nome_laboratorio    id_notificacao id_amostra data_exame exame alvo  resultado\n  &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;      &lt;IDate&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;    \n1 Hospital Universit… 043228         27c37cd8   2024-06-18 Micr… Plas… Positivo \n2 Hospital Universit… 043228         d2271be0   2024-06-25 Micr… Plas… Negativo \n\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQual afirmação sobre os dados laboratoriais está correta?\n\n Todos os casos de diferentes doenças são retestados Alguns casos de malária são retestados Todos os casos de malária são retestados\n\nSerá necessário deduplicar os dados laboratoriais para ligar com os dados de notificação?\n\n Sim - precisamos de uma linha representando o resultado do laboratório por notificação Não - os dados já estão suficientemente deduplicados\n\n\n\n\nSe respondeu que precisa deduplicar, está correto!\nDeduplicar os dados para ter uma linha por ID de notificação priorizando os resultados positivos, para que seja possível fazer a vinculação com os dados da notificação.\nPara fazer isso, siga um processo semelhante ao da tarefa B, utilizando a estrutura de dados produzida pela tarefa B:\n\nAgrupar por id_notificacao\nOrdenar pelo valor do resultado do exame, de modo a que os valores que começam por P tenham prioridade na linha superior, seguidos por N (negativo) e depois I (indeterminado).\nEm seguida, mantenha a primeira linha dentro de cada grupo de id_notificacaos, utilizando slice().\nAo fazer isto, crie um novo objeto chamado dados_lab_casos.\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAqui está o código para deduplicar as linhas dentro de cada grupo de linhas com o mesmo id_notificacao dando prioridade aos resultados positivos. Mais uma vez, você precisa especificar desc dentro de arrange(). Isto funciona perfeitamente porque a ordem de prioridade desejada para os resultados — positivos, depois negativos, depois indeterminados — alinha-se com a ordem alfabética inversa (P vem antes de N, que vem antes de I, quando ordenado de forma descendente).\nSe a sua ordem de prioridades fosse mais complexa ou não correspondesse à ordem alfabética (por exemplo, se “indeterminado” precisasse de vir antes de “negativo”), teria de converter a coluna de resultados num fator e explicitamente definir a ordem desejada dos seus níveis. Não se esqueça de desagrupar novamente no final.\n\ndados_lab_casos &lt;- dados_lab_testes |&gt; \n  group_by(id_notificacao) |&gt; \n  arrange(desc(resultado)) |&gt; \n  slice(1) |&gt;\n  ungroup()\n\nVocê pode então verificar novamente se o novo objeto dados_lab_casos tem apenas uma linha por exame, usando a combinação de count() e tabyl() como fez na Tarefa A. Esta tabela lhe mostra que todos os IDs de amostra únicos estão presentes em apenas uma linha cada:\n\ndados_lab_casos |&gt; \n  count(id_notificacao) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 858       1\n\n\n\n\n\n\n\n\n\nAgora temos dois objetos que podemos utilizar para a análise de dados laboratoriais: dados_lab_testes e dados_lab_casos.\n\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQue objeto você deve utilizar para analisar os exames?\n\n dados_lab_testes dados_lab_casos nenhum destes\n\nQuantos exames foram conduzidos para examinar para malária (através da microscopia de sangue total)?\n\n 215 503 88 190\n\nQue porcentagem dos exames para cólera (através da cultura de fezes) foi positiva?\n\n 21% 11% 84% 87%\n\nQuais exames tiveram a maior porcentagem de resultados indeterminados?\n\n IgM ELISA (para detecção de febre amarela) Cultura de fezes (para detecção de cólera) Hemocultura (para detecção de febre tifóide)\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUtilizando tabyl() podemos ver o número de resultados positivos, negativos e indeterminados por exame. Você pode adicionar uma série de funções adorn() para mostrar porcentagens e totais.\n\ntabyl(dados_lab_testes, exame, resultado) |&gt; \n  adorn_totals(where = \"col\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n                       exame Indeterminado    Negativo    Positivo        Total\n            Cultura de fezes    11.1%  (5)  4.4%   (2) 84.4%  (38) 100.0%  (45)\n          Dengue NS1/IgG/IgM     0.0%  (0) 13.5%  (29) 86.5% (186) 100.0% (215)\n                 Hemocultura     6.1%  (2) 72.7%  (24) 21.2%   (7) 100.0%  (33)\n                   IgM ELISA    11.4% (10) 51.1%  (45) 37.5%  (33) 100.0%  (88)\n Microscopia de sangue total    11.1% (56) 51.1% (257) 37.8% (190) 100.0% (503)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQue data frame de dados laboratoriais você deve usar para contar o número de casos supeitos examinados?\n\n dados_lab_bruto dados_lab_casos dados_lab_testes dados_lab\n\nQuantos casos suspeitos foram examinados nos dados laboratoriais de 2024?\n\n 858 1314 884\n\nExistem mais casos suspeitos nos dados de notificação ou nos dados laboratoriais?\n\n dados de notificação Dados laboratoriais\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (experimente primeiro!)\n\n\n\n\n\nVocê pode simplesmente analisar o número de linhas no data frame dados_lab_casos para ver o número de casos suspeitos que foram examinados.\n\nnrow(dados_lab_casos)\n\n[1] 858\n\n\nEste número é inferior ao número de casos suspeitos que estavam nos dados limpos de vigilância de doenças de notificação compulsória (dados_notif) - o que sugere que nem todos os casos suspeitos em 2024 foram examinados quando estes dados estavam disponíveis.\n\nnrow(dados_notif)\n\n[1] 987"
  },
  {
    "objectID": "pages/multidisease_surveillance.pt.html#etapa-6.-vinculação-e-processamento-final",
    "href": "pages/multidisease_surveillance.pt.html#etapa-6.-vinculação-e-processamento-final",
    "title": "Ligação e análise de dados de notificação e de dados laboratoriais em R",
    "section": "",
    "text": "Agora que ambas as listas de casos estão limpas e têm uma linha por caso suspeito, você pode vinculá-las para permitir a análise completa solicitada pelo seu chefe.\n\n\n\n\nCriar um novo objeto chamado dados_vinculados, utilizando uma função xxx_join() do {dplyr}. Pretende-se manter todas as notificações, mas adicionar resultados de exames, quando disponíveis, para cada caso suspeito.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQue função traz a abordagem correta se você quiser manter todas as linhas dos seus dados de notificação e trazer os resultados dos dados laboratoriais?\n\n left_join(dados_notif, dados_lab_casos… full_join(dados_notif, dados_lab_casos… right_join(dados_notif, dados_lab_casos…\n\nQue identificador deve ser utilizado para vincular as duas listas de casos?\n\n id_amostra id_notificacao id_amostra e data de notificação id_notificacao e data de notificação\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (experimente primeiro!)\n\n\n\n\n\nLigue os dados utilizando o left_join() com os dados de notificação como data frame principal à esquerda. Isto manterá todas as linhas deste data frame e apenas introduzirá os resultados dos exames nos dados laboratoriais especificados à “direita” da função.\n\ndados_vinculados &lt;- left_join(dados_notif, dados_lab_casos, \n                         by = \"id_notificacao\")\n\nVocê está ligando através da coluna id_notificacao, que está presente, completa e limpa em ambas as listas de casos.\nNota: Você tem sorte de trabalhar com um exemplo de ligação tão simples! Normalmente, seria necessário limpar e verificar a coluna de ID, ou vincular a outras colunas como o nome e a data de nascimento. Em Feveria, os clínicos são fantásticos em atribuir consistentemente IDs de notificação a cada doente, incluindo nos formulários de amostra enviados para o laboratório, e ainda o pessoal do laboratório é igualmente brilhante em registrar o ID de notificação nos seus sistemas de laboratório, para que os resultados possam ser associados ao caso.\n\n\n\n\n\n\nAgora, verifique os seus dados e revise algumas coisas.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuantas linhas tem o seu novo data frame dados_vinculados?\n\n 987 884 858\n\nComo este resultado se compara aos seus dados de notificação originais?\n\n mais linhas que o original o mesmo número de linhas menos linhas\n\nQue termo melhor descreve a vinculação que você acabou de realizar?\n\n muitos-para-um um-para-um muitos-para-muitos\n\nQuantos resultados de laboratório NÃO foram vinculados? (dica: use anti-join())?\n\n 30 19 0\n\nQuão sortudo você foi por sua vinculação de dados ter sido tão bem-sucedida?\n\n O quê? Nem toda vinculação de dados é simples assim?? Bastante! Normalmente alguns registros não têm correspondência.\n\nQuais são razões típicas para os dados laboratoriais não possuírem correspondência entre os dados de notificação?\n\n Existem erros de digitação nas colunas utilizadas para a vinculação, e por isso elas não são reconhecidas como correspondências Os dados laboratoriais podem conter casos adicionais de outras clínicas ou países Os dados laboratoriais podem incluir amostras de exames Notificações podem ter sido acidentalmente perdidas nos dados de notificação apesar da amostra ter sido examinada em laboratório Todas as opções acima\n\nQuantos casos supeitos não possuem um resultado?\n\n 83 100 129\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nVerifique o número de linhas em cada quadro de dados com o comando nrow() ou olhando as informações do objeto no seu ambiente. É possível ver que esta foi simplesmente uma vinculação de um para um, porque cada linha tinha um único id_notificacao, então uma linha nos dados de notificação se vinculou exatamente a uma linha dos dados laboratoriais.\nNúmero de linhas nos dados de notificação\n\nnrow(dados_notif)\n\n[1] 987\n\n\nNúmero de linhas nos dados vinculados\n\nnrow(dados_vinculados)\n\n[1] 987\n\n\nPara verificar se houve algum resultado de laboratório que não estava ligado aos dados de notificação, é possível usar anti_join(). Desta vez, o objeto dados_lab_casos está à esquerda, pois a função avalia quantas linhas do data frame da esquerda não foram encontradas no data frame da direita, ao realizar a correspondência por id_notificacao. Aqui não é necessário gerar um novo data frame, você pode simplesmente passar, através de um pipe, o resultado para nrow() para contar o número de linhas. A saída é 0, o que mostra que não houve resultados sem vínculo - incrível!\n\nanti_join(dados_lab_casos, dados_notif, \n          by = \"id_notificacao\") |&gt; nrow()\n\n[1] 0\n\n\nFinalmente, para verificar o número de notificações sem um resultado, você pode efetuar um anti_join ao colocar dados_notif primeiro:\n\nanti_join(dados_notif, dados_lab_casos, \n          by = \"id_notificacao\") |&gt; nrow()\n\n[1] 129\n\n\nOu, pode simplesmente tabular o número de valores em falta na coluna resultado em dados_vinculados (já que a coluna resultado provém dos dados laboratoriais).\n\ntabyl(is.na(dados_vinculados$resultado)) \n\n is.na(dados_vinculados$resultado)   n   percent\n                             FALSE 858 0.8693009\n                              TRUE 129 0.1306991\n\n\nAmbas as abordagens mostram que 129 casos suspeitos não têm um resultado de exame laboratorial.\n\n\n\n\n\n\n\n\n\nUtilize mutate() para criar uma nova coluna categoria_caso atualizando o rótulo dos casos suspeitos de acordo com o seu resultado laboratorial. As categorias devem ser as seguintes:\n\nSe o resultado for positivo: Confirmado\nSe o resultado for negativo: Descartado\nSe o resultado for indeterminado ou inexistente: Suspeito\n\nIsto significa que todos os casos nos dados de notificação são inicialmente suspeitos quando notificados, e permanecem suspeitos se não houver um resultado conclusivo no exame.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQual é a função mais apropriada para criar essa nova coluna?\n\n case_when() if_else() case_match()\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nVocê deve utilizar o case_when() para criar a nova coluna. Esta função é ideal para aplicar múltiplas condições lógicas para criar múltiplos valores, enquanto que case_match() é melhor para substituir valores específicos, e if_else() é melhor se houver apenas dois valores possíveis.\n\ndados_vinculados &lt;- dados_vinculados |&gt; \n  mutate(categoria_caso = case_when(resultado==\"Positivo\" ~ \"Confirmado\",\n                                   resultado==\"Negativo\" ~ \"Descartado\",\n                                   resultado==\"Indeterminado\" | is.na(resultado) ~ \"Suspeito\"))\n\n\n\n\n\n\n\n\n\n\nUtilizar tabyl() em geral, e também a tabulação cruzada por doença para responder às perguntas abaixo.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuantos casos nos dados de notificação vinculados não possuem um resultado positivo ou negativo?\n\n 202 347 250\n\nQue porcentagem dos casos nos dados de notificação POSSUEM um resultado positivo ou negativo?\n\n 60.1% 79.5% 92.2%\n\nPor que existem mais casos suspeitos remanescentes do que notificações sem vinculação?\n\n Casos suspeitos incluem notificações sem um resulado laboratorial e com um resultado indeterminado Existem casos suspeitos adicionais sendo trazidos dos laboratórios Existe algum problema com os dados\n\nQuais doenças possuíram a maior porcentagem de casos que permaneceram suspeitos após a vinculação?\n\n Cólera Malária Dengue Febre amarela\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nMais uma vez, você pode utilizar tabyl() para ver a distribuição das categorias de casos pelas notificações. O número total de casos suspeitos, ou seja, os que não têm qualquer resultado laboratorial ou têm um resultado indeterminado, é de 202. Isto significa que 785 casos, ou seja, 79,5%, tiveram um resultado laboratorial definitivo.\n\ntabyl(dados_vinculados, categoria_caso) \n\n categoria_caso   n   percent\n     Confirmado 438 0.4437690\n     Descartado 347 0.3515704\n       Suspeito 202 0.2046606\n\n\nPode também fazer uma tabela cruzada dos resultados originais (indeterminado/negativo/positivo) na coluna resultado com os novos resultados categoria_caso, primeiro para verificar se a sua lógica funcionou, e para ver como os valores originais se relacionam com os valores da nova coluna. Isto mostra que, além das 129 notificações que não foram vinculadas (com NA na coluna resultado), 73 tiveram resultados indeterminados, e assim foram classificadas como casos suspeitos.\n\ntabyl(dados_vinculados, categoria_caso, resultado) \n\n categoria_caso Indeterminado Negativo Positivo NA_\n     Confirmado             0        0      438   0\n     Descartado             0      347        0   0\n       Suspeito            73        0        0 129\n\n\nFinalmente, você pode também fazer uma tabela cruzada com o nome da doença para ver as categorias de casos por doença. Adicione adorn_xxx() para formatar as porcentagens. A tabela mostra que 22% dos casos de febre amarela permaneceram suspeitos, e que essa porcentagem foi a mais elevada em comparação com as outras doenças.\n\ntabyl(dados_vinculados, doenca_notificada, categoria_caso) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n doenca_notificada  Confirmado  Descartado    Suspeito        Total\n            colera 82.6%  (38)  4.3%   (2) 13.0%   (6) 100.0%  (46)\n            dengue 68.1% (186) 10.6%  (29) 21.2%  (58) 100.0% (273)\n     febre amarela 33.0%  (33) 45.0%  (45) 22.0%  (22) 100.0% (100)\n     febre tifoide 20.0%   (7) 68.6%  (24) 11.4%   (4) 100.0%  (35)\n           malaria 32.6% (174) 46.3% (247) 21.0% (112) 100.0% (533)\n             Total 44.4% (438) 35.2% (347) 20.5% (202) 100.0% (987)\n\n\n\n\n\n\n\n\nUtilize tabyl() mais uma vez para esta tarefa, analisando os resultados por doença. Pense no denominador correto!\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQue porcentagem de casos suspeitos repotados em em 2024 eram casos verdadeiros, de acordo com os resultados dos exames?\n\n 44% 56% 59%\n\nQue porcentagem dos casos suspeitos de malária eram realmente malária?\n\n 86% 41% 23%\n\nQue porcentagem de casos suspeitos de dengue eram realmente dengue?\n\n 87% 41% 23%\n\n\n\n\n\n\n\n\n\n\nClique para ler uma dica\n\n\n\n\n\nDividir o número de casos confirmados (ou seja, aqueles com um resultado positivo) pelo número de casos confirmados e descartados (ou seja, aqueles com um resultado positivo ou negativo). Obtém-se assim uma taxa de positivos, que se aproxima da porcentagem de casos suspeitos que eram efetivamente casos. Os resultados indeterminados são excluídos porque não fornecem um resultado claro e distorceriam a taxa de positivos.\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nFiltre os casos suspeitos e, em seguida, faça uma tabela cruzada para ver a porcentagem de casos originalmente suspeitos que foram confirmados ou descartados, entre aqueles com resultados de exame válidos.\nUma vez que existe uma linha de totais, pode ver-se que 56% dos casos suspeitos em geral foram confirmados, entre os que tinham um resultado válido. Também se pode ver que 41% e 87% dos casos de malária e dengue, respetivamente, foram confirmados.\n\ndados_vinculados |&gt; \n  filter(categoria_caso != \"Suspeito\") |&gt; \n  tabyl(doenca_notificada, categoria_caso) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n doenca_notificada  Confirmado  Descartado        Total\n            colera 95.0%  (38)  5.0%   (2) 100.0%  (40)\n            dengue 86.5% (186) 13.5%  (29) 100.0% (215)\n     febre amarela 42.3%  (33) 57.7%  (45) 100.0%  (78)\n     febre tifoide 22.6%   (7) 77.4%  (24) 100.0%  (31)\n           malaria 41.3% (174) 58.7% (247) 100.0% (421)\n             Total 55.8% (438) 44.2% (347) 100.0% (785)\n\n\n\n\n\n\n\n\n\nTarefa A: Criar uma nova lista de casos chamada dados_vinculados_confirmados.\nEsta é a que você utilizará nos relatórios oficiais de vigilância.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nPor que estamos optando por relatar apenas casos confirmados em nossos dados de vigilância?\n\n Relatar casos confirmados pode ser mais confiável e preciso quando a porcentagem de resultados positivos é baixa e os exames laboratoriais são rotineiros, ajudando assim a evitar a superestimação da carga da doença Relatar casos confirmados é mais lento, o que nos dá mais tempo para ter certeza do que estamos relatando Porque queremos esconder o número real de casos\n\nQual função é importante para criar a nova lista de linhas (linelist)?\n\n filter() arrange() mutate()\n\nQuantas linhas há neste novo data frame?\n\n 389 438 858\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nA sua unidade de vigilância quer concentrar-se em notificar os casos confirmados. Isto deve-se ao fato de os exames laboratoriais serem rotina em Feveria, tendo em vista que a notificação de casos suspeitos seria desnecessariamente imprecisa, com uma elevada porcentagem de casos suspeitos sendo descartados.\nA decisão de publicar casos suspeitos pode ser diferente em outros contextos. Por exemplo, se a taxa de positivos for elevada (a maioria dos casos são casos confirmados se examinados) e os exames em si não forem comuns, ou se os exames demorarem muito tempo e resultarem numa notificação tardia, isso sugeriria que as tendências de casos suspeitos são suficientemente precisas e também mais oportunas do que esperar pela confirmação laboratorial.\nCriar a nova lista de casos com a função filter():\ndados_vinculados_confirmados &lt;- dados_vinculados |&gt; \n  filter(categoria_caso==\"Confirmado\")\nE verifique o número de linhas consultando as informações no seu ambiente ou com nrow():\nnrow(dados_vinculados_confirmados)\n[1] 438"
  },
  {
    "objectID": "pages/multidisease_surveillance.pt.html#passo-7.-análise-descritiva-dos-casos-confirmados",
    "href": "pages/multidisease_surveillance.pt.html#passo-7.-análise-descritiva-dos-casos-confirmados",
    "title": "Ligação e análise de dados de notificação e de dados laboratoriais em R",
    "section": "",
    "text": "Agora que você tem sua lista de casos confirmados de doenças de notificação compulsória registrados em Feveria em 2024, você está pronto para conduzir a parte final da sua análise de vigilância! Especificamente, isso significa resumir as cinco doenças de notificação compulsória por área geográfica e tempo.\nDica: Normalmente, a análise de vigilância incluiria também uma análise por pessoa. Você pode expandir este estudo de caso, analisando também por variáveis demográficas.\n\n\n\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQual doença de notificação compulsória foi mais comumente relatada em 2024, quando restringimos apenas os casos confirmados?\n\n Dengue Malária Febre Amarela\n\nPor que a doença mais notificada muda quando olhamos os casos confirmados e suspeitos?\n\n A sensibilidade e especificidade do diagnóstico clínico pode variar por doença O desempenho dos exames utilizados nos laboratórios pode variar por doença Pode existir vieses de notificação Todas as opções acima!\n\nQual distrito relatou o maior número de casos confirmados de cólera em 2024?\n\n Lago Minara Feveria Central Kasara\n\nQuantos casos confirmados de cólera relatados em 2024 foram entre moradores de Feveria Central?\n\n 35 42 4\n\nQual distrito relatou mais casos confirmados de malária em 2024?\n\n Lago Minara Feveria Central Kasara\n\nEstes dados confirmam que a dengue é a doença infecciosa mais comum em Feveria?\n\n Não - uma doença diferente pode estar sendo subnotificada e/ou não ser de notificação compulsória Sim - se é a mais notificada então deve ser a mais comum\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nUtilizando tabyl() podemos ver que a dengue foi a doença mais frequentemente notificada em Feveria em 2024 quando consideramos apenas os casos confirmados, com 186 casos.\n\ndados_vinculados_confirmados |&gt; \n  tabyl(doenca_notificada) \n\n doenca_notificada   n    percent\n            colera  38 0.08675799\n            dengue 186 0.42465753\n     febre amarela  33 0.07534247\n     febre tifoide   7 0.01598174\n           malaria 174 0.39726027\n\n\nNote que isto é diferente dos casos suspeitos, em que a malária foi a doença mais notificada (com 533 casos suspeitos)! Isto foi sugerido anteriormente, quando se viu que a taxa de positivos para casos suspeitos de dengue era mais elevada do que para casos suspeitos de malária. Isto pode dever-se a diferentes razões, por exemplo, o método de diagnóstico clínico utilizado para a malária pode ser menos específico (então muitos dos casos suspeitos são, na realidade, outras doenças), ou o exame utilizado para a dengue pode ser mais sensível.\nPara fazer uma tabela cruzada com o distrito de residência, adicione as funções adorn_xxx() relevantes.\n\ndados_vinculados_confirmados |&gt; \n  tabyl(doenca_notificada, distrito_de_residencia) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n doenca_notificada Feveria Central     Kasara Lago Minara        Total\n            colera      92.1% (35)  7.9%  (3)  0.0%   (0) 100.0%  (38)\n            dengue       8.6% (16) 17.2% (32) 74.2% (138) 100.0% (186)\n     febre amarela       0.0%  (0) 18.2%  (6) 81.8%  (27) 100.0%  (33)\n     febre tifoide      71.4%  (5) 28.6%  (2)  0.0%   (0) 100.0%   (7)\n           malaria      14.9% (26) 22.4% (39) 62.6% (109) 100.0% (174)\n             Total      18.7% (82) 18.7% (82) 62.6% (274) 100.0% (438)\n\n\nTal como acontece com os casos suspeitos, podemos ver que a maioria dos casos confirmados de dengue, malária e febre amarela se localizaram em Lago Minara - a zona do lago com maior densidade de mosquitos e, por conseguinte, de doenças transmitidas por vetores. A maioria dos casos confirmados de cólera e febre tifoide registou-se em Feveria Central, onde existem problemas de água e saneamento.\nOs dados sugerem que as doenças transmitidas por vetores (dengue e malária) constituem uma preocupação especial neste país tropical. No entanto, não sabemos ao certo qual é a doença mais comum e quais são os padrões subjacentes - apenas cinco doenças são de notificação compulsória e, normalmente, os casos notificados representam apenas uma fração dos casos reais na comunidade.\n\n\n\n\n\n\n\nVocê irá trabalhar na construção desta curva epidêmica, ao longo das várias tarefas abaixo.\n\n\n\n\n\n\n\n\n\n\n\nCertifique-se de especificar o argumento binwidth=7 para que cada barra no histograma represente o número de casos dentro de um período de 7 dias.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuando foi notificado o primeiro caso de febre tifoide em Feveria em 2024?\n\n Janeiro de 2024 Maio de 2024 Outubro de 2024\n\nDe acordo com este gráfico, qual foi o maior número de casos de dengue notificados em uma única semana em 2024?\n\n 10 20 30 É muito difícil responder isto a partir do gráfico empilhado!\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAqui está um código simples para construir a curva epidêmica. Note que ainda não está controlando as cores, nem especificando em que dia da semana começa cada período de 7 dias.\n\ndados_vinculados_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = data_notificacao, fill = doenca_notificada)), binwidth=7)\n\n\n\n\n\n\n\n\nConsulte o capítulo sobre datas do Manual de R para Epidemiologistas caso queira uma formatação de data mais específica, por exemplo, de modo que cada barra represente uma semana de segunda a domingo, ou o eixo x indique o número da semana (semanas 1 - 52).\nImportante - não é simples visualizar as tendências por doença quando os dados estão empilhados dessa forma! Para ver essas tendências temporais, você deve produzir um histograma para cada doença.\n\n\n\n\n\n\nUtilize facet_wrap() para criar facilmente vários mini-plots, um por doença. Para entender isto melhor, você pode consultar a seção seção de facetas do capítulo sobre ggplot2 no Manual de R para Epidemiologistas\n\n\n\n\n\n\nPerguntas\n\n\n\n\nDe acordo com este gráfico facetado, qual foi o maior número de casos de dengue notificados em uma mesma semana em 2024?\n\n 11 15 29 Ainda não consigo responder!\n\nDentre os casos de dengue notificados naquela semana, em que distrito moravam?\n\n Todos os três distritos Feveria Central Kasara Lago Minara Este gráfico não mostra esta informação\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAgora você pode ver uma curva epidêmica por doença! E pode ver que, durante uma semana de julho, foram notificados 15 casos de dengue. No entanto, este gráfico ainda não apresenta qualquer informação geográfica.\n\ndados_vinculados_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = data_notificacao)), binwidth=7) + \n  facet_wrap(.~doenca_notificada)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nDentre os 15 casos de dengue notificados na mesma semana de julho de 2024, em que distritos moravam?\n\n Todos os três distritos Feveria Central Kasara Lago Minara\n\nEm qual distrito foi notificado o primeiro caso de febre tifoide de 2024?\n\n Kasara Feveria Central Lago Minara Ainda não consigo responder!\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAgora você pode ver uma curva epidêmica por doença, com a coloração refletindo o distrito de residência de onde é o caso\nPode-se ver que entre os 15 casos de dengue notificados na mesma semana, estes residiam em três distritos diferentes. Você também pode ver que o primeiro caso de febre tifoide foi notificado em Feveria Central.\n\ndados_vinculados_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = data_notificacao, fill = distrito_de_residencia)), binwidth=7) + \n  facet_wrap(.~doenca_notificada)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVocê pode especificar:\n\nO tema/aparência geral do gráfico (por exemplo, cor de fundo, aparência das linhas de grade)\nO título e os rótulos\nAs cores das barras (com scale_fill_manual())\nA formatação e o espaçamento das datas ao longo do eixo x (com scale_x_date)\nMuitas outras coisas!\n\n\n\n\n\n\n\nPerguntas\n\n\n\n\nA cólera e a febre tifoide aparentam ser endêmicas?\n\n Não - os dados sugerem pequenos surtos ocasionais Sim, ambas são endêmicas\n\nHouve alguma época específica do ano em que a malária atingiu o pico em 2024?\n\n Sim - por volta de novembro/dezembro Sim - por volta de julho/agosto (verão) Não, é consistentemente alta\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAqui está o código totalmente formatado. Observe que algumas outras alterações incluem especificar que queremos apenas duas colunas de mini gráficos dentro do facet_wrap() e que a etiqueta de data ao longo do eixo x deve apenas mostrar o dia e o mês (não o ano, uma vez que todos os casos são em 2024).\n\ndados_vinculados_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = data_notificacao, fill = distrito_de_residencia)), binwidth=7) +\n  facet_wrap(.~doenca_notificada, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"Distrito de residência\",\n       x = \"Data comunicada pela clínica\",\n       y = \"Contagem\",\n       subtitle = \"Número de casos confirmados de cólera, dengue, malária, febre tifoide e febre amarela por semana em Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n\n\n\n\n\n\nTambém podemos ver na curva epidêmica que a cólera e a febre tifoide parecem estar ocorrendo como surtos isolados, em vez de mostrarem endemicidade. No entanto, a malária e a dengue estiveram presentes em Feveria durante todo o ano, com a malária atingindo um pico mais evidente nos meses de verão.\n\n\n\n\n\n\nDesta vez, utilize group_by() e summarize() para produzir uma tabela por distrito com as datas mais antigas e mais recentes dos relatórios.\nVocê pode modificar a sua tabela com um filter() para criar esta tabela para um distrito de cada vez.\n\n\n\n\n\n\nPerguntas\n\n\n\n\nQuando foi notificado o primeiro caso de dengue de 2024 em Feveria?\n\n 18 de janeiro de 2024 17 de janeiro de 2024 12 de fevereiro de 2024\n\nQuando foi notificado o último caso de dengue em Feveria Central de 2024?\n\n 22 de agosto de 2024 18 de novembro de 2024 25 de dezembro de 2024\n\n\n\n\n\n\n\n\n\n\nClique para ver a solução (tente sozinho primeiro!)\n\n\n\n\n\nAgrupe os dados por doença e, em seguida, resuma a primeira e a última data para ver a cronologia geral de cada doença em Feveria.\n\ndados_vinculados_confirmados |&gt; \n  group_by(doenca_notificada) |&gt; \n  summarize(primeira_notificacao = min(data_notificacao), \n            ultima_notificacao = max(data_notificacao)) |&gt;\n  ungroup()\n\n# A tibble: 5 × 3\n  doenca_notificada primeira_notificacao ultima_notificacao\n  &lt;chr&gt;             &lt;date&gt;               &lt;date&gt;            \n1 colera            2024-06-03           2024-09-23        \n2 dengue            2024-01-17           2024-11-18        \n3 febre amarela     2024-03-08           2024-08-23        \n4 febre tifoide     2024-05-02           2024-11-07        \n5 malaria           2024-01-08           2024-12-25        \n\n\nAdicione um filter() ao código para ver as datas da primeira e da última notificações no distrito em que está interessado.\n\ndados_vinculados_confirmados |&gt; \n  filter(distrito_de_residencia == \"Feveria Central\") |&gt; \n  group_by(doenca_notificada) |&gt; \n  summarize(primeira_notificacao = min(data_notificacao), \n            ultima_notificacao = max(data_notificacao)) |&gt;\n  ungroup()\n\n# A tibble: 4 × 3\n  doenca_notificada primeira_notificacao ultima_notificacao\n  &lt;chr&gt;             &lt;date&gt;               &lt;date&gt;            \n1 colera            2024-06-03           2024-09-23        \n2 dengue            2024-01-29           2024-08-22        \n3 febre tifoide     2024-05-02           2024-11-07        \n4 malaria           2024-01-29           2024-12-17"
  },
  {
    "objectID": "pages/multidisease_surveillance.pt.html#conclusão",
    "href": "pages/multidisease_surveillance.pt.html#conclusão",
    "title": "Ligação e análise de dados de notificação e de dados laboratoriais em R",
    "section": "",
    "text": "Uau! De acordo com os objetivos deste estudo de caso, você conseguiu fazer o seguinte:\n\nUtilizar funções-chave do R para limpar, remodelar e vincular data frames, além de criar novas colunas utilizando condições lógicas.\nPara orientar o processamento dos dados, você realizou inspeções e verificações de dados ao longo do caminho\nVocê conduziu uma análise descritiva detalhada para compreender os dados dos exames e notificações, antes e depois da vinculação. Em resposta às quatro perguntas iniciais do seu supervisor, você pode dizer:\n\nQuantos casos suspeitos das diferentes doenças de notificação compulsória foram notificados em 2024, e qual foi o mais comum? A malária foi a doença de notificação compulsória mais comum em Feveria em 2024, notificada através do sistema de vigilância de doenças de notificação compulsória: Foram notificados 533 casos suspeitos de malária, 273 casos suspeitos de dengue, 100 de febre amarela, 46 de cólera e 35 de febre tifoide.\nQual a porcentagem de casos acabaram sendo confirmados? Quase 80% dos casos notificáveis notificados em 2024 tinham um resultado de exame laboratorial no momento em que o conjunto de dados vinculados foi criado, com alguma variação por doença. No total, 56% dos casos notificados acabaram por ser confirmados, mas esta percentagem variou entre 23% para a febre tifoide (7 casos confirmados de 31 casos suspeitos com resultados de exames) e 95% para a cólera (38 casos confirmados de 40 casos suspeitos com resultados de exames). Além disso, a taxa de positivos foi mais elevada para a suspeita de dengue do que para a suspeita de malária (87% contra 41%).\nQuantos casos confirmados das diferentes doenças de notificação compulsória foram notificados em 2024 e qual foi o mais comum? Os casos confirmados seguiram uma tendência ligeiramente diferente da dos casos suspeitos: a infecção mais notificada foi a dengue, com 186 casos, seguida da malária (174), da cólera (38), da febre amarela (33) e da febre tifoide (7).\nComo é que os casos confirmados se distribuem geográfica e temporalmente em Feveria? Feveria registrou transmissão de dengue e malária ao longo do ano, com picos no verão, e concentrados no distrito de Lago Minara. Feveria também registrou surtos pequenos e pouco frequentes de doenças diarreicas, por exemplo, cólera e febre tifoide, particularmente na área urbana de Feveria Central, onde pode haver problemas com água e saneamento.\n\nPor último, você refletiu sobre a forma como os processos envolvidos nos sistemas de vigilância de doenças de notificação compulsória e nos exames laboratoriais, por exemplo, a transferência de dados entre clínicas e laboratórios, podem afetar a qualidade e a integridade dos dados e, como consequência, os seus resultados.\n\nHá muito mais potencial pela frente. Você pode explorar padrões de doença por idade ou sexo, calcular taxas de doença com dados populacionais e até analisar atrasos na notificação, examinando as diferentes datas nos seus conjuntos de dados.\nVocê construiu uma base sólida e está bem equipado para levar a sua análise para o nível seguinte. Continue firme - descobertas emocionantes o aguardam!\nPara saber mais, consulte os outros estudos de caso ou mergulhe no Manual de R para Epidemiologistas."
  },
  {
    "objectID": "pages/multidisease_surveillance.pt.html#código-para-limpeza-e-análise-dos-dados",
    "href": "pages/multidisease_surveillance.pt.html#código-para-limpeza-e-análise-dos-dados",
    "title": "Ligação e análise de dados de notificação e de dados laboratoriais em R",
    "section": "",
    "text": "Veja abaixo um script de todas as etapas de limpeza de dados e análises descritivas. Repare como as análises são combinadas no final ao invés de intercaladas entre os passos de limpeza. Esta é uma forma mais organizada de estruturar o seu script.\nPara simplificar, o código abaixo não inclui todas as inspeções e verificações realizadas ao longo do processo, mas você pode optar por criar uma seção específica para esses verificações.\nO início do seu script também deve trazer informações que ajudem o leitor a entender para que ele serve, além de comentários ao longo do código. Você mesmo vai agradecer por ter incluído esses comentários no futuro!\n\n\n\n\n\n\nCódigo para limpar e analisar dados de notificação e dados laboratoriais de Feveria, 2024\n\n\n\n\n\n\n# Código para limpar e analisar dados de notificação e dados laboratoriais de Feveria, 2024\n# Data:\n# Autor:\n\n# Instalar os pacotes ----------------------------------------------\n# Verificar se o pacote \"pacman\" está instalado\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# Instala (se necessário) a partir do CRAN e carrega os pacotes a serem usados\npacman::p_load(\n  rio,        # importação de dados\n  skimr,      # visão geral dos dados\n  janitor,    # limpeza de dados e tabelas\n  lubridate,  # manipulação de datas\n  epikit,     # criação de categorias de idade\n  gtsummary,  # estatísticas descritivas, testes e regressão\n  apyramid,   # gráficos de pirâmides etárias\n  flextable,  # tabelas prontas para apresentação\n  naniar,     # análise de dados faltantes\n  remotes,    # instalação de pacotes para baixar dados\n  tidyverse   # manipulação e visualização de dados\n)\n\n# Importar os dados ------------------------------------------------\n\n# dados de notificação\ndados_notif_bruto &lt;- import(\"data/notificacoes_multidoencas.xlsx\")\n\n# Dados laboratoriais\ndados_lab_bruto &lt;- import(\"data/testes_multidoencas.csv\")\n\n# Limpar os dados de notificação -----------------------------------\ndados_notif &lt;- dados_notif_bruto |&gt; \n  clean_names() |&gt; \n  rename(data_notificacao = data_comunicada_pela_unidade_de_saude_comunidade) |&gt; \n  select(id_notificacao, distrito_de_residencia, doenca_notificada, data_notificacao) |&gt; \n  mutate(distrito_de_residencia = case_match(str_to_title(distrito_de_residencia),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\")) |&gt; \n  mutate(data_notificacao = ymd(data_notificacao)) \n\n\n# Limpar e consolidar os dados laboratoriais -----------------------\n# Padronizar valores\ndados_lab &lt;- dados_lab_bruto |&gt; \n  mutate(resultado = case_match(resultado, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positivo\",\n                            \"N\" ~ \"Negativo\",\n                            \"I\" ~ \"Indeterminado\"))\n\n# Criar base em nível de exame laboratorial\ndados_lab_testes &lt;- dados_lab |&gt; \n  filter(alvo != \"Dengue IgG\") |&gt; \n  group_by(id_amostra) |&gt; \n  arrange(desc(resultado)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Criar base em nível de caso\ndados_lab_casos &lt;- dados_lab_testes |&gt; \n  group_by(id_notificacao) |&gt; \n  arrange(desc(resultado)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Vincular dados de notificação e dados laboratoriais --------------\ndados_vinculados &lt;- left_join(dados_notif, dados_lab_casos, by = \"id_notificacao\")\n\n# Limpar os dados --------------------------------------------------\ndados_vinculados &lt;- dados_vinculados |&gt; \n  mutate(categoria_caso = case_when(resultado==\"Positivo\" ~ \"Confirmado\",\n                                   resultado==\"Negativo\" ~ \"Descartado\",\n                                   resultado==\"Indeterminado\" | is.na(resultado) ~ \"Suspeito\"))\n\ndados_vinculados_confirmados &lt;- dados_vinculados |&gt; \n  filter(categoria_caso==\"Confirmado\")\n\n# ANÁLISE ----------------------------------------------------------\n# Número de casos suspeitos em Feveria\ntabyl(dados_notif, doenca_notificada)\n\n# Distribuição de casos suspeitos por distrito\ntabyl(dados_notif, doenca_notificada, distrito_de_residencia) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n# Distribuição de resultados por exames específicos\ntabyl(dados_lab_testes, exame, resultado) |&gt; \n    adorn_totals(where = \"col\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribuição da categoria de caso, nos dados vinculados: todos os casos\ntabyl(dados_vinculados, categoria_caso) \n\n# Distribuição da categoria de caso por doença, nos dados vinculados: todos os casos\ntabyl(dados_vinculados, doenca_notificada, categoria_caso) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribuição da categoria de caso por doença, nos dados vinculados: apenas casos com um resultado válido\ndados_vinculados |&gt; \n    filter(categoria_caso != \"Suspeito\") |&gt; \n    tabyl(doenca_notificada, categoria_caso) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribuição de casos confirmados por distrito\ndados_vinculados_confirmados |&gt; \n  tabyl(doenca_notificada, distrito_de_residencia) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n\n# Visualizar casos confirmados ao longo do tempo\ndados_vinculados_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = data_notificacao, fill = distrito_de_residencia)), binwidth=7) +\n  facet_wrap(.~doenca_notificada, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"Distrito de residência\",\n       x = \"Data comunicada pela clínica\",\n       y = \"Contagem\",\n       subtitle = \"Número de casos confirmados de cólera, dengue, malária, febre tifoide e febre amarela por semana em Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n# Primeira e última notificações por doença\ndados_vinculados_confirmados |&gt; \n  group_by(doenca_notificada) |&gt; \n  summarize(primeira_notificacao = min(data_notificacao), \n            ultima_notificacao = max(data_notificacao)) |&gt;\n  ungroup()"
  },
  {
    "objectID": "pages/multidisease_surveillance.pt.html#informações-sobre-o-estudo-de-caso",
    "href": "pages/multidisease_surveillance.pt.html#informações-sobre-o-estudo-de-caso",
    "title": "Ligação e análise de dados de notificação e de dados laboratoriais em R",
    "section": "",
    "text": "Autores originais: Paula Blomquist e Alanah Jansen, com apoio técnico fornecido pelo CDC Global Surveillance, Laboratory, and Data Systems Branch em colaboração com a TEPHINET.\nFonte de dados: Dados fictícios fornecidos pela Applied Epi.\n\n\n\n\n\n\n\n\n\n\n\n\nData\nAlterações efetuadas\nVersão\nAutor\n\n\n\n\nJulho de 2025\nPrimeiro rascunho\n1\nPaula Blomquist e Alanah Jansen, Applied Epi, com o apoio técnico do CDC Global Surveillance, Laboratory, and Data Systems Branch em colaboração com a TEPHINET\n\n\nAgosto de 2025\nTradução para o português\n1\nLucca Nielsen e Pedro Menezes"
  },
  {
    "objectID": "pages/multidisease_surveillance.pt.html#termos-de-uso",
    "href": "pages/multidisease_surveillance.pt.html#termos-de-uso",
    "title": "Ligação e análise de dados de notificação e de dados laboratoriais em R",
    "section": "",
    "text": "Aviso legal: A informação apresentada neste exercício e os arquivos de dados associados foram desenvolvidos para ajudar os alunos a atingir os objetivos de aprendizagem pretendidos. Os conteúdos são da responsabilidade do(s) autor(es) e não representam necessariamente as opiniões oficiais do CDC, do Departamento de Saúde e Serviços Humanos dos EUA ou da TEPHINET.\nLicença: Este estudo de caso está sob uma licença CC BY-NC-SA 4.0. Para mais informações sobre o compartilhamento e adaptação deste estudo de caso, consulte a escritura associada.\nFinanciamento Este estudo de caso foi 100% apoiado pelo Acordo de Cooperação número NU2HGH000044 financiado pelos Centros de Controle e Prevenção de Doenças (CDC) dos EUA."
  },
  {
    "objectID": "pages/multidisease_surveillance.fr.html",
    "href": "pages/multidisease_surveillance.fr.html",
    "title": "Jonction et analyse des données de notification et des données de laboratoire dans R",
    "section": "",
    "text": "Outil: R Complexité technique: Intermédiaire Complexité méthodologique: Basique\nConnaissances préalables requises: bases de R (Utilisation de Rstudio ; packages R, fonctions et arguments, utilisation de l’opérateur pipe) ainsi que les fonctions clés de tidyverse et de ggplots.\nSource: Applied Epi, avec le soutien technique du CDC Global Surveillance, Laboratory, and Data Systems Branch en collaboration avec TEPHINET.\n\n\n\nPour savoir comment utiliser nos études de cas, consultez notre site web Guide Pratique. Nous vous invitons à nous faire part de vos commentaires et suggestions à l’adresse contact@appliedepi.org. Vous pouvez également discuter de l’étude de cas ou de sujets associés sur le Forum communautaire d’Applied Epi.\n\n\nVous êtes un épidémiologiste travaillant au bureau national de surveillance de Feveria, un tout petit pays tropical. Le pays compte trois districts :\n\nFeveria Central: une zone urbaine surpeuplée, avec des infrastructures d’eau et d’assainissement parfois peu fiables.\nLac Minara: une région lacustre dotée de bonnes infrastructures, mais avec une forte présence de moustiques pendant les mois les plus chauds de l’année.\nKasara: une zone suburbaine de l’autre côté de Feveria Central.\n\nCarte des districts du pays Feveria\n\nNous sommes en janvier 2025, et votre supérieure hiérarchique souhaite que vous transfériez le traitement de routine des données sur les maladies à déclaration obligatoire d’Excel à R, et d’effectuer quelques analyses sur ces données. Elle souhaite connaître au minimum:\n\nCombien de cas suspects des différentes maladies à déclaration obligatoire ont été signalés en 2024, et quelle était la plus représentée ?\nParmi eux, quel était le pourcentage de cas confirmés ?\nCombien de cas confirmés des différentes maladies à déclaration obligatoire ont été signalés en 2024, et quelle était la plus représentée ?\nComment se répartissaient géographiquement et temporellement les cas confirmés dans la région de Feveria ?\n\nElle vous demande d’écrire le code pour importer, nettoyer, joindre et analyser les listes linéaires suivantes :\n\nDonnées de surveillance 2024 des maladies à déclaration obligatoire : Appelées également “données de notification”, il s’agit de données de surveillance sur cinq maladies à déclaration obligatoire signalées par les cliniques de Feveria : la dengue, le paludisme, le choléra, la fièvre typhoïde et la fièvre jaune. Il s’agit de cas suspects, basés sur les symptômes des patients. Les cliniciens saisissent chaque notification dans un système en ligne tous les jours de la semaine.\nDonnées 2024 sur les résultats des tests de laboratoire : Ces données sont issues des résultats des tests de laboratoire effectués par trois grands laboratoires de Feveria. Ces résultats concernent des échantillons prélevés sur les cas suspects de maladies à déclaration obligatoire enregistrés dans la première base de données ci-dessus.\n\nAllons-y !\n\n\n\nDans cette étude de cas, vous allez :\n\nUtiliser des fonctions essentielles de R pour nettoyer des données, remodeler des bases de données, fusionner différentes sources de données et créer de nouvelles colonnes à l’aide de conditions logiques pour préparer les données pour l’analyse.\nPasser en revue les données et effectuer des contrôles de leur qualité à plusieurs étapes du projet et comprendre l’importance de ces actions pour une analyse fiable.\nConduire des analyses descriptives de base pour comparer les tendances des maladies à partir de différentes sources de données, avant et après la jointure.\nInterpréter les différences de résultats selon les sources de données et comprendre comment elles reflètent la structure et la conception du système de surveillance dans son ensemble.\n\n\n\n\n\n\nCommencez par la mise en place d’un flux de travail reproductible et bien organisé. Ce processus facilitera le renouvellement de votre analyse chaque fois que cela sera nécessaire.\nTâches :\n\nCréation d’un un projet RStudio\nCréation d’une structure claire de sous-dossiers dans lesquels vous placerez votre code, vos données et vos résultats / sorties.\nCréation d’un script R, ou d’un fichier R Markdown si vous préférez. Assurez-vous que que le but du script, la date et l’auteur sont écrits sous forme de commentaires en haut du script.\nAdditionnel : Assurez-vous que votre langue de travail dans RStudio est appropriée (par ex. le français pour cet exercice)\n\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\n\nCréez un dossier dans lequel vous placerez tous les travaux de cette étude de cas. Par exemple, créez un dossier “Analyse_multi_maladies” sur le bureau de votre ordinateur. Créez votre projet RStudio dans ce dossier.\nNous suggérons de créer les sous-dossiers suivants : scripts (pour votre code), donnees (pour vos données), et resultats (pour vos résultats d’analyse).\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nCréez un dossier (par exemple “Analyse_multi_maladies” sur votre bureau) pour cet exercice. Pour créer un projet Rstudio dans votre nouveau dossier, cliquez sur l’icône New Project en haut à gauche de votre fenêtre R Studio (ou sur File puis New Project), puis surExisting Directory puis Browse pour sélectionner votre nouveau dossier. Pour plus d’informations, consultez la section Projets R du Epi R Handbook.\nOuvrez un nouveau script R en cliquant sur l’icône New File en haut à gauche de votre écran R Studio (ou sur File puis New File), puis R Script. Sauvegardez-le immédiatement à un endroit approprié, par exemple, dans le sous-dossier scripts de votre dossier de projet R.\nAu début de votre nouveau script R, écrivez sous forme de commentaires quelques informations essentielles telles que votre nom, le but du fichier et la date.\nLes paramètres R “locale” déterminent la langue et les paramètres régionaux utilisés pour les scripts R comme les formats de date et les traductions. Si vos paramètres régionaux sont différents de la langue que vous souhaitez utiliser pour votre rapport (par exemple, les paramètres anglophones au lieu des paramètres francophones), vous pouvez les remplacer par les francophones en exécutant la commande Sys.setlocale(\"LC_ALL\", \"French\"). Incluez cette commande dans votre script si nécessaire, ou ignorez-la si vos paramètres sont appropriés. Ceci est expliqué plus en détail dans le Guide pratique.\n\n\n\n\n\n\nDans votre script R, vous devez maintenant installer et charger les packages R nécessaires. Cela permet de s’assurer que les fonctions nécessaires sont disponibles pour votre analyse.\nVous aurez besoin des packages suivants : {rio} (pour l’importation des données),{skimr} (pour l’examen des données), {janitor} (pour le nettoyage des données), {lubridate} (pour le nettoyage des dates), {epikit} (pour des tâches liées à l’épidémiologie), {gtsummary} (pour les statistiques descriptives / les tests et régressions), {apyramid} (pour les pyramides des âges et des sexes), {flextable} (pour des tableaux prêts à être présentés), {naniar} (pour l’analyse des données manquantes), et {tidyverse} (pour la manipulation générale des données et autres tâches scientifiques).\nVous aurez également besoin du package{remotes} pour télécharger les données - ce que nous expliquerons dans la section sur le téléchargement.\nAlors que vous commencez, votre collègue expérimenté vous glisse : “J’ai entendu parler du package {pacman} pour facilement gérer l’instalation et le chargement des packages dans R”.\nÀ vous de jouer !\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nUtilisez la fonction p_load() de pacman pour cette tâche. Vous fournissez à la fonction une liste de packages que vous souhaitez utiliser. La fonction effectuera deux étapes pour chaque package :\n\nVérifier si le package est installé sur votre ordinateur, et l’installer si nécessaire, puis\nCharger le package pour qu’il pour qu’il puisse être utilisé pendant cette session R.\n\nSi vous n’avez pas encore installé pacman, vous devrez d’abord l’installer de manière “traditionnelle”, à l’aide de la fonction install.packages().\nNotez que l’ordre des packages dans votre fonction p_load peut être important. Si deux packages possèdent une fonction avec un nom identique (par exemple select() dans le package MASS et select() dans tidyverse qui réalisent des tâches différentes), alors R utilisera la fonction du dernier package chargé. Pour donner la priorité aux fonctions de tidyverse, qui sont couramment utilisées pour la manipulation et la visualisation des données, chargez tidyverse en dernier.\n\n# Pour s'assurer que le package \"pacman\" est installé\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# Installation (si nécessaire) depuis le CRAN et chargement des packages à utiliser\npacman::p_load(\n  rio,        # importation de données  \n  skimr,      # aperçu des données\n  janitor,    # nettoyage des données et tableaux descriptifs\n  lubridate,  # manipulation des dates\n  epikit,     # pour créer des catégories d'âge\n  gtsummary,  # statistiques descriptives, tests et régressions \n  apyramid,   # tracé de pyramides des âges \n  flextable,  # tableaux prêts à être présentés\n  naniar,     # analyse des données manquantes\n  remotes,    # pour installer le package permettant de télécharger les données\n  tidyverse   # gestion et visualisation des données\n)\n\n\n\n\n\n\n\n\n\n\nVotre bureau vous fournit deux fichiers pour votre analyse, tous deux contenant des données pour 2024 et mises à jour au 15 janvier 2025 :\n\nun ensemble de données de notification des maladies (“multi_maladies_notifications.xlsx”) avec l’information sur les cas de 5 centres de santé.\nUn ensemble de données au niveau des tests de laboratoire (“multi_maladies_tests.csv”) soumis par trois laboratoires effectuant des tests pour les cinq centres de santé.\n\nPour cette étude de cas, vous pouvez télécharger les données via le répertoire de données d’Applied Epi, auquel vous pouvez accéder grâce au package {appliedepidata}. Suivez les étapes suivantes :\n\nInstallez le package {appliedepidata} depuis GitHub à l’aide de la fonction install_github() du package {remotes} (que vous avez installé précédemment)\n\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nEnregistrez les deux ensembles de données dans un dossier spécifique à l’aide de la fonction save_data() de {appliedepidata} en exécutant le code ci-dessous. Dans l’exemple ci-dessous, les données sont enregistrées dans un sous-dossier donnees du dossier de projet RStudio. Notez que si vous ne spécifiez pas d’emplacement spécifique avec l’argument path de la fonction, une fenêtre s’ouvrira pour vous demander de sélectionner manuellement un dossier.\n\n\n# Téléchargement des deux fichiers de données en utilisant la fonction save_data()de appliedepidata\nappliedepidata::save_data(\"multi_maladies_tests\",\n                        path = \"donnees\")\n\nappliedepidata::save_data(\"multi_maladies_notifications\",\n                          path = \"donnees\")\n\n\n\n\nTrès bien ! Merci au bureau national et à Applied Epi ! Il est maintenant temps d’importer les données de ce dossier dans RStudio, afin de pouvoir les analyser.\n\n\nIdéalement, vous utiliserez la même fonction pour importer les deux ensembles de données, bien qu’un soit un fichier .csv et l’autre un fichier .xlsx. Notez qu’à l’avenir, nous dirons simplement “environnement” lorsque nous parlerons de la fenêtre environnement dans R Studio.\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\nUtiliser la fonction import du package {rio}, qui peut reconnaître et importer différents types de fichiers. Elle remplace les fonctions d’importation qui sont spécifiques à un type de fichier, telles que read.csv() de {base} pour les fichiers .csv et read_excel() de {readxl} pour importer des fichiers .xlsx.\nPour en savoir plus sur les fonctions d’importation, lisez le chapitre Importer et exporter des données du Epi R Handbook.\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nCi-dessous, nous utilisons la fonction d’importation pour importer les deux fichiers. Notez que nous assignons les données importées à deux objets, l’un appelé data_notif_brut et un autre appelé data_lab_brut. Nous ajoutons le suffixe “brut” pour distinguer ces données des versions nettoyées que nous créerons plus tard.\n\n# Importation des données\n\n# Données de notification\ndata_notif_brut &lt;- import(\"donnees/multi_maladies_notifications.xlsx\")\n\n# Données de labo\ndata_lab_brut &lt;- import(\"donnees/multi_maladies_tests.csv\")\n\n\n\n\n\n\n\n\n\nLes données sont là, il est maintenant temps de voir ce qu’elles racontent. Jetez un premier coup d’oeil à vos deux ensembles de données brutes pour en vérifier le contenu et la qualité.\n\n\n\n\nUtilisez skim() du package {skimr} package, ainsi que names(), ncol() et nrow() pour inspecter votre ensemble de données.\nskim() vous donne de nombreuses informations sur la structure et le contenu des données, et names() vous fournira les différents noms de colonnes des données. Les fonctions ncol() et nrow() renvoient le nombre de colonnes ou de lignes dans les données. Savez-vous ce qu’il faut mettre entre les parenthèses ?\nLe plus simple est de regarder dans l’environnement. Rappelez-vous que l’objet de votre environnement contenant les données de notification s’appelle data_notif_brut.\nCliquez sur la solution sous l’encart de questions si vous avez besoin d’aide.\n\n\n\n\n\n\nQuestions\n\n\n\n\nCombien y a-t-il de colonnes dans les données de notification?\n\n 10 11 12 13\n\nLaquelle de ces colonnes n’apparait PAS dans les données?\n\n Date d'apparition Date signalée par l'établissement de santé/la communauté Date du résultat Date de test Date de naissance\n\nQuel est le nom de la / des colonne(s) permettant d’identifier chaque notification de cas?\n\n ID de notification Test ID Code de l'établissement de santé Combinaison de ID de notification et Sexe\n\nCombien y a-t-il de lignes dans les données de notification?\n\n 987 1314 950 778\n\nA quel type d’information n’avez vous PAS accès dans les données de notification?\n\n Le résultat du test de laboratoire Le district de résidence La date de naissance et le sexe La structure de santé où a eu lieu la notification L'issue de la maladie\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nUtilisez skim() du package {skimr} pour obtenir un résumé de l’ensemble des données, et View() pour consulter directement l’ensemble de la base de données sous forme de tableur :\n\nskim(data_notif_brut)\n\nVous pouvez également utiliser names() pour imprimer uniquement les noms des colonnes. Par l’intermédiaire de skim() et names() vous aurez accès à différents type d’information, notamment : l’établissement de santé du cas, la date de naissance, le sexe, un indicateur de grossesse, le district de résidence, la date d’apparition et la date rapportée par la clinique, ainsi que des informations sur l’issue de la maladie.\nIl y a également ID de notification qui semble être un identifiant unique pour un cas, mais nous devrions vérifier les doublons avant d’en être sûrs.\nNotez qu’il n’y a AUCUN résultat de test dans ces données, car ces notifications proviennent des cliniques qui notifient les maladies à déclaration obligatoire sur la base de définitions de cas cliniques.\n\nnames(data_notif_brut)\n\n [1] \"Nom de l'unite d'organisation\"                           \n [2] \"Code de l'etablissement de sante\"                        \n [3] \"ID de notification\"                                      \n [4] \"Date de naissance\"                                       \n [5] \"Sexe\"                                                    \n [6] \"Enceinte\"                                                \n [7] \"District residentiel\"                                    \n [8] \"Maladie notifiee\"                                        \n [9] \"Date d'apparition\"                                       \n[10] \"Date signalee par l'etablissement de sante/la communaute\"\n[11] \"Resultat\"                                                \n[12] \"Date du resultat\"                                        \n\n\nUtilisez ncol() et nrow() pour imprimer le nombre de colonnes et de lignes, comme ceci :\n\nncol(data_notif_brut)\nnrow(data_notif_brut)\n\nCeci imprimera le nombre de colonnes et de lignes dans votre console.\n\n\n[1] 12\n\n\n[1] 987\n\n\nPar ailleurs, si l’on examine l’environnement, on constate que le nombre d’observations (qui sont les mêmes que les lignes) et de colonnes sont à côté du nom de la base de données.\n\n\n\n\n\n\nUtilisez skim() du package {skimr} ou class() pour explorer les classes des colonnes.\nVous souvenez-vous de la façon de spécifier la colonne qui vous intéresse à l’intérieur de la fonction class() ? Vous pouvez également explorer les classes depuis l’environnement.\n\n\n\n\n\n\nQuestions\n\n\n\n\nCombien de colonnes dans l’ensemble de données de notification sont reconnues par R comme étant de classe date ?\n\n 0 2 4\n\nQuelle est la classe de la plupart des colonnes dans les données brutes de notification?\n\n character numeric factor\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVous pouvez utiliser class comme dans l’exemple ci-dessous. Le $ est un opérateur utilisé pour sélectionner une colonne spécifique de l’ensemble de données data_notif_brut.\nNotez l’utilisation d’apostrophes inversées (`) autour de Date de naissance parce que le nom de la colonne contient des espaces.\n\nclass(data_notif_brut$`Date de naissance`)\n\nPour consulter la classe via l’environnement, cliquez sur la flèche bleue à côté du nom de l’ensemble de données. Les noms des colonnes apparaissent, avec la classe à côté (par exemple, “chr” indique la classe texte / caractères).\nVous pouvez voir qu’aucune des colonnes qui devraient être des dates n’est reconnue comme telle. Au lieu de cela, elles sont reconnues comme des valeurs texte.\n\n\n\n\n\n\nUtiliser la fonction tabyl() pour inspecter les valeurs dans les colonnes qualitatives/catégorielles en spécifiant le nom de la base de données comme premier argument, et le nom de la colonne comme second argument.\nPar exemple, ce code renvoie le contenu de la colonne Sexe. La sortie montre que masculin et féminin sont sont orthographiés de manière incohérente dans les données. Cette colonne devra faire l’objet d’un nettoyage avant de pouvoir être analysée.\n\ntabyl(data_notif_brut, Sexe)\n\n     Sexe   n    percent valid_percent\n        F  47 0.04761905    0.05452436\n  FEMININ 146 0.14792300    0.16937355\n        M  40 0.04052685    0.04640371\n MASCULIN 172 0.17426545    0.19953596\n        f 154 0.15602837    0.17865429\n  feminin  98 0.09929078    0.11368910\n        m 119 0.12056738    0.13805104\n masculin  86 0.08713273    0.09976798\n     &lt;NA&gt; 125 0.12664640            NA\n\n\nPour analyser les données manquantes, vous pouvez utiliser la fonction miss_var_summary() du package {naniar} :\n\nmiss_var_summary(data_notif_brut)\n\n# A tibble: 12 × 3\n   variable                                                 n_miss pct_miss\n   &lt;chr&gt;                                                     &lt;int&gt;    &lt;num&gt;\n 1 Date d'apparition                                           691     70.0\n 2 Enceinte                                                    510     51.7\n 3 Resultat                                                    197     20.0\n 4 Date du resultat                                            197     20.0\n 5 Date de naissance                                           168     17.0\n 6 Sexe                                                        125     12.7\n 7 Nom de l'unite d'organisation                                 0      0  \n 8 Code de l'etablissement de sante                              0      0  \n 9 ID de notification                                            0      0  \n10 District residentiel                                          0      0  \n11 Maladie notifiee                                              0      0  \n12 Date signalee par l'etablissement de sante/la communaute      0      0  \n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nLes valeurs dans la colonne District résidentiel sont-elles standardisées ?\n\n Non, elles doivent être nettoyées Elles sont standardisées et prêtes à être utilisées dans l'analyse\n\nLes valeurs dans la colonne Maladie notifiee sont-elles normalisées ?\n\n Non, elles doivent être nettoyées Elles sont standardisées et prêtes à être utilisées dans l'analyse\n\nQu’est-ce que R reconnait comme une valeur manquante?\n\n Soit une absence de valeur, ou juste un espace ou un point Pas de valeur dans la cellule, représenté par NA Les mots Inconnu et Indéterminé\n\nSelon l’analyse des données manquantes, est-ce que la colonne Date d'apparition vous paraît exploitable et utile?\n\n Oui, il y a peu de données manquantes, elle est donc utile Assez peu, au vu de la proportion de données manquantes\n\nPourquoi certaines colonnes des données de notification peuvent présenter des orthographes différentes et des catégories non standardisées ?\n\n Un bot brouille les données afin qu'elles soient moins identifiables Chaque clinique peut utiliser un logiciel configuré de manière légèrement différente, ou utiliser des entrées en texte libre, ce qui entraîne des variations orthographiques Le logiciel du système de surveillance utilisé par les établissements cliniques comporte de nombreux bugs\n\nWhy might some columns in the notification data have high missingness?\n\n The clinician does not ask the patient the question during their consultation The patient might not know or want to share the answer The clinician might not have time to prioritise filling in that field in the data, even if they know the information All of the above, and many more reasons\n\nPourquoi certaines colonnes de données de notification peuvent présenter une proportion élevée de données manquantes ?\n\n Le clinicien ne pose pas la question au patient pendant la consultation Le patient peut ne pas connaître la réponse ou ne pas vouloir la partager Le clinicien peut ne pas avoir le temps de remplir ce champ dans les données, même s'il connaît l'information Toutes les raisons ci-dessus, et bien d'autres encore\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nUtilisez la fonction tabyl() le résumé des valeurs de la colonne District residentiel. Là encore, le premier argument est le nom de l’ensemble de données et le deuxième argument est le nom de la colonne.\n\ntabyl(data_notif_brut, `District residentiel`)\n\n District residentiel   n    percent\n       Au bord du lac 125 0.12664640\n            F Central  32 0.03242148\n            FEVERIA C  23 0.02330294\n      FEVERIA CENTRAL  85 0.08611955\n            Feveria C  24 0.02431611\n      Feveria Central  12 0.01215805\n               KASARA  64 0.06484296\n                  KSR  17 0.01722391\n               Kasara 109 0.11043566\n             L MINARA  50 0.05065856\n             L Minara 193 0.19554205\n           LAC MINARA 185 0.18743668\n           Lac Minara  68 0.06889564\n\n\nVous pouvez constater que chacun des trois emplacements (Feveria Central, Lac Minara et Kasara) sont orthographiés de différentes manières et en lettres majuscules ou minuscules. Il faudra faire le ménage si l’on veut analyser la distribution géographique des maladies à déclaration obligatoire.\nDe même, utilisez tabyl() résumer les valeurs contenues dans la colonne Maladie notifiee. Vous pouvez voir qu’elles sont écrites en toutes lettres de manière appropriée et cohérente, de sorte que vous pouvez déjà voir la distribution des maladie sans nettoyage supplémentaire.\n\ntabyl(data_notif_brut, `Maladie notifiee`)\n\n Maladie notifiee   n    percent\n          cholera  46 0.04660588\n           dengue 273 0.27659574\n     fievre jaune 100 0.10131712\n        paludisme 533 0.54002026\n         typhoide  35 0.03546099\n\n\nUne autre façon d’analyser les données manquantes est de résumer la sortie de la fonction is.na(). Dans l’exemple ci-dessous, la fonction is.na() évalue chaque cellule de la colonne Date d'apparition et renvoie TRUE pour pour les valeurs manquantes et FAUX pour les valeurs présentes.\nAppliquer tabyl() à cette série de TRUE/FALSE vous permet d’obtenir rapidement les effectifs et proportions de données manquantes dans cette colonne. N’oubliez pas que les valeurs comme un espace ou les mots “Inconnu” ou “Manquant” ne seront pas reconnues par R comme manquantes. R ne reconnaîtra que les cellules vides comme données manquantes, représentées par NA.\nPour Date d'apparition, vous pouvez voir que 70 % des cas n’ont pas de valeur, ce qui suggère que cette colonne n’est pas particulièrement utile pour analyser des tendances de maladies au fil du temps.\n\ntabyl(is.na(data_notif_brut$`Date d'apparition`))\n\n is.na(data_notif_brut$`Date d'apparition`)   n   percent\n                                      FALSE 296 0.2998987\n                                       TRUE 691 0.7001013\n\n\nLes données manquantes ou non standardisées peuvent être dues à de nombreuses raisons, notamment:\n\nla conception de l’outil de collecte de données (par exemple, si les questions sont obligatoires ou si elles utilisent du texte libre plutôt que des listes déroulantes),\nles processus et les normes en place (par exemple, des champs que le personnel a pour instruction de prioriser), et\nles facteurs contextuels (par exemple, si le personnel dispose de suffisamment de temps pour collecter les informations).\n\n\n\n\n\n\n\n\n\n\nComme pour les données de surveillance, utilisez skim(), ncol() et nrow()ou inspecter l’environnement pour inspecter les données de laboratoire.\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuelle liste linéaire comporte le plus de colonnes : les données de surveillance ou les données de laboratoire ?\n\n Les données de laboratoire Les données de surveillance Elles ont le même nombre de colonnes\n\nQuelle liste linéaire comporte le plus de lignes ?\n\n Les données de laboratoire Les données de surveillance Elles ont le même nombre de lignes\n\nInspectez les données de laboratoire avec View(). Pour quelle raison les données de laboratoire pourraient avoir plus d’enregistrements ?\n\n Il peut y avoir plusieurs tests ou cibles analysées par échantillon Il y a de nombreux résultats de tests d'étalonnage dans les données Toutes les notifications n'ont pas encore reçu de résultats de tests\n\nLaquelle de ces informations ne figure PAS dans les données de laboratoire ?\n\n ID de notification ID d'échantillon Type de test Date de naissance Résultat du test\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nComme dans la section 3.1, vous pouvez utiliser skim() du package {skimr} pour examiner l’ensemble de données de laboratoire avec les résultats des tests. Vous verrez également les différents noms de colonnes de données, montrant que les données de laboratoire ne contiennent que des informations sur le test et non sur le patient. Elles contiennent toutefois un identifiant de notification, comme les données de notification.\n\nskim(data_lab_brut)\n\nUtiliser ncol() et nrow() pour imprimer le nombre de colonnes et de lignes, comme ceci :\n\nncol(data_lab_brut)\nnrow(data_lab_brut)\n\nLes nombres de colonnes et de lignes s’afficheront dans votre console, vous montrant que les données de laboratoire ont plus de lignes que les données de notification que vous avez inspectées plus tôt.\n\n\n[1] 7\n\n\n[1] 1314\n\n\nIl y a souvent plus d’enregistrements dans les données de laboratoire que dans les données cliniques. Si vous inspectez les données avec View(data_lab_brut) et que vous cliquez ensuite sur la flèche en haut de la colonne id_notification pour les trier par ordre alphabétique, vous verrez que plusieurs lignes partagent le même numéro de notification. Cela peut se produire lorsque plusieurs cibles sont testées à partir du même échantillon (même ID d’échantillon), ou lorsqu’un cas est retesté (ce qui donne un numéro d’identification d’échantillon différent).\n\nView(data_lab_brut)\n\n\n\nnom_laboratoireid_notificationid_echantillondate_testtestciblevaleurHopital general de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue NS.1NHopital general de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgGNHopital general de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgMPHopital general de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue NS.1NHopital general de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgGNHopital general de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgMP\n\n\n\n\n\n\n\n\nComme ci-dessus, utilisez les fonctionc class(), skim() ou tabyl(), ou explorer l’environnement, pour examiner vos colonnes en détail.\n\n\n\n\n\n\nQuestions\n\n\n\n\nCombien de colonnes dans les données de laboratoire sont reconnues par R comme étant des colonnes de date ?\n\n 0 1 2\n\nCombien de colonnes des données de laboratoire n’ont aucune donnée manquante ?\n\n 1 3 7 (toutes!)\n\nQuel test détecte plusieurs cibles (et comporte donc plusieurs lignes par échantillon) ?\n\n Paludisme Dengue Fièvre jaune Choléra Fièvre typhoïde\n\nCombien de valeurs de résultats de test possibles y a-t-il dans la colonne valeur ?\n\n 5 3 4\n\nQuel résultat ne semble PAS être possible pour le test de culture des selles qui détecte la bactérie V.cholerae ?\n\n P P01 P0139 N I\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nLes données du laboratoire ont une colonne de date, reconnue par R comme une classe “IDate”. Il s’agit d’une classe de date utilisée par import() de {rio} lors de l’importation de fichiers csv. Comme la classe Date native de R, elle permet de trier par date et d’analyser les tendances dans le temps.\n\nclass(data_lab_brut$date_test)\n\n[1] \"IDate\" \"Date\" \n\n\nEn utilisant la fonction miss_var_summary() du package {naniar}, on réalise que toutes les colonnes des données de laboratoire sont complètes. Cela peut s’expliquer par le fait que les laboratoires utilisent des processus automatisés et qu’il y a donc beaucoup moins de risques d’erreur humaine.\n(Point important : Notez que dans la vie réelle, les données de laboratoire présenteraient probablement des problèmes aussi !)\n\nmiss_var_summary(data_lab_brut)\n\n# A tibble: 7 × 3\n  variable        n_miss pct_miss\n  &lt;chr&gt;            &lt;int&gt;    &lt;num&gt;\n1 nom_laboratoire      0        0\n2 id_notification      0        0\n3 id_echantillon       0        0\n4 date_test            0        0\n5 test                 0        0\n6 cible                0        0\n7 valeur               0        0\n\n\nPour connaître le nombre de cibles détectées par chaque test, vous pouvez croiser les colonnes test et cible avec tabyl(). Ecrivez les noms des colonnes dans la fonction comme deux arguments distincts (et donc séparés par une virgule). Le résultat montre que chaque test correspond clairement à une ou plusieurs cibles, et que seul le test de la dengue détecte plus d’une cible (IgG, IgM et NS.1).\nConseil : Essayez de modifier l’ordre des noms de colonnes dans tabyl() pour voir l’impact sur le tableau.\n\ntabyl(data_lab_brut, cible, test)\n\n                 cible Culture de selles Dengue NS1/IgG/IgM Hemoculture\n    Bacteries S. Typhi                 0                  0          33\n Bacteries V. cholerae                45                  0           0\n            Dengue IgG                 0                215           0\n            Dengue IgM                 0                215           0\n           Dengue NS.1                 0                215           0\n      Fievre jaune IgM                 0                  0           0\n            Plasmodium                 0                  0           0\n IgM ELISA Microscopie du sang total\n         0                         0\n         0                         0\n         0                         0\n         0                         0\n         0                         0\n        88                         0\n         0                       503\n\n\nEnfin, vous pouvez examiner les différentes valeurs des résultats du test dans la colonne valeur toujours à l’aide de la fonction tabyl(). Vous pouvez voir qu’il y a six résultats possibles, dont N pour négatif, P pour positif et I pour indéterminé. Seul le choléra ne présente aucun P, mais est le seul à présenter P01 et P0139, ce qui correspond à un résultat positif pour les sérogroupes O1 ou O139.\n\ntabyl(data_lab_brut, test, valeur)\n\n                      test  I   N   P PO1 PO139\n         Culture de selles  5   2   0  22    16\n        Dengue NS1/IgG/IgM  0 354 291   0     0\n               Hemoculture  2  24   7   0     0\n                 IgM ELISA 10  45  33   0     0\n Microscopie du sang total 56 257 190   0     0\n\n\n\n\n\n\n\n\n\n\nVous savez maintenant que les données de notification (data_notif_brut) contiennent des des informations sur les cas suspects, ainsi que des données démographiques de base (âge, sexe, grossesse, district de résidence), et des informations sur la date d’apparition des symptômes, la date de notification par l’établissement de santé, et l’issue. Certaines colonnes doivent être nettoyées avant de poursuivre l’analyse, en raison des variations dans l’orthographe des valeurs catégorielles et de certaines colonnes non reconnues comme des dates.\nVous allez maintenant commencer à écrire de plus longs morceaux de code pour nettoyer les données, à l’aide de plusieurs fonctions {dplyr} reliées à l’aide d’opérateurs “pipe” (qui ressemblent à ceci : |&gt;).\nNOTE SUR LES ‘PIPES’ : Les “pipes” vous permettent d’effectuer plusieurs opérations en une seule commande fluide, en “enchaînant” différentes fonctions. La sortie d’une fonction devient l’entrée de la suivante. Si vous avez besoin de plus d’informations sur les pipes, veuillez vous référer au chapitre du Epi R Handbook.\nNotez que cet exercice utilise le pipe de base (|&gt;) plutôt que le pipe magrittr (%&gt;%), car il est plus rapide et ne nécessite pas l’installation de packages. Utilisez le pipe magrittr si vous préférez.\n\n\n\n\nPour des raisons de qualité et de stockage des données, votre équipe vous recommande de créer une liste linéaire propre qui ne contienne que des informations sur l’identifiant unique, la localisation du cas, la maladie et la date de notification au système de surveillance.\nÉcrivez une commande R pour produire une nouvelle base de données propre appelée data_notif, en appliquant les étapes de nettoyage suivantes:\n\nRenommer les colonnes pour qu’elles soient plus facilement lisibles par la machine (supprimer les espaces et les majuscules) en utilisant clean_names() du package {janitor}.\nUtiliser la fonction rename() de {dplyr} pour que:\n\nle nom de la colonne avec la date à laquelle le cas a été signalé soit remplacé par un nom plus concis date_notif.\nle nom de la colonne d’identifiant de la notification soit plus concis (id_notification).\n\nSélectionnez les colonnes pertinentes pour l’analyse à l’aide de la fonction select() du package {dplyr}.\n\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\nCommencez votre code par le nom du nouvel ensemble de données, l’opérateur d’assignation et le nom de l’objet contenant les données brutes. Ainsi le résultat du traitement des données brutes sera assigné à un nouvel objet appelé data_notif.\n\ndata_notif &lt;- data_notif_brut\n\nIl faudra ensuite construire la commande de nettoyage en ajoutant des fonctions supplémentaires, liées à l’aide d’un pipe. Cela vous permet d’effectuer plusieurs opérations en une seule commande fluide. Tout d’abord, vous utiliserez clean_names() pour normaliser tous les noms de colonnes. Il remplace automatiquement les espaces et les caractères spéciaux par des traits de soulignement (underscore), supprime les accents et les apostrophes, et convertit tous les caractères en minuscules, ce qui rend les noms de colonnes plus facile à utiliser. Vous pouvez ensuite utiliser rename() pour donner à une colonne un nouveau nom. Rappelez-vous que lorsque vous utilisez rename(), la colonne aura déjà reçu le nom issu de clean_names().\n\ndata_notif &lt;- data_notif_brut |&gt; \n  clean_names() |&gt; \n  rename(NOUVEAU_NOM = ANCIEN_NOM) |&gt; \n  select(VAR_NAMES)\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVoici le code permettant de nettoyer les noms de colonnes et de sélectionner les bonnes colonnes pour l’analyse :\n\n# Données propres\ndata_notif &lt;- data_notif_brut |&gt; \n  clean_names() |&gt; \n  rename(date_notif = date_signalee_par_letablissement_de_sante_la_communaute,\n         id_notification = id_de_notification) |&gt; \n  select(id_notification, district_residentiel, maladie_notifiee, date_notif)\n\n\n\n\n\n\n\nVous savez déjà, grâce à l’inspection des données, que les valeurs de district ne sont pas normalisées.\nAjouter un mutate() pour nettoyer la colonne district_residentiel, afin de:\n\nNormaliser l’utilisation d’écriture minuscule / majuscule dans la colonne\nRemplacer la colonne district_residentiel existante par une colonne qui ne contient que les valeurs pour les districts : “Lac Minara”, “Feveria Central” et “Kasara”.\n\nConsultez l’indice pour savoir quelles fonctions vous pourriez utiliser.\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\nEssayez d’utiliser str_to_title() du package {stringr} de façon à ce que la première lettre de chaque mot soit en majuscule et que toutes les autres lettres soient en minuscule. Vous pouvez également utiliser case_match() pour spécifier différentes fautes de frappe spécifiques. Comme pour l’utilisation de rename() après clean_names(), prenez en compte que la fonction str_to_title() a modifié les valeurs des données fournies à la fonctioncase_match().\nUtilisez le panneau d’aide (“Help”) de RStudio pour savoir comment utiliser ces fonctions. Par exemple, tapez ?case_match dans votre console pour obtenir la page d’aide. NOTE sur case_match() : il s’agit d’une fonction très utile pour remplacer ou corriger des valeurs, qui remplace la fonction recode().\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVotre code de nettoyage devrait maintenant ressembler à ceci :\n\n# Données propres\ndata_notif &lt;- data_notif_brut |&gt; \n  clean_names() |&gt; \n  rename(date_notif = date_signalee_par_letablissement_de_sante_la_communaute,\n         id_notification = id_de_notification) |&gt; \n  select(id_notification, district_residentiel, maladie_notifiee, date_notif) |&gt; \n  mutate(district_residentiel = str_to_title(district_residentiel)) |&gt; \n  mutate(district_residentiel = case_match(district_residentiel,\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lac Minara\", \"Au Bord Du Lac\") ~ \"Lac Minara\"))\n\nVous pouvez également directement insérer la fonction str_to_title() dans la fonction case_match() pour un code plus court, comme suit :\n\n# Données propres\ndata_notif &lt;- data_notif_brut |&gt; \n  clean_names() |&gt; \n  rename(date_notif = date_signalee_par_letablissement_de_sante_la_communaute,\n         id_notification = id_de_notification) |&gt; \n  select(id_notification, district_residentiel, maladie_notifiee, date_notif) |&gt; \n  mutate(district_residentiel = case_match(str_to_title(district_residentiel),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lac Minara\", \"Au Bord Du Lac\") ~ \"Lac Minara\"))\n\n\n\n\n\n\n\nLa colonne de la date de notification doit être transformée de manière à ce qu’elle soit reconnue comme une date dans R. Cela vous permettra d’analyser les tendances au fil du temps, y compris en utilisant un décompte par semaine ou par mois.\nExaminez les valeurs de la colonne date_notif. Ajoutez ensuite une ligne à votre code de nettoyage pour modifier date_notif en une classe de date.\nConnaître le format de date d’origine vous permettra d’utiliser la bonne fonction pour convertir la colonne en classe de date. Nous vous recommandons d’utiliser l’une des fonctions du package {lubridate} : soit ymd() (pour convertir les dates écrites sous la forme année-mois-jour), mdy() (pour les dates mois-jour-année), ou dmy() (pour les dates jour-mois-année). Ces fonctions reconnaîtront n’importe quelle façon d’écrire la date, à condition qu’elle soit organisée dans cet ordre. Par exemple “21 août 2025” (oui! oui! même en français) et “21-08-2024” seraient toutes deux reconnues par dmy().\n\n\n\n\n\n\nQuestions\n\n\n\n\nComment les dates sont-elles actuellement formatées ?\n\n jour-mois-année année-mois-jour mois-jour-année année-jour-mois\n\nQuelle fonction mutate() devez-vous utiliser pour convertir la colonne date_notif en une classe de date ?\n\n mutate(date_notif = ymd(date_notif)) mutate(date_notif = dmy(date_notif)) mutate(date_notif = mdy(date_notif))\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVous pouvez utiliser la fonction head() pour afficher les six premières lignes de données de la colonne date_notif. Vous pouvez voir qu’elles sont écrites avec d’abord l’année, puis le mois, puis le jour.\n\nhead(data_notif$date_notif)\n\n[1] \"2024-03-08\" \"2024-03-11\" \"2024-03-11\" \"2024-03-18\" \"2024-03-14\"\n[6] \"2024-03-12\"\n\n\nVous pouvez utiliser la fonction ymd() à l’intérieur de mutate() pour convertir la classe de la colonne date_notif. Vous pouvez vérifier que la classe est correcte en utilisant la fonction class() par la suite.\nVotre code de nettoyage devrait maintenant ressembler à ceci :\n\n# Données propres\ndata_notif &lt;- data_notif_brut |&gt; \n  clean_names() |&gt; \n  rename(date_notif = date_signalee_par_letablissement_de_sante_la_communaute,\n         id_notification = id_de_notification) |&gt; \n  select(id_notification, district_residentiel, maladie_notifiee, date_notif) |&gt; \n  mutate(district_residentiel = case_match(str_to_title(district_residentiel),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lac Minara\", \"Au Bord Du Lac\") ~ \"Lac Minara\")) |&gt; \n  mutate(date_notif = ymd(date_notif)) \n\nEt vous pouvez vérifier la classe comme ceci :\n\nclass(data_notif$date_notif)\n\n[1] \"Date\"\n\n\n\n\n\n\n\n\nVos collègues vous disent que chaque id_notification représente un cas suspect unique. Vous souhaitez maintenant créer une table pour vérifier s’il existe des doublons de id_notification sur plusieurs lignes de vos données.\n\n\n\n\n\n\nQuestions\n\n\n\n\nUne ligne dans les données de notification correspond-elle à un cas ?\n\n Oui Non\n\nAvez-vous besoin de dédupliquer vos données pour l’analyse épidémiologique des cas ?\n\n Oui Non\n\n\n\n\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\nIl existe de nombreuses façons de procéder, mais essayez d’utiliser la fonction count() de {dplyr}. Elle créera un tableau qui comptera le nombre de lignes par valeur unique de la colonne que vous spécifiez dans la fonction. Ensuite, utiliser tabyl() pour examiner la distribution de ces effectifs.\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nTout d’abord, il faut faire passer les données de surveillance dans la fonction count() en spécifiant à la fonction id_notification comme seul argument. Cela crée un tableau qui compte le nombre de lignes par valeur unique de id_notification, dans une nouvelle colonne n. Vous pouvez voir par exemple dans les premières lignes qu’il n’y a qu’une seule ligne pour chacune de ces 6 id_notification.\n\ndata_notif |&gt; \n  count(id_notification) \n\n\n\n  id_notification n\n1          00399b 1\n2          005c85 1\n3          006f52 1\n4          00cbbb 1\n5          01830d 1\n6          019045 1\n\n\nEnsuite décrivez la nouvelle colonne n avec tabyl(), qui montrera qu’il n’y a qu’une ligne par id_notification. Cela signifie qu’une ligne correspond à un cas, et qu’aucune autre déduplication n’est nécessaire.\n\ndata_notif |&gt; \n  count(id_notification) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 987       1\n\n\n\n\n\n\n\n\n\nVous pouvez maintenant procéder à une analyse descriptive des cas, puisque vos données sont propres et que vous savez qu’une ligne équivaut à un cas. Utilisez la fonction tabyl() pour réaliser les tâches suivantes.\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuelle maladie a été la plus fréquemment diagnostiquée par les cliniques de Feveria en 2024 ?\n\n Choléra Paludisme Dengue Fièvre typhoïde Fièvre jaune\n\nQuelle maladie a été la moins fréquemment diagnostiquée par les cliniques de Feveria en 2024 ?\n\n Choléra Paludisme Dengue Fièvre typhoïde Fièvre jaune\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nEn utilisant tabyl() nous pouvons voir qu’il y a eu 533 cas suspects de paludisme à Feveria en 2024, et seulement 35 cas suspects de fièvre typhoïde.\n\ntabyl(data_notif, maladie_notifiee)\n\n maladie_notifiee   n    percent\n          cholera  46 0.04660588\n           dengue 273 0.27659574\n     fievre jaune 100 0.10131712\n        paludisme 533 0.54002026\n         typhoide  35 0.03546099\n\n\n\n\n\n\n\n\nUtilisez tabyl() pour croiser les colonnes maladie et district de résidence.\nComplétez votre tableau en ajoutant diverses fonctions adorn du package {janitor}, pour afficher la distribution en pourcentage. Par exemple adorn_percentages(), adorn_pct_formatting() et adorn_ns().\nTapez le nom de la fonction après un ? dans votre console (par ex. ?adorn_ns) pour afficher les pages d’aide correspondantes. Vous pouvez également consulter la section à propos de {janitor} dans le Epi R Handbook pour plus d’explications sur les fonctions adorn_xxx().\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuel district a signalé le plus grand nombre de maladies vectorielles en 2024 (paludisme, dengue, fièvre jaune) ?\n\n Lac Minara Feveria Central Kasara\n\nQuel district a signalé le plus grand nombre de maladies diarrhéiques en 2024 (choléra, fièvre typhoïde) ?\n\n Lac Minara Feveria Central Kasara\n\nQuels facteurs contribuent à l’augmentation des maladies diarrhéiques dans ce district spécifique (sélectionné dans la question précédente) ?\n\n Infrastructures d'approvisionnement en eau et d'assainissement peu fiables Surpopulation de moustiques Nous ne savons pas\n\n\n\n\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\nVoici du code pour vous aider à démarrer. Il croise maladie_notifiee et district_residentiel avec tabyl(), puis en ajoutant adorn_percentages() convertit ces nombres en proportions avec de nombreuses décimales. Vous devrez ensuite rajouter adorn_pct_formatting() avec un autre pipe, pour convertir les proportions en pourcentages, et enfin adorn_ns() pour ajouter à nouveau les effectifs entre parenthèses. Notez que les fonctions adorn_xxx() doivent être appliquées dans un ordre spécifique !\n\ntabyl(data_notif, maladie_notifiee, district_residentiel) |&gt;\n  adorn_percentages()\n\nPour les facteurs contribuant à l’augmentation des maladies diarrhéiques, revenez au début de l’étude de cas, à la partie présentant les districts!\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nEn utlisant tabyl(), nous pouvons constater que la plupart des cas suspects de dengue, de paludisme et de fièvre jaune étaient localisés dans le district de Lac Minara - la zone lacustre avec une forte densité de moustiques et donc de maladies à transmission vectorielle. Dans le même temps, la majorité des cas de choléra et de fièvre typhoïde se trouvait à Feveria Central, la zone urbaine surpeuplée souffrant de problèmes d’infrastructures d’approvisionnement en eau et d’assainissement entraînant un risque accru d’inondation et de contamination de l’eau potable par temps de pluie.\n\ntabyl(data_notif, maladie_notifiee, district_residentiel) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n maladie_notifiee Feveria Central      Kasara  Lac Minara\n          cholera      91.3% (42)  8.7%   (4)  0.0%   (0)\n           dengue       9.5% (26) 17.6%  (48) 72.9% (199)\n     fievre jaune      11.0% (11) 21.0%  (21) 68.0%  (68)\n        paludisme      13.7% (73) 19.9% (106) 66.4% (354)\n         typhoide      68.6% (24) 31.4%  (11)  0.0%   (0)\n\n\n\n\n\n\n\n\n\n\nLe travail effectué à l’étape 3 vous a permis de constater que les données de laboratoire ne contiennent que des données sur les tests et aucune information sur les patients. Les données sont déjà très propres, nous n’avons à standardiser qu’une seule colonne. Nous voudrons également traiter l’ensemble de données du laboratoire de manière à ce qu’il y ait une ligne par notification, afin de pouvoir le lier proprement à l’ensemble de données de notification.\n\n\n\n\nCréez un nouvel objet data_lab. Cela permettra une analyse et une interprétation des résultats plus simples.\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nUtilisez case_match() pour transformer les différentes valeurs originales en “Positif”, “Négatif” ou “Indéterminé” :\n\ndata_lab &lt;- data_lab_brut |&gt; \n  mutate(valeur = case_match(valeur, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positif\",\n                            \"N\" ~ \"Négatif\",\n                            \"I\" ~ \"Indéterminé\"))\n\nVous pouvez ensuite vérifier que les nouvelles valeurs sont correctes en résumant et en comparant les valeurs de la base de données originale et de la base de données nettoyée. Assurez-vous d’avoir utilisé la lettre “O” et non le chiffre “0”!\n\ntabyl(data_lab_brut, valeur)\n\n valeur   n    percent\n      I  73 0.05555556\n      N 682 0.51902588\n      P 521 0.39649924\n    PO1  22 0.01674277\n  PO139  16 0.01217656\n\n\n\ntabyl(data_lab, valeur)\n\n      valeur   n    percent\n Indéterminé  73 0.05555556\n     Négatif 682 0.51902588\n     Positif 559 0.42541857\n\n\n\n\n\n\n\n\n\n\n\nNous savons déjà que certains échantillons se retrouvent sur plusieurs lignes, et que c’est dû au test de la dengue qui a trois cibles, avec une ligne par pour le résultat de chaque cible.\nMaintenant, trouvez le nombre d’échantillons présentant plusieurs lignes.\nProcédez de la même manière que pour les données de notification, en utilisant l’objet data_lab: comptez d’abord le nombre de lignes par échantillon, puis créer un tableau montrant la distribution des nombres de lignes. Il faut garder à l’esprit que que chaque échantillon est identifié par un id_echantillon.\n\n\n\n\n\n\nQuestions\n\n\n\n\nCombien d’échantillons (id_echantillon unique) sont répétés sur 3 lignes?\n\n 200 215 230\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nTout d’abord, il faut faire passer (avec un pipe) les données du laboratoire à la fonction count() en donnant à la fonction id_echantillon comme seul argument. Cela crée un tableau qui compte le nombre de lignes par valeur unique de id_echantillon, affichée dans une nouvelle colonne n. Vous pouvez voir par exemple que le id_echantillon “000e8eee” est présent sur trois lignes, alors que le id_echantillon “001e1878” n’apparaît que sur une seule ligne.\n\ndata_lab |&gt; \n  count(id_echantillon) \n\n\n\n  id_echantillon n\n1       000e8eee 3\n2       001e1878 1\n3       005f39af 1\n4       00b30781 3\n5       00b56d18 1\n6       0110abcd 3\n\n\nPuis résumez la nouvelle colonne n avec tabyl().\n\ndata_lab |&gt; \n  count(id_echantillon) |&gt; \n  tabyl(n)\n\n n n_n   percent\n 1 669 0.7567873\n 3 215 0.2432127\n\n\nVous pouvez même vérifier que cela ne s’applique qu’au test de la dengue en en ajoutant la colonne test dans la commande. Vous pouvez voir que seul le test de la dengue comporte 3 lignes par échantillon.\n\ndata_lab |&gt; \n  count(test, id_echantillon) |&gt; \n  tabyl(test, n)\n\n                      test   1   3\n         Culture de selles  45   0\n        Dengue NS1/IgG/IgM   0 215\n               Hemoculture  33   0\n                 IgM ELISA  88   0\n Microscopie du sang total 503   0\n\n\n\n\n\n\n\n\nComme vous l’avez vu dans la section 3.2, votre test de dengue fournit des résultats pour trois cibles biologiques différentes : IgG, IgM et NS.1. Les résultats pour chacune de ces cibles peuvent être soit négatifs, soit positifs. Cependant, pour simplifier et consolider vos données, vous souhaitez attribuer une seule valeur “Négatif” ou “Positif” à chaque échantillon, pour indiquer si l’échantillon révélait une infection en cours.\n\n\ncibleNégatifPositifDengue IgG110105Dengue IgM105110Dengue NS.113976\n\n\nVotre collègue Ben, qui travaille au laboratoire, vous conseille ce qui suit :\n\nUn échantillon peut être considéré comme positif si le NS.1 ou les IgM sont positifs (les deux pouvant représenter une infection aiguë).\nVous pouvez ignorer les IgG (parce qu’un résultat positif en l’absence de NS.1 ou d’IgM positifs indique une immunité après une infection passée résolue).\n\nVous devez maintenant consolider les résultats du test de la dengue en une ligne par test, avec une valeur unique de résultat. Utiliser filter(), arrange() et slice(), en veillant à ce que tout échantillon positif pour NS.1 ou IgM soit considéré comme positif pour la dengue. Créez un nouvel objet appelé data_lab_tests\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\nEssayez d’appliquer ce qui suit pour consolider selon la recommandation de Ben :\n\nSupprimer les résultats IgG : filtrez les lignes où la cible est “IgG” à l’aide de filter() de {dplyr}.\nDonner la priorité aux résultats positifs pour les IgM/NS1 : Regroupez par id_echantillon et réorganisez les lignes avec arrange() afin que tout résultat “Positif” apparaisse en premier.\nFiltrer pour obtenir le résultat final : Ne conservez que la première ligne de chaque groupe en utilisant slice(1) pour obtenir le résultat global positif ou négatif de l’échantillon.\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVoici le code pour filtrer les résultats des IgG de la dengue, et ensuite consolider les résultats des tests à l’intérieur de chaque groupe de lignes ayant les mêmes id_echantillon, en donnant la priorité aux résultats positifs.\nVous devez utiliser desc à l’intérieur de arrange() car cela signifie que les résultats seront listés par ordre alphabétique DESCendant, ce qui signifie que “Positif” sera en haut pour chaque identifiant.\nAjoutez également la fonction ungroup() à la fin pour que les nouvelles données ne soient plus groupées, ce qui pourrait perturber les analyses ultérieures.\n\ndata_lab_tests &lt;- data_lab |&gt; \n  filter(cible != \"Dengue IgG\") |&gt; \n  group_by(id_echantillon) |&gt; \n  arrange(desc(valeur)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\nVous pouvez alors vérifier que le nouvel objet data_lab_tests ne présente qu’une seule ligne par test, en utilisant la combinaison de count() et tabyl() comme vous l’avez fait pour la tâche A.\nCe tableau vous montre que tous les ID d’échantillons uniques ne sont présents que dans une seule ligne chacun :\n\ndata_lab_tests |&gt; \n  count(id_echantillon) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 884       1\n\n\n\n\n\n\n\n\nMaintenant, vérifiez le nombre de tests par identifiant de notification dans vos nouvelles données consolidées.\nVous pouvez voir qu’il y a 26 lignes avec le même id_notification, mais seulement parmi les cas testés par microscopie du sang total pour le paludisme.\n\ndata_lab_tests |&gt; \n  count(test, id_notification) |&gt; \n  tabyl(test, n)\n\n                      test   1  2\n         Culture de selles  45  0\n        Dengue NS1/IgG/IgM 215  0\n               Hemoculture  33  0\n                 IgM ELISA  88  0\n Microscopie du sang total 451 26\n\n\nVous poursuivez vos recherches en examinant un exemple de cas avec le id_notification “043228”. Cela vous apprend que ce cas a été testé deux fois, avec deux échantillons différents, à une semaine d’intervalle. Le premier résultat était positif, et le second résultat était négatif.\n\ndata_lab_tests |&gt; \n  filter(id_notification == \"043228\")\n\n# A tibble: 2 × 7\n  nom_laboratoire   id_notification id_echantillon date_test  test  cible valeur\n  &lt;chr&gt;             &lt;chr&gt;           &lt;chr&gt;          &lt;IDate&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; \n1 Hopital universi… 043228          27c37cd8       2024-06-18 Micr… Plas… Posit…\n2 Hopital universi… 043228          d2271be0       2024-06-25 Micr… Plas… Négat…\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuelle affirmation concernant les données de laboratoire est correcte ?\n\n Tous les cas des différentes maladies sont retestés Certains cas de paludisme sont retestés Tous les cas de paludisme sont retestés\n\nAurez-vous besoin de dédupliquer les données de laboratoire pour les relier aux données de notification ?\n\n Oui, nous avons besoin d'une unique ligne représentant le résultat de laboratoire par notification Non, les données sont suffisamment dédupliquées\n\n\n\n\nSi vous avez répondu que vous devez dédupliquer, vous avez raison !\nDédupliquez vos données afin d’avoir une ligne par id_notification, en priorisant les résultats positifs, afin de pouvoir établir un lien avec les données de notification.\nPour ce faire, suivez un processus similaire à celui de la tâche B, en utilisant la base de données produite par la tâche B :\n\nRegrouper par id_notification\nClasser par valeur du résultat du test de manière à ce que les valeurs commençant par P soient listées dans la première ligne, suivies des N (Négatif), puis des I (Indéterminé).\nConservez ensuite la première ligne de chaque groupe de id_notificationen utilisant slice().\nPour finir, assignez le résultat à un nouvel objet appelé data_lab_cas.\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVoici le code pour dédupliquer les lignes à l’intérieur de chaque groupe de lignes avec un même id_notification en donnant la priorité aux résultats positifs. Une fois de plus, vous devez utiliser desc à l’intérieur dearrange(). Cela fonctionne parfaitement car l’ordre de priorité souhaité pour les résultats - positifs, puis négatifs, puis indéterminés - correspond à l’ordre alphabétique inversé (P vient à avant N, qui vient avant I, dans l’ordre alphabétique inversé).\nSi votre ordre de priorité était plus complexe ou ne correspondait pas à l’ordre alphabétique (par exemple, si “indéterminé” devait être placé avant “négatif”), vous devriez convertir la colonne de résultats en un facteur et fournir explicitement l’ordre souhaité de ses niveaux. N’oubliez pas de dégrouper à nouveau à la fin.\n\ndata_lab_cas &lt;- data_lab_tests |&gt; \n  group_by(id_notification) |&gt; \n  arrange(desc(valeur)) |&gt; \n  slice(1) |&gt;\n  ungroup()\n\nVous pouvez alors vérifier que le nouvel objet data_lab_cas n’a qu’une seule ligne par identifiant de notification, en utilisant la combinaison de count() et tabyl() comme dans la tâche A. Ce tableau vous montre que tous id_notification uniques sont ne sont présents que dans une seule ligne chacun:\n\ndata_lab_cas |&gt; \n  count(id_notification) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 858       1\n\n\n\n\n\n\n\n\n\nNous disposons maintenant de deux objets que nous pouvons utiliser pour l’analyse des données de laboratoire : data_lab_tests et data_lab_cas.\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuel objet devez-vous utiliser pour analyser les tests ?\n\n data_lab_tests data_lab_cas Aucun des deux\n\nCombien de tests ont été effectués pour dépister le paludisme (par microscopie du sang total) ?\n\n 215 503 88 190\n\nQuel pourcentage de tests de dépistage du choléra (par culture de selles) s’est révélé positif ?\n\n 21% 11% 84% 87%\n\nQuel test a donné le pourcentage le plus élevé de résultats indéterminés ?\n\n IgM ELISA (pour la détection de la fièvre jaune) Culture de selles (pour la détection du choléra) Hémoculture (pour la détection de la fièvre typhoïde)\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nEn utilisant tabyl() nous pouvons voir le nombre de résultats positifs, négatifs et indéterminés par test. Vous pouvez ajouter une série de adorn() pour afficher les pourcentages et les totaux.\n\ntabyl(data_lab_tests, test, valeur) |&gt; \n  adorn_totals(where = \"col\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n                      test Indéterminé     Négatif     Positif        Total\n         Culture de selles  11.1%  (5)  4.4%   (2) 84.4%  (38) 100.0%  (45)\n        Dengue NS1/IgG/IgM   0.0%  (0) 13.5%  (29) 86.5% (186) 100.0% (215)\n               Hemoculture   6.1%  (2) 72.7%  (24) 21.2%   (7) 100.0%  (33)\n                 IgM ELISA  11.4% (10) 51.1%  (45) 37.5%  (33) 100.0%  (88)\n Microscopie du sang total  11.1% (56) 51.1% (257) 37.8% (190) 100.0% (503)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuelle base de données de laboratoire devez-vous utiliser pour compter le nombre de cas suspects testés ?\n\n data_lab_brut data_lab_cas data_lab_tests data_lab\n\nCombien de cas suspects ont été testés dans les données de laboratoire de 2024 ?\n\n 858 1314 884\n\nY a-t-il plus de cas suspects dans les données de notification ou dans les données de laboratoire ?\n\n Données de notification Données de laboratoire\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVous pouvez simplement regarder le nombre de lignes dans le fichier data_lab_cas pour connaître le nombre de cas suspects qui ont été testés.\n\nnrow(data_lab_cas)\n\n[1] 858\n\n\nCe nombre est inférieur au nombre de cas suspects figurant dans la base de données des maladies à déclaration obligatoire (data_notif); ce qui suggère qu’une partie seulement des cas suspect notifié en 2024 avait été testée au moment où ces données étaient rendues disponibles.\n\nnrow(data_notif)\n\n[1] 987\n\n\n\n\n\n\n\n\n\n\nMaintenant que les deux listes linéaires sont nettoyées et qu’elles comportent une ligne par cas suspect, vous pouvez les joindre pour permettre l’analyse complète demandée par votre patron.\n\n\n\n\nCréer un nouvel objet appelé data_jointes en utilisant une fonction xxx_join() de {dplyr}. Vous souhaitez conserver toutes les notifications, mais ajouter les résultats de tests lorsqu’ils sont disponibles pour chaque cas suspect.\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuelle fonction permet la bonne approche si vous souhaitez conserver toutes les lignes de vos données de notification et intégrer les résultats de vos données de laboratoire ?\n\n left_join(data_notif, data_lab_cas… full_join(data_notif, data_lab_cas… right_join(data_notif, data_lab_cas…\n\nQuel identifiant doit être utilisé pour joindre les deux listes linéaires ?\n\n id_echantillon id_notification id_echantillon et date_notif id_notification et date_notif\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nReliez les données à l’aide de la fonction left_join() avec les données de notification comme ensemble de données principal à gauche. Toutes les lignes de cet ensemble de données seront conservées et seuls les résultats des tests provenant de l’ensemble de données de laboratoire renseigné à “droite” de la fonction seront ajoutés.\n\ndata_jointes &lt;- left_join(data_notif, data_lab_cas, \n                         by = \"id_notification\")\n\nVous créez la jointure avec la colonne id_notification qui est présente, complète et propre dans les deux base de données.\nNote: Vous avez de la chance de travailler avec un exemple de jointure aussi simple ! D’habitude, il faut vraiment nettoyer et vérifier la colonne d’identifiant, ou établir un lien avec d’autres colonnes comme le nom et la date de naissance. À Feveria, le personnel de la clinique est fantastique pour attribuer systématiquement des identifiants de notification à chaque patient, et de les renseigner sur les formulaires d’échantillon envoyés au laboratoire, et le personnel du laboratoire est tout aussi brillant pour enregistrer l’identifiant de notification dans leur système informatique afin que les résultats puissent être reliés au cas.\n\n\n\n\n\n\nVérifiez maintenant vos données et examinez quelques points.\n\n\n\n\n\n\nQuestions\n\n\n\n\nCombien de lignes contient votre nouvelle base de données data_jointes ?\n\n 987 884 858\n\nEt par rapport à vos données de notification d’origine ?\n\n plus de lignes que l'original même nombre de lignes moins de lignes\n\nQuel terme décrit le mieux la jointure que vous venez de réaliser?\n\n plusieurs-à-un un-à-un plusieurs-à-plusieurs\n\nCombien de résultats de laboratoire n’ont PAS été joints aux données de notification (indice : utilisez la fonction anti_join()) ?\n\n 30 19 0\n\nAvez-vous de la chance que votre jointure soit si réussi ?\n\n Quoi ? Toutes les jointures ne sont-ils pas aussi simples que cela ? Tout à fait ! En général, certains enregistrements ne trouvent pas de correspondance\n\nQuelles sont les raisons typiques pour lesquelles il n’y a pas de correspondance trouvé pour des données de laboratoire et des données sur les maladies à déclaration obligatoire ?\n\n Il y a des fautes de frappe dans les colonnes utilisées pour la correspondance, elles ne sont donc pas reconnues comme correspondant Les données de laboratoire peuvent contenir des cas supplémentaires provenant d'autres cliniques ou pays Les données de laboratoire peuvent inclure des échantillons de test Des notifications peuvent avoir été accidentellement omises dans les données de surveillance même si l'échantillon a été testé en laboratoire Toutes les réponses ci-dessus\n\nCombien de cas suspects n’ont pas de résultat ?\n\n 83 100 129\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVérifiez le nombre de lignes dans chaque ensemble de données à l’aide de la fonction nrow() ou en vérifiant les informations relatives à l’objet dans votre environnement. Vous pouvez constater l’opération était une jointure un-à-un, car chaque ligne avait un id_notification unique, de sorte qu’une ligne dans les données de notification était directement liée à une ligne dans les données de laboratoire.\nNombre de lignes dans les données de notification\n\nnrow(data_notif)\n\n[1] 987\n\n\nNombre de lignes dans les données jointes\n\nnrow(data_jointes)\n\n[1] 987\n\n\nPour vérifier si des résultats de laboratoire n’ont pas été reliés à des données de notification, vous pouvez utiliser la fonction anti_join(). Cette fois, data_lab_cas est à gauche, car la fonction évalue le nombre de lignes de l’objet de gauche qui n’ont pas été trouvées dans l’ensemble de données de droite, en les faisant correspondre par id_notification. Ici, il n’est pas nécessaire de créer un nouvel objet, vous pouvez simplement faire passer le résultat à nrow() avec un pipe pour compter le nombre de lignes. Le résultat est 0, ce qui montre qu’il n’y a pas eu de résultats de labo non reliés - incroyable !\n\nanti_join(data_lab_cas, data_notif, \n          by = \"id_notification\") |&gt; nrow()\n\n[1] 0\n\n\nEnfin, pour vérifier le nombre de notifications sans résultat, vous pouvez soit réaliser un anti_join() en mettant data_notif d’abord :\n\nanti_join(data_notif, data_lab_cas, \n          by = \"id_notification\") |&gt; nrow()\n\n[1] 129\n\n\nOu vous pouvez aussi simplement évaluer le nombre de valeurs manquantes dans la colonne valeur dans data_jointes (puisque valeur provient des données de laboratoire).\n\ntabyl(is.na(data_jointes$valeur)) \n\n is.na(data_jointes$valeur)   n   percent\n                      FALSE 858 0.8693009\n                       TRUE 129 0.1306991\n\n\nCes deux approches montrent que 129 cas suspects ne présentent pas de résultat de laboratoire.\n\n\n\n\n\n\n\n\n\nUtiliser mutate() pour créer une nouvelle colonne cas_categorie, afin de mettre à jour le status de cas suspect en fonction de leurs résultats de laboratoire. Les catégories devraient être les suivantes :\n\nSi le résultat est positif : Confirmé\nSi le résultat est négatif : Ecarté\nSi le résultat est indéterminé ou manquant : Suspect\n\nCela signifie que tous les cas figurant dans les données de notification sont d’abord “Suspect” lorsqu’ils sont déclarés, puis restent “Suspect” en l’absence d’un résultat de test concluant.\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuelle est la fonction la plus appropriée pour créer cette nouvelle colonne?\n\n case_when() if_else() case_match()\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVous devez utiliser case_when() pour créer la nouvelle colonne. Cette fonction est idéale pour appliquer plusieurs conditions logiques afin d’attribuer de multiples valeurs différentes, alors que case_match() est plus adapté pour remplacer des valeurs spécifiques, et if_else() est préférable s’il n’y a que deux valeurs possibles.\n\ndata_jointes &lt;- data_jointes |&gt; \n  mutate(cas_categorie = case_when(valeur==\"Positif\" ~ \"Confirmé\",\n                                   valeur==\"Négatif\" ~ \"Ecarté\",\n                                   valeur==\"Indéterminé\" | is.na(valeur) ~ \"Suspect\"))\n\n\n\n\n\n\n\n\n\n\nUtilisez tabyl() directement, et aussi en croisant avec les maladies pour répondre aux questions ci-dessous.\n\n\n\n\n\n\nQuestions\n\n\n\n\nCombien de cas dans les données de notification jointes n’ont pas de résultat positif ou négatif ?\n\n 202 347 250\n\nQuel pourcentage de cas dans les données de notification ONT un résultat positif ou négatif ?\n\n 60,1 % 79,5 % 92,2 %\n\nPourquoi y a-t-il plus de cas suspects restants que de notifications sans résultat de laboratoire relié?\n\n Les cas suspects comprennent les notifications sans résultat de laboratoire et avec un résultat de laboratoire indéterminé Il y a des cas suspects supplémentaires provenant du laboratoire Il y a un problème avec les données\n\nQuelle maladie présentait le pourcentage le plus élevé de cas restés suspects après la jointure?\n\n Choléra Paludisme Dengue Fièvre jaune\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nUne fois de plus, vous pouvez utiliser tabyl() pour voir la répartition des catégories de cas entre les notifications. Le nombre total de cas suspects, c’est-à-dire ceux pour lesquels aucun résultat de laboratoire n’a été obtenu ou pour lesquels le résultat est indéterminé, est de 202. Cela signifie que 785 cas, soit 79,5 %, ont obtenu un résultat de laboratoire définitif.\n\ntabyl(data_jointes, cas_categorie) \n\n cas_categorie   n   percent\n      Confirmé 438 0.4437690\n        Ecarté 347 0.3515704\n       Suspect 202 0.2046606\n\n\nVous pouvez également croiser les résultats originaux (indéterminé/négatif/positif) de valeur avec la nouvelle colonne cas_categorie, pour vérifier que votre logique a fonctionné et pour voir comment les valeurs originales correspondent aux valeurs de la nouvelle colonne. Cela montre qu’en plus des 129 notifications qui n’ont pas été reliées à un résultat de test (avec NA dans la colonne valeur), 73 avaient des résultats indéterminés et ont donc été classées dans la catégorie des cas suspects.\n\ntabyl(data_jointes, cas_categorie, valeur) \n\n cas_categorie Indéterminé Négatif Positif NA_\n      Confirmé           0       0     438   0\n        Ecarté           0     347       0   0\n       Suspect          73       0       0 129\n\n\nEnfin, vous pouvez également croiser les catégories avec les noms de maladie pour voir les catégories de cas par maladie. Ajoutez des fonctions adorn_xxx() pour ajouter et mettre en forme des pourcentages. Le tableau montre ainsi que 22 % des cas de fièvre jaune sont restés suspects, ce qui représente le pourcentage le plus élevé par rapport aux autres maladies.\n\ntabyl(data_jointes, maladie_notifiee, cas_categorie) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n maladie_notifiee    Confirmé      Ecarté     Suspect        Total\n          cholera 82.6%  (38)  4.3%   (2) 13.0%   (6) 100.0%  (46)\n           dengue 68.1% (186) 10.6%  (29) 21.2%  (58) 100.0% (273)\n     fievre jaune 33.0%  (33) 45.0%  (45) 22.0%  (22) 100.0% (100)\n        paludisme 32.6% (174) 46.3% (247) 21.0% (112) 100.0% (533)\n         typhoide 20.0%   (7) 68.6%  (24) 11.4%   (4) 100.0%  (35)\n            Total 44.4% (438) 35.2% (347) 20.5% (202) 100.0% (987)\n\n\n\n\n\n\n\n\nUtilisez tabyl() à nouveau, en examinant les résultats par maladie. Réfléchissez au dénominateur adéquat !\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuel pourcentage de cas suspects notifié en 2024 étaient de vrais cas selon leurs résultats de test?\n\n 44% 56% 59%\n\nQuel pourcentage de cas supects de paludisme étaient effectivement atteint de paludisme?\n\n 86% 41% 23%\n\nQuel pourcentage de cas supects de dengue étaient effectivement atteint de dengue?\n\n 87% 41% 23%\n\n\n\n\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\nDiviser le nombre de cas confirmés (c’est-à-dire ceux dont le résultat est positif) par le nombre de cas confirmés plus les cas écartés (c’est-à-dire ceux dont le résultat est soit positif, soit négatif). On obtient ainsi un taux de positivité, qui correspond approximativement au pourcentage de cas suspects qui étaient réellement des cas. Les résultats indéterminés sont exclus du dénominateur car ils ne fournissent pas de résultat clair et fausseraient le taux de positivité.\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nFiltrez les cas toujours suspects, puis réalisez un tableau croisé pour connaître le pourcentage de cas initialement suspectés qui ont été ou confirmés ou écartés, parmi ceux dont les résultats de test sont valides.\nAvec la ligne de totaux, vous pouvez voir que 56 % des cas suspects ont été confirmés parmi ceux dont les résultats étaient valides. Vous pouvez également voir que 41 % et 87 % des cas de paludisme et de dengue, respectivement, ont été confirmés.\n\ndata_jointes |&gt; \n  filter(cas_categorie != \"Suspect\") |&gt; \n  tabyl(maladie_notifiee, cas_categorie) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n maladie_notifiee    Confirmé      Ecarté        Total\n          cholera 95.0%  (38)  5.0%   (2) 100.0%  (40)\n           dengue 86.5% (186) 13.5%  (29) 100.0% (215)\n     fievre jaune 42.3%  (33) 57.7%  (45) 100.0%  (78)\n        paludisme 41.3% (174) 58.7% (247) 100.0% (421)\n         typhoide 22.6%   (7) 77.4%  (24) 100.0%  (31)\n            Total 55.8% (438) 44.2% (347) 100.0% (785)\n\n\n\n\n\n\n\n\n\nTâche A : Créer une nouvelle liste linéaire appelée data_jointes_confirme.\nC’est ce que vous utiliserez dans les rapports de surveillance officiels.\n\n\n\n\n\n\nQuestions\n\n\n\n\nPourquoi choisissons-nous de ne signaler que les cas confirmés dans nos données de surveillance ?\n\n La déclaration des cas confirmés peut être plus fiable et précise lorsque le pourcentage de tests positifs est faible et que les tests en laboratoire sont systématiques, ce qui permet d'éviter une surestimation de la morbidité La déclaration des cas confirmés est plus lente, ce qui nous donne plus de temps pour nous assurer de l'exactitude de nos déclarations Parce que nous voulons cacher le nombre réel de cas\n\nQuelle fonction est importante pour créer la nouvelle liste linéaire ?\n\n filter() arrange() mutate()\n\nCombien de lignes contient ce nouvel ensemble de données ?\n\n 389 438 858\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVotre équipe de surveillance souhaite se concentrer sur les cas confirmés dans ses rapports. En effet, les tests de laboratoire sont intégrés dans les activités de routine à Feveria, et la déclaration des cas suspects serait inutilement imprécise, un pourcentage élevé de cas suspects étant écartés.\nLa décision de publier les cas suspects peut être différente dans dans d’autres contextes. Par exemple, si le taux de positivité est élevé (la plupart des cas sont des cas réels s’ils sont testés) et que le test lui-même n’est pas courant, ou que le test prend beaucoup de temps et entraînerait un retard dans le rapportage, cela suggérerait que les tendances des cas suspects sont suffisamment précises et également plus opportunes que l’attente d’une confirmation en laboratoire.\nCréez la nouvelle liste linéaire à l’aide de la fonction filter() :\ndata_jointes_confirme &lt;- data_jointes |&gt; \n  filter(cas_categorie==\"Confirmé\")\nEt vérifiez le nombre de lignes en consultant les informations dans votre environnement, ou avec nrow():\nnrow(data_jointes_confirme)\n[1] 438\n\n\n\n\n\n\n\nMaintenant que vous disposez de la liste des cas confirmés de maladies à déclaration obligatoire signalés à Feveria en 2024, vous êtes prêt à effectuer la dernière partie de votre analyse de surveillance ! Il s’agit de décrire les cinq maladies à déclaration obligatoire par zone géographique et par période.\nConseil: L’analyse des données de surveillance comprend généralement une analyse par personne. Vous pourriez développer cette étude de cas en procédant à une analyse selon les variables démographiques.\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuelle maladie à déclaration obligatoire a été la plus souvent notifiée en 2024, en se limitant aux seuls cas confirmés ?\n\n Dengue Paludisme Fièvre jaune\n\nPourquoi la maladie la plus fréquemment signalée diffère-t-elle entre les cas confirmés et les cas suspects ?\n\n La sensibilité et la spécificité du diagnostic clinique peuvent varier selon la maladie Les performances des tests utilisés en laboratoire peuvent varier selon la maladie Il peut y avoir des biais de notification Toutes les réponses ci-dessus !\n\nQuel district a signalé le plus grand nombre de cas confirmés de choléra en 2024 ?\n\n Lac Minara Feveria Central Kasara\n\nCombien de cas confirmés de choléra signalés en 2024 concernaient des résidents de Feveria Central ?\n\n 35 42 4\n\nQuel district a signalé le plus grand nombre de cas confirmés de paludisme en 2024 ?\n\n Lac Minara Feveria Central Kasara\n\nCes données confirment-elles que la dengue est la maladie infectieuse la plus courante à Feveria ?\n\n Non, une autre maladie peut être sous-déclarée et/ou non systématiquement notifiée Oui, si c'est la maladie la plus notifiée, c'est qu'elle doit être la plus courante\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nEn utilisant tabyl() nous pouvons voir que la dengue était la maladie la plus fréquemment notifiée à Feveria en 2024, en se limitant aux cas confirmés, avec 186 cas.\n\ndata_jointes_confirme |&gt; \n  tabyl(maladie_notifiee) \n\n maladie_notifiee   n    percent\n          cholera  38 0.08675799\n           dengue 186 0.42465753\n     fievre jaune  33 0.07534247\n        paludisme 174 0.39726027\n         typhoide   7 0.01598174\n\n\nNotez que cela diffère des cas suspects, où le paludisme a été le plus notifié (avec 533 cas suspects) ! Il y avait déjà des indices, avec un taux de positivité pour les cas suspects de dengue plus élevé que pour les cas suspects de paludisme. Cela peut s’expliquer par différentes raisons, par exemple la méthode de diagnostic clinique utilisée pour le paludisme peut être moins spécifique (de nombreux cas suspects sont en fait d’autres maladies), ou le test utilisé pour la dengue peut être plus sensible.\nCroisez les données avec celles du district résidentiel, puis ajoutez les fonctions adorn_xxx() pertinentes.\n\ndata_jointes_confirme |&gt; \n  tabyl(maladie_notifiee, district_residentiel) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n maladie_notifiee Feveria Central     Kasara  Lac Minara        Total\n          cholera      92.1% (35)  7.9%  (3)  0.0%   (0) 100.0%  (38)\n           dengue       8.6% (16) 17.2% (32) 74.2% (138) 100.0% (186)\n     fievre jaune       0.0%  (0) 18.2%  (6) 81.8%  (27) 100.0%  (33)\n        paludisme      14.9% (26) 22.4% (39) 62.6% (109) 100.0% (174)\n         typhoide      71.4%  (5) 28.6%  (2)  0.0%   (0) 100.0%   (7)\n            Total      18.7% (82) 18.7% (82) 62.6% (274) 100.0% (438)\n\n\nComme pour les cas suspects, on constate que la plupart des cas confirmés de dengue, de paludisme et de fièvre jaune se situent à Lac Minara, zone lacustre où la densité de moustiques et donc de maladies à transmission vectorielle est la plus élevée. La majorité des cas confirmés de choléra et de fièvre typhoïde se trouvaient à Feveria Central, sujet à des problèmes d’eau et d’assainissement.\nLes données suggèrent que les maladies à transmission vectorielle (dengue et paludisme) sont particulièrement préoccupantes dans ce pays tropical. Cependant, nous ne savons pas avec certitude quelle est la maladie la plus fréquente et quels sont les schémas sous-jacents - seules cinq maladies sont à déclaration obligatoire et les cas notifiés ne représentent généralement qu’une fraction des cas réels au sein de la communauté.\n\n\n\n\n\n\n\nVous allez travailler à la réalisation de cette courbe épidémique, à travers les tâches ci-dessous.\n\n\n\n\n\n\n\n\n\n\n\nVeillez à spécifier l’argument binwidth=7 afin que chaque barre de l’histogramme représente le nombre de cas sur une période de 7 jours.\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuand a été notifié le premier cas de fièvre typhoïde de 2024 à Feveria?\n\n Janvier 2024 Mai 2024 Octobre 2024\n\nD’après ce graphique, quel a été le plus grand nombre de cas de dengue notifiés en une seule semaine en 2024?\n\n 10 20 30 Difficile à dire avec ce graphique empilé!\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVoici un code simple pour produire la courbe épidémique. Notez que vous ne contrôlez pas encore les couleurs, ni ne spécifiez le jour de la semaine où commence chaque période de 7 jours.\n\ndata_jointes_confirme |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_notif, fill = maladie_notifiee)), binwidth=7)\n\n\n\n\n\n\n\n\nReportez-vous au chapitre sur les dates du Epi R Handbook si vous souhaitez réaliser un formatage plus spécifique des dates, par exemple pour que chaque barre représente une semaine du lundi au dimanche, ou que l’axe des x indique le numéro de la semaine épidémiologique (semaines 1 à 52).\nIl est important de noter qu’il n’est pas facile de voir les tendances par maladie lorsqu’elles sont empilées de cette manière ! Pour analyser ces tendances temporelles, vous devez produire un histogramme par maladie.\n\n\n\n\n\n\nUtilisez facet_wrap() pour créer facilement plusieurs mini-graphiques, un par maladie. Pour en savoir plus, vous pouvez consulter le chapitre sur les facettes avec ggplot2 du Epi R Handbook\n\n\n\n\n\n\nQuestions\n\n\n\n\nD’après ce graphique stratifié, quel a été le nombre le plus élevé de cas de dengue signalés en une seule semaine en 2024 ?\n\n 11 15 29 Je ne peux toujours rien en dire!\n\nParmi les cas de dengue signalés cette semaine-là, dans quels districts vivaient les personnes concernées ?\n\n Les trois districts Feveria Central Kasara Lac Minara Ce graphique ne montre pas cette information\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVous pouvez maintenant admirer une courbe épidémique par maladie ! Et vous pouvez voir qu’au cours d’une semaine de juillet, 15 cas de dengue ont été signalés. Cependant, ce graphique ne contient pas encore d’informations géographiques.\n\ndata_jointes_confirme |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_notif)), binwidth=7) + \n  facet_wrap(.~maladie_notifiee)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nDans quel(s) district(s) vivaient les 15 cas de dengue notifiés en une semaine en juillet 2024?\n\n Les trois districts Feveria Central Kasara Lac Minara\n\nDans quel district vivait le premier cas de fièvre typhoïde notifié en 2024?\n\n Kasara Feveria Central Lac Minara Je ne peux pas encore le savoir!\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVous pouvez maintenant observer une épicurve par maladie, avec des couleurs reflétant le district dans lequel le cas résidait.\nVous pouvez voir que les 15 cas de dengue signalés au cours d’une seule semaine résidaient dans trois districts différents. Vous pouvez également voir que le premier cas de typhoïde a été signalé à Feveria Central.\n\ndata_jointes_confirme |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_notif, fill = district_residentiel)), binwidth=7) + \n  facet_wrap(.~maladie_notifiee)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVous pouvez ajouter, préciser ou modifier :\n\nLe thème/l’apparence de l’ensemble du graphique (par exemple, la couleur d’arrière-plan ou l’apparence des lignes de la grille)\nLe titre, sous-titre… et les étiquettes des axes\nLes couleurs des barres (avec scale_fill_manual())\nLe formatage et l’espacement des dates le long de l’axe des x (avec scale_x_date)\nBeaucoup d’autres choses !\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nLe choléra et la fièvre typhoïde semblent-ils endémiques ?\n\n Non, les données suggèrent des épidémies occasionnelles de faible ampleur Oui, ils sont tous deux endémiques\n\nY a-t-il une période particulière de l’année où le paludisme a atteint un pic en 2024 ?\n\n Oui, vers novembre/décembre Oui, vers juillet/août (été) Non, le nombre de cas est constamment élevée\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVoici le code pour un formatage complet. Notez que d’autres changements ont été apportés, notamment la spécification que nous ne voulons que deux colonnes de mini-graphiques dans facet_wrap() et que l’étiquette de la date le long de l’axe des x ne doit indiquer que le jour et le mois (et non l’année, puisque tous les cas sont en 2024 de toute façon).\n\ndata_jointes_confirme |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_notif, fill = district_residentiel)), binwidth=7) +\n  facet_wrap(.~maladie_notifiee, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"District de résidence\",\n       x = \"Date de notification par la clinique\",\n       y = \"Nombre\",\n       subtitle = \"Nombres de cas confirmés de choléra, de dengue, de paludisme de fièvre typhoïde et de fièvre jaune par semaine à Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n\n\n\n\n\n\nLes courbes épidémiques montrent également que le choléra et la typhoïde semblent se manifester sous la forme de flambées isolées, plutôt que de présenter un caractère endémique. Le paludisme et la dengue ont par contre présenté une circulation à Feveria tout au long de l’année, le paludisme atteignant un pic assez net pendant les mois d’été.\n\n\n\n\n\n\nCette fois, utilisez group_by() et summarize() pour produire un tableau par district indiquant les dates de notifications les plus anciennes et les plus récentes.\nA l’aide d’une fontion filter(), vous pourrez générer ce tableau pour un district à la fois.\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuand le premier cas de dengue a-t-il été signalé à Feveria en 2024 ?\n\n 18 janvier 2024 17 janvier 2024 12 février 2024\n\nQuand le dernier cas de dengue a-t-il été signalé à Feveria Central en 2024 ?\n\n 22 août 2024 18 novembre 2024 25 décembre 2024\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nRegroupez les données par maladie, puis, dans une fonction summarize(), définissez la première et la dernière date pour obtenir la chronologie globale de chaque maladie à Feveria.\n\ndata_jointes_confirme |&gt; \n  group_by(maladie_notifiee) |&gt; \n  summarize(prem_notif = min(date_notif), \n            der_notif = max(date_notif)) |&gt;\n  ungroup()\n\n# A tibble: 5 × 3\n  maladie_notifiee prem_notif der_notif \n  &lt;chr&gt;            &lt;date&gt;     &lt;date&gt;    \n1 cholera          2024-06-03 2024-09-23\n2 dengue           2024-01-17 2024-11-18\n3 fievre jaune     2024-03-08 2024-08-23\n4 paludisme        2024-01-08 2024-12-25\n5 typhoide         2024-05-02 2024-11-07\n\n\nAjouter un filter() au code pour consulter les dates de la première notification et de la notification la plus récente pour le district qui vous intéresse.\n\ndata_jointes_confirme |&gt; \n  filter(district_residentiel == \"Feveria Central\") |&gt; \n  group_by(maladie_notifiee) |&gt; \n  summarize(prem_notif = min(date_notif), \n            der_notif = max(date_notif)) |&gt;\n  ungroup()\n\n# A tibble: 4 × 3\n  maladie_notifiee prem_notif der_notif \n  &lt;chr&gt;            &lt;date&gt;     &lt;date&gt;    \n1 cholera          2024-06-03 2024-09-23\n2 dengue           2024-01-29 2024-08-22\n3 paludisme        2024-01-29 2024-12-17\n4 typhoide         2024-05-02 2024-11-07\n\n\n\n\n\n\n\n\n\n\nSuperbe ! Conformément aux objectifs de cette étude de cas, vous avez fait ce qui suit :\n\nVous avez utilisé des fonctions clés de R pour nettoyer, remodeler et joindre des ensembles de données, et vous avez créé de nouvelles colonnes à l’aide de conditions logiques.\nPour obtenir des informations sur le traitement des données, vous avez procédé à des analyses exploratoires et à des vérifications des données tout au long du processus.\nVous avez effectué une analyse descriptive approfondie pour comprendre les données de laboratoire et de notification, avant et après la jointure. En réponse aux quatre questions initiales de votre superviseur, vous pouvez dire :\n\nCombien de cas suspects des différentes maladies à déclaration obligatoire ont été signalés en 2024, et lesquels étaient les plus fréquents ? Le paludisme était la maladie à déclaration obligatoire la plus courante à Feveria en 2024. Selon le système de surveillance des maladies à déclaration obligatoire : Il y a eu 533 cas suspects de paludisme, 273 cas suspects de dengue, 100 cas de fièvre jaune, 46 cas de choléra et 35 cas de typhoïde.\nQuel pourcentage de ces cas a été confirmé ? Près de 80 % des cas à déclaration obligatoire signalés en 2024 avaient donné lieu à un résultat de test de laboratoire au moment de la jointure des données, avec quelques variations selon les maladies. Au total, 56 % des cas notifiés ont finalement été confirmés, mais ce pourcentage variait de 23 % seulement pour la fièvre typhoïde (7 cas confirmés sur 31 cas suspects avec résultats de tests) à 95 % pour le choléra (38 cas confirmés sur 40 cas suspects avec résultats de tests). En outre, le taux de positivité était plus élevé pour les cas présumés de dengue que pour les cas présumés de paludisme (87 % contre 41 %).\nCombien de cas confirmés de différentes maladies à déclaration obligatoire ont été signalés en 2024, et laquelle était la plus fréquente ? Les cas confirmés ont suivi une tendance légèrement différente de celle des cas suspects : l’infection la plus fréquemment signalée était la dengue avec 186 cas, suivie du paludisme (174), puis du choléra (38), de la fièvre jaune (33) et de la fièvre typhoïde (7).\nComment les cas confirmés se répartissent-ils géographiquement et temporellement dans la région de Feveria ? Feveria a connu une transmission de la dengue et du paludisme tout au long de l’année, avec un pic en été, et concentrée dans le district de Lac Minara. Feveria a également connu de petites et rares épidémies de maladies diarrhéiques, telles que le choléra et la fièvre typhoïde, en particulier dans la zone urbaine de Feveria Central, où l’eau et l’assainissement peuvent poser problème.\n\nEnfin, vous avez pu réfléchir à la manière dont les processus des systèmes de surveillance des maladies à déclaration obligatoire et ceux des tests de diagnostique de laboratoire, par exemple le transfert des données entre les cliniques et les laboratoires, peuvent affecter la qualité et l’exhaustivité des données, et donc vos résultats.\n\nIl reste encore beaucoup de possibilités. Vous pouvez explorer les distributions des maladies par âge ou par sexe, calculer des taux d’incidence ou de prévalence des maladies à l’aide de données démographiques et même analyser les délais de déclaration en examinant les différentes dates de vos ensembles de données.\nVous avez acquis de solides bases et vous êtes bien équipé pour passer à l’étape suivante de votre analyse. Continuez, des découvertes passionnantes vous attendent !\nPour en savoir plus, consultez les autres études de cas ou plongez dans le Epi R Handbook.\n\n\n\nVous trouverez ci-dessous un script de toutes les étapes de nettoyage des données et des analyses descriptives. Notez que les analyses sont combinées à la fin plutôt qu’intercalées entre les étapes de nettoyage. Il s’agit d’une façon plus ordonnée d’organiser votre script.\nPar souci de concision, le code ci-dessous n’inclut pas toutes les inspections et vérifications effectuées en cours de route, mais vous pouvez décider de créer des sections avec de telles vérifications.\nLe début de votre script doit également contenir des informations pour aider le lecteur à comprendre à quoi sert le script, ainsi que des commentaires tout au long du script. Vous vous remercierez plus tard d’avoir ajouté ces commentaires !\n\n\n\n\n\n\nCode pour nettoyer et analyser les données de notification et les données de laboratoire de Feveria, 2024\n\n\n\n\n\n\n# Code pour nettoyer et analyser les données de notification et les données de laboratoire de Feveria, 2024\n# Date:\n# Author:\n\n# Installation des packages --------------------------------\n# Pour s'assurer que le package \"pacman\" est installé\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# Installation (si nécessaire) depuis le CRAN et chargement des packages à utiliser\npacman::p_load(\n  rio,        # importation de données  \n  skimr,      # aperçu des données\n  janitor,    # nettoyage des données et tableaux descriptifs\n  lubridate,  # manipulation des dates\n  epikit,     # pour créer des catégories d'âge\n  gtsummary,  # statistiques descriptives, tests et régressions \n  apyramid,   # tracé de pyramides des âges \n  flextable,  # tableaux prêts à être présentés\n  naniar,     # analyse des données manquantes\n  remotes,    # pour installer le package permettant de télécharger les données\n  tidyverse   # gestion et visualisation des données\n)\n\n# Importation des données --------------------------------------------\n\n# Données de notification\ndata_notif_brut &lt;- import(\"donnees/multi_maladies_notifications.xlsx\")\n\n# Données de labo\ndata_lab_brut &lt;- import(\"donnees/multi_maladies_tests.csv\")\n\n# Nettoyage des données de notification --------------------------------\ndata_notif &lt;- data_notif_brut |&gt; \n  clean_names() |&gt; \n  rename(date_notif = date_signalee_par_letablissement_de_sante_la_communaute,\n         id_notification = id_de_notification) |&gt; \n  select(id_notification, district_residentiel, maladie_notifiee, date_notif) |&gt; \n  mutate(district_residentiel = case_match(str_to_title(district_residentiel),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lac Minara\", \"Au Bord Du Lac\") ~ \"Lac Minara\")) |&gt; \n  mutate(date_notif = ymd(date_notif)) \n\n\n# Nettoyage et consolidation des données de labo -----------------------\n# Nettoyage des valeurs\ndata_lab &lt;- data_lab_brut |&gt; \n  mutate(valeur = case_match(valeur, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positif\",\n                            \"N\" ~ \"Négatif\",\n                            \"I\" ~ \"Indéterminé\"))\n\n# Création de la base de données de labo orientée tests\ndata_lab_tests &lt;- data_lab |&gt; \n  filter(cible != \"Dengue IgG\") |&gt; \n  group_by(id_echantillon) |&gt; \n  arrange(desc(valeur)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Création de la base de données de labo orientée cas\ndata_lab_cas &lt;- data_lab_tests |&gt; \n  group_by(id_notification) |&gt; \n  arrange(desc(valeur)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Jointure des données de notification et de labo -----------------\ndata_jointes &lt;- left_join(data_notif, data_lab_cas, by = \"id_notification\")\n\n# Nettoyage des données jointes -----------------------------------\ndata_jointes &lt;- data_jointes |&gt; \n  mutate(cas_categorie = case_when(valeur==\"Positif\" ~ \"Confirmé\",\n                                   valeur==\"Négatif\" ~ \"Ecarté\",\n                                   valeur==\"Indéterminé\" | is.na(valeur) ~ \"Suspect\"))\n\ndata_jointes_confirme &lt;- data_jointes |&gt; \n  filter(cas_categorie==\"Confirmé\")\n\n# ANALYSE ---------------------------------------------------------\n# Nombre de cas suspects à Feveria\ntabyl(data_notif, maladie_notifiee)\n\n# Distribution des cas suspects par district\ntabyl(data_notif, maladie_notifiee, district_residentiel) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n# Distribution des résultats de test par type de test\ntabyl(data_lab_tests, test, valeur) |&gt; \n    adorn_totals(where = \"col\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution des catégories de cas dans les données jointes\ntabyl(data_jointes, cas_categorie) \n\n# Distribution des catégories de cas par maladie dans les données jointes\ntabyl(data_jointes, maladie_notifiee, cas_categorie) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution des catégories de cas par maladie dans les données jointes, uniquement pour les cas avec un résultat de test valide\ndata_jointes |&gt; \n    filter(cas_categorie != \"Suspect\") |&gt; \n    tabyl(maladie_notifiee, cas_categorie) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution des cas confirmés par district\ndata_jointes_confirme |&gt; \n  tabyl(maladie_notifiee, district_residentiel) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n\n# Visualisation de l'évolution temporelle de le nombre de cas confirmé par district\ndata_jointes_confirme |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_notif, fill = district_residentiel)), binwidth=7) +\n  facet_wrap(.~maladie_notifiee, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"District de résidence\",\n       x = \"Date de notification par la clinique\",\n       y = \"Nombre\",\n       subtitle = \"Nombres de cas confirmés de choléra, de dengue, de paludisme de fièvre typhoïde et de fièvre jaune par semaine à Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n# Première et dernière date de notification de cas confirmé par maladie\ndata_jointes_confirme |&gt; \n  group_by(maladie_notifiee) |&gt; \n  summarize(prem_notif = min(date_notif), \n            der_notif = max(date_notif)) |&gt;\n  ungroup()\n\n\n\n\n\n\n\n\n\n\n\n\n\nAuteurs originaux Paula Blomquist et Alanah Jansen, avec le soutien technique du CDC Global Surveillance, Laboratory, and Data Systems Branch en collaboration avec TEPHINET.\nSource des données Données fictives fournies par Applied Epi.\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nModifications apportées\nVersion\nAuteur\n\n\n\n\nJuillet 2025\nPremière version\n1\nPaula Blomquist et Alanah Jansen, Applied Epi, avec le soutien technique du CDC Global Surveillance, Laboratory, and Data Systems Branch en collaboration avec TEPHINET.\n\n\nAoût 2025\nTraduction française\n1\nLaurent LeHot et Olivia Boyd\n\n\n\n\n\n\nClause de non-responsabilité Les informations présentées dans cet exercice et les fichiers de données associés ont été développés pour aider les apprenants à atteindre les objectifs d’apprentissage prévus. Le contenu est celui de l’auteur ou des auteurs et ne représente pas nécessairement les opinions officielles du CDC, du US Department of Health and Human Services ou de TEPHINET.\nLicence d’utilisation Licence : Cette étude de cas est sous licence licence CC BY-NC-SA 4.0. Pour plus d’informations sur le partage et l’adaptation de cette étude de cas, voir le certificat associé.\nFinancement Cette étude de cas a été soutenue à 100 % par l’accord de coopération numéro NU2HGH000044 financé par le US Centers for Disease Control and Prevention (CDC)"
  },
  {
    "objectID": "pages/multidisease_surveillance.fr.html#scénario",
    "href": "pages/multidisease_surveillance.fr.html#scénario",
    "title": "Jonction et analyse des données de notification et des données de laboratoire dans R",
    "section": "",
    "text": "Vous êtes un épidémiologiste travaillant au bureau national de surveillance de Feveria, un tout petit pays tropical. Le pays compte trois districts :\n\nFeveria Central: une zone urbaine surpeuplée, avec des infrastructures d’eau et d’assainissement parfois peu fiables.\nLac Minara: une région lacustre dotée de bonnes infrastructures, mais avec une forte présence de moustiques pendant les mois les plus chauds de l’année.\nKasara: une zone suburbaine de l’autre côté de Feveria Central.\n\nCarte des districts du pays Feveria\n\nNous sommes en janvier 2025, et votre supérieure hiérarchique souhaite que vous transfériez le traitement de routine des données sur les maladies à déclaration obligatoire d’Excel à R, et d’effectuer quelques analyses sur ces données. Elle souhaite connaître au minimum:\n\nCombien de cas suspects des différentes maladies à déclaration obligatoire ont été signalés en 2024, et quelle était la plus représentée ?\nParmi eux, quel était le pourcentage de cas confirmés ?\nCombien de cas confirmés des différentes maladies à déclaration obligatoire ont été signalés en 2024, et quelle était la plus représentée ?\nComment se répartissaient géographiquement et temporellement les cas confirmés dans la région de Feveria ?\n\nElle vous demande d’écrire le code pour importer, nettoyer, joindre et analyser les listes linéaires suivantes :\n\nDonnées de surveillance 2024 des maladies à déclaration obligatoire : Appelées également “données de notification”, il s’agit de données de surveillance sur cinq maladies à déclaration obligatoire signalées par les cliniques de Feveria : la dengue, le paludisme, le choléra, la fièvre typhoïde et la fièvre jaune. Il s’agit de cas suspects, basés sur les symptômes des patients. Les cliniciens saisissent chaque notification dans un système en ligne tous les jours de la semaine.\nDonnées 2024 sur les résultats des tests de laboratoire : Ces données sont issues des résultats des tests de laboratoire effectués par trois grands laboratoires de Feveria. Ces résultats concernent des échantillons prélevés sur les cas suspects de maladies à déclaration obligatoire enregistrés dans la première base de données ci-dessus.\n\nAllons-y !"
  },
  {
    "objectID": "pages/multidisease_surveillance.fr.html#les-objectifs",
    "href": "pages/multidisease_surveillance.fr.html#les-objectifs",
    "title": "Jonction et analyse des données de notification et des données de laboratoire dans R",
    "section": "",
    "text": "Dans cette étude de cas, vous allez :\n\nUtiliser des fonctions essentielles de R pour nettoyer des données, remodeler des bases de données, fusionner différentes sources de données et créer de nouvelles colonnes à l’aide de conditions logiques pour préparer les données pour l’analyse.\nPasser en revue les données et effectuer des contrôles de leur qualité à plusieurs étapes du projet et comprendre l’importance de ces actions pour une analyse fiable.\nConduire des analyses descriptives de base pour comparer les tendances des maladies à partir de différentes sources de données, avant et après la jointure.\nInterpréter les différences de résultats selon les sources de données et comprendre comment elles reflètent la structure et la conception du système de surveillance dans son ensemble."
  },
  {
    "objectID": "pages/multidisease_surveillance.fr.html#étape-1.-mise-en-place",
    "href": "pages/multidisease_surveillance.fr.html#étape-1.-mise-en-place",
    "title": "Jonction et analyse des données de notification et des données de laboratoire dans R",
    "section": "",
    "text": "Commencez par la mise en place d’un flux de travail reproductible et bien organisé. Ce processus facilitera le renouvellement de votre analyse chaque fois que cela sera nécessaire.\nTâches :\n\nCréation d’un un projet RStudio\nCréation d’une structure claire de sous-dossiers dans lesquels vous placerez votre code, vos données et vos résultats / sorties.\nCréation d’un script R, ou d’un fichier R Markdown si vous préférez. Assurez-vous que que le but du script, la date et l’auteur sont écrits sous forme de commentaires en haut du script.\nAdditionnel : Assurez-vous que votre langue de travail dans RStudio est appropriée (par ex. le français pour cet exercice)\n\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\n\nCréez un dossier dans lequel vous placerez tous les travaux de cette étude de cas. Par exemple, créez un dossier “Analyse_multi_maladies” sur le bureau de votre ordinateur. Créez votre projet RStudio dans ce dossier.\nNous suggérons de créer les sous-dossiers suivants : scripts (pour votre code), donnees (pour vos données), et resultats (pour vos résultats d’analyse).\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nCréez un dossier (par exemple “Analyse_multi_maladies” sur votre bureau) pour cet exercice. Pour créer un projet Rstudio dans votre nouveau dossier, cliquez sur l’icône New Project en haut à gauche de votre fenêtre R Studio (ou sur File puis New Project), puis surExisting Directory puis Browse pour sélectionner votre nouveau dossier. Pour plus d’informations, consultez la section Projets R du Epi R Handbook.\nOuvrez un nouveau script R en cliquant sur l’icône New File en haut à gauche de votre écran R Studio (ou sur File puis New File), puis R Script. Sauvegardez-le immédiatement à un endroit approprié, par exemple, dans le sous-dossier scripts de votre dossier de projet R.\nAu début de votre nouveau script R, écrivez sous forme de commentaires quelques informations essentielles telles que votre nom, le but du fichier et la date.\nLes paramètres R “locale” déterminent la langue et les paramètres régionaux utilisés pour les scripts R comme les formats de date et les traductions. Si vos paramètres régionaux sont différents de la langue que vous souhaitez utiliser pour votre rapport (par exemple, les paramètres anglophones au lieu des paramètres francophones), vous pouvez les remplacer par les francophones en exécutant la commande Sys.setlocale(\"LC_ALL\", \"French\"). Incluez cette commande dans votre script si nécessaire, ou ignorez-la si vos paramètres sont appropriés. Ceci est expliqué plus en détail dans le Guide pratique.\n\n\n\n\n\n\nDans votre script R, vous devez maintenant installer et charger les packages R nécessaires. Cela permet de s’assurer que les fonctions nécessaires sont disponibles pour votre analyse.\nVous aurez besoin des packages suivants : {rio} (pour l’importation des données),{skimr} (pour l’examen des données), {janitor} (pour le nettoyage des données), {lubridate} (pour le nettoyage des dates), {epikit} (pour des tâches liées à l’épidémiologie), {gtsummary} (pour les statistiques descriptives / les tests et régressions), {apyramid} (pour les pyramides des âges et des sexes), {flextable} (pour des tableaux prêts à être présentés), {naniar} (pour l’analyse des données manquantes), et {tidyverse} (pour la manipulation générale des données et autres tâches scientifiques).\nVous aurez également besoin du package{remotes} pour télécharger les données - ce que nous expliquerons dans la section sur le téléchargement.\nAlors que vous commencez, votre collègue expérimenté vous glisse : “J’ai entendu parler du package {pacman} pour facilement gérer l’instalation et le chargement des packages dans R”.\nÀ vous de jouer !\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nUtilisez la fonction p_load() de pacman pour cette tâche. Vous fournissez à la fonction une liste de packages que vous souhaitez utiliser. La fonction effectuera deux étapes pour chaque package :\n\nVérifier si le package est installé sur votre ordinateur, et l’installer si nécessaire, puis\nCharger le package pour qu’il pour qu’il puisse être utilisé pendant cette session R.\n\nSi vous n’avez pas encore installé pacman, vous devrez d’abord l’installer de manière “traditionnelle”, à l’aide de la fonction install.packages().\nNotez que l’ordre des packages dans votre fonction p_load peut être important. Si deux packages possèdent une fonction avec un nom identique (par exemple select() dans le package MASS et select() dans tidyverse qui réalisent des tâches différentes), alors R utilisera la fonction du dernier package chargé. Pour donner la priorité aux fonctions de tidyverse, qui sont couramment utilisées pour la manipulation et la visualisation des données, chargez tidyverse en dernier.\n\n# Pour s'assurer que le package \"pacman\" est installé\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# Installation (si nécessaire) depuis le CRAN et chargement des packages à utiliser\npacman::p_load(\n  rio,        # importation de données  \n  skimr,      # aperçu des données\n  janitor,    # nettoyage des données et tableaux descriptifs\n  lubridate,  # manipulation des dates\n  epikit,     # pour créer des catégories d'âge\n  gtsummary,  # statistiques descriptives, tests et régressions \n  apyramid,   # tracé de pyramides des âges \n  flextable,  # tableaux prêts à être présentés\n  naniar,     # analyse des données manquantes\n  remotes,    # pour installer le package permettant de télécharger les données\n  tidyverse   # gestion et visualisation des données\n)"
  },
  {
    "objectID": "pages/multidisease_surveillance.fr.html#étape-2.-télécharger-et-importer-les-données",
    "href": "pages/multidisease_surveillance.fr.html#étape-2.-télécharger-et-importer-les-données",
    "title": "Jonction et analyse des données de notification et des données de laboratoire dans R",
    "section": "",
    "text": "Votre bureau vous fournit deux fichiers pour votre analyse, tous deux contenant des données pour 2024 et mises à jour au 15 janvier 2025 :\n\nun ensemble de données de notification des maladies (“multi_maladies_notifications.xlsx”) avec l’information sur les cas de 5 centres de santé.\nUn ensemble de données au niveau des tests de laboratoire (“multi_maladies_tests.csv”) soumis par trois laboratoires effectuant des tests pour les cinq centres de santé.\n\nPour cette étude de cas, vous pouvez télécharger les données via le répertoire de données d’Applied Epi, auquel vous pouvez accéder grâce au package {appliedepidata}. Suivez les étapes suivantes :\n\nInstallez le package {appliedepidata} depuis GitHub à l’aide de la fonction install_github() du package {remotes} (que vous avez installé précédemment)\n\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nEnregistrez les deux ensembles de données dans un dossier spécifique à l’aide de la fonction save_data() de {appliedepidata} en exécutant le code ci-dessous. Dans l’exemple ci-dessous, les données sont enregistrées dans un sous-dossier donnees du dossier de projet RStudio. Notez que si vous ne spécifiez pas d’emplacement spécifique avec l’argument path de la fonction, une fenêtre s’ouvrira pour vous demander de sélectionner manuellement un dossier.\n\n\n# Téléchargement des deux fichiers de données en utilisant la fonction save_data()de appliedepidata\nappliedepidata::save_data(\"multi_maladies_tests\",\n                        path = \"donnees\")\n\nappliedepidata::save_data(\"multi_maladies_notifications\",\n                          path = \"donnees\")\n\n\n\n\nTrès bien ! Merci au bureau national et à Applied Epi ! Il est maintenant temps d’importer les données de ce dossier dans RStudio, afin de pouvoir les analyser.\n\n\nIdéalement, vous utiliserez la même fonction pour importer les deux ensembles de données, bien qu’un soit un fichier .csv et l’autre un fichier .xlsx. Notez qu’à l’avenir, nous dirons simplement “environnement” lorsque nous parlerons de la fenêtre environnement dans R Studio.\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\nUtiliser la fonction import du package {rio}, qui peut reconnaître et importer différents types de fichiers. Elle remplace les fonctions d’importation qui sont spécifiques à un type de fichier, telles que read.csv() de {base} pour les fichiers .csv et read_excel() de {readxl} pour importer des fichiers .xlsx.\nPour en savoir plus sur les fonctions d’importation, lisez le chapitre Importer et exporter des données du Epi R Handbook.\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nCi-dessous, nous utilisons la fonction d’importation pour importer les deux fichiers. Notez que nous assignons les données importées à deux objets, l’un appelé data_notif_brut et un autre appelé data_lab_brut. Nous ajoutons le suffixe “brut” pour distinguer ces données des versions nettoyées que nous créerons plus tard.\n\n# Importation des données\n\n# Données de notification\ndata_notif_brut &lt;- import(\"donnees/multi_maladies_notifications.xlsx\")\n\n# Données de labo\ndata_lab_brut &lt;- import(\"donnees/multi_maladies_tests.csv\")"
  },
  {
    "objectID": "pages/multidisease_surveillance.fr.html#étape-3.-inspecter-les-données",
    "href": "pages/multidisease_surveillance.fr.html#étape-3.-inspecter-les-données",
    "title": "Jonction et analyse des données de notification et des données de laboratoire dans R",
    "section": "",
    "text": "Les données sont là, il est maintenant temps de voir ce qu’elles racontent. Jetez un premier coup d’oeil à vos deux ensembles de données brutes pour en vérifier le contenu et la qualité.\n\n\n\n\nUtilisez skim() du package {skimr} package, ainsi que names(), ncol() et nrow() pour inspecter votre ensemble de données.\nskim() vous donne de nombreuses informations sur la structure et le contenu des données, et names() vous fournira les différents noms de colonnes des données. Les fonctions ncol() et nrow() renvoient le nombre de colonnes ou de lignes dans les données. Savez-vous ce qu’il faut mettre entre les parenthèses ?\nLe plus simple est de regarder dans l’environnement. Rappelez-vous que l’objet de votre environnement contenant les données de notification s’appelle data_notif_brut.\nCliquez sur la solution sous l’encart de questions si vous avez besoin d’aide.\n\n\n\n\n\n\nQuestions\n\n\n\n\nCombien y a-t-il de colonnes dans les données de notification?\n\n 10 11 12 13\n\nLaquelle de ces colonnes n’apparait PAS dans les données?\n\n Date d'apparition Date signalée par l'établissement de santé/la communauté Date du résultat Date de test Date de naissance\n\nQuel est le nom de la / des colonne(s) permettant d’identifier chaque notification de cas?\n\n ID de notification Test ID Code de l'établissement de santé Combinaison de ID de notification et Sexe\n\nCombien y a-t-il de lignes dans les données de notification?\n\n 987 1314 950 778\n\nA quel type d’information n’avez vous PAS accès dans les données de notification?\n\n Le résultat du test de laboratoire Le district de résidence La date de naissance et le sexe La structure de santé où a eu lieu la notification L'issue de la maladie\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nUtilisez skim() du package {skimr} pour obtenir un résumé de l’ensemble des données, et View() pour consulter directement l’ensemble de la base de données sous forme de tableur :\n\nskim(data_notif_brut)\n\nVous pouvez également utiliser names() pour imprimer uniquement les noms des colonnes. Par l’intermédiaire de skim() et names() vous aurez accès à différents type d’information, notamment : l’établissement de santé du cas, la date de naissance, le sexe, un indicateur de grossesse, le district de résidence, la date d’apparition et la date rapportée par la clinique, ainsi que des informations sur l’issue de la maladie.\nIl y a également ID de notification qui semble être un identifiant unique pour un cas, mais nous devrions vérifier les doublons avant d’en être sûrs.\nNotez qu’il n’y a AUCUN résultat de test dans ces données, car ces notifications proviennent des cliniques qui notifient les maladies à déclaration obligatoire sur la base de définitions de cas cliniques.\n\nnames(data_notif_brut)\n\n [1] \"Nom de l'unite d'organisation\"                           \n [2] \"Code de l'etablissement de sante\"                        \n [3] \"ID de notification\"                                      \n [4] \"Date de naissance\"                                       \n [5] \"Sexe\"                                                    \n [6] \"Enceinte\"                                                \n [7] \"District residentiel\"                                    \n [8] \"Maladie notifiee\"                                        \n [9] \"Date d'apparition\"                                       \n[10] \"Date signalee par l'etablissement de sante/la communaute\"\n[11] \"Resultat\"                                                \n[12] \"Date du resultat\"                                        \n\n\nUtilisez ncol() et nrow() pour imprimer le nombre de colonnes et de lignes, comme ceci :\n\nncol(data_notif_brut)\nnrow(data_notif_brut)\n\nCeci imprimera le nombre de colonnes et de lignes dans votre console.\n\n\n[1] 12\n\n\n[1] 987\n\n\nPar ailleurs, si l’on examine l’environnement, on constate que le nombre d’observations (qui sont les mêmes que les lignes) et de colonnes sont à côté du nom de la base de données.\n\n\n\n\n\n\nUtilisez skim() du package {skimr} ou class() pour explorer les classes des colonnes.\nVous souvenez-vous de la façon de spécifier la colonne qui vous intéresse à l’intérieur de la fonction class() ? Vous pouvez également explorer les classes depuis l’environnement.\n\n\n\n\n\n\nQuestions\n\n\n\n\nCombien de colonnes dans l’ensemble de données de notification sont reconnues par R comme étant de classe date ?\n\n 0 2 4\n\nQuelle est la classe de la plupart des colonnes dans les données brutes de notification?\n\n character numeric factor\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVous pouvez utiliser class comme dans l’exemple ci-dessous. Le $ est un opérateur utilisé pour sélectionner une colonne spécifique de l’ensemble de données data_notif_brut.\nNotez l’utilisation d’apostrophes inversées (`) autour de Date de naissance parce que le nom de la colonne contient des espaces.\n\nclass(data_notif_brut$`Date de naissance`)\n\nPour consulter la classe via l’environnement, cliquez sur la flèche bleue à côté du nom de l’ensemble de données. Les noms des colonnes apparaissent, avec la classe à côté (par exemple, “chr” indique la classe texte / caractères).\nVous pouvez voir qu’aucune des colonnes qui devraient être des dates n’est reconnue comme telle. Au lieu de cela, elles sont reconnues comme des valeurs texte.\n\n\n\n\n\n\nUtiliser la fonction tabyl() pour inspecter les valeurs dans les colonnes qualitatives/catégorielles en spécifiant le nom de la base de données comme premier argument, et le nom de la colonne comme second argument.\nPar exemple, ce code renvoie le contenu de la colonne Sexe. La sortie montre que masculin et féminin sont sont orthographiés de manière incohérente dans les données. Cette colonne devra faire l’objet d’un nettoyage avant de pouvoir être analysée.\n\ntabyl(data_notif_brut, Sexe)\n\n     Sexe   n    percent valid_percent\n        F  47 0.04761905    0.05452436\n  FEMININ 146 0.14792300    0.16937355\n        M  40 0.04052685    0.04640371\n MASCULIN 172 0.17426545    0.19953596\n        f 154 0.15602837    0.17865429\n  feminin  98 0.09929078    0.11368910\n        m 119 0.12056738    0.13805104\n masculin  86 0.08713273    0.09976798\n     &lt;NA&gt; 125 0.12664640            NA\n\n\nPour analyser les données manquantes, vous pouvez utiliser la fonction miss_var_summary() du package {naniar} :\n\nmiss_var_summary(data_notif_brut)\n\n# A tibble: 12 × 3\n   variable                                                 n_miss pct_miss\n   &lt;chr&gt;                                                     &lt;int&gt;    &lt;num&gt;\n 1 Date d'apparition                                           691     70.0\n 2 Enceinte                                                    510     51.7\n 3 Resultat                                                    197     20.0\n 4 Date du resultat                                            197     20.0\n 5 Date de naissance                                           168     17.0\n 6 Sexe                                                        125     12.7\n 7 Nom de l'unite d'organisation                                 0      0  \n 8 Code de l'etablissement de sante                              0      0  \n 9 ID de notification                                            0      0  \n10 District residentiel                                          0      0  \n11 Maladie notifiee                                              0      0  \n12 Date signalee par l'etablissement de sante/la communaute      0      0  \n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nLes valeurs dans la colonne District résidentiel sont-elles standardisées ?\n\n Non, elles doivent être nettoyées Elles sont standardisées et prêtes à être utilisées dans l'analyse\n\nLes valeurs dans la colonne Maladie notifiee sont-elles normalisées ?\n\n Non, elles doivent être nettoyées Elles sont standardisées et prêtes à être utilisées dans l'analyse\n\nQu’est-ce que R reconnait comme une valeur manquante?\n\n Soit une absence de valeur, ou juste un espace ou un point Pas de valeur dans la cellule, représenté par NA Les mots Inconnu et Indéterminé\n\nSelon l’analyse des données manquantes, est-ce que la colonne Date d'apparition vous paraît exploitable et utile?\n\n Oui, il y a peu de données manquantes, elle est donc utile Assez peu, au vu de la proportion de données manquantes\n\nPourquoi certaines colonnes des données de notification peuvent présenter des orthographes différentes et des catégories non standardisées ?\n\n Un bot brouille les données afin qu'elles soient moins identifiables Chaque clinique peut utiliser un logiciel configuré de manière légèrement différente, ou utiliser des entrées en texte libre, ce qui entraîne des variations orthographiques Le logiciel du système de surveillance utilisé par les établissements cliniques comporte de nombreux bugs\n\nWhy might some columns in the notification data have high missingness?\n\n The clinician does not ask the patient the question during their consultation The patient might not know or want to share the answer The clinician might not have time to prioritise filling in that field in the data, even if they know the information All of the above, and many more reasons\n\nPourquoi certaines colonnes de données de notification peuvent présenter une proportion élevée de données manquantes ?\n\n Le clinicien ne pose pas la question au patient pendant la consultation Le patient peut ne pas connaître la réponse ou ne pas vouloir la partager Le clinicien peut ne pas avoir le temps de remplir ce champ dans les données, même s'il connaît l'information Toutes les raisons ci-dessus, et bien d'autres encore\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nUtilisez la fonction tabyl() le résumé des valeurs de la colonne District residentiel. Là encore, le premier argument est le nom de l’ensemble de données et le deuxième argument est le nom de la colonne.\n\ntabyl(data_notif_brut, `District residentiel`)\n\n District residentiel   n    percent\n       Au bord du lac 125 0.12664640\n            F Central  32 0.03242148\n            FEVERIA C  23 0.02330294\n      FEVERIA CENTRAL  85 0.08611955\n            Feveria C  24 0.02431611\n      Feveria Central  12 0.01215805\n               KASARA  64 0.06484296\n                  KSR  17 0.01722391\n               Kasara 109 0.11043566\n             L MINARA  50 0.05065856\n             L Minara 193 0.19554205\n           LAC MINARA 185 0.18743668\n           Lac Minara  68 0.06889564\n\n\nVous pouvez constater que chacun des trois emplacements (Feveria Central, Lac Minara et Kasara) sont orthographiés de différentes manières et en lettres majuscules ou minuscules. Il faudra faire le ménage si l’on veut analyser la distribution géographique des maladies à déclaration obligatoire.\nDe même, utilisez tabyl() résumer les valeurs contenues dans la colonne Maladie notifiee. Vous pouvez voir qu’elles sont écrites en toutes lettres de manière appropriée et cohérente, de sorte que vous pouvez déjà voir la distribution des maladie sans nettoyage supplémentaire.\n\ntabyl(data_notif_brut, `Maladie notifiee`)\n\n Maladie notifiee   n    percent\n          cholera  46 0.04660588\n           dengue 273 0.27659574\n     fievre jaune 100 0.10131712\n        paludisme 533 0.54002026\n         typhoide  35 0.03546099\n\n\nUne autre façon d’analyser les données manquantes est de résumer la sortie de la fonction is.na(). Dans l’exemple ci-dessous, la fonction is.na() évalue chaque cellule de la colonne Date d'apparition et renvoie TRUE pour pour les valeurs manquantes et FAUX pour les valeurs présentes.\nAppliquer tabyl() à cette série de TRUE/FALSE vous permet d’obtenir rapidement les effectifs et proportions de données manquantes dans cette colonne. N’oubliez pas que les valeurs comme un espace ou les mots “Inconnu” ou “Manquant” ne seront pas reconnues par R comme manquantes. R ne reconnaîtra que les cellules vides comme données manquantes, représentées par NA.\nPour Date d'apparition, vous pouvez voir que 70 % des cas n’ont pas de valeur, ce qui suggère que cette colonne n’est pas particulièrement utile pour analyser des tendances de maladies au fil du temps.\n\ntabyl(is.na(data_notif_brut$`Date d'apparition`))\n\n is.na(data_notif_brut$`Date d'apparition`)   n   percent\n                                      FALSE 296 0.2998987\n                                       TRUE 691 0.7001013\n\n\nLes données manquantes ou non standardisées peuvent être dues à de nombreuses raisons, notamment:\n\nla conception de l’outil de collecte de données (par exemple, si les questions sont obligatoires ou si elles utilisent du texte libre plutôt que des listes déroulantes),\nles processus et les normes en place (par exemple, des champs que le personnel a pour instruction de prioriser), et\nles facteurs contextuels (par exemple, si le personnel dispose de suffisamment de temps pour collecter les informations).\n\n\n\n\n\n\n\n\n\n\nComme pour les données de surveillance, utilisez skim(), ncol() et nrow()ou inspecter l’environnement pour inspecter les données de laboratoire.\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuelle liste linéaire comporte le plus de colonnes : les données de surveillance ou les données de laboratoire ?\n\n Les données de laboratoire Les données de surveillance Elles ont le même nombre de colonnes\n\nQuelle liste linéaire comporte le plus de lignes ?\n\n Les données de laboratoire Les données de surveillance Elles ont le même nombre de lignes\n\nInspectez les données de laboratoire avec View(). Pour quelle raison les données de laboratoire pourraient avoir plus d’enregistrements ?\n\n Il peut y avoir plusieurs tests ou cibles analysées par échantillon Il y a de nombreux résultats de tests d'étalonnage dans les données Toutes les notifications n'ont pas encore reçu de résultats de tests\n\nLaquelle de ces informations ne figure PAS dans les données de laboratoire ?\n\n ID de notification ID d'échantillon Type de test Date de naissance Résultat du test\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nComme dans la section 3.1, vous pouvez utiliser skim() du package {skimr} pour examiner l’ensemble de données de laboratoire avec les résultats des tests. Vous verrez également les différents noms de colonnes de données, montrant que les données de laboratoire ne contiennent que des informations sur le test et non sur le patient. Elles contiennent toutefois un identifiant de notification, comme les données de notification.\n\nskim(data_lab_brut)\n\nUtiliser ncol() et nrow() pour imprimer le nombre de colonnes et de lignes, comme ceci :\n\nncol(data_lab_brut)\nnrow(data_lab_brut)\n\nLes nombres de colonnes et de lignes s’afficheront dans votre console, vous montrant que les données de laboratoire ont plus de lignes que les données de notification que vous avez inspectées plus tôt.\n\n\n[1] 7\n\n\n[1] 1314\n\n\nIl y a souvent plus d’enregistrements dans les données de laboratoire que dans les données cliniques. Si vous inspectez les données avec View(data_lab_brut) et que vous cliquez ensuite sur la flèche en haut de la colonne id_notification pour les trier par ordre alphabétique, vous verrez que plusieurs lignes partagent le même numéro de notification. Cela peut se produire lorsque plusieurs cibles sont testées à partir du même échantillon (même ID d’échantillon), ou lorsqu’un cas est retesté (ce qui donne un numéro d’identification d’échantillon différent).\n\nView(data_lab_brut)\n\n\n\nnom_laboratoireid_notificationid_echantillondate_testtestciblevaleurHopital general de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue NS.1NHopital general de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgGNHopital general de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgMPHopital general de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue NS.1NHopital general de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgGNHopital general de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgMP\n\n\n\n\n\n\n\n\nComme ci-dessus, utilisez les fonctionc class(), skim() ou tabyl(), ou explorer l’environnement, pour examiner vos colonnes en détail.\n\n\n\n\n\n\nQuestions\n\n\n\n\nCombien de colonnes dans les données de laboratoire sont reconnues par R comme étant des colonnes de date ?\n\n 0 1 2\n\nCombien de colonnes des données de laboratoire n’ont aucune donnée manquante ?\n\n 1 3 7 (toutes!)\n\nQuel test détecte plusieurs cibles (et comporte donc plusieurs lignes par échantillon) ?\n\n Paludisme Dengue Fièvre jaune Choléra Fièvre typhoïde\n\nCombien de valeurs de résultats de test possibles y a-t-il dans la colonne valeur ?\n\n 5 3 4\n\nQuel résultat ne semble PAS être possible pour le test de culture des selles qui détecte la bactérie V.cholerae ?\n\n P P01 P0139 N I\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nLes données du laboratoire ont une colonne de date, reconnue par R comme une classe “IDate”. Il s’agit d’une classe de date utilisée par import() de {rio} lors de l’importation de fichiers csv. Comme la classe Date native de R, elle permet de trier par date et d’analyser les tendances dans le temps.\n\nclass(data_lab_brut$date_test)\n\n[1] \"IDate\" \"Date\" \n\n\nEn utilisant la fonction miss_var_summary() du package {naniar}, on réalise que toutes les colonnes des données de laboratoire sont complètes. Cela peut s’expliquer par le fait que les laboratoires utilisent des processus automatisés et qu’il y a donc beaucoup moins de risques d’erreur humaine.\n(Point important : Notez que dans la vie réelle, les données de laboratoire présenteraient probablement des problèmes aussi !)\n\nmiss_var_summary(data_lab_brut)\n\n# A tibble: 7 × 3\n  variable        n_miss pct_miss\n  &lt;chr&gt;            &lt;int&gt;    &lt;num&gt;\n1 nom_laboratoire      0        0\n2 id_notification      0        0\n3 id_echantillon       0        0\n4 date_test            0        0\n5 test                 0        0\n6 cible                0        0\n7 valeur               0        0\n\n\nPour connaître le nombre de cibles détectées par chaque test, vous pouvez croiser les colonnes test et cible avec tabyl(). Ecrivez les noms des colonnes dans la fonction comme deux arguments distincts (et donc séparés par une virgule). Le résultat montre que chaque test correspond clairement à une ou plusieurs cibles, et que seul le test de la dengue détecte plus d’une cible (IgG, IgM et NS.1).\nConseil : Essayez de modifier l’ordre des noms de colonnes dans tabyl() pour voir l’impact sur le tableau.\n\ntabyl(data_lab_brut, cible, test)\n\n                 cible Culture de selles Dengue NS1/IgG/IgM Hemoculture\n    Bacteries S. Typhi                 0                  0          33\n Bacteries V. cholerae                45                  0           0\n            Dengue IgG                 0                215           0\n            Dengue IgM                 0                215           0\n           Dengue NS.1                 0                215           0\n      Fievre jaune IgM                 0                  0           0\n            Plasmodium                 0                  0           0\n IgM ELISA Microscopie du sang total\n         0                         0\n         0                         0\n         0                         0\n         0                         0\n         0                         0\n        88                         0\n         0                       503\n\n\nEnfin, vous pouvez examiner les différentes valeurs des résultats du test dans la colonne valeur toujours à l’aide de la fonction tabyl(). Vous pouvez voir qu’il y a six résultats possibles, dont N pour négatif, P pour positif et I pour indéterminé. Seul le choléra ne présente aucun P, mais est le seul à présenter P01 et P0139, ce qui correspond à un résultat positif pour les sérogroupes O1 ou O139.\n\ntabyl(data_lab_brut, test, valeur)\n\n                      test  I   N   P PO1 PO139\n         Culture de selles  5   2   0  22    16\n        Dengue NS1/IgG/IgM  0 354 291   0     0\n               Hemoculture  2  24   7   0     0\n                 IgM ELISA 10  45  33   0     0\n Microscopie du sang total 56 257 190   0     0"
  },
  {
    "objectID": "pages/multidisease_surveillance.fr.html#étape-4.-nettoyer-et-décrire-les-données-de-notification",
    "href": "pages/multidisease_surveillance.fr.html#étape-4.-nettoyer-et-décrire-les-données-de-notification",
    "title": "Jonction et analyse des données de notification et des données de laboratoire dans R",
    "section": "",
    "text": "Vous savez maintenant que les données de notification (data_notif_brut) contiennent des des informations sur les cas suspects, ainsi que des données démographiques de base (âge, sexe, grossesse, district de résidence), et des informations sur la date d’apparition des symptômes, la date de notification par l’établissement de santé, et l’issue. Certaines colonnes doivent être nettoyées avant de poursuivre l’analyse, en raison des variations dans l’orthographe des valeurs catégorielles et de certaines colonnes non reconnues comme des dates.\nVous allez maintenant commencer à écrire de plus longs morceaux de code pour nettoyer les données, à l’aide de plusieurs fonctions {dplyr} reliées à l’aide d’opérateurs “pipe” (qui ressemblent à ceci : |&gt;).\nNOTE SUR LES ‘PIPES’ : Les “pipes” vous permettent d’effectuer plusieurs opérations en une seule commande fluide, en “enchaînant” différentes fonctions. La sortie d’une fonction devient l’entrée de la suivante. Si vous avez besoin de plus d’informations sur les pipes, veuillez vous référer au chapitre du Epi R Handbook.\nNotez que cet exercice utilise le pipe de base (|&gt;) plutôt que le pipe magrittr (%&gt;%), car il est plus rapide et ne nécessite pas l’installation de packages. Utilisez le pipe magrittr si vous préférez.\n\n\n\n\nPour des raisons de qualité et de stockage des données, votre équipe vous recommande de créer une liste linéaire propre qui ne contienne que des informations sur l’identifiant unique, la localisation du cas, la maladie et la date de notification au système de surveillance.\nÉcrivez une commande R pour produire une nouvelle base de données propre appelée data_notif, en appliquant les étapes de nettoyage suivantes:\n\nRenommer les colonnes pour qu’elles soient plus facilement lisibles par la machine (supprimer les espaces et les majuscules) en utilisant clean_names() du package {janitor}.\nUtiliser la fonction rename() de {dplyr} pour que:\n\nle nom de la colonne avec la date à laquelle le cas a été signalé soit remplacé par un nom plus concis date_notif.\nle nom de la colonne d’identifiant de la notification soit plus concis (id_notification).\n\nSélectionnez les colonnes pertinentes pour l’analyse à l’aide de la fonction select() du package {dplyr}.\n\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\nCommencez votre code par le nom du nouvel ensemble de données, l’opérateur d’assignation et le nom de l’objet contenant les données brutes. Ainsi le résultat du traitement des données brutes sera assigné à un nouvel objet appelé data_notif.\n\ndata_notif &lt;- data_notif_brut\n\nIl faudra ensuite construire la commande de nettoyage en ajoutant des fonctions supplémentaires, liées à l’aide d’un pipe. Cela vous permet d’effectuer plusieurs opérations en une seule commande fluide. Tout d’abord, vous utiliserez clean_names() pour normaliser tous les noms de colonnes. Il remplace automatiquement les espaces et les caractères spéciaux par des traits de soulignement (underscore), supprime les accents et les apostrophes, et convertit tous les caractères en minuscules, ce qui rend les noms de colonnes plus facile à utiliser. Vous pouvez ensuite utiliser rename() pour donner à une colonne un nouveau nom. Rappelez-vous que lorsque vous utilisez rename(), la colonne aura déjà reçu le nom issu de clean_names().\n\ndata_notif &lt;- data_notif_brut |&gt; \n  clean_names() |&gt; \n  rename(NOUVEAU_NOM = ANCIEN_NOM) |&gt; \n  select(VAR_NAMES)\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVoici le code permettant de nettoyer les noms de colonnes et de sélectionner les bonnes colonnes pour l’analyse :\n\n# Données propres\ndata_notif &lt;- data_notif_brut |&gt; \n  clean_names() |&gt; \n  rename(date_notif = date_signalee_par_letablissement_de_sante_la_communaute,\n         id_notification = id_de_notification) |&gt; \n  select(id_notification, district_residentiel, maladie_notifiee, date_notif)\n\n\n\n\n\n\n\nVous savez déjà, grâce à l’inspection des données, que les valeurs de district ne sont pas normalisées.\nAjouter un mutate() pour nettoyer la colonne district_residentiel, afin de:\n\nNormaliser l’utilisation d’écriture minuscule / majuscule dans la colonne\nRemplacer la colonne district_residentiel existante par une colonne qui ne contient que les valeurs pour les districts : “Lac Minara”, “Feveria Central” et “Kasara”.\n\nConsultez l’indice pour savoir quelles fonctions vous pourriez utiliser.\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\nEssayez d’utiliser str_to_title() du package {stringr} de façon à ce que la première lettre de chaque mot soit en majuscule et que toutes les autres lettres soient en minuscule. Vous pouvez également utiliser case_match() pour spécifier différentes fautes de frappe spécifiques. Comme pour l’utilisation de rename() après clean_names(), prenez en compte que la fonction str_to_title() a modifié les valeurs des données fournies à la fonctioncase_match().\nUtilisez le panneau d’aide (“Help”) de RStudio pour savoir comment utiliser ces fonctions. Par exemple, tapez ?case_match dans votre console pour obtenir la page d’aide. NOTE sur case_match() : il s’agit d’une fonction très utile pour remplacer ou corriger des valeurs, qui remplace la fonction recode().\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVotre code de nettoyage devrait maintenant ressembler à ceci :\n\n# Données propres\ndata_notif &lt;- data_notif_brut |&gt; \n  clean_names() |&gt; \n  rename(date_notif = date_signalee_par_letablissement_de_sante_la_communaute,\n         id_notification = id_de_notification) |&gt; \n  select(id_notification, district_residentiel, maladie_notifiee, date_notif) |&gt; \n  mutate(district_residentiel = str_to_title(district_residentiel)) |&gt; \n  mutate(district_residentiel = case_match(district_residentiel,\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lac Minara\", \"Au Bord Du Lac\") ~ \"Lac Minara\"))\n\nVous pouvez également directement insérer la fonction str_to_title() dans la fonction case_match() pour un code plus court, comme suit :\n\n# Données propres\ndata_notif &lt;- data_notif_brut |&gt; \n  clean_names() |&gt; \n  rename(date_notif = date_signalee_par_letablissement_de_sante_la_communaute,\n         id_notification = id_de_notification) |&gt; \n  select(id_notification, district_residentiel, maladie_notifiee, date_notif) |&gt; \n  mutate(district_residentiel = case_match(str_to_title(district_residentiel),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lac Minara\", \"Au Bord Du Lac\") ~ \"Lac Minara\"))\n\n\n\n\n\n\n\nLa colonne de la date de notification doit être transformée de manière à ce qu’elle soit reconnue comme une date dans R. Cela vous permettra d’analyser les tendances au fil du temps, y compris en utilisant un décompte par semaine ou par mois.\nExaminez les valeurs de la colonne date_notif. Ajoutez ensuite une ligne à votre code de nettoyage pour modifier date_notif en une classe de date.\nConnaître le format de date d’origine vous permettra d’utiliser la bonne fonction pour convertir la colonne en classe de date. Nous vous recommandons d’utiliser l’une des fonctions du package {lubridate} : soit ymd() (pour convertir les dates écrites sous la forme année-mois-jour), mdy() (pour les dates mois-jour-année), ou dmy() (pour les dates jour-mois-année). Ces fonctions reconnaîtront n’importe quelle façon d’écrire la date, à condition qu’elle soit organisée dans cet ordre. Par exemple “21 août 2025” (oui! oui! même en français) et “21-08-2024” seraient toutes deux reconnues par dmy().\n\n\n\n\n\n\nQuestions\n\n\n\n\nComment les dates sont-elles actuellement formatées ?\n\n jour-mois-année année-mois-jour mois-jour-année année-jour-mois\n\nQuelle fonction mutate() devez-vous utiliser pour convertir la colonne date_notif en une classe de date ?\n\n mutate(date_notif = ymd(date_notif)) mutate(date_notif = dmy(date_notif)) mutate(date_notif = mdy(date_notif))\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVous pouvez utiliser la fonction head() pour afficher les six premières lignes de données de la colonne date_notif. Vous pouvez voir qu’elles sont écrites avec d’abord l’année, puis le mois, puis le jour.\n\nhead(data_notif$date_notif)\n\n[1] \"2024-03-08\" \"2024-03-11\" \"2024-03-11\" \"2024-03-18\" \"2024-03-14\"\n[6] \"2024-03-12\"\n\n\nVous pouvez utiliser la fonction ymd() à l’intérieur de mutate() pour convertir la classe de la colonne date_notif. Vous pouvez vérifier que la classe est correcte en utilisant la fonction class() par la suite.\nVotre code de nettoyage devrait maintenant ressembler à ceci :\n\n# Données propres\ndata_notif &lt;- data_notif_brut |&gt; \n  clean_names() |&gt; \n  rename(date_notif = date_signalee_par_letablissement_de_sante_la_communaute,\n         id_notification = id_de_notification) |&gt; \n  select(id_notification, district_residentiel, maladie_notifiee, date_notif) |&gt; \n  mutate(district_residentiel = case_match(str_to_title(district_residentiel),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lac Minara\", \"Au Bord Du Lac\") ~ \"Lac Minara\")) |&gt; \n  mutate(date_notif = ymd(date_notif)) \n\nEt vous pouvez vérifier la classe comme ceci :\n\nclass(data_notif$date_notif)\n\n[1] \"Date\"\n\n\n\n\n\n\n\n\nVos collègues vous disent que chaque id_notification représente un cas suspect unique. Vous souhaitez maintenant créer une table pour vérifier s’il existe des doublons de id_notification sur plusieurs lignes de vos données.\n\n\n\n\n\n\nQuestions\n\n\n\n\nUne ligne dans les données de notification correspond-elle à un cas ?\n\n Oui Non\n\nAvez-vous besoin de dédupliquer vos données pour l’analyse épidémiologique des cas ?\n\n Oui Non\n\n\n\n\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\nIl existe de nombreuses façons de procéder, mais essayez d’utiliser la fonction count() de {dplyr}. Elle créera un tableau qui comptera le nombre de lignes par valeur unique de la colonne que vous spécifiez dans la fonction. Ensuite, utiliser tabyl() pour examiner la distribution de ces effectifs.\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nTout d’abord, il faut faire passer les données de surveillance dans la fonction count() en spécifiant à la fonction id_notification comme seul argument. Cela crée un tableau qui compte le nombre de lignes par valeur unique de id_notification, dans une nouvelle colonne n. Vous pouvez voir par exemple dans les premières lignes qu’il n’y a qu’une seule ligne pour chacune de ces 6 id_notification.\n\ndata_notif |&gt; \n  count(id_notification) \n\n\n\n  id_notification n\n1          00399b 1\n2          005c85 1\n3          006f52 1\n4          00cbbb 1\n5          01830d 1\n6          019045 1\n\n\nEnsuite décrivez la nouvelle colonne n avec tabyl(), qui montrera qu’il n’y a qu’une ligne par id_notification. Cela signifie qu’une ligne correspond à un cas, et qu’aucune autre déduplication n’est nécessaire.\n\ndata_notif |&gt; \n  count(id_notification) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 987       1\n\n\n\n\n\n\n\n\n\nVous pouvez maintenant procéder à une analyse descriptive des cas, puisque vos données sont propres et que vous savez qu’une ligne équivaut à un cas. Utilisez la fonction tabyl() pour réaliser les tâches suivantes.\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuelle maladie a été la plus fréquemment diagnostiquée par les cliniques de Feveria en 2024 ?\n\n Choléra Paludisme Dengue Fièvre typhoïde Fièvre jaune\n\nQuelle maladie a été la moins fréquemment diagnostiquée par les cliniques de Feveria en 2024 ?\n\n Choléra Paludisme Dengue Fièvre typhoïde Fièvre jaune\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nEn utilisant tabyl() nous pouvons voir qu’il y a eu 533 cas suspects de paludisme à Feveria en 2024, et seulement 35 cas suspects de fièvre typhoïde.\n\ntabyl(data_notif, maladie_notifiee)\n\n maladie_notifiee   n    percent\n          cholera  46 0.04660588\n           dengue 273 0.27659574\n     fievre jaune 100 0.10131712\n        paludisme 533 0.54002026\n         typhoide  35 0.03546099\n\n\n\n\n\n\n\n\nUtilisez tabyl() pour croiser les colonnes maladie et district de résidence.\nComplétez votre tableau en ajoutant diverses fonctions adorn du package {janitor}, pour afficher la distribution en pourcentage. Par exemple adorn_percentages(), adorn_pct_formatting() et adorn_ns().\nTapez le nom de la fonction après un ? dans votre console (par ex. ?adorn_ns) pour afficher les pages d’aide correspondantes. Vous pouvez également consulter la section à propos de {janitor} dans le Epi R Handbook pour plus d’explications sur les fonctions adorn_xxx().\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuel district a signalé le plus grand nombre de maladies vectorielles en 2024 (paludisme, dengue, fièvre jaune) ?\n\n Lac Minara Feveria Central Kasara\n\nQuel district a signalé le plus grand nombre de maladies diarrhéiques en 2024 (choléra, fièvre typhoïde) ?\n\n Lac Minara Feveria Central Kasara\n\nQuels facteurs contribuent à l’augmentation des maladies diarrhéiques dans ce district spécifique (sélectionné dans la question précédente) ?\n\n Infrastructures d'approvisionnement en eau et d'assainissement peu fiables Surpopulation de moustiques Nous ne savons pas\n\n\n\n\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\nVoici du code pour vous aider à démarrer. Il croise maladie_notifiee et district_residentiel avec tabyl(), puis en ajoutant adorn_percentages() convertit ces nombres en proportions avec de nombreuses décimales. Vous devrez ensuite rajouter adorn_pct_formatting() avec un autre pipe, pour convertir les proportions en pourcentages, et enfin adorn_ns() pour ajouter à nouveau les effectifs entre parenthèses. Notez que les fonctions adorn_xxx() doivent être appliquées dans un ordre spécifique !\n\ntabyl(data_notif, maladie_notifiee, district_residentiel) |&gt;\n  adorn_percentages()\n\nPour les facteurs contribuant à l’augmentation des maladies diarrhéiques, revenez au début de l’étude de cas, à la partie présentant les districts!\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nEn utlisant tabyl(), nous pouvons constater que la plupart des cas suspects de dengue, de paludisme et de fièvre jaune étaient localisés dans le district de Lac Minara - la zone lacustre avec une forte densité de moustiques et donc de maladies à transmission vectorielle. Dans le même temps, la majorité des cas de choléra et de fièvre typhoïde se trouvait à Feveria Central, la zone urbaine surpeuplée souffrant de problèmes d’infrastructures d’approvisionnement en eau et d’assainissement entraînant un risque accru d’inondation et de contamination de l’eau potable par temps de pluie.\n\ntabyl(data_notif, maladie_notifiee, district_residentiel) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n maladie_notifiee Feveria Central      Kasara  Lac Minara\n          cholera      91.3% (42)  8.7%   (4)  0.0%   (0)\n           dengue       9.5% (26) 17.6%  (48) 72.9% (199)\n     fievre jaune      11.0% (11) 21.0%  (21) 68.0%  (68)\n        paludisme      13.7% (73) 19.9% (106) 66.4% (354)\n         typhoide      68.6% (24) 31.4%  (11)  0.0%   (0)"
  },
  {
    "objectID": "pages/multidisease_surveillance.fr.html#étape-5.-nettoyer-consolider-et-décrire-les-données-de-laboratoire",
    "href": "pages/multidisease_surveillance.fr.html#étape-5.-nettoyer-consolider-et-décrire-les-données-de-laboratoire",
    "title": "Jonction et analyse des données de notification et des données de laboratoire dans R",
    "section": "",
    "text": "Le travail effectué à l’étape 3 vous a permis de constater que les données de laboratoire ne contiennent que des données sur les tests et aucune information sur les patients. Les données sont déjà très propres, nous n’avons à standardiser qu’une seule colonne. Nous voudrons également traiter l’ensemble de données du laboratoire de manière à ce qu’il y ait une ligne par notification, afin de pouvoir le lier proprement à l’ensemble de données de notification.\n\n\n\n\nCréez un nouvel objet data_lab. Cela permettra une analyse et une interprétation des résultats plus simples.\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nUtilisez case_match() pour transformer les différentes valeurs originales en “Positif”, “Négatif” ou “Indéterminé” :\n\ndata_lab &lt;- data_lab_brut |&gt; \n  mutate(valeur = case_match(valeur, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positif\",\n                            \"N\" ~ \"Négatif\",\n                            \"I\" ~ \"Indéterminé\"))\n\nVous pouvez ensuite vérifier que les nouvelles valeurs sont correctes en résumant et en comparant les valeurs de la base de données originale et de la base de données nettoyée. Assurez-vous d’avoir utilisé la lettre “O” et non le chiffre “0”!\n\ntabyl(data_lab_brut, valeur)\n\n valeur   n    percent\n      I  73 0.05555556\n      N 682 0.51902588\n      P 521 0.39649924\n    PO1  22 0.01674277\n  PO139  16 0.01217656\n\n\n\ntabyl(data_lab, valeur)\n\n      valeur   n    percent\n Indéterminé  73 0.05555556\n     Négatif 682 0.51902588\n     Positif 559 0.42541857\n\n\n\n\n\n\n\n\n\n\n\nNous savons déjà que certains échantillons se retrouvent sur plusieurs lignes, et que c’est dû au test de la dengue qui a trois cibles, avec une ligne par pour le résultat de chaque cible.\nMaintenant, trouvez le nombre d’échantillons présentant plusieurs lignes.\nProcédez de la même manière que pour les données de notification, en utilisant l’objet data_lab: comptez d’abord le nombre de lignes par échantillon, puis créer un tableau montrant la distribution des nombres de lignes. Il faut garder à l’esprit que que chaque échantillon est identifié par un id_echantillon.\n\n\n\n\n\n\nQuestions\n\n\n\n\nCombien d’échantillons (id_echantillon unique) sont répétés sur 3 lignes?\n\n 200 215 230\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nTout d’abord, il faut faire passer (avec un pipe) les données du laboratoire à la fonction count() en donnant à la fonction id_echantillon comme seul argument. Cela crée un tableau qui compte le nombre de lignes par valeur unique de id_echantillon, affichée dans une nouvelle colonne n. Vous pouvez voir par exemple que le id_echantillon “000e8eee” est présent sur trois lignes, alors que le id_echantillon “001e1878” n’apparaît que sur une seule ligne.\n\ndata_lab |&gt; \n  count(id_echantillon) \n\n\n\n  id_echantillon n\n1       000e8eee 3\n2       001e1878 1\n3       005f39af 1\n4       00b30781 3\n5       00b56d18 1\n6       0110abcd 3\n\n\nPuis résumez la nouvelle colonne n avec tabyl().\n\ndata_lab |&gt; \n  count(id_echantillon) |&gt; \n  tabyl(n)\n\n n n_n   percent\n 1 669 0.7567873\n 3 215 0.2432127\n\n\nVous pouvez même vérifier que cela ne s’applique qu’au test de la dengue en en ajoutant la colonne test dans la commande. Vous pouvez voir que seul le test de la dengue comporte 3 lignes par échantillon.\n\ndata_lab |&gt; \n  count(test, id_echantillon) |&gt; \n  tabyl(test, n)\n\n                      test   1   3\n         Culture de selles  45   0\n        Dengue NS1/IgG/IgM   0 215\n               Hemoculture  33   0\n                 IgM ELISA  88   0\n Microscopie du sang total 503   0\n\n\n\n\n\n\n\n\nComme vous l’avez vu dans la section 3.2, votre test de dengue fournit des résultats pour trois cibles biologiques différentes : IgG, IgM et NS.1. Les résultats pour chacune de ces cibles peuvent être soit négatifs, soit positifs. Cependant, pour simplifier et consolider vos données, vous souhaitez attribuer une seule valeur “Négatif” ou “Positif” à chaque échantillon, pour indiquer si l’échantillon révélait une infection en cours.\n\n\ncibleNégatifPositifDengue IgG110105Dengue IgM105110Dengue NS.113976\n\n\nVotre collègue Ben, qui travaille au laboratoire, vous conseille ce qui suit :\n\nUn échantillon peut être considéré comme positif si le NS.1 ou les IgM sont positifs (les deux pouvant représenter une infection aiguë).\nVous pouvez ignorer les IgG (parce qu’un résultat positif en l’absence de NS.1 ou d’IgM positifs indique une immunité après une infection passée résolue).\n\nVous devez maintenant consolider les résultats du test de la dengue en une ligne par test, avec une valeur unique de résultat. Utiliser filter(), arrange() et slice(), en veillant à ce que tout échantillon positif pour NS.1 ou IgM soit considéré comme positif pour la dengue. Créez un nouvel objet appelé data_lab_tests\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\nEssayez d’appliquer ce qui suit pour consolider selon la recommandation de Ben :\n\nSupprimer les résultats IgG : filtrez les lignes où la cible est “IgG” à l’aide de filter() de {dplyr}.\nDonner la priorité aux résultats positifs pour les IgM/NS1 : Regroupez par id_echantillon et réorganisez les lignes avec arrange() afin que tout résultat “Positif” apparaisse en premier.\nFiltrer pour obtenir le résultat final : Ne conservez que la première ligne de chaque groupe en utilisant slice(1) pour obtenir le résultat global positif ou négatif de l’échantillon.\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVoici le code pour filtrer les résultats des IgG de la dengue, et ensuite consolider les résultats des tests à l’intérieur de chaque groupe de lignes ayant les mêmes id_echantillon, en donnant la priorité aux résultats positifs.\nVous devez utiliser desc à l’intérieur de arrange() car cela signifie que les résultats seront listés par ordre alphabétique DESCendant, ce qui signifie que “Positif” sera en haut pour chaque identifiant.\nAjoutez également la fonction ungroup() à la fin pour que les nouvelles données ne soient plus groupées, ce qui pourrait perturber les analyses ultérieures.\n\ndata_lab_tests &lt;- data_lab |&gt; \n  filter(cible != \"Dengue IgG\") |&gt; \n  group_by(id_echantillon) |&gt; \n  arrange(desc(valeur)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\nVous pouvez alors vérifier que le nouvel objet data_lab_tests ne présente qu’une seule ligne par test, en utilisant la combinaison de count() et tabyl() comme vous l’avez fait pour la tâche A.\nCe tableau vous montre que tous les ID d’échantillons uniques ne sont présents que dans une seule ligne chacun :\n\ndata_lab_tests |&gt; \n  count(id_echantillon) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 884       1\n\n\n\n\n\n\n\n\nMaintenant, vérifiez le nombre de tests par identifiant de notification dans vos nouvelles données consolidées.\nVous pouvez voir qu’il y a 26 lignes avec le même id_notification, mais seulement parmi les cas testés par microscopie du sang total pour le paludisme.\n\ndata_lab_tests |&gt; \n  count(test, id_notification) |&gt; \n  tabyl(test, n)\n\n                      test   1  2\n         Culture de selles  45  0\n        Dengue NS1/IgG/IgM 215  0\n               Hemoculture  33  0\n                 IgM ELISA  88  0\n Microscopie du sang total 451 26\n\n\nVous poursuivez vos recherches en examinant un exemple de cas avec le id_notification “043228”. Cela vous apprend que ce cas a été testé deux fois, avec deux échantillons différents, à une semaine d’intervalle. Le premier résultat était positif, et le second résultat était négatif.\n\ndata_lab_tests |&gt; \n  filter(id_notification == \"043228\")\n\n# A tibble: 2 × 7\n  nom_laboratoire   id_notification id_echantillon date_test  test  cible valeur\n  &lt;chr&gt;             &lt;chr&gt;           &lt;chr&gt;          &lt;IDate&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; \n1 Hopital universi… 043228          27c37cd8       2024-06-18 Micr… Plas… Posit…\n2 Hopital universi… 043228          d2271be0       2024-06-25 Micr… Plas… Négat…\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuelle affirmation concernant les données de laboratoire est correcte ?\n\n Tous les cas des différentes maladies sont retestés Certains cas de paludisme sont retestés Tous les cas de paludisme sont retestés\n\nAurez-vous besoin de dédupliquer les données de laboratoire pour les relier aux données de notification ?\n\n Oui, nous avons besoin d'une unique ligne représentant le résultat de laboratoire par notification Non, les données sont suffisamment dédupliquées\n\n\n\n\nSi vous avez répondu que vous devez dédupliquer, vous avez raison !\nDédupliquez vos données afin d’avoir une ligne par id_notification, en priorisant les résultats positifs, afin de pouvoir établir un lien avec les données de notification.\nPour ce faire, suivez un processus similaire à celui de la tâche B, en utilisant la base de données produite par la tâche B :\n\nRegrouper par id_notification\nClasser par valeur du résultat du test de manière à ce que les valeurs commençant par P soient listées dans la première ligne, suivies des N (Négatif), puis des I (Indéterminé).\nConservez ensuite la première ligne de chaque groupe de id_notificationen utilisant slice().\nPour finir, assignez le résultat à un nouvel objet appelé data_lab_cas.\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVoici le code pour dédupliquer les lignes à l’intérieur de chaque groupe de lignes avec un même id_notification en donnant la priorité aux résultats positifs. Une fois de plus, vous devez utiliser desc à l’intérieur dearrange(). Cela fonctionne parfaitement car l’ordre de priorité souhaité pour les résultats - positifs, puis négatifs, puis indéterminés - correspond à l’ordre alphabétique inversé (P vient à avant N, qui vient avant I, dans l’ordre alphabétique inversé).\nSi votre ordre de priorité était plus complexe ou ne correspondait pas à l’ordre alphabétique (par exemple, si “indéterminé” devait être placé avant “négatif”), vous devriez convertir la colonne de résultats en un facteur et fournir explicitement l’ordre souhaité de ses niveaux. N’oubliez pas de dégrouper à nouveau à la fin.\n\ndata_lab_cas &lt;- data_lab_tests |&gt; \n  group_by(id_notification) |&gt; \n  arrange(desc(valeur)) |&gt; \n  slice(1) |&gt;\n  ungroup()\n\nVous pouvez alors vérifier que le nouvel objet data_lab_cas n’a qu’une seule ligne par identifiant de notification, en utilisant la combinaison de count() et tabyl() comme dans la tâche A. Ce tableau vous montre que tous id_notification uniques sont ne sont présents que dans une seule ligne chacun:\n\ndata_lab_cas |&gt; \n  count(id_notification) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 858       1\n\n\n\n\n\n\n\n\n\nNous disposons maintenant de deux objets que nous pouvons utiliser pour l’analyse des données de laboratoire : data_lab_tests et data_lab_cas.\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuel objet devez-vous utiliser pour analyser les tests ?\n\n data_lab_tests data_lab_cas Aucun des deux\n\nCombien de tests ont été effectués pour dépister le paludisme (par microscopie du sang total) ?\n\n 215 503 88 190\n\nQuel pourcentage de tests de dépistage du choléra (par culture de selles) s’est révélé positif ?\n\n 21% 11% 84% 87%\n\nQuel test a donné le pourcentage le plus élevé de résultats indéterminés ?\n\n IgM ELISA (pour la détection de la fièvre jaune) Culture de selles (pour la détection du choléra) Hémoculture (pour la détection de la fièvre typhoïde)\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nEn utilisant tabyl() nous pouvons voir le nombre de résultats positifs, négatifs et indéterminés par test. Vous pouvez ajouter une série de adorn() pour afficher les pourcentages et les totaux.\n\ntabyl(data_lab_tests, test, valeur) |&gt; \n  adorn_totals(where = \"col\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n                      test Indéterminé     Négatif     Positif        Total\n         Culture de selles  11.1%  (5)  4.4%   (2) 84.4%  (38) 100.0%  (45)\n        Dengue NS1/IgG/IgM   0.0%  (0) 13.5%  (29) 86.5% (186) 100.0% (215)\n               Hemoculture   6.1%  (2) 72.7%  (24) 21.2%   (7) 100.0%  (33)\n                 IgM ELISA  11.4% (10) 51.1%  (45) 37.5%  (33) 100.0%  (88)\n Microscopie du sang total  11.1% (56) 51.1% (257) 37.8% (190) 100.0% (503)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuelle base de données de laboratoire devez-vous utiliser pour compter le nombre de cas suspects testés ?\n\n data_lab_brut data_lab_cas data_lab_tests data_lab\n\nCombien de cas suspects ont été testés dans les données de laboratoire de 2024 ?\n\n 858 1314 884\n\nY a-t-il plus de cas suspects dans les données de notification ou dans les données de laboratoire ?\n\n Données de notification Données de laboratoire\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVous pouvez simplement regarder le nombre de lignes dans le fichier data_lab_cas pour connaître le nombre de cas suspects qui ont été testés.\n\nnrow(data_lab_cas)\n\n[1] 858\n\n\nCe nombre est inférieur au nombre de cas suspects figurant dans la base de données des maladies à déclaration obligatoire (data_notif); ce qui suggère qu’une partie seulement des cas suspect notifié en 2024 avait été testée au moment où ces données étaient rendues disponibles.\n\nnrow(data_notif)\n\n[1] 987"
  },
  {
    "objectID": "pages/multidisease_surveillance.fr.html#étape-6.-jonction-et-traitement-final",
    "href": "pages/multidisease_surveillance.fr.html#étape-6.-jonction-et-traitement-final",
    "title": "Jonction et analyse des données de notification et des données de laboratoire dans R",
    "section": "",
    "text": "Maintenant que les deux listes linéaires sont nettoyées et qu’elles comportent une ligne par cas suspect, vous pouvez les joindre pour permettre l’analyse complète demandée par votre patron.\n\n\n\n\nCréer un nouvel objet appelé data_jointes en utilisant une fonction xxx_join() de {dplyr}. Vous souhaitez conserver toutes les notifications, mais ajouter les résultats de tests lorsqu’ils sont disponibles pour chaque cas suspect.\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuelle fonction permet la bonne approche si vous souhaitez conserver toutes les lignes de vos données de notification et intégrer les résultats de vos données de laboratoire ?\n\n left_join(data_notif, data_lab_cas… full_join(data_notif, data_lab_cas… right_join(data_notif, data_lab_cas…\n\nQuel identifiant doit être utilisé pour joindre les deux listes linéaires ?\n\n id_echantillon id_notification id_echantillon et date_notif id_notification et date_notif\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nReliez les données à l’aide de la fonction left_join() avec les données de notification comme ensemble de données principal à gauche. Toutes les lignes de cet ensemble de données seront conservées et seuls les résultats des tests provenant de l’ensemble de données de laboratoire renseigné à “droite” de la fonction seront ajoutés.\n\ndata_jointes &lt;- left_join(data_notif, data_lab_cas, \n                         by = \"id_notification\")\n\nVous créez la jointure avec la colonne id_notification qui est présente, complète et propre dans les deux base de données.\nNote: Vous avez de la chance de travailler avec un exemple de jointure aussi simple ! D’habitude, il faut vraiment nettoyer et vérifier la colonne d’identifiant, ou établir un lien avec d’autres colonnes comme le nom et la date de naissance. À Feveria, le personnel de la clinique est fantastique pour attribuer systématiquement des identifiants de notification à chaque patient, et de les renseigner sur les formulaires d’échantillon envoyés au laboratoire, et le personnel du laboratoire est tout aussi brillant pour enregistrer l’identifiant de notification dans leur système informatique afin que les résultats puissent être reliés au cas.\n\n\n\n\n\n\nVérifiez maintenant vos données et examinez quelques points.\n\n\n\n\n\n\nQuestions\n\n\n\n\nCombien de lignes contient votre nouvelle base de données data_jointes ?\n\n 987 884 858\n\nEt par rapport à vos données de notification d’origine ?\n\n plus de lignes que l'original même nombre de lignes moins de lignes\n\nQuel terme décrit le mieux la jointure que vous venez de réaliser?\n\n plusieurs-à-un un-à-un plusieurs-à-plusieurs\n\nCombien de résultats de laboratoire n’ont PAS été joints aux données de notification (indice : utilisez la fonction anti_join()) ?\n\n 30 19 0\n\nAvez-vous de la chance que votre jointure soit si réussi ?\n\n Quoi ? Toutes les jointures ne sont-ils pas aussi simples que cela ? Tout à fait ! En général, certains enregistrements ne trouvent pas de correspondance\n\nQuelles sont les raisons typiques pour lesquelles il n’y a pas de correspondance trouvé pour des données de laboratoire et des données sur les maladies à déclaration obligatoire ?\n\n Il y a des fautes de frappe dans les colonnes utilisées pour la correspondance, elles ne sont donc pas reconnues comme correspondant Les données de laboratoire peuvent contenir des cas supplémentaires provenant d'autres cliniques ou pays Les données de laboratoire peuvent inclure des échantillons de test Des notifications peuvent avoir été accidentellement omises dans les données de surveillance même si l'échantillon a été testé en laboratoire Toutes les réponses ci-dessus\n\nCombien de cas suspects n’ont pas de résultat ?\n\n 83 100 129\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVérifiez le nombre de lignes dans chaque ensemble de données à l’aide de la fonction nrow() ou en vérifiant les informations relatives à l’objet dans votre environnement. Vous pouvez constater l’opération était une jointure un-à-un, car chaque ligne avait un id_notification unique, de sorte qu’une ligne dans les données de notification était directement liée à une ligne dans les données de laboratoire.\nNombre de lignes dans les données de notification\n\nnrow(data_notif)\n\n[1] 987\n\n\nNombre de lignes dans les données jointes\n\nnrow(data_jointes)\n\n[1] 987\n\n\nPour vérifier si des résultats de laboratoire n’ont pas été reliés à des données de notification, vous pouvez utiliser la fonction anti_join(). Cette fois, data_lab_cas est à gauche, car la fonction évalue le nombre de lignes de l’objet de gauche qui n’ont pas été trouvées dans l’ensemble de données de droite, en les faisant correspondre par id_notification. Ici, il n’est pas nécessaire de créer un nouvel objet, vous pouvez simplement faire passer le résultat à nrow() avec un pipe pour compter le nombre de lignes. Le résultat est 0, ce qui montre qu’il n’y a pas eu de résultats de labo non reliés - incroyable !\n\nanti_join(data_lab_cas, data_notif, \n          by = \"id_notification\") |&gt; nrow()\n\n[1] 0\n\n\nEnfin, pour vérifier le nombre de notifications sans résultat, vous pouvez soit réaliser un anti_join() en mettant data_notif d’abord :\n\nanti_join(data_notif, data_lab_cas, \n          by = \"id_notification\") |&gt; nrow()\n\n[1] 129\n\n\nOu vous pouvez aussi simplement évaluer le nombre de valeurs manquantes dans la colonne valeur dans data_jointes (puisque valeur provient des données de laboratoire).\n\ntabyl(is.na(data_jointes$valeur)) \n\n is.na(data_jointes$valeur)   n   percent\n                      FALSE 858 0.8693009\n                       TRUE 129 0.1306991\n\n\nCes deux approches montrent que 129 cas suspects ne présentent pas de résultat de laboratoire.\n\n\n\n\n\n\n\n\n\nUtiliser mutate() pour créer une nouvelle colonne cas_categorie, afin de mettre à jour le status de cas suspect en fonction de leurs résultats de laboratoire. Les catégories devraient être les suivantes :\n\nSi le résultat est positif : Confirmé\nSi le résultat est négatif : Ecarté\nSi le résultat est indéterminé ou manquant : Suspect\n\nCela signifie que tous les cas figurant dans les données de notification sont d’abord “Suspect” lorsqu’ils sont déclarés, puis restent “Suspect” en l’absence d’un résultat de test concluant.\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuelle est la fonction la plus appropriée pour créer cette nouvelle colonne?\n\n case_when() if_else() case_match()\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVous devez utiliser case_when() pour créer la nouvelle colonne. Cette fonction est idéale pour appliquer plusieurs conditions logiques afin d’attribuer de multiples valeurs différentes, alors que case_match() est plus adapté pour remplacer des valeurs spécifiques, et if_else() est préférable s’il n’y a que deux valeurs possibles.\n\ndata_jointes &lt;- data_jointes |&gt; \n  mutate(cas_categorie = case_when(valeur==\"Positif\" ~ \"Confirmé\",\n                                   valeur==\"Négatif\" ~ \"Ecarté\",\n                                   valeur==\"Indéterminé\" | is.na(valeur) ~ \"Suspect\"))\n\n\n\n\n\n\n\n\n\n\nUtilisez tabyl() directement, et aussi en croisant avec les maladies pour répondre aux questions ci-dessous.\n\n\n\n\n\n\nQuestions\n\n\n\n\nCombien de cas dans les données de notification jointes n’ont pas de résultat positif ou négatif ?\n\n 202 347 250\n\nQuel pourcentage de cas dans les données de notification ONT un résultat positif ou négatif ?\n\n 60,1 % 79,5 % 92,2 %\n\nPourquoi y a-t-il plus de cas suspects restants que de notifications sans résultat de laboratoire relié?\n\n Les cas suspects comprennent les notifications sans résultat de laboratoire et avec un résultat de laboratoire indéterminé Il y a des cas suspects supplémentaires provenant du laboratoire Il y a un problème avec les données\n\nQuelle maladie présentait le pourcentage le plus élevé de cas restés suspects après la jointure?\n\n Choléra Paludisme Dengue Fièvre jaune\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nUne fois de plus, vous pouvez utiliser tabyl() pour voir la répartition des catégories de cas entre les notifications. Le nombre total de cas suspects, c’est-à-dire ceux pour lesquels aucun résultat de laboratoire n’a été obtenu ou pour lesquels le résultat est indéterminé, est de 202. Cela signifie que 785 cas, soit 79,5 %, ont obtenu un résultat de laboratoire définitif.\n\ntabyl(data_jointes, cas_categorie) \n\n cas_categorie   n   percent\n      Confirmé 438 0.4437690\n        Ecarté 347 0.3515704\n       Suspect 202 0.2046606\n\n\nVous pouvez également croiser les résultats originaux (indéterminé/négatif/positif) de valeur avec la nouvelle colonne cas_categorie, pour vérifier que votre logique a fonctionné et pour voir comment les valeurs originales correspondent aux valeurs de la nouvelle colonne. Cela montre qu’en plus des 129 notifications qui n’ont pas été reliées à un résultat de test (avec NA dans la colonne valeur), 73 avaient des résultats indéterminés et ont donc été classées dans la catégorie des cas suspects.\n\ntabyl(data_jointes, cas_categorie, valeur) \n\n cas_categorie Indéterminé Négatif Positif NA_\n      Confirmé           0       0     438   0\n        Ecarté           0     347       0   0\n       Suspect          73       0       0 129\n\n\nEnfin, vous pouvez également croiser les catégories avec les noms de maladie pour voir les catégories de cas par maladie. Ajoutez des fonctions adorn_xxx() pour ajouter et mettre en forme des pourcentages. Le tableau montre ainsi que 22 % des cas de fièvre jaune sont restés suspects, ce qui représente le pourcentage le plus élevé par rapport aux autres maladies.\n\ntabyl(data_jointes, maladie_notifiee, cas_categorie) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n maladie_notifiee    Confirmé      Ecarté     Suspect        Total\n          cholera 82.6%  (38)  4.3%   (2) 13.0%   (6) 100.0%  (46)\n           dengue 68.1% (186) 10.6%  (29) 21.2%  (58) 100.0% (273)\n     fievre jaune 33.0%  (33) 45.0%  (45) 22.0%  (22) 100.0% (100)\n        paludisme 32.6% (174) 46.3% (247) 21.0% (112) 100.0% (533)\n         typhoide 20.0%   (7) 68.6%  (24) 11.4%   (4) 100.0%  (35)\n            Total 44.4% (438) 35.2% (347) 20.5% (202) 100.0% (987)\n\n\n\n\n\n\n\n\nUtilisez tabyl() à nouveau, en examinant les résultats par maladie. Réfléchissez au dénominateur adéquat !\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuel pourcentage de cas suspects notifié en 2024 étaient de vrais cas selon leurs résultats de test?\n\n 44% 56% 59%\n\nQuel pourcentage de cas supects de paludisme étaient effectivement atteint de paludisme?\n\n 86% 41% 23%\n\nQuel pourcentage de cas supects de dengue étaient effectivement atteint de dengue?\n\n 87% 41% 23%\n\n\n\n\n\n\n\n\n\n\nCliquez pour lire un indice\n\n\n\n\n\nDiviser le nombre de cas confirmés (c’est-à-dire ceux dont le résultat est positif) par le nombre de cas confirmés plus les cas écartés (c’est-à-dire ceux dont le résultat est soit positif, soit négatif). On obtient ainsi un taux de positivité, qui correspond approximativement au pourcentage de cas suspects qui étaient réellement des cas. Les résultats indéterminés sont exclus du dénominateur car ils ne fournissent pas de résultat clair et fausseraient le taux de positivité.\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nFiltrez les cas toujours suspects, puis réalisez un tableau croisé pour connaître le pourcentage de cas initialement suspectés qui ont été ou confirmés ou écartés, parmi ceux dont les résultats de test sont valides.\nAvec la ligne de totaux, vous pouvez voir que 56 % des cas suspects ont été confirmés parmi ceux dont les résultats étaient valides. Vous pouvez également voir que 41 % et 87 % des cas de paludisme et de dengue, respectivement, ont été confirmés.\n\ndata_jointes |&gt; \n  filter(cas_categorie != \"Suspect\") |&gt; \n  tabyl(maladie_notifiee, cas_categorie) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n maladie_notifiee    Confirmé      Ecarté        Total\n          cholera 95.0%  (38)  5.0%   (2) 100.0%  (40)\n           dengue 86.5% (186) 13.5%  (29) 100.0% (215)\n     fievre jaune 42.3%  (33) 57.7%  (45) 100.0%  (78)\n        paludisme 41.3% (174) 58.7% (247) 100.0% (421)\n         typhoide 22.6%   (7) 77.4%  (24) 100.0%  (31)\n            Total 55.8% (438) 44.2% (347) 100.0% (785)\n\n\n\n\n\n\n\n\n\nTâche A : Créer une nouvelle liste linéaire appelée data_jointes_confirme.\nC’est ce que vous utiliserez dans les rapports de surveillance officiels.\n\n\n\n\n\n\nQuestions\n\n\n\n\nPourquoi choisissons-nous de ne signaler que les cas confirmés dans nos données de surveillance ?\n\n La déclaration des cas confirmés peut être plus fiable et précise lorsque le pourcentage de tests positifs est faible et que les tests en laboratoire sont systématiques, ce qui permet d'éviter une surestimation de la morbidité La déclaration des cas confirmés est plus lente, ce qui nous donne plus de temps pour nous assurer de l'exactitude de nos déclarations Parce que nous voulons cacher le nombre réel de cas\n\nQuelle fonction est importante pour créer la nouvelle liste linéaire ?\n\n filter() arrange() mutate()\n\nCombien de lignes contient ce nouvel ensemble de données ?\n\n 389 438 858\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVotre équipe de surveillance souhaite se concentrer sur les cas confirmés dans ses rapports. En effet, les tests de laboratoire sont intégrés dans les activités de routine à Feveria, et la déclaration des cas suspects serait inutilement imprécise, un pourcentage élevé de cas suspects étant écartés.\nLa décision de publier les cas suspects peut être différente dans dans d’autres contextes. Par exemple, si le taux de positivité est élevé (la plupart des cas sont des cas réels s’ils sont testés) et que le test lui-même n’est pas courant, ou que le test prend beaucoup de temps et entraînerait un retard dans le rapportage, cela suggérerait que les tendances des cas suspects sont suffisamment précises et également plus opportunes que l’attente d’une confirmation en laboratoire.\nCréez la nouvelle liste linéaire à l’aide de la fonction filter() :\ndata_jointes_confirme &lt;- data_jointes |&gt; \n  filter(cas_categorie==\"Confirmé\")\nEt vérifiez le nombre de lignes en consultant les informations dans votre environnement, ou avec nrow():\nnrow(data_jointes_confirme)\n[1] 438"
  },
  {
    "objectID": "pages/multidisease_surveillance.fr.html#étape-7.-analyse-descriptive-des-cas-confirmés",
    "href": "pages/multidisease_surveillance.fr.html#étape-7.-analyse-descriptive-des-cas-confirmés",
    "title": "Jonction et analyse des données de notification et des données de laboratoire dans R",
    "section": "",
    "text": "Maintenant que vous disposez de la liste des cas confirmés de maladies à déclaration obligatoire signalés à Feveria en 2024, vous êtes prêt à effectuer la dernière partie de votre analyse de surveillance ! Il s’agit de décrire les cinq maladies à déclaration obligatoire par zone géographique et par période.\nConseil: L’analyse des données de surveillance comprend généralement une analyse par personne. Vous pourriez développer cette étude de cas en procédant à une analyse selon les variables démographiques.\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuelle maladie à déclaration obligatoire a été la plus souvent notifiée en 2024, en se limitant aux seuls cas confirmés ?\n\n Dengue Paludisme Fièvre jaune\n\nPourquoi la maladie la plus fréquemment signalée diffère-t-elle entre les cas confirmés et les cas suspects ?\n\n La sensibilité et la spécificité du diagnostic clinique peuvent varier selon la maladie Les performances des tests utilisés en laboratoire peuvent varier selon la maladie Il peut y avoir des biais de notification Toutes les réponses ci-dessus !\n\nQuel district a signalé le plus grand nombre de cas confirmés de choléra en 2024 ?\n\n Lac Minara Feveria Central Kasara\n\nCombien de cas confirmés de choléra signalés en 2024 concernaient des résidents de Feveria Central ?\n\n 35 42 4\n\nQuel district a signalé le plus grand nombre de cas confirmés de paludisme en 2024 ?\n\n Lac Minara Feveria Central Kasara\n\nCes données confirment-elles que la dengue est la maladie infectieuse la plus courante à Feveria ?\n\n Non, une autre maladie peut être sous-déclarée et/ou non systématiquement notifiée Oui, si c'est la maladie la plus notifiée, c'est qu'elle doit être la plus courante\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nEn utilisant tabyl() nous pouvons voir que la dengue était la maladie la plus fréquemment notifiée à Feveria en 2024, en se limitant aux cas confirmés, avec 186 cas.\n\ndata_jointes_confirme |&gt; \n  tabyl(maladie_notifiee) \n\n maladie_notifiee   n    percent\n          cholera  38 0.08675799\n           dengue 186 0.42465753\n     fievre jaune  33 0.07534247\n        paludisme 174 0.39726027\n         typhoide   7 0.01598174\n\n\nNotez que cela diffère des cas suspects, où le paludisme a été le plus notifié (avec 533 cas suspects) ! Il y avait déjà des indices, avec un taux de positivité pour les cas suspects de dengue plus élevé que pour les cas suspects de paludisme. Cela peut s’expliquer par différentes raisons, par exemple la méthode de diagnostic clinique utilisée pour le paludisme peut être moins spécifique (de nombreux cas suspects sont en fait d’autres maladies), ou le test utilisé pour la dengue peut être plus sensible.\nCroisez les données avec celles du district résidentiel, puis ajoutez les fonctions adorn_xxx() pertinentes.\n\ndata_jointes_confirme |&gt; \n  tabyl(maladie_notifiee, district_residentiel) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n maladie_notifiee Feveria Central     Kasara  Lac Minara        Total\n          cholera      92.1% (35)  7.9%  (3)  0.0%   (0) 100.0%  (38)\n           dengue       8.6% (16) 17.2% (32) 74.2% (138) 100.0% (186)\n     fievre jaune       0.0%  (0) 18.2%  (6) 81.8%  (27) 100.0%  (33)\n        paludisme      14.9% (26) 22.4% (39) 62.6% (109) 100.0% (174)\n         typhoide      71.4%  (5) 28.6%  (2)  0.0%   (0) 100.0%   (7)\n            Total      18.7% (82) 18.7% (82) 62.6% (274) 100.0% (438)\n\n\nComme pour les cas suspects, on constate que la plupart des cas confirmés de dengue, de paludisme et de fièvre jaune se situent à Lac Minara, zone lacustre où la densité de moustiques et donc de maladies à transmission vectorielle est la plus élevée. La majorité des cas confirmés de choléra et de fièvre typhoïde se trouvaient à Feveria Central, sujet à des problèmes d’eau et d’assainissement.\nLes données suggèrent que les maladies à transmission vectorielle (dengue et paludisme) sont particulièrement préoccupantes dans ce pays tropical. Cependant, nous ne savons pas avec certitude quelle est la maladie la plus fréquente et quels sont les schémas sous-jacents - seules cinq maladies sont à déclaration obligatoire et les cas notifiés ne représentent généralement qu’une fraction des cas réels au sein de la communauté.\n\n\n\n\n\n\n\nVous allez travailler à la réalisation de cette courbe épidémique, à travers les tâches ci-dessous.\n\n\n\n\n\n\n\n\n\n\n\nVeillez à spécifier l’argument binwidth=7 afin que chaque barre de l’histogramme représente le nombre de cas sur une période de 7 jours.\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuand a été notifié le premier cas de fièvre typhoïde de 2024 à Feveria?\n\n Janvier 2024 Mai 2024 Octobre 2024\n\nD’après ce graphique, quel a été le plus grand nombre de cas de dengue notifiés en une seule semaine en 2024?\n\n 10 20 30 Difficile à dire avec ce graphique empilé!\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVoici un code simple pour produire la courbe épidémique. Notez que vous ne contrôlez pas encore les couleurs, ni ne spécifiez le jour de la semaine où commence chaque période de 7 jours.\n\ndata_jointes_confirme |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_notif, fill = maladie_notifiee)), binwidth=7)\n\n\n\n\n\n\n\n\nReportez-vous au chapitre sur les dates du Epi R Handbook si vous souhaitez réaliser un formatage plus spécifique des dates, par exemple pour que chaque barre représente une semaine du lundi au dimanche, ou que l’axe des x indique le numéro de la semaine épidémiologique (semaines 1 à 52).\nIl est important de noter qu’il n’est pas facile de voir les tendances par maladie lorsqu’elles sont empilées de cette manière ! Pour analyser ces tendances temporelles, vous devez produire un histogramme par maladie.\n\n\n\n\n\n\nUtilisez facet_wrap() pour créer facilement plusieurs mini-graphiques, un par maladie. Pour en savoir plus, vous pouvez consulter le chapitre sur les facettes avec ggplot2 du Epi R Handbook\n\n\n\n\n\n\nQuestions\n\n\n\n\nD’après ce graphique stratifié, quel a été le nombre le plus élevé de cas de dengue signalés en une seule semaine en 2024 ?\n\n 11 15 29 Je ne peux toujours rien en dire!\n\nParmi les cas de dengue signalés cette semaine-là, dans quels districts vivaient les personnes concernées ?\n\n Les trois districts Feveria Central Kasara Lac Minara Ce graphique ne montre pas cette information\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVous pouvez maintenant admirer une courbe épidémique par maladie ! Et vous pouvez voir qu’au cours d’une semaine de juillet, 15 cas de dengue ont été signalés. Cependant, ce graphique ne contient pas encore d’informations géographiques.\n\ndata_jointes_confirme |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_notif)), binwidth=7) + \n  facet_wrap(.~maladie_notifiee)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nDans quel(s) district(s) vivaient les 15 cas de dengue notifiés en une semaine en juillet 2024?\n\n Les trois districts Feveria Central Kasara Lac Minara\n\nDans quel district vivait le premier cas de fièvre typhoïde notifié en 2024?\n\n Kasara Feveria Central Lac Minara Je ne peux pas encore le savoir!\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVous pouvez maintenant observer une épicurve par maladie, avec des couleurs reflétant le district dans lequel le cas résidait.\nVous pouvez voir que les 15 cas de dengue signalés au cours d’une seule semaine résidaient dans trois districts différents. Vous pouvez également voir que le premier cas de typhoïde a été signalé à Feveria Central.\n\ndata_jointes_confirme |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_notif, fill = district_residentiel)), binwidth=7) + \n  facet_wrap(.~maladie_notifiee)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVous pouvez ajouter, préciser ou modifier :\n\nLe thème/l’apparence de l’ensemble du graphique (par exemple, la couleur d’arrière-plan ou l’apparence des lignes de la grille)\nLe titre, sous-titre… et les étiquettes des axes\nLes couleurs des barres (avec scale_fill_manual())\nLe formatage et l’espacement des dates le long de l’axe des x (avec scale_x_date)\nBeaucoup d’autres choses !\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nLe choléra et la fièvre typhoïde semblent-ils endémiques ?\n\n Non, les données suggèrent des épidémies occasionnelles de faible ampleur Oui, ils sont tous deux endémiques\n\nY a-t-il une période particulière de l’année où le paludisme a atteint un pic en 2024 ?\n\n Oui, vers novembre/décembre Oui, vers juillet/août (été) Non, le nombre de cas est constamment élevée\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nVoici le code pour un formatage complet. Notez que d’autres changements ont été apportés, notamment la spécification que nous ne voulons que deux colonnes de mini-graphiques dans facet_wrap() et que l’étiquette de la date le long de l’axe des x ne doit indiquer que le jour et le mois (et non l’année, puisque tous les cas sont en 2024 de toute façon).\n\ndata_jointes_confirme |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_notif, fill = district_residentiel)), binwidth=7) +\n  facet_wrap(.~maladie_notifiee, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"District de résidence\",\n       x = \"Date de notification par la clinique\",\n       y = \"Nombre\",\n       subtitle = \"Nombres de cas confirmés de choléra, de dengue, de paludisme de fièvre typhoïde et de fièvre jaune par semaine à Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n\n\n\n\n\n\nLes courbes épidémiques montrent également que le choléra et la typhoïde semblent se manifester sous la forme de flambées isolées, plutôt que de présenter un caractère endémique. Le paludisme et la dengue ont par contre présenté une circulation à Feveria tout au long de l’année, le paludisme atteignant un pic assez net pendant les mois d’été.\n\n\n\n\n\n\nCette fois, utilisez group_by() et summarize() pour produire un tableau par district indiquant les dates de notifications les plus anciennes et les plus récentes.\nA l’aide d’une fontion filter(), vous pourrez générer ce tableau pour un district à la fois.\n\n\n\n\n\n\nQuestions\n\n\n\n\nQuand le premier cas de dengue a-t-il été signalé à Feveria en 2024 ?\n\n 18 janvier 2024 17 janvier 2024 12 février 2024\n\nQuand le dernier cas de dengue a-t-il été signalé à Feveria Central en 2024 ?\n\n 22 août 2024 18 novembre 2024 25 décembre 2024\n\n\n\n\n\n\n\n\n\n\nCliquez pour voir la solution (essayez d’abord par vous-même !)\n\n\n\n\n\nRegroupez les données par maladie, puis, dans une fonction summarize(), définissez la première et la dernière date pour obtenir la chronologie globale de chaque maladie à Feveria.\n\ndata_jointes_confirme |&gt; \n  group_by(maladie_notifiee) |&gt; \n  summarize(prem_notif = min(date_notif), \n            der_notif = max(date_notif)) |&gt;\n  ungroup()\n\n# A tibble: 5 × 3\n  maladie_notifiee prem_notif der_notif \n  &lt;chr&gt;            &lt;date&gt;     &lt;date&gt;    \n1 cholera          2024-06-03 2024-09-23\n2 dengue           2024-01-17 2024-11-18\n3 fievre jaune     2024-03-08 2024-08-23\n4 paludisme        2024-01-08 2024-12-25\n5 typhoide         2024-05-02 2024-11-07\n\n\nAjouter un filter() au code pour consulter les dates de la première notification et de la notification la plus récente pour le district qui vous intéresse.\n\ndata_jointes_confirme |&gt; \n  filter(district_residentiel == \"Feveria Central\") |&gt; \n  group_by(maladie_notifiee) |&gt; \n  summarize(prem_notif = min(date_notif), \n            der_notif = max(date_notif)) |&gt;\n  ungroup()\n\n# A tibble: 4 × 3\n  maladie_notifiee prem_notif der_notif \n  &lt;chr&gt;            &lt;date&gt;     &lt;date&gt;    \n1 cholera          2024-06-03 2024-09-23\n2 dengue           2024-01-29 2024-08-22\n3 paludisme        2024-01-29 2024-12-17\n4 typhoide         2024-05-02 2024-11-07"
  },
  {
    "objectID": "pages/multidisease_surveillance.fr.html#conclusion",
    "href": "pages/multidisease_surveillance.fr.html#conclusion",
    "title": "Jonction et analyse des données de notification et des données de laboratoire dans R",
    "section": "",
    "text": "Superbe ! Conformément aux objectifs de cette étude de cas, vous avez fait ce qui suit :\n\nVous avez utilisé des fonctions clés de R pour nettoyer, remodeler et joindre des ensembles de données, et vous avez créé de nouvelles colonnes à l’aide de conditions logiques.\nPour obtenir des informations sur le traitement des données, vous avez procédé à des analyses exploratoires et à des vérifications des données tout au long du processus.\nVous avez effectué une analyse descriptive approfondie pour comprendre les données de laboratoire et de notification, avant et après la jointure. En réponse aux quatre questions initiales de votre superviseur, vous pouvez dire :\n\nCombien de cas suspects des différentes maladies à déclaration obligatoire ont été signalés en 2024, et lesquels étaient les plus fréquents ? Le paludisme était la maladie à déclaration obligatoire la plus courante à Feveria en 2024. Selon le système de surveillance des maladies à déclaration obligatoire : Il y a eu 533 cas suspects de paludisme, 273 cas suspects de dengue, 100 cas de fièvre jaune, 46 cas de choléra et 35 cas de typhoïde.\nQuel pourcentage de ces cas a été confirmé ? Près de 80 % des cas à déclaration obligatoire signalés en 2024 avaient donné lieu à un résultat de test de laboratoire au moment de la jointure des données, avec quelques variations selon les maladies. Au total, 56 % des cas notifiés ont finalement été confirmés, mais ce pourcentage variait de 23 % seulement pour la fièvre typhoïde (7 cas confirmés sur 31 cas suspects avec résultats de tests) à 95 % pour le choléra (38 cas confirmés sur 40 cas suspects avec résultats de tests). En outre, le taux de positivité était plus élevé pour les cas présumés de dengue que pour les cas présumés de paludisme (87 % contre 41 %).\nCombien de cas confirmés de différentes maladies à déclaration obligatoire ont été signalés en 2024, et laquelle était la plus fréquente ? Les cas confirmés ont suivi une tendance légèrement différente de celle des cas suspects : l’infection la plus fréquemment signalée était la dengue avec 186 cas, suivie du paludisme (174), puis du choléra (38), de la fièvre jaune (33) et de la fièvre typhoïde (7).\nComment les cas confirmés se répartissent-ils géographiquement et temporellement dans la région de Feveria ? Feveria a connu une transmission de la dengue et du paludisme tout au long de l’année, avec un pic en été, et concentrée dans le district de Lac Minara. Feveria a également connu de petites et rares épidémies de maladies diarrhéiques, telles que le choléra et la fièvre typhoïde, en particulier dans la zone urbaine de Feveria Central, où l’eau et l’assainissement peuvent poser problème.\n\nEnfin, vous avez pu réfléchir à la manière dont les processus des systèmes de surveillance des maladies à déclaration obligatoire et ceux des tests de diagnostique de laboratoire, par exemple le transfert des données entre les cliniques et les laboratoires, peuvent affecter la qualité et l’exhaustivité des données, et donc vos résultats.\n\nIl reste encore beaucoup de possibilités. Vous pouvez explorer les distributions des maladies par âge ou par sexe, calculer des taux d’incidence ou de prévalence des maladies à l’aide de données démographiques et même analyser les délais de déclaration en examinant les différentes dates de vos ensembles de données.\nVous avez acquis de solides bases et vous êtes bien équipé pour passer à l’étape suivante de votre analyse. Continuez, des découvertes passionnantes vous attendent !\nPour en savoir plus, consultez les autres études de cas ou plongez dans le Epi R Handbook."
  },
  {
    "objectID": "pages/multidisease_surveillance.fr.html#code-de-nettoyage-et-danalyse-des-données",
    "href": "pages/multidisease_surveillance.fr.html#code-de-nettoyage-et-danalyse-des-données",
    "title": "Jonction et analyse des données de notification et des données de laboratoire dans R",
    "section": "",
    "text": "Vous trouverez ci-dessous un script de toutes les étapes de nettoyage des données et des analyses descriptives. Notez que les analyses sont combinées à la fin plutôt qu’intercalées entre les étapes de nettoyage. Il s’agit d’une façon plus ordonnée d’organiser votre script.\nPar souci de concision, le code ci-dessous n’inclut pas toutes les inspections et vérifications effectuées en cours de route, mais vous pouvez décider de créer des sections avec de telles vérifications.\nLe début de votre script doit également contenir des informations pour aider le lecteur à comprendre à quoi sert le script, ainsi que des commentaires tout au long du script. Vous vous remercierez plus tard d’avoir ajouté ces commentaires !\n\n\n\n\n\n\nCode pour nettoyer et analyser les données de notification et les données de laboratoire de Feveria, 2024\n\n\n\n\n\n\n# Code pour nettoyer et analyser les données de notification et les données de laboratoire de Feveria, 2024\n# Date:\n# Author:\n\n# Installation des packages --------------------------------\n# Pour s'assurer que le package \"pacman\" est installé\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# Installation (si nécessaire) depuis le CRAN et chargement des packages à utiliser\npacman::p_load(\n  rio,        # importation de données  \n  skimr,      # aperçu des données\n  janitor,    # nettoyage des données et tableaux descriptifs\n  lubridate,  # manipulation des dates\n  epikit,     # pour créer des catégories d'âge\n  gtsummary,  # statistiques descriptives, tests et régressions \n  apyramid,   # tracé de pyramides des âges \n  flextable,  # tableaux prêts à être présentés\n  naniar,     # analyse des données manquantes\n  remotes,    # pour installer le package permettant de télécharger les données\n  tidyverse   # gestion et visualisation des données\n)\n\n# Importation des données --------------------------------------------\n\n# Données de notification\ndata_notif_brut &lt;- import(\"donnees/multi_maladies_notifications.xlsx\")\n\n# Données de labo\ndata_lab_brut &lt;- import(\"donnees/multi_maladies_tests.csv\")\n\n# Nettoyage des données de notification --------------------------------\ndata_notif &lt;- data_notif_brut |&gt; \n  clean_names() |&gt; \n  rename(date_notif = date_signalee_par_letablissement_de_sante_la_communaute,\n         id_notification = id_de_notification) |&gt; \n  select(id_notification, district_residentiel, maladie_notifiee, date_notif) |&gt; \n  mutate(district_residentiel = case_match(str_to_title(district_residentiel),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lac Minara\", \"Au Bord Du Lac\") ~ \"Lac Minara\")) |&gt; \n  mutate(date_notif = ymd(date_notif)) \n\n\n# Nettoyage et consolidation des données de labo -----------------------\n# Nettoyage des valeurs\ndata_lab &lt;- data_lab_brut |&gt; \n  mutate(valeur = case_match(valeur, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positif\",\n                            \"N\" ~ \"Négatif\",\n                            \"I\" ~ \"Indéterminé\"))\n\n# Création de la base de données de labo orientée tests\ndata_lab_tests &lt;- data_lab |&gt; \n  filter(cible != \"Dengue IgG\") |&gt; \n  group_by(id_echantillon) |&gt; \n  arrange(desc(valeur)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Création de la base de données de labo orientée cas\ndata_lab_cas &lt;- data_lab_tests |&gt; \n  group_by(id_notification) |&gt; \n  arrange(desc(valeur)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Jointure des données de notification et de labo -----------------\ndata_jointes &lt;- left_join(data_notif, data_lab_cas, by = \"id_notification\")\n\n# Nettoyage des données jointes -----------------------------------\ndata_jointes &lt;- data_jointes |&gt; \n  mutate(cas_categorie = case_when(valeur==\"Positif\" ~ \"Confirmé\",\n                                   valeur==\"Négatif\" ~ \"Ecarté\",\n                                   valeur==\"Indéterminé\" | is.na(valeur) ~ \"Suspect\"))\n\ndata_jointes_confirme &lt;- data_jointes |&gt; \n  filter(cas_categorie==\"Confirmé\")\n\n# ANALYSE ---------------------------------------------------------\n# Nombre de cas suspects à Feveria\ntabyl(data_notif, maladie_notifiee)\n\n# Distribution des cas suspects par district\ntabyl(data_notif, maladie_notifiee, district_residentiel) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n# Distribution des résultats de test par type de test\ntabyl(data_lab_tests, test, valeur) |&gt; \n    adorn_totals(where = \"col\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution des catégories de cas dans les données jointes\ntabyl(data_jointes, cas_categorie) \n\n# Distribution des catégories de cas par maladie dans les données jointes\ntabyl(data_jointes, maladie_notifiee, cas_categorie) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution des catégories de cas par maladie dans les données jointes, uniquement pour les cas avec un résultat de test valide\ndata_jointes |&gt; \n    filter(cas_categorie != \"Suspect\") |&gt; \n    tabyl(maladie_notifiee, cas_categorie) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution des cas confirmés par district\ndata_jointes_confirme |&gt; \n  tabyl(maladie_notifiee, district_residentiel) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n\n# Visualisation de l'évolution temporelle de le nombre de cas confirmé par district\ndata_jointes_confirme |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_notif, fill = district_residentiel)), binwidth=7) +\n  facet_wrap(.~maladie_notifiee, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"District de résidence\",\n       x = \"Date de notification par la clinique\",\n       y = \"Nombre\",\n       subtitle = \"Nombres de cas confirmés de choléra, de dengue, de paludisme de fièvre typhoïde et de fièvre jaune par semaine à Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n# Première et dernière date de notification de cas confirmé par maladie\ndata_jointes_confirme |&gt; \n  group_by(maladie_notifiee) |&gt; \n  summarize(prem_notif = min(date_notif), \n            der_notif = max(date_notif)) |&gt;\n  ungroup()"
  },
  {
    "objectID": "pages/multidisease_surveillance.fr.html#informations-sur-létude-de-cas",
    "href": "pages/multidisease_surveillance.fr.html#informations-sur-létude-de-cas",
    "title": "Jonction et analyse des données de notification et des données de laboratoire dans R",
    "section": "",
    "text": "Auteurs originaux Paula Blomquist et Alanah Jansen, avec le soutien technique du CDC Global Surveillance, Laboratory, and Data Systems Branch en collaboration avec TEPHINET.\nSource des données Données fictives fournies par Applied Epi.\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nModifications apportées\nVersion\nAuteur\n\n\n\n\nJuillet 2025\nPremière version\n1\nPaula Blomquist et Alanah Jansen, Applied Epi, avec le soutien technique du CDC Global Surveillance, Laboratory, and Data Systems Branch en collaboration avec TEPHINET.\n\n\nAoût 2025\nTraduction française\n1\nLaurent LeHot et Olivia Boyd"
  },
  {
    "objectID": "pages/multidisease_surveillance.fr.html#conditions-dutilisation",
    "href": "pages/multidisease_surveillance.fr.html#conditions-dutilisation",
    "title": "Jonction et analyse des données de notification et des données de laboratoire dans R",
    "section": "",
    "text": "Clause de non-responsabilité Les informations présentées dans cet exercice et les fichiers de données associés ont été développés pour aider les apprenants à atteindre les objectifs d’apprentissage prévus. Le contenu est celui de l’auteur ou des auteurs et ne représente pas nécessairement les opinions officielles du CDC, du US Department of Health and Human Services ou de TEPHINET.\nLicence d’utilisation Licence : Cette étude de cas est sous licence licence CC BY-NC-SA 4.0. Pour plus d’informations sur le partage et l’adaptation de cette étude de cas, voir le certificat associé.\nFinancement Cette étude de cas a été soutenue à 100 % par l’accord de coopération numéro NU2HGH000044 financé par le US Centers for Disease Control and Prevention (CDC)"
  },
  {
    "objectID": "pages/multidisease_surveillance.es.html",
    "href": "pages/multidisease_surveillance.es.html",
    "title": "Vinculación y análisis de datos de notificación y datos de laboratorio en R",
    "section": "",
    "text": "Herramienta: R Complejidad técnica: Intermedia Complejidad metodológica: Básica\nConocimientos previos necesarios: Fundamentos de R - uso de Rstudio, paquetes de R, funciones y argumentos, uso de tuberías - así como funciones clave de tidyverse y ggplot2.\nFuente: Applied Epi, con el apoyo técnico de la Subdivisión de Vigilancia Mundial, Laboratorios y Sistemas de Datos de los CDC, en colaboración con TEPHINET.\n\n\n\nPara obtener instrucciones sobre cómo utilizar nuestros estudios de caso, consulte la guía práctica. Puede enviar sus comentarios y sugerencias a contact@appliedepi.org. También puede debatir el caso práctico o los conceptos relacionados en la Comunidad de Epi Aplicada.\n\n\nUsted es epidemiologo o epidemióloga en la oficina nacional de vigilancia de Feveria, un pequeño país tropical compuesto por tres distritos:\n\nFeveria Central: zona urbana densamente poblada, con infraestructuras de agua y saneamiento a veces poco fiables.\nLago Minara: zona lacustre con buena infraestructura, pero con gran abundancia de mosquitos durante los meses más cálidos del año.\nKasara: zona suburbana situada al otro lado de Feveria Central.\n\nMapa de los distritos de Feveria\n\nEs enero 2025, y su supervisor quiere que transfiera la rutina de procesamiento de enfermedades de declaración obligatoria de Excel a R, y que realice algunos análisis de datos. Como mínimo, quiere saber:\n\n¿Cuántos casos sospechosos de las diferentes enfermedades de declaración obligatoria se notificaron en 2024, y cuál fue la más frecuente?\n¿Qué porcentaje de ellos fue confirmado?\n¿Cuántos casos confirmados de las diferentes enfermedades de declaración obligatoria se notificaron en 2024, y cuál fue la más frecuente?\n¿Cómo se distribuyeron geográfica y temporalmente los casos confirmados en Feveria?\n\nSu supervisor le pide que escriba código para importar, limpiar, combinar y analizar las siguientes listas:\n\nDatos de vigilancia de enfermedades de declaración obligatoria de 2024: también denominados “datos de notificación”, se trata de datos de vigilancia sobre cinco enfermedades de declaración obligatoria notificadas por las clínicas de Feveria: dengue, paludismo, cólera, fiebre tifoidea y fiebre amarilla. Estos corresponden a casos sospechosos, basados en los síntomas de los pacientes. Los clínicos introducen cada notificación en un sistema en línea todos los días de la semana.\nDatos de resultados de pruebas de laboratorio de 2024: procedentes de tres grandes laboratorios de Feveria. Estos resultados corresponden a muestras tomadas de los casos sospechosos de las enfermedades de declaración obligatoria mencionadas anteriormente.\n\n¡Vamos!\n\n\n\nEn este caso práctico deberá:\n\nUtilizar funciones clave de R para limpiar datos, remodelar bases de datos, combinar fuentes de datos y crear nuevas columnas mediante condiciones lógicas, con el fin de preparar los datos para el análisis.\nRealizar inspecciones de datos y comprobaciones de calidad en diferentes fases del proyecto, comprendiendo su importancia para garantizar un análisis fiable.\nLlevar a cabo análisis descriptivos básicos para comparar las tendencias de las enfermedades entre distintas fuentes de datos, tanto antes como después de la vinculación.\nInterpretar las diferencias en los resultados de las distintas fuentes de datos y comprender cómo éstas reflejan la estructura y el diseño del sistema de vigilancia.\n\n\n\n\n\n\nEmpiece por establecer un flujo de trabajo reproducible y bien organizado. Esto le facilitará repetir el análisis siempre que sea necesario.\nTareas:\n\nConfigurar un proyecto en RStudio.\nEstablecer subcarpetas claras para su código, datos y resultados.\nCrear un script en R, o un archivo R Markdown si lo prefiere. Asegúrese de que el propósito del script, la fecha y el autor figuren como comentarios en la parte superior del archivo.\nExtra: compruebe que el idioma de trabajo en RStudio sea el adecuado (por ejemplo, español para este ejercicio).\n\n\n\n\n\n\n\nHaga clic para leer una pista\n\n\n\n\n\n\nCree una carpeta donde fuardará todo el trabajo de este caso práctico. Por ejemplo, puede llamarla ‘multienfermedad_lab’ y crearla en el escritorio de su ordenador. En esta carpeta debe crear su proyecto de RStudio.\nLe sugerimos crear las siguientes subcarpeta: scripts (para su código), datos (para sus datos), y resultados (para sus resultados analíticos).\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nCree una carpeta (por ejemplo: ‘multienfermedad_lab’ en su escritorio) para su trabajo. Para crear un proyecto de Rstudio en su nueva carpeta, haga clic en la esquina superior izquierda de R Studio y seleccione la opción New Project..., luego seleccione Existing Directory y, a continuación, en Browse para seleccionar su nueva carpeta. Para obtener más información, consulte la sección proyectos en R del Manual de R para Epis.\nInicie un nuevo script de R haciendo clic en New File en la parte superior izquierda de RStudio y, a continuación, seleccione R Script. Guárdelo de inmediato en la ubicación apropiada, por ejemplo, en la subcarpeta scripts de su proyecto.\nEn la parte superior de su nuevo script de R, escriba información esencial como su nombre, el propósito del archivo y la fecha.\nTenga en cuenta que su configuración regional en R determina el idioma y la localización que se utilizarán para aspectos como los formatos de fecha o las traducciones. Si su configuración regional es distinta del idioma que desea para su informe (por ejemplo, configuración regional en español frente a un informe en inglés), puede cambiarla al inglés ejecutando: Sys.setlocale(\"LC_ALL\", \"English\").\nIncluya esta línea en su script si fuera necesario, o bien omítala si su configuración regional ya es la adecuada. Esto se explica con más detalle en la Guía práctica.\n\n\n\n\n\n\nA continuación, en su script de R, debe instalar y cargar los paquetes necesarios. Esto garantiza que las funciones que necesita estén disponibles para realizar su análisis.\nNecesitará los siguientes paquetes:\n{rio} (para importar datos) {skimr} (para revisar datos) {janitor} (para limpiar datos) {lubridate} (para la gestión de fechas y tiempos) {epikit} (para tareas relacionadas con epidemiología) {gtsummary} (para estadísticas descriptivas, pruebas y regresión) {apyramid} (para pirámides de edad y sexo) {flextable} (para generar tablas listas para su presentación) {naniar} (para evaluar datos faltantes) {tidyverse} (para tareas generales de manipulación y análisis de datos)\nAdemás, necesitará {remotes} para descargar datos, algo que se explicará en la sección correspondiente a descargas.\nMientras empieza, su colega de confianza le da un codazo y le susurra: “He oído que una forma estupenda de gestionar sus paquetes… es con el paquete {pacman}”.\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nUtilice la función p_load() del paquete {pacman} para esta tarea. Es suficiente con proporcionarle una lista de los paquetes que desee utilizar. La función realiza dos pasos por cada paquete:\n\nComprueba si el paquete está instalado en su ordenador y, si no lo está, lo instala automáticamente.\nCarga el paquete para que pueda usarse durante la sesión de R.\n\nSi aún no tiene instalado {pacman}, deberá hacerlo a la manera tradicional, con install.packages().\nTenga en cuenta que el orden de los paquetes en p_load() puede ser importante. Si dos paquetes contienen funciones con el mismo nombre (por ejemplo, select() en {MASS} y select() en {tidyverse}), R utilizará la versión del paquete cargado más recientemente. Por ello, se recomienda cargar {tidyverse} en último lugar para priorizar sus funciones, muy utilizadas en la manipulación y visualización de datos.\n\n# Asegurarse de que el paquete \"pacman\" está instalado\nif (!require(\"pacman\")) { install.packages(\"pacman\") }\n\n# Instalar (si es necesario) desde CRAN y cargar los paquetes a utilizar\npacman::p_load(\n  rio,        # importar datos  \n  skimr,      # revisar datos de forma rápida\n  janitor,    # limpieza de datos y tablas\n  lubridate,  # manejo de fechas\n  epikit,     # crear categorías de edad\n  gtsummary,  # estadísticas descriptivas, pruebas y regresión \n  apyramid,   # crear pirámides de edad y sexo \n  flextable,  # tablas listas para presentación\n  naniar,     # explorar datos faltantes\n  remotes,    # instalar paquetes para descarga de datos\n  tidyverse   # manipulación y visualización de datos (último, para priorizar sus funciones)\n)\n\n\n\n\n\n\n\n\n\n\nSu oficina le proporciona dos archivos para su análisis, ambos correspondientes al año 2024 y actualizados al 15 de enero de 2025:\n\nUna base de datos de notificación de enfermedades (“notificaciones_multienfermedad.xlsx”) con los casos procedentes de 5 centros de salud.\nUna base de datos de pruebas de laboratorio (“pruebas_multienfermedad.csv”) enviada por tres laboratorios que realizan pruebas para los mismos 5 centros de salud.\n\nPara este estudio de caso, puede descargar los datos desde la página web de Applied Epi mediante el paquete {appliedepidata}. Siga estos pasos:\n\nInstale el paquete {appliedepidata} desde GitHub utilizando el comando install_github() del paquete {remotes} (que ya instaló anteriormente):\n\n\n# Usar la función install_github de remotes para instalar {appliedepidata}\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nGuarde las dos bases de datos en una carpeta específica utilizando la función save_data() del paquete {appliedepidata}. Este código guardará los archivos en la subcarpeta datos dentro de la carpeta de su proyecto en RStudio. Tenga en cuenta que, si no especifica ninguna ubicación en el argumento path, aparecerá una ventana para que seleccione manualmente la carpeta.\n\n\n# Guardar los dos archivos de datos usando la función save_data() de appliedepidata\nappliedepidata::save_data(\"pruebas_multienfermedad\",\n                          path = \"datos\")\n\nappliedepidata::save_data(\"notificaciones_multienfermedad\",\n                          path = \"datos\")\n\n\n\n\n¡Gracias a la oficina nacional y a Applied Epi! Ahora es el momento de importar los datos desde la carpeta a RStudio, para poder analizarlos.\n\n\nLo ideal es que utilice la misma función para importar ambas bases de datos al Entorno, aunque uno sea un archivo .csv y el otro un .xlsx. A partir de ahora, cuando hablemos de Entorno, nos referiremos al panel Environment (Entorno en español) de RStudio.\n\n\n\n\n\n\nHaga clic para leer una pista\n\n\n\n\n\nUtilice la función import() del paquete {rio}, que reconoce e importa distintos tipos de archivos. De esta manera no tendrá que usar funciones específicas según el formato, como read.csv() de {base} para archivos .csv o read_excel() de {readxl} para archivos .xlsx.\nSi quiere más información sobre la importanción de datos, puede consultar la sección Importar y exportar de nuestro manual de R.\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nA continuación se muestra cómo importar los dos archivos utilizando la función import(). Los datos se guardan en dos objetos:\n\ndata_notif_crudos para los datos de notificaciones,\ndata_lab_crudos para los datos de laboratorio.\n\nEl sufijo *_crudos* le servirá para distinguirlos de las versiones depuradas que creará más adelante.\n\n# Importar datos\n\n# Datos de notificación\ndatos_notif_crudos &lt;- import(\"datos/notificaciones_multienfermedad.xlsx\")\n\n# Datos de laboratorio\ndatos_lab_crudos &lt;- import(\"datos/pruebas_multienfermedad.csv\")\n\n\n\n\n\n\n\n\n\nYa tiene los datos, y ahora es el momento de ver qué historia cuentan. Tómese un momento para comprobar su contenido y su calidad.\n\n\n\n\nUtilice las siguients funciones para explorar sus datos: skim() del paquete {skimr}, names(), col() y nrow().\nskim() le proporciona información muy completa sobre la estructura y el contenido de los datos. names() le mostrará los nombres de las columnas. ncol() y nrow() cuentan, respectivamente, el número de columnas y de filas de su base de datos.\nPiense: ¿qué debe poner dentro de los paréntesis de cada función?\nLas pista más sencilla está en su Entorno. Recuerde que el objeto que contiene los datos de notificación se llama: datos_notif_crudos.\nSi necesita ayuda, haga click en el cuadro de soluciones situado debajo de las preguntas.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuántas columnas hay en los datos de notificación?\n\n 10 11 12 13\n\n¿Cuál de estas columnas NO aparece en los datos?\n\n Fecha de inicio Fecha notificada por el centro de salud/la comunidad Fecha del resultado Fecha de la prueba Fecha de nacimiento\n\n¿Cuál es el nombre de la columna en los datos de notificación que identifica cada notificación?\n\n ID de notificacion ID prueba Codigo del centro de salud Combinación de ID de notificacion y Sexo\n\n¿Cuántas filas hay en los datos de notificación?\n\n 987 1314 950 778\n\n¿Qué tipo de información NO se encuentra en los datos de notificación?\n\n Resultados de pruebas de laboratorio Distrito de residencia Fecha de nacimiento y sexo Centro de salud donde se diagnosticó el caso Resultado\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nUtilice skim() del paquete {skimr} para ver un resumen de toda la base de datos, y View() para visualizar directamente los datos completos:\n\nskim(datos_notif_crudos)\n\nTambién puede emplear names() para imprimir únicamente los nombres de las columnas. Tanto con skim() como con names() podrá observar los tipos de información incluidos: el centro sanitario del caso, la fecha de nacimiento, el sexo, un indicador de embarazo, el distrito de residencia, la fecha de inicio de síntomas y la fecha notificada por la clínica, así como información sobre el desenlace.\nAdemás, encontrará una columna ID de notificacion que parece ser un identificador único para cada caso, aunque conviene comprobar posibles duplicados antes de confirmarlo.\nTenga en cuenta que en estos datos no hay resultados de laboratorio, ya que las notificaciones proceden de las clínicas, que notifican enfermedades de declaración obligatoria en base a criterios clínicos.\n\nnames(datos_notif_crudos)\n\n [1] \"Nombre de la unidad organizativa\"                    \n [2] \"Codigo del centro de salud\"                          \n [3] \"ID de notificacion\"                                  \n [4] \"Fecha de nacimiento\"                                 \n [5] \"Sexo\"                                                \n [6] \"Embarazada\"                                          \n [7] \"Distrito residencial\"                                \n [8] \"Enfermedad notificada\"                               \n [9] \"Fecha de inicio\"                                     \n[10] \"Fecha notificada por el centro de salud/la comunidad\"\n[11] \"Resultado\"                                           \n[12] \"Fecha del resultado\"                                 \n\n\nPara obtener el número de columnas y de filas puede utilizar:\n\nncol(datos_notif_crudos)\nnrow(datos_notif_crudos)\n\nEsto imprimirá en la consola el número de columnas y de filas de la base de datos.\n\n\n[1] 12\n\n\n[1] 987\n\n\nOtra manera rápida es mirar el Entorno en RStudio, donde verá, junto al nombre de la base de datos, el número de observaciones (filas) y de variables (columnas).\n\n\n\n\n\n\nUtilice skim() del paquete {skimr} o la función class() para comprobar las clases de las columnas.\n¿Recuerda cómo indicar la columna de interés dentro de la función class()? Alternativamente, puede observar el panel de Entorno en RStudio, donde aparece la clase de cada columna junto a su nombre.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuántas columnas de la base de datos de notificación reconoce R como columnas de tipo fecha?\n\n 0 2 4\n\n¿Cuál es la clase de la mayoría de las columnas en la base de datos de notificación en bruto?\n\n character (texto) numeric (numérico) factor\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nPuede usar class() como en el ejemplo siguiente. El operador $ sirve para seleccionar una columna concreta de la base de datos datos_notif_crudos. Fíjese en que se usan comillas invertidas (`) alrededor de Fecha de nacimiento porque el nombre de la columna contiene espacios.\n\nclass(datos_notif_crudos$`Fecha de nacimiento`)\n\nPara ver la clase desde el panel Entorno, haga click en la flecha azul junto con el nombre de la base de datos: aparececerán los nombres de las columnas con su clase al lado (por ejemplo, “chr” para indicar clase character o nominal)\nVerá que ninguna de las columnas que deberían ser fechas está reconocida como tal; en su lugar, R las interpreta como texto (character).\n\n\n\n\n\n\nUtilice tabyl() para inspeccionar los valores dentro de las columnas categóricas, especificando en el primer argumento la base de datos y en el segundo el nombre de la columna.\nPor ejemplo, este código tabula los valores de la columna Sexo. La salida muestra que los valores “masculino” y “femenino” están escritos de manera incoherente, por lo que esta columna necesitaría limpieza antes del análisis:\n\ntabyl(datos_notif_crudos, Sexo)\n\n      Sexo   n    percent valid_percent\n         F  47 0.04761905    0.05452436\n  FEMENINO 146 0.14792300    0.16937355\n         M  40 0.04052685    0.04640371\n MASCULINO 172 0.17426545    0.19953596\n         f 154 0.15602837    0.17865429\n  femenino  98 0.09929078    0.11368910\n         m 119 0.12056738    0.13805104\n masculino  86 0.08713273    0.09976798\n      &lt;NA&gt; 125 0.12664640            NA\n\n\nPara inspeccionar los valores faltantes (o perdidos), puede usar la función miss_var_summary() del paquete {naniar}:\n\nmiss_var_summary(datos_notif_crudos)\n\n# A tibble: 12 × 3\n   variable                                             n_miss pct_miss\n   &lt;chr&gt;                                                 &lt;int&gt;    &lt;num&gt;\n 1 Fecha de inicio                                         691     70.0\n 2 Embarazada                                              510     51.7\n 3 Resultado                                               197     20.0\n 4 Fecha del resultado                                     197     20.0\n 5 Fecha de nacimiento                                     168     17.0\n 6 Sexo                                                    125     12.7\n 7 Nombre de la unidad organizativa                          0      0  \n 8 Codigo del centro de salud                                0      0  \n 9 ID de notificacion                                        0      0  \n10 Distrito residencial                                      0      0  \n11 Enfermedad notificada                                     0      0  \n12 Fecha notificada por el centro de salud/la comunidad      0      0  \n\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Los valores de la columna Distrito residencial están estandarizados?\n\n No: necesitan limpieza Sí: están estandarizados y listos para usarse en el análisis\n\n¿Los valores de la columna Enfermedad notificada están estandarizados?\n\n No: necesitan limpieza Sí: están estandarizados y listos para usarse en el análisis\n\n¿Qué reconoce R como un valor faltante?\n\n Sin valor, o solo un espacio, o solo un punto Sin valor en una celda, representado como NA Las palabras 'desconocido' e 'incierto'\n\nSegún los valores faltantes, ¿es útil la columna Fecha de inicio?\n\n Sí, la cantidad de valores faltantes es baja y esta columna es útil No demasiado: la ausencia es muy alta\n\n¿Por qué algunas columnas en los datos de notificación pueden tener grafías diferentes y categorías no estandarizadas?\n\n Un bot revuelve los datos para que sean menos identificables Cada clínica puede usar software configurado de forma diferente, o permitir entradas de texto libre, lo que genera variaciones en la ortografía El software de vigilancia usado en las clínicas tiene muchos errores en el código\n\n¿Por qué algunas columnas en los datos de notificación pueden tener una alta proporción de valores faltantes?\n\n El personal sanitario no pregunta al paciente durante la consulta El paciente no sabe o no quiere dar la respuesta El personal sanitario no tiene tiempo de completar ese campo, aunque sepa la información Todas las anteriores, y muchas más razones\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nUse tabyl() para tabular los valores de la columna Distrito residencial. De nuevo, el primer argumento es el nombre de la base de datos y el segundo el nombre de la columna:\n\ntabyl(datos_notif_crudos, `Distrito residencial`)\n\n Distrito residencial   n    percent\n            F Central  32 0.03242148\n            FEVERIA C  23 0.02330294\n      FEVERIA CENTRAL  85 0.08611955\n            Feveria C  24 0.02431611\n      Feveria Central  12 0.01215805\n               KASARA  64 0.06484296\n                  KSR  17 0.01722391\n               Kasara 109 0.11043566\n             L MINARA  50 0.05065856\n             L Minara 193 0.19554205\n          LAGO MINARA 185 0.18743668\n          Lago Minara  68 0.06889564\n             Lakeside 125 0.12664640\n\n\nVerá que cada una de las tres ubicaciones (Feveria Central, Lago Minara y Kasara) aparece escrita de distintas maneras y con diferentes mayúsculas. Esto deberá limpiarse si se quiere analizar la distribución geográfica de las enfermedades de declaración obligatoria.\nDe forma similar, utilice tabyl() para tabular los valores de la columna Enfermedad notificada. En este caso, verá que están escritos de forma adecuada y coherente, de modo que se puede analizar la distribución de los casos por enfermedad sin necesidad de más limpieza:\n\ntabyl(datos_notif_crudos, `Enfermedad notificada`)\n\n Enfermedad notificada   n    percent\n                colera  46 0.04660588\n                dengue 273 0.27659574\n       fiebre amarilla 100 0.10131712\n       fiebre tifoidea  35 0.03546099\n             paludismo 533 0.54002026\n\n\nPara comprobar los valores faltantes también puede usar is.na(). En el ejemplo siguiente, la función evalúa cada celda de la columna Fecha de inicio, devolviendo TRUE si falta el valor y FALSE si está presente. Si aplica tabyl() a este resultado, obtendrá de inmediato un recuento y un porcentaje claros de valores faltantes y no faltantes en esa columna.\nRecuerde: valores como un espacio vacío o las palabras “Desconocido” o “Faltante” no son reconocidos por R como NA. Solo los valores realmente en blanco, representados con NA, se consideran ausentes.\nEn el caso de Fecha de inicio, puede comprobar que aproximadamente un 70 % de las filas carecen de fecha de inicio, lo que hace que esta columna sea poco útil para analizar tendencias temporales.\n\ntabyl(is.na(datos_notif_crudos$`Fecha de inicio`))\n\n is.na(datos_notif_crudos$`Fecha de inicio`)   n   percent\n                                       FALSE 296 0.2998987\n                                        TRUE 691 0.7001013\n\n\nLos valores faltantes o las categorías no estandarizadas pueden deberse a muchas razones:\n\nEl diseño de la herramienta de recogida de datos (por ejemplo, si un campo es obligatorio o si se permite texto libre en lugar de listas desplegables),\nLos procesos y normas vigentes (por ejemplo, qué campos prioriza el personal),\nFactores contextuales (como la carga de trabajo o el tiempo disponible para recopilar la información).\n\n\n\n\n\n\n\n\n\n\nIgual que con los datos de vigilancia, utilice skim(), ncol() y nrow() o consulte el panel Entorno para inspeccionar los datos de laboratorio.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué base de datos tiene más columnas: la de notificación o la de laboratorio?\n\n Datos de laboratorio Datos de notificación Tienen el mismo número de columnas\n\n¿Qué base de datos tiene más filas: la de notificación o la de laboratorio?\n\n Datos de laboratorio Datos de notificación Tienen el mismo número de filas\n\nInspeccione los datos de laboratorio con View(). ¿Por qué podría haber más registros en la base de datos de laboratorio?\n\n Puede haber varias pruebas u objetivos por muestra Hay muchos resultados de pruebas de ensayo en los datos No todas las notificaciones tienen resultados de laboratorio todavía\n\n¿Cuál de estas columnas NO está en la base de datos de laboratorio?\n\n ID de notificacion ID de muestra Prueba Fecha de nacimiento Valor\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nAl igual que en la sección 3.1, puede utilizar skim() del paquete {skimr} para visualizar toda la base de datos del laboratorio con los resultados de las pruebas. Esto también le mostrará los distintos nombres de las columnas, poniendo de manifiesto que la base de datos del laboratorio solo contiene información sobre la prueba y no sobre el paciente. No obstante, también incluye un identificador de notificación similar, similar a los datos de notificación.\n\nskim(datos_lab_crudos)\n\nUtilice ncol() y nrow() para imprimir el número de columnas y filas, de la siguiente forma:\n\nncol(datos_lab_crudos)\nnrow(datos_lab_crudos)\n\nEsto mostrará en su consola el número de columnas y de filas, de manera que podrá comprobar que la base de datos de laboratorio tiene más filas que la base de datos de notificación que inspeccionó anteriormente.\n\n\n[1] 7\n\n\n[1] 1314\n\n\nA menudo hay más registros en la base de datos de laboratorio que en los datos clínicos. Si inspecciona los datos con View(datos_lab_crudos) y luego hace clic en la flecha de la parte superior de la columna ID de notificacion para ordenarla alfabéticamente, verá que varias filas comparten el mismo ID de notificacion. Esto puede suceder cuando se analizan varios objetivos de la misma muestra (mismo identificador de muestra), o cuando se repite el análisis de un caso (lo que da lugar a un identificador de muestra diferente).\n\nView(datos_lab_crudos)\n\n\n\nnombre_laboratorioid_notificacionid_muestrafecha_pruebapruebaobjetivovalorHospital General de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue NS.1NHospital General de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgGNHospital General de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgMPHospital General de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue NS.1NHospital General de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgGNHospital General de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgMP\n\n\n\n\n\n\n\n\nAl igual que en el caso anterior, utilice las funciones class(), skim()o tabyl(), o inspeccione el Entorno, para observar las columnas con más detalle.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuántas columnas de la base de datos de laboratorio reconoce R como columnas de tipo fecha?\n\n 0 1 2\n\n¿Cuántas columnas de la base de datos de laboratorio tienen datos completos?\n\n 1 3 7 (Todas)\n\n¿Qué prueba detecta múltiples objetivos (y, por lo tanto, tiene varias filas por muestra)?\n\n Paludismo Dengue Fiebre Amarilla Cólera Fiebre tifoidea\n\n¿Cuántos valores posibles de resultado de prueba hay en la columna valor?\n\n 5 3 4\n\n¿Cuál de estos NO es un posible resultado en la prueba de cultivo de heces que detecta la bacteria V. cholerae?\n\n P P01 P0139 N I\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nLos datos de laboratorio tienen una columna de fecha reconocida por R con la clase “IDate”. Se trata de una clase de fecha que suele aparecer al importar CSV con la función import() de {rio}. Igual que la clase “Date” de R base, permite ordenar por fecha y analizar tendencias en el tiempo.\n\nclass(datos_lab_crudos$fecha_prueba)\n\n[1] \"IDate\" \"Date\" \n\n\nEl uso de la función miss_var_summary() del paquete {naniar} muestra que todas las columnas de los datos de laboratorio están completas. Esto puede deberse a que los sistemas de laboratorio utilizan procesos automatizados, por lo que es menos probable que se produzcan errores humanos.\n(Punto importante: Tenga en cuenta que, en la vida real, los datos de laboratorio también presentarían probablemente algunos problemas).\n\nmiss_var_summary(datos_lab_crudos)\n\n# A tibble: 7 × 3\n  variable           n_miss pct_miss\n  &lt;chr&gt;               &lt;int&gt;    &lt;num&gt;\n1 nombre_laboratorio      0        0\n2 id_notificacion         0        0\n3 id_muestra              0        0\n4 fecha_prueba            0        0\n5 prueba                  0        0\n6 objetivo                0        0\n7 valor                   0        0\n\n\nPara ver cuántos objetivos se detectan en cada prueba, puede realizar una tabulación cruzada de las columnas prueba y objetivo con tabyl(). Escriba los nombres de las columnas en la función como dos argumentos separados. La salida muestra que cada prueba se alinea claramente con uno o más objetivos, y solo la prueba de dengue detecta más de un objetivo (IgG, IgM y NS1).\nConsejo: Pruebe a cambiar el orden de los nombres de las columnas en la función para ver el impacto en la tabla.\n\ntabyl(datos_lab_crudos, objetivo, prueba)\n\n             objetivo Cultivo de heces Dengue NS1/IgG/IgM Hemocultivo IgM ELISA\n Bacteria V. cholerae               45                  0           0         0\n   Bacterias S. Typhi                0                  0          33         0\n           Dengue IgG                0                215           0         0\n           Dengue IgM                0                215           0         0\n          Dengue NS.1                0                215           0         0\n  Fiebre amarilla IgM                0                  0           0        88\n           Plasmodium                0                  0           0         0\n Microscopía de sangre total\n                           0\n                           0\n                           0\n                           0\n                           0\n                           0\n                         503\n\n\nPor último, puede inspeccionar los distintos valores de los resultados de las pruebas en la columna valor utilizando de nuevo tabyl(). Verá que hay seis resultados posibles, incluidos N (negativo), P (positivo) e I (indeterminado). En el caso del cólera no aparece P, pero sí pueden aparecer P01 y P0139, que en este ejemplo representan positividad para los serogrupos O1 u O139.\n\ntabyl(datos_lab_crudos, prueba, valor)\n\n                      prueba  I   N   P PO1 PO139\n            Cultivo de heces  5   2   0  22    16\n          Dengue NS1/IgG/IgM  0 354 291   0     0\n                 Hemocultivo  2  24   7   0     0\n                   IgM ELISA 10  45  33   0     0\n Microscopía de sangre total 56 257 190   0     0\n\n\n\n\n\n\n\n\n\n\nLos datos de notificación (datos_notif_crudos) contienen información sobre casos sospechosos, junto con datos demográficos básicos (edad, sexo, embarazo, distrito de residencia), e información sobre su fecha de inicio, fecha reportada por el centro de salud, y resultado. Algunas columnas deben limpiarse antes de continuar con el análisis, debido a variaciones en la ortografía de los valores categóricos y a que algunas no se reconocen como fechas.\nAhora comenzará a redactar fragmentos más extensos de código para realizar limpieza de datos, utilizando diversas funciones de {dplyr} encadenadas mediante pipes (que se representan de la siguiente manera: |&gt;).\nNOTA SOBRE PIPES: Los pipes permiten ejecutar varias operaciones en una secuencia continua, “encadenando” diferentes funciones. La salida de una función se convierte en la entrada de la siguiente.\nPara obtener más información sobre el uso de pipes, consultar el Manual de R para Epis.\nCabe destacar que este ejercicio utiliza el pipe de base (|&gt;) en lugar del pipe de magrittr (%&gt;%), ya que resulta más rápido y no requiere instalación de paquetes. Si prefiere, puede utilizar el pipe de magrittr.\n\n\n\n\nDebido a problemas de calidad y de almacenamiento de datos, se recomienda elaborar una lista depurada (linelist) que contenga únicamente la información sobre el identificador único, la ubicación del caso, la enfermedad y la fecha en que la notificación fue reportada al sistema de vigilancia.\nEscribir código en R para generar una nueva base de datos limpio denominado datos_notif, aplicando las siguientes tareas de limpieza:\n\nRenombrar las columnas para que resulten más legibles por las máquinas (eliminando espacios y mayúsculas) mediante la función clean_names() del paquete {janitor}.\nUtilizar la función rename() de {dplyr} para que:\n\nel nombre de la columna con la fecha en la que se notificó el caso se sustituya por un nombre más conciso fecha_notificada.\nel nombre de la columna del identificador de la notificación sea más conciso (id_notificacion).\n\nSeleccionar las columnas relevantes para el análisis con la función select() del paquete {dplyr}.\n\n\n\n\n\n\n\nHaga clic para leer una pista\n\n\n\n\n\nIniciar el código con el nombre de la nueva base de datos, la flecha de asignación y el nombre del objeto de datos en bruto. Esto indica que el resultado del procesamiento de los datos en bruto será asignado a un nuevo objeto denominado datos_notif.\n\ndatos_notif &lt;- datos_notif_crudos\n\nA continuación, construya sobre este código añadiendo funciones adicionales, encadenadas mediante un pipe. Esto permite realizar varias operaciones en una secuencia continua. Primero, utilice clean_names() para estandarizar todos los nombres de columnas. Esta función reemplaza automáticamente los espacios y caracteres especiales por guiones bajos y convierte todo a minúsculas, lo que facilita el manejo de los nombres. Después, utilice rename() para asignar un nombre nuevo a una columna. Recordar que, al usar rename(), la columna ya tendrá la versión transformada por clean_names().\n\n# datos_notif &lt;- datos_notif_crudos |&gt; \n#   clean_names() |&gt; \n#   rename(NOMBRE_NUEVO = NOMBRE_ANTERIOR) |&gt; \n#   select(NOMBRES_VARIABLES)\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nAquí está el código para limpiar los nombres de las columnas y seleccionar las columnas adecuadas para análisis:\n\n# Limpiar datos \ndatos_notif &lt;- datos_notif_crudos |&gt; \n  clean_names() |&gt; \n  rename(\n    fecha_notificada = fecha_notificada_por_el_centro_de_salud_la_comunidad,\n    id_notificacion = id_de_notificacion) |&gt;\n  select(id_notificacion, distrito_residencial, enfermedad_notificada, fecha_notificada)\n\n\n\n\n\n\n\nA partir de la inspección de los datos, ya sabe que los valores de la columna distrito_residencial no están estandarizados.\nAgregar una función mutate() para limpiar la columna distrito_residencial, con el fin de:\n\nEstandarizar la capitalización de la columna.\n\nReemplazar la columna existente distrito_residencial por una columna depurada que contenga únicamente los siguientes valores de distrito: “Lago Minara”, “Feveria Central” y “Kasara”.\n\nConsultar la pista para ver qué funciones se pueden utilizar.\n\n\n\n\n\n\nHaga clic para leer una pista\n\n\n\n\n\nPrueba a utilizar str_to_title() del paquete {stringr} para que la primera letra de cada palabra sea mayúscula y todas las demás letras sean minúsculas. También puede utilizar case_match() para especificar distintas erratas concretas.\nUtilice la función ‘help’ de RStudio para ver cómo utilizar las funciones. Por ejemplo, escriba ?case_match en su consola para obtener la página de ayuda de la función. NOTA en case_match() - se trata de una función muy útil para sustituir o corregir valores, y sustituye a recode().\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nSu código de limpieza debería tener ahora este aspecto:\n\n# Limpiar datos\ndatos_notif &lt;- datos_notif_crudos |&gt; \n  clean_names() |&gt; \n  rename(\n    fecha_notificada = fecha_notificada_por_el_centro_de_salud_la_comunidad,\n    id_notificacion = id_de_notificacion) |&gt;\n  select(id_notificacion, distrito_residencial, enfermedad_notificada, fecha_notificada) |&gt; \n  mutate(distrito_residencial = str_to_title(distrito_residencial)) |&gt; \n  mutate(distrito_residencial = case_match(distrito_residencial,\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\"))\n\nTambién puede envolver str_to_title en la función case_match() para acortar el código, como se indica a continuación:\n\n# Limpiar datos\ndatos_notif &lt;- datos_notif_crudos |&gt; \n  clean_names() |&gt; \n  rename(\n    fecha_notificada = fecha_notificada_por_el_centro_de_salud_la_comunidad,\n    id_notificacion = id_de_notificacion) |&gt; \n  select(id_notificacion, distrito_residencial, enfermedad_notificada, fecha_notificada) |&gt; \n  mutate(distrito_residencial = case_match(str_to_title(distrito_residencial),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\"))\n\n\n\n\n\n\n\nLa columna correspondiente a la fecha de notificación necesita ser transformada para que sea reconocida como una fecha en R. Esto permitirá analizar tendencias a lo largo del tiempo, incluyendo semanas y meses.\nRevisar los valores dentro de la columna fecha_notificada. Luego, agregar una línea al código de limpieza para convertir fecha_notificada en una clase de fecha.\nConocer la estructura de la columna permitirá utilizar la función adecuada para transformarla en clase de fecha. Se recomienda emplear alguna de las funciones del paquete {lubridate}: ymd() (para fechas escritas como año-mes-día), mdy() (para fechas escritas como mes-día-año) o dmy() (para fechas escritas como día-mes-año). Estas funciones reconocerán cualquier formato de escritura de fecha siempre que el orden sea correcto; por ejemplo, “21st August 2025” y “21-08-2024” serían reconocidos por dmy().\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cómo están formateadas actualmente las fechas?\n\n día-mes-año año-mes-día mes-día-año año-día-mes\n\n¿Qué función de mutate() deberías usar para convertir la columna fecha_notificada en una clase de fecha?\n\n mutate(fecha_notificada = ymd(fecha_notificada)) mutate(fecha_notificada = dmy(fecha_notificada)) mutate(fecha_notificada = mdy(fecha_notificada))\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nSe puede utilizar la función head() para visualizar las primeras seis filas de datos de la columna fecha_notificada. Al observarlas, se identifica que están escritas con el año en primer lugar, seguido del mes y, posteriormente, del día.\n\nhead(datos_notif$fecha_notificada)\n\n[1] \"2024-03-08\" \"2024-03-11\" \"2024-03-11\" \"2024-03-18\" \"2024-03-14\"\n[6] \"2024-03-12\"\n\n\nSe puede utilizar la función ymd() dentro de mutate() para convertir la clase de la columna fecha_notificada. Es posible verificar que la clase sea la correcta ejecutando posteriormente la función class().\nEl código de limpieza debería ahora tener el siguiente aspecto:\n\n# Limpiar datos\ndatos_notif &lt;- datos_notif_crudos |&gt; \n  clean_names() |&gt; \n  rename(\n    fecha_notificada = fecha_notificada_por_el_centro_de_salud_la_comunidad,\n    id_notificacion = id_de_notificacion) |&gt;\n  select(id_notificacion, distrito_residencial, enfermedad_notificada, fecha_notificada) |&gt; \n  mutate(distrito_residencial = case_match(str_to_title(distrito_residencial),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\")) |&gt; \n  mutate(fecha_notificada = ymd(fecha_notificada)) \n\nY se puede volver a comprobar la clase con esto:\n\nclass(datos_notif$fecha_notificada)\n\n[1] \"Date\"\n\n\n\n\n\n\n\n\nLos colegas indican que cada id_notificacion representa un caso sospechoso. Ahora se desea crear una tabla para verificar si id_notificacion se encuentra duplicado en las filas de los datos.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Equivale una fila en los datos de notificación a un caso?\n\n Sí No\n\n¿Necesita depurar (eliminar duplicados) sus datos para el análisis epidemiológico de casos?\n\n Sí No\n\n\n\n\n\n\n\n\n\n\nHaga clic para leer una pista\n\n\n\n\n\nExisten varias formas de realizar esta verificación, pero se sugiere utilizar la función count() de {dplyr}. Esta función creará una tabla que contabiliza el número de filas por cada valor único de la columna que se especifique dentro de la función. Posteriormente, emplear tabyl() para observar la distribución de estos conteos.\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nPrimero, encadenar los datos de vigilancia mediante un pipe hacia la función count(), indicando la columna id_notificacion como el único argumento. Esto generará una tabla que contabiliza el número de filas por cada valor único de id_notificacion, mostrando el resultado en una nueva columna denominada n. En este extracto se puede observar, por ejemplo, que existe solo una fila para cada uno de estos seis valores de id_notificacion.\n\ndatos_notif |&gt; \n  count(id_notificacion) \n\n\n\n  id_notificacion n\n1          00399b 1\n2          005c85 1\n3          006f52 1\n4          00cbbb 1\n5          01830d 1\n6          019045 1\n\n\nA continuación, tabular la nueva columna n con la función tabyl(), lo que demuestra que existe únicamente una fila por cada id_notificacion único. Esto significa que una fila equivale a un caso y que no se requiere realizar una deduplicación adicional.\n\ndatos_notif |&gt; \n  count(id_notificacion) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 987       1\n\n\n\n\n\n\n\n\n\nAhora puede proceder cómodamente al análisis descriptivo de los casos, ya que sus datos están limpios y sabe que una fila equivale a un caso. Utilice la función tabyl() para las siguientes tareas.\n\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué enfermedad fue diagnosticada con mayor frecuencia por las clínicas en Feveria en 2024?\n\n Cólera Paludismo Dengue Fiebre tifoidea Fiebre amarilla\n\n¿Qué enfermedad fue diagnosticada con menor frecuencia por las clínicas en Feveria en 2024?\n\n Cólera Paludismo Dengue Fiebre tifoidea Fiebre amarilla\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nUtilizando tabyl() podemos ver que había 533 casos sospechosos de paludismo en Feveria en 2024, y sólo 35 casos sospechosos de fiebre tifoidea.\n\ntabyl(datos_notif, enfermedad_notificada)\n\n enfermedad_notificada   n    percent\n                colera  46 0.04660588\n                dengue 273 0.27659574\n       fiebre amarilla 100 0.10131712\n       fiebre tifoidea  35 0.03546099\n             paludismo 533 0.54002026\n\n\n\n\n\n\n\n\nUtilice tabyl() para cruzar las columnas de enfermedad y distrito de residencia.\nComplete la tabla incorporando diversas funciones adorn del paquete {janitor}, con el fin de visualizar distribuciones porcentuales, por ejemplo: adorn_percentages(), adorn_pct_formatting() y adorn_ns().\nEscribir el nombre de la función precedido de un signo de interrogación en la consola (por ejemplo, ?adorn_ns) para consultar las páginas de ayuda correspondientes. También se puede revisar la sección sobre {janitor} en el manual de R para Epis para obtener una explicación más detallada sobre las funciones adorn_xxx().\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué distrito notificó la mayor cantidad de enfermedades transmitidas por vectores en 2024 (paludismo, dengue, fiebre amarilla)?\n\n Lago Minara Feveria Central Kasara\n\n¿Qué distrito notificó la mayor cantidad de enfermedades diarreicas en 2024 (cólera, fiebre tifoidea)?\n\n Lago Minara Feveria Central Kasara\n\n¿Qué factores contribuyen al aumento de enfermedades diarreicas en este distrito específico (seleccionado en la pregunta anterior)?\n\n Infraestructura deficiente de agua y saneamiento Hacinamiento de mosquitos No lo sabemos\n\n\n\n\n\n\n\n\n\n\nHaga clic para leer una pista\n\n\n\n\n\nAquí se presenta código para comenzar. Primero, se realiza una tabla de contingencia entre enfermedad_notificada y distrito_residencial con tabyl(). Luego, al agregar adorn_percentages(), estos valores se convierten en porcentajes con muchos decimales. A continuación, encadenar mediante pipes hacia adorn_pct_formatting() para aplicar un formato porcentual adecuado y, posteriormente, hacia adorn_ns() para reincorporar los números entre paréntesis.\nTener en cuenta que las funciones adorn_xxx() deben aplicarse en un orden específico.\n\ntabyl(datos_notif, enfermedad_notificada, distrito_residencial) |&gt;\n  adorn_percentages()\n\nPara conocer los factores que contribuyen a un mayor número de diarreas, desplácese hasta el principio del estudio de caso, cuando se presentaron por primera vez los distritos.\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nAl utilizar tabyl(), se observa que la mayoría de los casos sospechosos de dengue, paludismo y fiebre amarilla se localizaron en Lago Minara, el área lacustre con mayor densidad de mosquitos y, por lo tanto, con enfermedades transmitidas por vectores. Mientras tanto, la mayoría de los casos de cólera y fiebre tifoidea se concentraron en Feveria Central, el área urbana sobrepoblada con problemas en la infraestructura de agua y saneamiento que generan un mayor riesgo de inundaciones y de contaminación del agua potable durante la temporada de lluvias.\n\ntabyl(datos_notif, enfermedad_notificada, distrito_residencial) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n enfermedad_notificada Feveria Central      Kasara Lago Minara\n                colera      91.3% (42)  8.7%   (4)  0.0%   (0)\n                dengue       9.5% (26) 17.6%  (48) 72.9% (199)\n       fiebre amarilla      11.0% (11) 21.0%  (21) 68.0%  (68)\n       fiebre tifoidea      68.6% (24) 31.4%  (11)  0.0%   (0)\n             paludismo      13.7% (73) 19.9% (106) 66.4% (354)\n\n\n\n\n\n\n\n\n\n\nA partir del trabajo realizado anteriormente en el paso 3, se identificó que los datos de laboratorio contienen únicamente información de pruebas y no incluyen datos de pacientes. Los datos ya se encuentran muy depurados, por lo que únicamente es necesario estandarizar una columna. Asimismo, se debe procesar el marco de datos de laboratorio para que contenga una fila por cada notificación, de manera que pueda unirse de forma ordenada con la base de datos de notificación.\n\n\n\n\nCrear un nuevo objeto denominado datos_lab. Esto permitirá un análisis y una interpretación de resultados más directos.\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nUtilice case_match() para convertir los distintos valores originales en “Positivo”, “Negativo” o “Indeterminado”:\n\ndatos_lab &lt;- datos_lab_crudos |&gt; \n  mutate(valor = case_match(valor, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positivo\",\n                            \"N\" ~ \"Negativo\",\n                            \"I\" ~ \"Indeterminado\"))\n\nPosteriormente, se puede verificar que los nuevos valores sean correctos mediante la tabulación y la comparación de los valores en la base de datos original y en el depurado. Asegurarse de haber utilizado la letra ‘O’ y no el número ‘0’.\n\ntabyl(datos_lab_crudos, valor)\n\n valor   n    percent\n     I  73 0.05555556\n     N 682 0.51902588\n     P 521 0.39649924\n   PO1  22 0.01674277\n PO139  16 0.01217656\n\n\n\ntabyl(datos_lab, valor)\n\n         valor   n    percent\n Indeterminado  73 0.05555556\n      Negativo 682 0.51902588\n      Positivo 559 0.42541857\n\n\n\n\n\n\n\n\n\n\n\nYa se sabe que algunas muestras tienen varias filas, y que esto se debe a que el ensayo de dengue posee tres objetivos, con un resultado por fila para cada uno de ellos.\nAhora, determinar el número de muestras con varias filas.\nPara ello, proceder de la misma manera que con los datos de notificación, utilizando el objeto datos_lab: primero contar el número de filas por muestra y luego crear una tabla que muestre la distribución de la cantidad de filas. Tener en cuenta que cada muestra se identifica mediante un identificador de muestra (id_muestra).\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuántas muestras (identificadores únicos id_muestra) están repetidas en tres filas?\n\n 200 215 230\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nPrimero, encadenar los datos de laboratorio mediante un pipe hacia la función count(), indicando la columna id_muestra como el único argumento. Esto generará una tabla que contabiliza el número de filas por cada valor único de id_muestra, mostrando el resultado en una nueva columna denominada n. Por ejemplo, se puede observar que el id_muestra “000e8eee” tiene tres filas, mientras que el id_muestra “001e1878” aparece únicamente en una fila.\n\ndatos_lab |&gt; \n  count(id_muestra) \n\n\n\n  id_muestra n\n1   000e8eee 3\n2   001e1878 1\n3   005f39af 1\n4   00b30781 3\n5   00b56d18 1\n6   0110abcd 3\n\n\nA continuación, tabular la nueva columna n utilizando la función tabyl().\n\ndatos_lab |&gt; \n  count(id_muestra) |&gt; \n  tabyl(n)\n\n n n_n   percent\n 1 669 0.7567873\n 3 215 0.2432127\n\n\nIncluso se puede verificar que esto aplica únicamente al ensayo de dengue añadiendo la columna prueba al cálculo. De esta manera, se observa que solo la prueba de dengue presenta tres filas por muestra.\n\ndatos_lab |&gt; \n  count(prueba, id_muestra) |&gt; \n  tabyl(prueba, n)\n\n                      prueba   1   3\n            Cultivo de heces  45   0\n          Dengue NS1/IgG/IgM   0 215\n                 Hemocultivo  33   0\n                   IgM ELISA  88   0\n Microscopía de sangre total 503   0\n\n\n\n\n\n\n\n\nComo se observó en la sección 3.2, la prueba de dengue proporciona resultados para tres objetivos diferentes: IgG, IgM y NS.1. Los resultados de cada uno de estos objetivos pueden ser negativos o positivos. Sin embargo, para simplificar y consolidar los datos, se desea asignar una sola etiqueta (negativa o positiva) a cada muestra, con el fin de indicar si la muestra representa una infección activa.\n\n\nobjetivoNegativoPositivoDengue IgG110105Dengue IgM105110Dengue NS.113976\n\n\nSu colega Ben, quien trabaja en el laboratorio, recomienda lo siguiente para la depuración:\n\nConsiderar una muestra como positiva si NS.1 o IgM son positivos (ambos pueden representar una infección aguda).\n\nIgnorar IgG (porque un resultado positivo en ausencia de NS.1 o IgM positivos es indicativo de inmunidad tras una infección pasada resuelta).\n\nAhora, consolidar los resultados de la prueba de dengue en una fila por prueba, con un único valor de resultado. Utilizar filter(), arrange() y slice(), asegurándose de que cualquier muestra positiva para NS.1 o IgM se considere positiva para dengue.\nCrear un nuevo objeto denominado datos_lab_pruebas.\n\n\n\n\n\n\nHaz clic para leer una pista\n\n\n\n\n\nIntentar aplicar lo siguiente para consolidar conforme a la recomendación de Ben:\n\nEliminar resultados de IgG: filtrar las filas donde el objetivo sea “IgG” utilizando filter() de {dplyr}.\n\nPriorizar resultados positivos de IgM/NS1: agrupar por id_muestra y ordenar las filas con arrange() de modo que cualquier resultado ‘P’ (positivo) aparezca primero.\n\nFiltrar al estado final: conservar únicamente la primera fila utilizando slice(1) para obtener el resultado positivo o negativo de la muestra.\n\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nA continuación se presenta el código para filtrar los resultados de IgG del dengue y, posteriormente, consolidar el resultado de la prueba dentro de cada grupo de filas con el mismo id_muestra, priorizando los resultados positivos. Es necesario especificar desc dentro de arrange(), ya que este ordena en orden alfabético inverso, colocando la letra P en la parte superior. Además, agregar la función ungroup() al final para que la nueva base de datos no quede agrupada, lo cual podría generar confusión en análisis posteriores.\n\ndatos_lab_pruebas &lt;- datos_lab |&gt; \n  filter(objetivo != \"Dengue IgG\") |&gt; \n  group_by(id_muestra) |&gt; \n  arrange(desc(valor)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\nPosteriormente, se puede verificar que el nuevo objeto datos_lab_pruebas contenga una sola fila por prueba utilizando la combinación de count() y tabyl(), tal como se hizo en la Tarea A. Esta tabla muestra que todos los identificadores de muestra únicos aparecen únicamente en una fila cada uno:\n\ndatos_lab_pruebas |&gt; \n  count(id_muestra) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 884       1\n\n\n\n\n\n\n\n\nA continuación, verificar el número de pruebas por identificador de notificación en los datos consolidados.\nSe observa que existen 26 filas con el mismo identificador de notificación que otra fila, pero únicamente en los casos analizados mediante microscopía de sangre total para paludismo.\n\ndatos_lab_pruebas |&gt; \n  count(prueba, id_notificacion) |&gt; \n  tabyl(prueba, n)\n\n                      prueba   1  2\n            Cultivo de heces  45  0\n          Dengue NS1/IgG/IgM 215  0\n                 Hemocultivo  33  0\n                   IgM ELISA  88  0\n Microscopía de sangre total 451 26\n\n\nSe procede a investigar con mayor detalle, examinando un caso de ejemplo con id_notificacion “043228”. Esto muestra que dicho caso fue analizado en dos ocasiones, con dos muestras diferentes tomadas con una semana de diferencia. El primer resultado fue positivo y el segundo resultado fue negativo.\n\ndatos_lab_pruebas |&gt; \n  filter(id_notificacion == \"043228\")\n\n# A tibble: 2 × 7\n  nombre_laboratorio     id_notificacion id_muestra fecha_prueba prueba objetivo\n  &lt;chr&gt;                  &lt;chr&gt;           &lt;chr&gt;      &lt;IDate&gt;      &lt;chr&gt;  &lt;chr&gt;   \n1 Hospital Universitari… 043228          27c37cd8   2024-06-18   Micro… Plasmod…\n2 Hospital Universitari… 043228          d2271be0   2024-06-25   Micro… Plasmod…\n# ℹ 1 more variable: valor &lt;chr&gt;\n\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuál afirmación sobre los datos de laboratorio es correcta?\n\n Todos los casos de diferentes enfermedades se vuelven a analizar Algunos casos de paludismo se vuelven a analizar Todos los casos de paludismo se vuelven a analizar\n\n¿Será necesario depurar (eliminar duplicados) los datos de laboratorio para unirlos con los datos de notificación?\n\n Sí - necesitamos una fila que represente el resultado de laboratorio por notificación No - los datos ya están suficientemente depurados\n\n\n\n\n¡Si la respuesta fue que es necesario deduplicar, es correcto!\nDeduplicar los datos para tener una sola fila por id_notificacion, priorizando los resultados positivos, de modo que puedan unirse con los datos de notificación.\nPara ello, seguir un proceso similar al de la Tarea B, utilizando el cuadro de datos generado en dicha tarea:\n\nAgrupar por id_notificacion.\n\nOrdenar por el valor del resultado de la prueba, de manera que los valores que comienzan con P tengan prioridad en la primera fila, seguidos por N (negativo) y luego I (indeterminado).\n\nConservar únicamente la primera fila dentro de cada grupo de id_notificacion, utilizando slice().\n\nAl realizar esto, crear un nuevo objeto denominado datos_lab_casos.\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡intente hacerlo primero!)\n\n\n\n\n\nA continuación se presenta el código para deduplicar las filas dentro de cada grupo con el mismo id_notificacion, priorizando los resultados positivos. Una vez más, es necesario especificar desc dentro de arrange(). Esto funciona perfectamente porque el orden de prioridad deseado para los resultados —positivo, luego negativo y finalmente indeterminado— coincide con el orden alfabético inverso (P aparece antes que N, que aparece antes que I, al ordenar de forma descendente).\nSi el orden de prioridad fuera más complejo o no coincidiera con el orden alfabético (por ejemplo, si “indeterminado” debiera colocarse antes que “negativo”), sería necesario convertir la columna de resultados en un factor y definir explícitamente el orden deseado de sus niveles. No olvidar desagrupar nuevamente al final.\n\ndatos_lab_casos &lt;- datos_lab_pruebas |&gt; \n  group_by(id_notificacion) |&gt; \n  arrange(desc(valor)) |&gt; \n  slice(1) |&gt;\n  ungroup()\n\nA continuación, puede volver a comprobar que el nuevo objeto datos_lab_casos sólo tiene una fila por prueba, utilizando la combinación de count() y tabyl() como que hizo en la Tarea A. Esta tabla le muestra que todos los ID de muestra únicos son sólo están presentes en una fila cada uno:\n\ndatos_lab_casos |&gt; \n  count(id_notificacion) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 858       1\n\n\n\n\n\n\n\n\n\nAhora tenemos dos objetos que podemos utilizar para el análisis de los datos de laboratorio: datos_lab_pruebas y datos_lab_casos.\n\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué objeto debería usar para analizar las pruebas?\n\n datos_lab_pruebas datos_lab_casos ninguno\n\n¿Cuántas pruebas se realizaron para detectar paludismo (mediante microscopía de sangre completa)?\n\n 215 503 88 190\n\n¿Qué porcentaje de las pruebas para cólera (mediante cultivo de heces) resultaron positivas?\n\n 21% 11% 84% 87%\n\n¿Qué prueba tuvo el mayor porcentaje de resultados indeterminados?\n\n ELISA IgM (para la detección de fiebre amarilla) Cultivo de heces (para la detección de cólera) Hemocultivo (para la detección de fiebre tifoidea)\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nAl utilizar tabyl() se puede ver el número de positivos, negativos y resultados indeterminados por prueba. Se puede añadir una serie de funciones de adorn() para mostrar porcentajes y totales.\n\ntabyl(datos_lab_pruebas, prueba, valor) |&gt; \n  adorn_totals(where = \"col\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n                      prueba Indeterminado    Negativo    Positivo        Total\n            Cultivo de heces    11.1%  (5)  4.4%   (2) 84.4%  (38) 100.0%  (45)\n          Dengue NS1/IgG/IgM     0.0%  (0) 13.5%  (29) 86.5% (186) 100.0% (215)\n                 Hemocultivo     6.1%  (2) 72.7%  (24) 21.2%   (7) 100.0%  (33)\n                   IgM ELISA    11.4% (10) 51.1%  (45) 37.5%  (33) 100.0%  (88)\n Microscopía de sangre total    11.1% (56) 51.1% (257) 37.8% (190) 100.0% (503)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué base de datos de laboratorio debería usar para contar el número de casos sospechosos analizados?\n\n datos_lab_crudos datos_lab_casos datos_lab_pruebas datos_lab\n\n¿Cuántos casos sospechosos fueron analizados en los datos de laboratorio de 2024?\n\n 858 1314 884\n\n¿Hay más casos sospechosos en los datos de notificación o en los datos de laboratorio?\n\n Datos de notificación Datos de laboratorio\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nSe puede consultar el número de filas en la base de datos datos_lab_casos para observar la cantidad de casos sospechosos que fueron analizados.\n\nnrow(datos_lab_casos)\n\n[1] 858\n\n\nEste número es menor al de los casos sospechosos registrados en los datos depurados de vigilancia de enfermedades de notificación obligatoria (datos_notif), lo que sugiere que no todos los casos sospechosos en 2024 fueron analizados al momento en que estos datos estuvieron disponibles.\n\nnrow(datos_notif)\n\n[1] 987\n\n\n\n\n\n\n\n\n\n\nAhora que ambas linelists están depuradas y cuentan con una sola fila por caso sospechoso, es posible unirlos para habilitar el análisis completo solicitado por la jefatura.\n\n\n\n\nCrear un nuevo objeto denominado datos_unidos, utilizando una función xxx_join() de {dplyr}. Conservar todas las notificaciones y añadir los resultados de laboratorio cuando estén disponibles para cada caso sospechoso.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué función es la correcta si desea conservar todas las filas de sus datos de notificación e incorporar los resultados de sus datos de laboratorio?\n\n left_join(datos_notif, datos_lab_casos… full_join(datos_notif, datos_lab_casos… right_join(datos_notif, datos_lab_casos…\n\n¿Qué identificador debería usarse para enlazar las dos listas línea?\n\n id_muestra id_notificacion id_muestra y fecha_notificada id_notificacion y fecha_notificada\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡intente hacerlo primero!)\n\n\n\n\n\nUnir los datos utilizando la función left_join(), colocando los datos de notificación como la base de datos principal a la izquierda. Esto permitirá conservar todas las filas de dicha base de datos e incorporar únicamente los resultados de laboratorio provenientes de la base de datos especificado a la derecha de la función.\n\ndatos_unidos &lt;- left_join(datos_notif, datos_lab_casos, \n                         by = \"id_notificacion\")\n\nLa unión se realiza mediante la columna id_notificacion, la cual está presente, completa y depurada en ambas linelists.\nNota: En este caso resulta afortunado contar con un ejemplo tan sencillo de unión. Normalmente sería necesario depurar y verificar exhaustivamente la columna de identificadores, o bien realizar la unión a través de otras variables como el nombre y la fecha de nacimiento. En Feveria, el personal de las clínicas es excelente asignando de manera consistente los identificadores de notificación a cada paciente, incluso en los formularios de muestra enviados al laboratorio; a su vez, el personal de laboratorio es igualmente destacado registrando el identificador de notificación en sus sistemas, lo que permite que los resultados se unan adecuadamente con cada caso.\n\n\n\n\n\n\nAhora comprueba tus datos y revisa.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuántas filas hay en su nueva base de datos datos_unidos?\n\n 987 884 858\n\n¿Cómo se compara esto con sus datos originales de notificación?\n\n más filas que el original el mismo número de filas menos filas\n\n¿Qué término describe mejor la unión que acaba de realizar?\n\n muchos-a-uno uno-a-uno muchos-a-muchos\n\n¿Cuántos resultados de laboratorio NO se unieron (pista: usar anti_join())?\n\n 30 19 0\n\n¿Qué tan afortunado es de que su unión haya sido tan exitosa?\n\n ¿Qué? ¿Acaso no toda unión es así de simple?? ¡Muy afortunado! Usualmente algunos registros no coinciden\n\n¿Cuáles son las razones típicas por las que los datos de laboratorio no coinciden con los datos de enfermedades de notificación obligatoria?\n\n Hay errores tipográficos en las columnas usadas para la unión, por lo que no se reconocen como coincidentes Los datos de laboratorio pueden contener casos adicionales de otras clínicas o países Los datos de laboratorio pueden incluir muestras de prueba Las notificaciones pueden haberse omitido accidentalmente en los datos de vigilancia aunque la muestra haya sido analizada en el laboratorio Todas las anteriores\n\n¿Cuántos casos sospechosos no tienen un resultado?\n\n 83 100 129\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡intente hacerlo primero!)\n\n\n\n\n\nVerificar el número de filas en cada marco de datos con la función nrow(), o consultando la información del objeto en el Entorno. Se puede observar que esta fue simplemente una unión uno-a-uno, ya que cada fila tenía un id_notificacion único; por lo tanto, una fila en los datos de notificación se unió directamente con una fila en los datos de laboratorio.\nNúmero de filas en los datos de notificación\n\nnrow(datos_notif)\n\n[1] 987\n\n\nNúmero de filas en los datos enlazados\n\nnrow(datos_unidos)\n\n[1] 987\n\n\nPara comprobar si existió algún resultado de laboratorio que no se unirá con los datos de notificación, se puede utilizar anti_join(). En este caso, el objeto datos_lab_casos se coloca a la izquierda, ya que la función evalúa cuántas filas de la base de datos de la izquierda no se encuentran en la base de datos de la derecha, haciendo la coincidencia por id_notificacion.\nEn esta ocasión no es necesario generar una nueva base de datos; simplemente se puede encadenar con un nrow() para contar el número de filas. El resultado es 0, lo que demuestra que no hubo resultados no unidos, ¡excelente!\n\nanti_join(datos_lab_casos, datos_notif, \n          by = \"id_notificacion\") |&gt; nrow()\n\n[1] 0\n\n\nPor último, para comprobar el número de notificaciones sin resultado, puede realizar un anti_join en putting datos_notif primero:\n\nanti_join(datos_notif, datos_lab_casos, \n          by = \"id_notificacion\") |&gt; nrow()\n\n[1] 129\n\n\nO bien, puede simplemente tabular el número de valores que faltan en el columna valor en datos_unidos (como la columna valor procede de los datos del laboratorio).\n\ntabyl(is.na(datos_unidos$valor)) \n\n is.na(datos_unidos$valor)   n   percent\n                     FALSE 858 0.8693009\n                      TRUE 129 0.1306991\n\n\nAmbos enfoques muestran que 129 casos sospechosos no tienen un resultado de laboratorio.\n\n\n\n\n\n\n\n\n\nUtilizar mutate() para crear una nueva columna denominada categoria_casos, actualizando la categoría de los casos sospechosos de acuerdo con su resultado de laboratorio. Las categorías deben definirse de la siguiente manera:\n\nSi el resultado fue positivo: Confirmado\n\nSi el resultado fue negativo: Descartado\n\nSi el resultado fue indeterminado o faltante: Sospechoso\n\nEsto implica que todos los casos en los datos de notificación se consideran inicialmente sospechosos al momento de ser reportados, y permanecen como sospechosos si no existe un resultado de prueba concluyente.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuál es la función más apropiada para crear esta nueva columna?\n\n case_when() if_else() case_match()\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nDebe utilizar case_when() para crear la nueva columna. Esta función es ideal para aplicar múltiples condiciones lógicas para crear múltiples valores, mientras que case_match() es mejor para sustituir valores específicos, y if_else() es mejor si sólo hay dos valores posibles.\n\ndatos_unidos &lt;- datos_unidos |&gt; \n  mutate(categoria_casos = case_when(valor==\"Positivo\" ~ \"Confirmado\",\n                                   valor==\"Negativo\" ~ \"Descartado\",\n                                   valor==\"Indeterminado\" | is.na(valor) ~ \"Sospechoso\"))\n\n\n\n\n\n\n\n\n\n\nUtilizar tabyl() en general, y también la tabulación cruzada por enfermedad para responder a las siguientes preguntas.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuántos casos en los datos de notificación unidos no tenían un resultado positivo ni negativo?\n\n 202 347 250\n\n¿Qué porcentaje de casos en los datos de notificación SÍ tenían un resultado positivo o negativo?\n\n 60.1% 79.5% 92.2%\n\n¿Por qué hay más casos sospechosos restantes que notificaciones no enlazadas?\n\n Los casos sospechosos incluyen notificaciones sin resultado de laboratorio y con un resultado de laboratorio indeterminado Se están incorporando casos sospechosos adicionales desde el laboratorio Hay un problema con los datos\n\n¿Qué enfermedad tuvo el mayor porcentaje de casos que permanecieron como sospechosos después de la unión?\n\n Cólera Paludismo Dengue Fiebre amarilla\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡intente hacerlo primero!)\n\n\n\n\n\nUna vez más se puede utilizar tabyl() para observar la distribución de las categorías de casos en las notificaciones. El número total de casos sospechosos, es decir, aquellos sin resultado de laboratorio o con un resultado indeterminado, es de 202. Esto significa que 785 casos, es decir, el 79.5%, sí contaron con un resultado de laboratorio concluyente.\n\ntabyl(datos_unidos, categoria_casos) \n\n categoria_casos   n   percent\n      Confirmado 438 0.4437690\n      Descartado 347 0.3515704\n      Sospechoso 202 0.2046606\n\n\nTambién se puede realizar una tabla de contingencia entre los resultados originales (indeterminado/negativo/positivo) en la columna valor y la nueva columna categoria_casos, primero para comprobar que la lógica haya funcionado correctamente y, además, para visualizar cómo se asignaron los valores originales a las nuevas categorías. Esto muestra que, además de las 129 notificaciones que no fueron unidas (con NA en la columna valor), 73 tuvieron resultados indeterminados, por lo que fueron clasificadas como casos sospechosos.\n\ntabyl(datos_unidos, categoria_casos, valor) \n\n categoria_casos Indeterminado Negativo Positivo NA_\n      Confirmado             0        0      438   0\n      Descartado             0      347        0   0\n      Sospechoso            73        0        0 129\n\n\nFinalmente, también se puede realizar una tabla de contingencia con el nombre de la enfermedad para observar las categorías de caso por enfermedad. Es posible añadir funciones adicionales adorn_xxx() para aplicar un formato porcentual. La tabla muestra que el 22% de los casos de fiebre amarilla permanecieron como sospechosos, lo cual representó el porcentaje más alto en comparación con las demás enfermedades.\n\ntabyl(datos_unidos, enfermedad_notificada, categoria_casos) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n enfermedad_notificada  Confirmado  Descartado  Sospechoso        Total\n                colera 82.6%  (38)  4.3%   (2) 13.0%   (6) 100.0%  (46)\n                dengue 68.1% (186) 10.6%  (29) 21.2%  (58) 100.0% (273)\n       fiebre amarilla 33.0%  (33) 45.0%  (45) 22.0%  (22) 100.0% (100)\n       fiebre tifoidea 20.0%   (7) 68.6%  (24) 11.4%   (4) 100.0%  (35)\n             paludismo 32.6% (174) 46.3% (247) 21.0% (112) 100.0% (533)\n                 Total 44.4% (438) 35.2% (347) 20.5% (202) 100.0% (987)\n\n\n\n\n\n\n\n\nUtilice tabyl() para ello una vez más, observando los resultados por enfermedad. ¡Piense en el denominador correcto!\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué porcentaje de los casos sospechosos notificados en 2024 fueron casos verdaderos, según sus resultados de laboratorio?\n\n 44% 56% 59%\n\n¿Qué porcentaje de los casos sospechosos de paludismo fueron realmente paludismo?\n\n 86% 41% 23%\n\n¿Qué porcentaje de los casos sospechosos de dengue fueron realmente dengue?\n\n 87% 41% 23%\n\n\n\n\n\n\n\n\n\n\nHaga clic para leer una pista\n\n\n\n\n\nDividir el número de casos confirmados (es decir, aquellos con un resultado positivo) entre el número de casos confirmados más los descartados (es decir, aquellos con resultado positivo o negativo). Esto genera una tasa de positividad, que aproxima el porcentaje de casos sospechosos que realmente fueron casos. Los resultados indeterminados se excluyen porque no aportan un desenlace claro y distorsionarían la tasa de positividad.\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡intente hacerlo primero!)\n\n\n\n\n\nFiltrar los casos sospechosos y luego realizar una tabla de contingencia, para observar el porcentaje de casos inicialmente sospechosos que se convierten en confirmados o descartados, entre aquellos con resultados válidos.\nDado que existe una fila de totales, se puede ver que, en general, el 56% de los casos sospechosos terminaron confirmados, entre aquellos con resultado válido. También se observa que el 41% de los casos de paludismo y el 87% de los casos de dengue fueron confirmados.\n\ndatos_unidos |&gt; \n  filter(categoria_casos != \"Sospechoso\") |&gt; \n  tabyl(enfermedad_notificada, categoria_casos) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n enfermedad_notificada  Confirmado  Descartado        Total\n                colera 95.0%  (38)  5.0%   (2) 100.0%  (40)\n                dengue 86.5% (186) 13.5%  (29) 100.0% (215)\n       fiebre amarilla 42.3%  (33) 57.7%  (45) 100.0%  (78)\n       fiebre tifoidea 22.6%   (7) 77.4%  (24) 100.0%  (31)\n             paludismo 41.3% (174) 58.7% (247) 100.0% (421)\n                 Total 55.8% (438) 44.2% (347) 100.0% (785)\n\n\n\n\n\n\n\n\n\nTarea A: Crear una nueva linelist llamada datos_unidos_confirmados.\nEsto es lo que se utilizará en los informes oficiales de vigilancia.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Por qué estamos optando por reportar solo casos confirmados en nuestros datos de vigilancia?\n\n Reportar casos confirmados puede ser más confiable y preciso cuando el porcentaje de pruebas positivas es bajo y las pruebas de laboratorio son rutinarias, ayudando así a prevenir la sobreestimación de la carga de enfermedad Reportar casos confirmados es más lento, lo que nos da más tiempo para estar seguros de lo que estamos reportando Porque queremos ocultar el número real de casos\n\n¿Qué función es importante para crear la nueva lista de casos (linelist)?\n\n filter() arrange() mutate()\n\n¿Cuántas filas hay en esta nueva base de datos?\n\n 389 438 858\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡intente hacerlo primero!)\n\n\n\n\n\nLa unidad de vigilancia desea centrarse en los casos confirmados en los informes. Esto se debe a que las pruebas de laboratorio son de rutina en Feveria y, por lo tanto, informar los casos sospechosos sería innecesariamente inexacto, ya que un alto porcentaje de estos terminan siendo descartados.\nLa decisión de publicar casos sospechosos puede ser diferente en otros contextos. Por ejemplo, si la tasa de positividad es alta (la mayoría de los casos resultan ser verdaderos al realizar la prueba), y las pruebas no son frecuentes o tardan mucho en realizarse, lo que retrasaría la notificación, se recomendaría que las tendencias de casos sospechosos fueran suficientemente precisas y más oportunas que esperar la confirmación de laboratorio.\nCrear la nueva linelist con la función filter():\ndatos_unidos_confirmados &lt;- datos_unidos |&gt; \n  filter(categoria_casos==\"Confirmado\")\nY compruebe el número de filas consultando la información de su Entorno, o con nrow():\nnrow(datos_unidos_confirmados)\n[1] 438\n\n\n\n\n\n\n\nAhora que ya tiene la lista de casos confirmados de enfermedades de notificación obligatoria reportados en Feveria en 2024, está listo o lista para llevar a cabo la parte final de su análisis de vigilancia. Se trata de resumir las cinco enfermedades de notificación obligatoria por zonas geográficas y por épocas.\nSugerencia Normalmente, el análisis de vigilancia también incluye el análisis por persona. Podría ampliar este estudio de caso analizando también los casos por variables demográficas.\n\n\n\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué enfermedad de notificación obligatoria se reportó con mayor frecuencia en 2024, al restringirse solo a los casos confirmados?\n\n Dengue Paludismo Fiebre amarilla\n\n¿Por qué la enfermedad más reportada es diferente al comparar los casos confirmados con los sospechosos?\n\n La sensibilidad y especificidad del diagnóstico clínico pueden variar según la enfermedad El desempeño de las pruebas utilizadas en el laboratorio puede variar según la enfermedad Puede haber sesgos en la notificación ¡Todas las anteriores!\n\n¿Qué distrito reportó el mayor número de casos confirmados de cólera en 2024?\n\n Lago Minara Feveria Central Kasara\n\n¿Cuántos casos confirmados de cólera reportados en 2024 correspondieron a residentes de Feveria Central?\n\n 35 42 4\n\n¿Qué distrito reportó el mayor número de casos confirmados de paludismo en 2024?\n\n Lago Minara Feveria Central Kasara\n\n¿Confirman estos datos que el dengue es la enfermedad infecciosa más común en Feveria?\n\n No - otra enfermedad puede estar subnotificada o no ser de notificación obligatoria Sí - si es la más reportada entonces debe ser la más común\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡inténtelo usted primero!)\n\n\n\n\n\nUtilizando tabyl() podemos ver que el dengue fue la enfermedad más reportada en Feveria en 2024 cuando se restringe a casos confirmados, con 186 casos.\n\ndatos_unidos_confirmados |&gt; \n  tabyl(enfermedad_notificada) \n\n enfermedad_notificada   n    percent\n                colera  38 0.08675799\n                dengue 186 0.42465753\n       fiebre amarilla  33 0.07534247\n       fiebre tifoidea   7 0.01598174\n             paludismo 174 0.39726027\n\n\nNótese que esto es diferente a los casos sospechosos, ¡donde el paludismo fue la enfermedad más reportada (con 533 casos sospechosos)! Esto ya se insinuó anteriormente, cuando observamos que la tasa de positividad de los casos sospechosos de dengue era mayor que la de los casos sospechosos de paludismo. Esto puede deberse a diferentes razones, por ejemplo, el método de diagnóstico clínico utilizado para el paludismo puede ser menos específico (lo que podría significar que muchos de los casos sospechosos en realidad se deban a otras enfermedades), o bien la prueba utilizada para el dengue puede ser más sensible.\nPara realizar una tabulación cruzada con el distrito residencial, añada las funciones adorn_xxx().\n\ndatos_unidos_confirmados |&gt; \n  tabyl(enfermedad_notificada, distrito_residencial) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n enfermedad_notificada Feveria Central     Kasara Lago Minara        Total\n                colera      92.1% (35)  7.9%  (3)  0.0%   (0) 100.0%  (38)\n                dengue       8.6% (16) 17.2% (32) 74.2% (138) 100.0% (186)\n       fiebre amarilla       0.0%  (0) 18.2%  (6) 81.8%  (27) 100.0%  (33)\n       fiebre tifoidea      71.4%  (5) 28.6%  (2)  0.0%   (0) 100.0%   (7)\n             paludismo      14.9% (26) 22.4% (39) 62.6% (109) 100.0% (174)\n                 Total      18.7% (82) 18.7% (82) 62.6% (274) 100.0% (438)\n\n\nAl igual que con los casos sospechosos, podemos ver que la mayoría de los casos confirmados de dengue, paludismo y fiebre amarilla se localizaron en el Lago Minara, la zona lacustre con mayor densidad de mosquitos y, por lo tanto, de enfermedades transmitidas por vectores. La mayoría de los casos confirmados de cólera y fiebre tifoidea se observaron en Feveria Central, donde hay problemas de agua y saneamiento.\nLos datos sugieren que las enfermedades transmitidas por vectores (dengue y paludismo) son especialmente preocupantes en este país tropical. Sin embargo, no sabemos con certeza cuál es la enfermedad más común ni cuáles son los patrones subyacentes: sólo cinco enfermedades son de notificación obligatoria, y normalmente los casos notificados sólo representan una fracción de los casos reales en la comunidad.\n\n\n\n\n\n\n\nProducirá esta curva epidémica en las siguientes tareas distintas.\n\n\n\n\n\n\n\n\n\n\n\nAsegúrese de especificar el argumento binwidth=7 para que cada barra del histograma represente el número de casos en un periodo de 7 días.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuándo se reportó el primer caso de fiebre tifoidea en Feveria en 2024?\n\n Enero 2024 Mayo 2024 Octubre 2024\n\nSegún este gráfico, ¿cuál fue el mayor número de casos de dengue reportados en una sola semana en 2024?\n\n 10 20 30 ¡Es muy difícil saberlo según este gráfico apilado!\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡inténtelo usted primero!)\n\n\n\n\n\nEste es un código sencillo para producir la curva epidémica. Tenga en cuenta que aún no especificamos los colores ni en qué día de la semana comienza cada período de 7 días.\n\ndatos_unidos_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = fecha_notificada, fill = enfermedad_notificada)), binwidth=7)\n\n\n\n\n\n\n\n\nConsulte el capítulo de Trabajando con Fechas en el Manual de R para Epis si desea un formato de fecha más específico o que el eje x indique el número de semana (semanas 1 a 52).\nImportante: ¡no es fácil ver las tendencias por enfermedad cuando se grafican apiladas de esta forma! Para visualizar estas tendencias temporales, debe producir un histograma para cada enfermedad.\n\n\n\n\n\n\nUtilice facet_wrap() para crear fácilmente pequeños gráficos multiples, uno por enfermedad. Para entender mejor la función, puede consultar la página Facetas del capítulo sobre ggplot2 en el Manual de R para Epis.\n\n\n\n\n\n\nPreguntas\n\n\n\n\nSegún este gráfico facetado, ¿cuál fue el mayor número de casos notificados de dengue en una sola semana en 2024?\n\n 11 15 29 ¡Todavía no lo puedo determinar!\n\n¿En qué distritos residían los casos de dengue notificados en esa semana?\n\n Los tres distritos Feveria Central Kasara Lago Minara Este gráfico no muestra esa información\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡inténtelo usted primero!)\n\n\n\n\n\nAhora puede ver una curva epidémica por enfermedad. Y puede ver que durante una semana de julio se notificaron 15 casos de dengue. Sin embargo, este gráfico aún no muestra ninguna información geográfica.\n\ndatos_unidos_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = fecha_notificada)), binwidth=7) + \n  facet_wrap(.~enfermedad_notificada)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿En qué distrito residían los 15 casos de dengue notificados en una semana de julio de 2024?\n\n Los tres distritos Feveria Central Kasara Lago Minara\n\n¿En qué distrito se notificó el primer caso de fiebre tifoidea en 2024?\n\n Kasara Feveria Central Lago Minara ¡Todavía no lo puedo determinar!\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡inténtelo usted primero!)\n\n\n\n\n\nAhora puede ver una curva epidémica por enfermedad, con la coloración que refleja el distrito en el que reside el caso.\nSe puede ver que los 15 casos notificados de dengue en una sola semana vivían en tres distritos diferentes. También puede ver que el primer caso de fiebre tifoidea se registró en Feveria Central.\n\ndatos_unidos_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = fecha_notificada, fill = distrito_residencial)), binwidth=7) + \n  facet_wrap(.~enfermedad_notificada)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPuede especificar:\n\nEl tema o diseño predeterminado del gráfico general (por ejemplo, color de fondo, aspecto de las líneas de la cuadrícula)\nEl título y las etiquetas\nLos colores de las barras (con scale_fill_manual())\nEl formato y espaciado de las fechas a lo largo del eje x (con scale_x_date)\n¡Muchas otras cosas!\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿El cólera y la fiebre tifoidea parecen endémicas?\n\n No - los datos sugieren brotes pequeños y ocasionales Sí los dos son endémicos\n\n¿Hubo un periodo particular del año en que el paludismo alcanzó su pico en 2024?\n\n Sí - alrededor de noviembre/diciembre Sí - alrededor de julio/agosto (verano) No, se mantuvo constantemente alto\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡inténtelo usted primero!)\n\n\n\n\n\nAquí está el código completo. Puede ver que este ejemplo contiene modificaciones adicionales. Por un lado, dentro de facet_wrap() se ha especificado que el panel tenga dos columnas. Por el otro, dentro de scale_x_date() se ha especificado que se muestre solo el día y el mes en el eje x.\n\ndatos_unidos_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = fecha_notificada, fill = distrito_residencial)), binwidth=7) +\n  facet_wrap(.~enfermedad_notificada, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"Distrito residencial\",\n       x = \"Fecha notificada por el centro de salud\",\n       y = \"Recuento\",\n       subtitle = \"Número de casos confirmados de cólera, dengue, paludismo, fiebre tifoidea, y fiebre amarilla por semana en Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n\n\n\n\n\n\nTambién podemos observar en la curva epidémica que el cólera y la fiebre tifoidea parecen presentarse como brotes aislados, en lugar de mostrar endemicidad. El paludismo y el dengue, sin embargo, estuvieron presentes en Feveria durante todo el año, con un pico de paludismo más evidente en los meses de verano.\n\n\n\n\n\n\nEsta vez, utilice group_by() y summarize() para producir una tabla por distrito que muestre las fechas más tempranas y más tardías de las notificaciones.\nPuede ajustar la tabla con filter() para crearla para un distrito a la vez.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuándo se notificó el primer caso de dengue en Feveria en 2024?\n\n 18 de enero 2024 17 de enero 2024 12 de febrero 2024\n\n¿Cuándo se notificó el último caso de dengue en Feveria Central en 2024?\n\n 22 de agosto 2024 18 de noviembre 2024 25 de diciembre 2024\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡inténtelo usted primero!)\n\n\n\n\n\nAgrupe los datos por enfermedad y luego extraiga la primera y la última fecha para ver la cronología general de cada enfermedad en Feveria.\n\ndatos_unidos_confirmados |&gt; \n  group_by(enfermedad_notificada) |&gt; \n  summarize(primer_reporte = min(fecha_notificada), \n            ultimo_reporte = max(fecha_notificada)) |&gt;\n  ungroup()\n\n# A tibble: 5 × 3\n  enfermedad_notificada primer_reporte ultimo_reporte\n  &lt;chr&gt;                 &lt;date&gt;         &lt;date&gt;        \n1 colera                2024-06-03     2024-09-23    \n2 dengue                2024-01-17     2024-11-18    \n3 fiebre amarilla       2024-03-08     2024-08-23    \n4 fiebre tifoidea       2024-05-02     2024-11-07    \n5 paludismo             2024-01-08     2024-12-25    \n\n\nAñada filter() al código para obtener las fechas de “Feveria Central”.\n\ndatos_unidos_confirmados |&gt; \n  filter(distrito_residencial == \"Feveria Central\") |&gt; \n  group_by(enfermedad_notificada) |&gt; \n  summarize(primer_reporte = min(fecha_notificada), \n            recent_reported = max(fecha_notificada)) |&gt;\n  ungroup()\n\n# A tibble: 4 × 3\n  enfermedad_notificada primer_reporte recent_reported\n  &lt;chr&gt;                 &lt;date&gt;         &lt;date&gt;         \n1 colera                2024-06-03     2024-09-23     \n2 dengue                2024-01-29     2024-08-22     \n3 fiebre tifoidea       2024-05-02     2024-11-07     \n4 paludismo             2024-01-29     2024-12-17     \n\n\n\n\n\n\n\n\n\n\n¡Vaya! De acuerdo con los objetivos de este estudio de caso, usted ha hecho lo siguiente:\n\nHa utilizado funciones clave de R para limpiar, procesar y unir bases de datos, además de crear nuevas columnas utilizando condiciones lógicas.\nPara tomar decisiones sobre el procesamiento de datos, ha realizado inspecciones y comprobaciones de los datos.\nRealizó un análisis descriptivo exhaustivo para comprender las notificaciones y los datos de laboratorio, antes y después de unirlos. En relación a las cuatro preguntas originales de su supervisor, puede decir:\n\n¿Cuántos casos sospechosos de las diferentes enfermedades de notificación obligatoria se reportaron en 2024, y cuál fue la más frecuente? Según los registros del sistema de vigilancia de enfermedades de notificación obligatoria, el paludismo fue la enfermedad más común en Feveria en 2024: 533 casos sospechosos de paludismo, 273 casos sospechosos de dengue, 100 de fiebre amarilla, 46 de cólera y 35 de fiebre tifoidea.\n¿Qué porcentaje de ellos acabo confirmándose? Casi el 80% de los casos de notificación obligatoria reportados en 2024 tenían un resultado de pruebas de laboratorio en el momento en que se creó la base de datos, con algunas variaciones según la enfermedad. En total, el 56% de los casos notificados acabaron confirmándose, pero este porcentaje osciló entre sólo el 23% en el caso de la fiebre tifoidea (7 casos confirmados de 31 sospechosos) y el 95% en el caso del cólera (38 casos confirmados de 40 sospechosos). Además, la tasa de positividad fue mayor en los casos sospechosos de dengue que en los de paludismo (87% frente a 41%).\n¿Cuántos casos confirmados de las diferentes enfermedades de notificación obligatoria se reportaron en 2024, y cuál fue la más frecuente? Los casos confirmados siguieron una tendencia ligeramente diferente a la de los casos sospechosos: la infección notificada con más frecuencia fue el dengue, con 186 casos, seguido por el paludismo (174), el cólera (38), la fiebre amarilla (33) y la fiebre tifoidea (7).\n¿Cómo se distribuyeron geográfica y temporalmente los casos confirmados en Feveria? Feveria experimentó transmisión de dengue y paludismo durante todo el año, con un pico en verano, y se concentró en el distrito de Lago Minara. También se registraron brotes pequeños y poco frecuentes de enfermedades diarreicas, como el cólera y la fiebre tifoidea, sobre todo en la zona urbana de Feveria Central, donde podrían existir problemas de agua y saneamiento.\n\nPor último, ha reflexionado sobre cómo la calidad y exhaustividad de los datos están determinados por procesos inherentes a la transferencia de los mismos entre los sistemas de vigilancia y los laboratorios.\n\nTiene un gran potencial por delante. Puede utilizar datos de vigilancia para explorar patrones por edad o sexo, calcular tasas con datos poblacionales e incluso analizar retrasos en la notificación al comparar las diferentes fechas en su base de datos.\nHa construido una base sólida y tiene las herramientas óptimas para llevar su análisis al siguiente nivel. Siga adelante: ¡le esperan descubrimientos emocionantes!\nPara profundizar, consulte los demás estudios de casos o explore el Manual de R para Epis.\n\n\n\nA continuación encontrará un script con todos los pasos para la limpieza de datos y el análisis descriptivo. Observe cómo los análisis se incluyen al final, en vez de intercalarse entre los pasos de limpieza. Esta es una forma más ordenada de organizar el script.\nPor motivos de brevedad, el código que aparece a continuación no incluye todas las inspecciones y comprobaciones realizadas durante el proceso, pero si desea puede crear una sección con dichas comprobaciones.\nLa parte superior de su script también debería contener información para ayudar al lector a entender cuál es el propósito del script, así como comentarios a lo largo del mismo. Más adelante se agradecerá haber añadido estos comentarios.\n\n\n\n\n\n\nCódigo para limpiar y analizar los datos de notificación y los datos de laboratorio de Feveria, 2024\n\n\n\n\n\n\n# Código para limpiar y analizar los datos de notificación y de laboratorio de Feveria, 2024\n# Fecha:\n# Elaborado por:\n\n# Instalar paquetes -------------------------------------------------\n# Asegurarse que el paquete \"pacman\" está instalado\nif (!require(\"pacman\")) {\n  install.packages(\"pacman\") }\n\n# Instalar (si es necesario) desde CRAN y cargar los paquetes necesarios\npacman::p_load(\n  rio,        # para importar datos  \n  skimr,      # para revisar los datos\n  janitor,    # para limpieza de datos y crear tablas \n  lubridate,  # para limpieza de fechas\n  epikit,     # para crear grupos de edad \n  gtsummary,  # para generar resúmenes estadísticos, pruebas y regresiones\n  apyramid,   # para graficar pirámides de edad  \n  flextable,  # para crear tablas listas para presentar \n  naniar,     # para evaluar los datos faltantes\n  remotes,    # para instalar paquetes necesarios para descargar datos \n  tidyverse   # para gestión y visualización de datos \n)\n\n# Importar datos --------------------------------------------\n\n# Datos de notificación \ndatos_notif_crudos &lt;- import(\"datos/notificaciones_multienfermedad.xlsx\")\n\n# Datos de laboratorio\ndatos_lab_crudos &lt;- import(\"datos/pruebas_multienfermedad.csv\")\n\n# Limpiar datos de notificación --------------------------------\ndatos_notif &lt;- datos_notif_crudos |&gt; \n  clean_names() |&gt; names()\n  rename(\n    fecha_notificada = fecha_notificada_por_el_centro_de_salud_la_comunidad,\n    id_notificacion = id_de_notificacion) |&gt;\n  select(id_notificacion, distrito_residencial, enfermedad_notificada, fecha_notificada) |&gt; \n  mutate(distrito_residencial = case_match(\n    str_to_title(distrito_residencial),\n    c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n    c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n    c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\")) |&gt; \n  mutate(fecha_notificada = ymd(fecha_notificada)) \n\n\n# Limpiar datos de laboratorio ---------------------------------\n# Limpiar los valores\ndatos_lab &lt;- datos_lab_crudos |&gt; \n  mutate(valor = case_match(valor, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positivo\",\n                            \"N\" ~ \"Negativo\",\n                            \"I\" ~ \"Indeterminado\"))\n\n# Crear datos de laboratorio a nivel de prueba \ndatos_lab_pruebas &lt;- datos_lab |&gt; \n  filter(objetivo != \"Dengue IgG\") |&gt; \n  group_by(id_muestra) |&gt; \n  arrange(desc(valor)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Crear datos de laboratorio a nivel de caso\ndatos_lab_casos &lt;- datos_lab_pruebas |&gt; \n  group_by(id_notificacion) |&gt; \n  arrange(desc(valor)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Unir datos de notificación y de laboratorio  ----------------------------\ndatos_unidos &lt;- left_join(datos_notif, datos_lab_casos, by = \"id_notificacion\")\n\n# Limpiar base de datos unificada -----------------------------------------\ndatos_unidos &lt;- datos_unidos |&gt; \n  mutate(categoria_casos = case_when(\n    valor==\"Positivo\" ~ \"Confirmado\",\n    valor==\"Negativo\" ~ \"Descartado\",\n    valor==\"Indeterminado\" | is.na(valor) ~ \"Sospechoso\"))\n\ndatos_unidos_confirmados &lt;- datos_unidos |&gt; \n  filter(categoria_casos==\"Confirmado\")\n\n# ANÁLISIS ---------------------------------------------------------\n# Número de casos sospechosos en Feveria \ntabyl(datos_notif, enfermedad_notificada)\n\n# Distribución de casos sospechosos por distrito \ntabyl(datos_notif, enfermedad_notificada, distrito_residencial) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n# Distribución de los resultados por prueba especifíca de cada enfermedad \ntabyl(datos_lab_pruebas, prueba, valor) |&gt; \n  adorn_totals(where = \"col\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n# Distribución de la categoria de caso, en la base de datos unificada \ntabyl(datos_unidos, categoria_casos) \n\n# Distribución de la categoria de caso por enfermedad, en la base de datos unificada\ntabyl(datos_unidos, enfermedad_notificada, categoria_casos) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n# Distribución de la categoria de caso por enfermedad, en la base de datos unificada: \n# solo casos con un resultado válido\ndatos_unidos |&gt; \n  filter(categoria_casos != \"Sospechoso\") |&gt; \n  tabyl(enfermedad_notificada, categoria_casos) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n# Distribución de casos confirmados por distrito \ndatos_unidos_confirmados |&gt; \n  tabyl(enfermedad_notificada, distrito_residencial) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n# Visualizar casos confirmados a lo largo del tiempo \ndatos_unidos_confirmados |&gt; \n  ggplot() +\n  geom_histogram(\n    aes(x = fecha_notificada, fill = distrito_residencial), \n    binwidth=7\n  ) +\n  facet_wrap(.~enfermedad_notificada, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"Distrito residencial\",\n       x = \"Fecha notificada por el centro de salud\",\n       y = \"Recuento\",\n       subtitle = \"Número de casos confirmados de cólera, dengue, paludismo, fiebre tifoidea, y fiebre amarilla por semana en Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n# Primera y última fecha de notificación por enfermedad \ndatos_unidos_confirmados |&gt; \n  group_by(enfermedad_notificada) |&gt; \n  summarize(primer_reporte = min(fecha_notificada), \n            ultimo_reporte = max(fecha_notificada)) |&gt;\n  ungroup()\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutores originales Paula Blomquist y Alanah Jansen, con el apoyo técnico de la Subdivisión de Vigilancia Mundial, Laboratorios y Sistemas de Datos de los CDC, en colaboración con TEPHINET.\nFuente de datos Datos ficticios proporcionados por Applied Epi.\n\n\n\n\n\n\n\n\n\n\n\n\nFecha\nCambios realizados\nVersión\nAutor\n\n\n\n\nJulio 2025\nPrimer borrador\n1\nPaula Blomquist y Alanah Jansen, Applied Epi, con el apoyo técnico de la Subdivisión de Vigilancia Mundial, Laboratorios y Sistemas de Datos de los CDC, en colaboración con TEPHINET.\n\n\nAgosto 2025\nVersión en español\n1\nLuis Quezada, Martin Lotto y Shazia Ruybal\n\n\n\n\n\n\nDescargo de responsabilidad La información presentada en este ejercicio y los archivos de datos asociados se han elaborado para ayudar al alumnado a alcanzar los objetivos de aprendizaje previstos. El contenido es responsabilidad de los autores y no refleja necesariamente la opinión oficial de los CDC, del Departamento de Salud y Servicios Humanos de EE. UU. o de TEPHINET.\nLicencia: Este estudio de caso está bajo una licencia CC BY-NC-SA 4.0. Para obtener más información sobre cómo compartir y adaptar este estudio de caso, consulte la página escritura asociada.\nFinanciación Este estudio de caso fue financiado al 100% por el Acuerdo de Cooperación número NU2HGH000044 financiado por los Centros para el Control y la Prevención de Enfermedades (CDC) de EE.UU."
  },
  {
    "objectID": "pages/multidisease_surveillance.es.html#escenario",
    "href": "pages/multidisease_surveillance.es.html#escenario",
    "title": "Vinculación y análisis de datos de notificación y datos de laboratorio en R",
    "section": "",
    "text": "Usted es epidemiologo o epidemióloga en la oficina nacional de vigilancia de Feveria, un pequeño país tropical compuesto por tres distritos:\n\nFeveria Central: zona urbana densamente poblada, con infraestructuras de agua y saneamiento a veces poco fiables.\nLago Minara: zona lacustre con buena infraestructura, pero con gran abundancia de mosquitos durante los meses más cálidos del año.\nKasara: zona suburbana situada al otro lado de Feveria Central.\n\nMapa de los distritos de Feveria\n\nEs enero 2025, y su supervisor quiere que transfiera la rutina de procesamiento de enfermedades de declaración obligatoria de Excel a R, y que realice algunos análisis de datos. Como mínimo, quiere saber:\n\n¿Cuántos casos sospechosos de las diferentes enfermedades de declaración obligatoria se notificaron en 2024, y cuál fue la más frecuente?\n¿Qué porcentaje de ellos fue confirmado?\n¿Cuántos casos confirmados de las diferentes enfermedades de declaración obligatoria se notificaron en 2024, y cuál fue la más frecuente?\n¿Cómo se distribuyeron geográfica y temporalmente los casos confirmados en Feveria?\n\nSu supervisor le pide que escriba código para importar, limpiar, combinar y analizar las siguientes listas:\n\nDatos de vigilancia de enfermedades de declaración obligatoria de 2024: también denominados “datos de notificación”, se trata de datos de vigilancia sobre cinco enfermedades de declaración obligatoria notificadas por las clínicas de Feveria: dengue, paludismo, cólera, fiebre tifoidea y fiebre amarilla. Estos corresponden a casos sospechosos, basados en los síntomas de los pacientes. Los clínicos introducen cada notificación en un sistema en línea todos los días de la semana.\nDatos de resultados de pruebas de laboratorio de 2024: procedentes de tres grandes laboratorios de Feveria. Estos resultados corresponden a muestras tomadas de los casos sospechosos de las enfermedades de declaración obligatoria mencionadas anteriormente.\n\n¡Vamos!"
  },
  {
    "objectID": "pages/multidisease_surveillance.es.html#objetivos",
    "href": "pages/multidisease_surveillance.es.html#objetivos",
    "title": "Vinculación y análisis de datos de notificación y datos de laboratorio en R",
    "section": "",
    "text": "En este caso práctico deberá:\n\nUtilizar funciones clave de R para limpiar datos, remodelar bases de datos, combinar fuentes de datos y crear nuevas columnas mediante condiciones lógicas, con el fin de preparar los datos para el análisis.\nRealizar inspecciones de datos y comprobaciones de calidad en diferentes fases del proyecto, comprendiendo su importancia para garantizar un análisis fiable.\nLlevar a cabo análisis descriptivos básicos para comparar las tendencias de las enfermedades entre distintas fuentes de datos, tanto antes como después de la vinculación.\nInterpretar las diferencias en los resultados de las distintas fuentes de datos y comprender cómo éstas reflejan la estructura y el diseño del sistema de vigilancia."
  },
  {
    "objectID": "pages/multidisease_surveillance.es.html#etapa-1.-instalación",
    "href": "pages/multidisease_surveillance.es.html#etapa-1.-instalación",
    "title": "Vinculación y análisis de datos de notificación y datos de laboratorio en R",
    "section": "",
    "text": "Empiece por establecer un flujo de trabajo reproducible y bien organizado. Esto le facilitará repetir el análisis siempre que sea necesario.\nTareas:\n\nConfigurar un proyecto en RStudio.\nEstablecer subcarpetas claras para su código, datos y resultados.\nCrear un script en R, o un archivo R Markdown si lo prefiere. Asegúrese de que el propósito del script, la fecha y el autor figuren como comentarios en la parte superior del archivo.\nExtra: compruebe que el idioma de trabajo en RStudio sea el adecuado (por ejemplo, español para este ejercicio).\n\n\n\n\n\n\n\nHaga clic para leer una pista\n\n\n\n\n\n\nCree una carpeta donde fuardará todo el trabajo de este caso práctico. Por ejemplo, puede llamarla ‘multienfermedad_lab’ y crearla en el escritorio de su ordenador. En esta carpeta debe crear su proyecto de RStudio.\nLe sugerimos crear las siguientes subcarpeta: scripts (para su código), datos (para sus datos), y resultados (para sus resultados analíticos).\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nCree una carpeta (por ejemplo: ‘multienfermedad_lab’ en su escritorio) para su trabajo. Para crear un proyecto de Rstudio en su nueva carpeta, haga clic en la esquina superior izquierda de R Studio y seleccione la opción New Project..., luego seleccione Existing Directory y, a continuación, en Browse para seleccionar su nueva carpeta. Para obtener más información, consulte la sección proyectos en R del Manual de R para Epis.\nInicie un nuevo script de R haciendo clic en New File en la parte superior izquierda de RStudio y, a continuación, seleccione R Script. Guárdelo de inmediato en la ubicación apropiada, por ejemplo, en la subcarpeta scripts de su proyecto.\nEn la parte superior de su nuevo script de R, escriba información esencial como su nombre, el propósito del archivo y la fecha.\nTenga en cuenta que su configuración regional en R determina el idioma y la localización que se utilizarán para aspectos como los formatos de fecha o las traducciones. Si su configuración regional es distinta del idioma que desea para su informe (por ejemplo, configuración regional en español frente a un informe en inglés), puede cambiarla al inglés ejecutando: Sys.setlocale(\"LC_ALL\", \"English\").\nIncluya esta línea en su script si fuera necesario, o bien omítala si su configuración regional ya es la adecuada. Esto se explica con más detalle en la Guía práctica.\n\n\n\n\n\n\nA continuación, en su script de R, debe instalar y cargar los paquetes necesarios. Esto garantiza que las funciones que necesita estén disponibles para realizar su análisis.\nNecesitará los siguientes paquetes:\n{rio} (para importar datos) {skimr} (para revisar datos) {janitor} (para limpiar datos) {lubridate} (para la gestión de fechas y tiempos) {epikit} (para tareas relacionadas con epidemiología) {gtsummary} (para estadísticas descriptivas, pruebas y regresión) {apyramid} (para pirámides de edad y sexo) {flextable} (para generar tablas listas para su presentación) {naniar} (para evaluar datos faltantes) {tidyverse} (para tareas generales de manipulación y análisis de datos)\nAdemás, necesitará {remotes} para descargar datos, algo que se explicará en la sección correspondiente a descargas.\nMientras empieza, su colega de confianza le da un codazo y le susurra: “He oído que una forma estupenda de gestionar sus paquetes… es con el paquete {pacman}”.\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nUtilice la función p_load() del paquete {pacman} para esta tarea. Es suficiente con proporcionarle una lista de los paquetes que desee utilizar. La función realiza dos pasos por cada paquete:\n\nComprueba si el paquete está instalado en su ordenador y, si no lo está, lo instala automáticamente.\nCarga el paquete para que pueda usarse durante la sesión de R.\n\nSi aún no tiene instalado {pacman}, deberá hacerlo a la manera tradicional, con install.packages().\nTenga en cuenta que el orden de los paquetes en p_load() puede ser importante. Si dos paquetes contienen funciones con el mismo nombre (por ejemplo, select() en {MASS} y select() en {tidyverse}), R utilizará la versión del paquete cargado más recientemente. Por ello, se recomienda cargar {tidyverse} en último lugar para priorizar sus funciones, muy utilizadas en la manipulación y visualización de datos.\n\n# Asegurarse de que el paquete \"pacman\" está instalado\nif (!require(\"pacman\")) { install.packages(\"pacman\") }\n\n# Instalar (si es necesario) desde CRAN y cargar los paquetes a utilizar\npacman::p_load(\n  rio,        # importar datos  \n  skimr,      # revisar datos de forma rápida\n  janitor,    # limpieza de datos y tablas\n  lubridate,  # manejo de fechas\n  epikit,     # crear categorías de edad\n  gtsummary,  # estadísticas descriptivas, pruebas y regresión \n  apyramid,   # crear pirámides de edad y sexo \n  flextable,  # tablas listas para presentación\n  naniar,     # explorar datos faltantes\n  remotes,    # instalar paquetes para descarga de datos\n  tidyverse   # manipulación y visualización de datos (último, para priorizar sus funciones)\n)"
  },
  {
    "objectID": "pages/multidisease_surveillance.es.html#paso-2.-descargar-e-importar-los-datos",
    "href": "pages/multidisease_surveillance.es.html#paso-2.-descargar-e-importar-los-datos",
    "title": "Vinculación y análisis de datos de notificación y datos de laboratorio en R",
    "section": "",
    "text": "Su oficina le proporciona dos archivos para su análisis, ambos correspondientes al año 2024 y actualizados al 15 de enero de 2025:\n\nUna base de datos de notificación de enfermedades (“notificaciones_multienfermedad.xlsx”) con los casos procedentes de 5 centros de salud.\nUna base de datos de pruebas de laboratorio (“pruebas_multienfermedad.csv”) enviada por tres laboratorios que realizan pruebas para los mismos 5 centros de salud.\n\nPara este estudio de caso, puede descargar los datos desde la página web de Applied Epi mediante el paquete {appliedepidata}. Siga estos pasos:\n\nInstale el paquete {appliedepidata} desde GitHub utilizando el comando install_github() del paquete {remotes} (que ya instaló anteriormente):\n\n\n# Usar la función install_github de remotes para instalar {appliedepidata}\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nGuarde las dos bases de datos en una carpeta específica utilizando la función save_data() del paquete {appliedepidata}. Este código guardará los archivos en la subcarpeta datos dentro de la carpeta de su proyecto en RStudio. Tenga en cuenta que, si no especifica ninguna ubicación en el argumento path, aparecerá una ventana para que seleccione manualmente la carpeta.\n\n\n# Guardar los dos archivos de datos usando la función save_data() de appliedepidata\nappliedepidata::save_data(\"pruebas_multienfermedad\",\n                          path = \"datos\")\n\nappliedepidata::save_data(\"notificaciones_multienfermedad\",\n                          path = \"datos\")\n\n\n\n\n¡Gracias a la oficina nacional y a Applied Epi! Ahora es el momento de importar los datos desde la carpeta a RStudio, para poder analizarlos.\n\n\nLo ideal es que utilice la misma función para importar ambas bases de datos al Entorno, aunque uno sea un archivo .csv y el otro un .xlsx. A partir de ahora, cuando hablemos de Entorno, nos referiremos al panel Environment (Entorno en español) de RStudio.\n\n\n\n\n\n\nHaga clic para leer una pista\n\n\n\n\n\nUtilice la función import() del paquete {rio}, que reconoce e importa distintos tipos de archivos. De esta manera no tendrá que usar funciones específicas según el formato, como read.csv() de {base} para archivos .csv o read_excel() de {readxl} para archivos .xlsx.\nSi quiere más información sobre la importanción de datos, puede consultar la sección Importar y exportar de nuestro manual de R.\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nA continuación se muestra cómo importar los dos archivos utilizando la función import(). Los datos se guardan en dos objetos:\n\ndata_notif_crudos para los datos de notificaciones,\ndata_lab_crudos para los datos de laboratorio.\n\nEl sufijo *_crudos* le servirá para distinguirlos de las versiones depuradas que creará más adelante.\n\n# Importar datos\n\n# Datos de notificación\ndatos_notif_crudos &lt;- import(\"datos/notificaciones_multienfermedad.xlsx\")\n\n# Datos de laboratorio\ndatos_lab_crudos &lt;- import(\"datos/pruebas_multienfermedad.csv\")"
  },
  {
    "objectID": "pages/multidisease_surveillance.es.html#paso-3.-inspeccionar-los-datos",
    "href": "pages/multidisease_surveillance.es.html#paso-3.-inspeccionar-los-datos",
    "title": "Vinculación y análisis de datos de notificación y datos de laboratorio en R",
    "section": "",
    "text": "Ya tiene los datos, y ahora es el momento de ver qué historia cuentan. Tómese un momento para comprobar su contenido y su calidad.\n\n\n\n\nUtilice las siguients funciones para explorar sus datos: skim() del paquete {skimr}, names(), col() y nrow().\nskim() le proporciona información muy completa sobre la estructura y el contenido de los datos. names() le mostrará los nombres de las columnas. ncol() y nrow() cuentan, respectivamente, el número de columnas y de filas de su base de datos.\nPiense: ¿qué debe poner dentro de los paréntesis de cada función?\nLas pista más sencilla está en su Entorno. Recuerde que el objeto que contiene los datos de notificación se llama: datos_notif_crudos.\nSi necesita ayuda, haga click en el cuadro de soluciones situado debajo de las preguntas.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuántas columnas hay en los datos de notificación?\n\n 10 11 12 13\n\n¿Cuál de estas columnas NO aparece en los datos?\n\n Fecha de inicio Fecha notificada por el centro de salud/la comunidad Fecha del resultado Fecha de la prueba Fecha de nacimiento\n\n¿Cuál es el nombre de la columna en los datos de notificación que identifica cada notificación?\n\n ID de notificacion ID prueba Codigo del centro de salud Combinación de ID de notificacion y Sexo\n\n¿Cuántas filas hay en los datos de notificación?\n\n 987 1314 950 778\n\n¿Qué tipo de información NO se encuentra en los datos de notificación?\n\n Resultados de pruebas de laboratorio Distrito de residencia Fecha de nacimiento y sexo Centro de salud donde se diagnosticó el caso Resultado\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nUtilice skim() del paquete {skimr} para ver un resumen de toda la base de datos, y View() para visualizar directamente los datos completos:\n\nskim(datos_notif_crudos)\n\nTambién puede emplear names() para imprimir únicamente los nombres de las columnas. Tanto con skim() como con names() podrá observar los tipos de información incluidos: el centro sanitario del caso, la fecha de nacimiento, el sexo, un indicador de embarazo, el distrito de residencia, la fecha de inicio de síntomas y la fecha notificada por la clínica, así como información sobre el desenlace.\nAdemás, encontrará una columna ID de notificacion que parece ser un identificador único para cada caso, aunque conviene comprobar posibles duplicados antes de confirmarlo.\nTenga en cuenta que en estos datos no hay resultados de laboratorio, ya que las notificaciones proceden de las clínicas, que notifican enfermedades de declaración obligatoria en base a criterios clínicos.\n\nnames(datos_notif_crudos)\n\n [1] \"Nombre de la unidad organizativa\"                    \n [2] \"Codigo del centro de salud\"                          \n [3] \"ID de notificacion\"                                  \n [4] \"Fecha de nacimiento\"                                 \n [5] \"Sexo\"                                                \n [6] \"Embarazada\"                                          \n [7] \"Distrito residencial\"                                \n [8] \"Enfermedad notificada\"                               \n [9] \"Fecha de inicio\"                                     \n[10] \"Fecha notificada por el centro de salud/la comunidad\"\n[11] \"Resultado\"                                           \n[12] \"Fecha del resultado\"                                 \n\n\nPara obtener el número de columnas y de filas puede utilizar:\n\nncol(datos_notif_crudos)\nnrow(datos_notif_crudos)\n\nEsto imprimirá en la consola el número de columnas y de filas de la base de datos.\n\n\n[1] 12\n\n\n[1] 987\n\n\nOtra manera rápida es mirar el Entorno en RStudio, donde verá, junto al nombre de la base de datos, el número de observaciones (filas) y de variables (columnas).\n\n\n\n\n\n\nUtilice skim() del paquete {skimr} o la función class() para comprobar las clases de las columnas.\n¿Recuerda cómo indicar la columna de interés dentro de la función class()? Alternativamente, puede observar el panel de Entorno en RStudio, donde aparece la clase de cada columna junto a su nombre.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuántas columnas de la base de datos de notificación reconoce R como columnas de tipo fecha?\n\n 0 2 4\n\n¿Cuál es la clase de la mayoría de las columnas en la base de datos de notificación en bruto?\n\n character (texto) numeric (numérico) factor\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nPuede usar class() como en el ejemplo siguiente. El operador $ sirve para seleccionar una columna concreta de la base de datos datos_notif_crudos. Fíjese en que se usan comillas invertidas (`) alrededor de Fecha de nacimiento porque el nombre de la columna contiene espacios.\n\nclass(datos_notif_crudos$`Fecha de nacimiento`)\n\nPara ver la clase desde el panel Entorno, haga click en la flecha azul junto con el nombre de la base de datos: aparececerán los nombres de las columnas con su clase al lado (por ejemplo, “chr” para indicar clase character o nominal)\nVerá que ninguna de las columnas que deberían ser fechas está reconocida como tal; en su lugar, R las interpreta como texto (character).\n\n\n\n\n\n\nUtilice tabyl() para inspeccionar los valores dentro de las columnas categóricas, especificando en el primer argumento la base de datos y en el segundo el nombre de la columna.\nPor ejemplo, este código tabula los valores de la columna Sexo. La salida muestra que los valores “masculino” y “femenino” están escritos de manera incoherente, por lo que esta columna necesitaría limpieza antes del análisis:\n\ntabyl(datos_notif_crudos, Sexo)\n\n      Sexo   n    percent valid_percent\n         F  47 0.04761905    0.05452436\n  FEMENINO 146 0.14792300    0.16937355\n         M  40 0.04052685    0.04640371\n MASCULINO 172 0.17426545    0.19953596\n         f 154 0.15602837    0.17865429\n  femenino  98 0.09929078    0.11368910\n         m 119 0.12056738    0.13805104\n masculino  86 0.08713273    0.09976798\n      &lt;NA&gt; 125 0.12664640            NA\n\n\nPara inspeccionar los valores faltantes (o perdidos), puede usar la función miss_var_summary() del paquete {naniar}:\n\nmiss_var_summary(datos_notif_crudos)\n\n# A tibble: 12 × 3\n   variable                                             n_miss pct_miss\n   &lt;chr&gt;                                                 &lt;int&gt;    &lt;num&gt;\n 1 Fecha de inicio                                         691     70.0\n 2 Embarazada                                              510     51.7\n 3 Resultado                                               197     20.0\n 4 Fecha del resultado                                     197     20.0\n 5 Fecha de nacimiento                                     168     17.0\n 6 Sexo                                                    125     12.7\n 7 Nombre de la unidad organizativa                          0      0  \n 8 Codigo del centro de salud                                0      0  \n 9 ID de notificacion                                        0      0  \n10 Distrito residencial                                      0      0  \n11 Enfermedad notificada                                     0      0  \n12 Fecha notificada por el centro de salud/la comunidad      0      0  \n\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Los valores de la columna Distrito residencial están estandarizados?\n\n No: necesitan limpieza Sí: están estandarizados y listos para usarse en el análisis\n\n¿Los valores de la columna Enfermedad notificada están estandarizados?\n\n No: necesitan limpieza Sí: están estandarizados y listos para usarse en el análisis\n\n¿Qué reconoce R como un valor faltante?\n\n Sin valor, o solo un espacio, o solo un punto Sin valor en una celda, representado como NA Las palabras 'desconocido' e 'incierto'\n\nSegún los valores faltantes, ¿es útil la columna Fecha de inicio?\n\n Sí, la cantidad de valores faltantes es baja y esta columna es útil No demasiado: la ausencia es muy alta\n\n¿Por qué algunas columnas en los datos de notificación pueden tener grafías diferentes y categorías no estandarizadas?\n\n Un bot revuelve los datos para que sean menos identificables Cada clínica puede usar software configurado de forma diferente, o permitir entradas de texto libre, lo que genera variaciones en la ortografía El software de vigilancia usado en las clínicas tiene muchos errores en el código\n\n¿Por qué algunas columnas en los datos de notificación pueden tener una alta proporción de valores faltantes?\n\n El personal sanitario no pregunta al paciente durante la consulta El paciente no sabe o no quiere dar la respuesta El personal sanitario no tiene tiempo de completar ese campo, aunque sepa la información Todas las anteriores, y muchas más razones\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nUse tabyl() para tabular los valores de la columna Distrito residencial. De nuevo, el primer argumento es el nombre de la base de datos y el segundo el nombre de la columna:\n\ntabyl(datos_notif_crudos, `Distrito residencial`)\n\n Distrito residencial   n    percent\n            F Central  32 0.03242148\n            FEVERIA C  23 0.02330294\n      FEVERIA CENTRAL  85 0.08611955\n            Feveria C  24 0.02431611\n      Feveria Central  12 0.01215805\n               KASARA  64 0.06484296\n                  KSR  17 0.01722391\n               Kasara 109 0.11043566\n             L MINARA  50 0.05065856\n             L Minara 193 0.19554205\n          LAGO MINARA 185 0.18743668\n          Lago Minara  68 0.06889564\n             Lakeside 125 0.12664640\n\n\nVerá que cada una de las tres ubicaciones (Feveria Central, Lago Minara y Kasara) aparece escrita de distintas maneras y con diferentes mayúsculas. Esto deberá limpiarse si se quiere analizar la distribución geográfica de las enfermedades de declaración obligatoria.\nDe forma similar, utilice tabyl() para tabular los valores de la columna Enfermedad notificada. En este caso, verá que están escritos de forma adecuada y coherente, de modo que se puede analizar la distribución de los casos por enfermedad sin necesidad de más limpieza:\n\ntabyl(datos_notif_crudos, `Enfermedad notificada`)\n\n Enfermedad notificada   n    percent\n                colera  46 0.04660588\n                dengue 273 0.27659574\n       fiebre amarilla 100 0.10131712\n       fiebre tifoidea  35 0.03546099\n             paludismo 533 0.54002026\n\n\nPara comprobar los valores faltantes también puede usar is.na(). En el ejemplo siguiente, la función evalúa cada celda de la columna Fecha de inicio, devolviendo TRUE si falta el valor y FALSE si está presente. Si aplica tabyl() a este resultado, obtendrá de inmediato un recuento y un porcentaje claros de valores faltantes y no faltantes en esa columna.\nRecuerde: valores como un espacio vacío o las palabras “Desconocido” o “Faltante” no son reconocidos por R como NA. Solo los valores realmente en blanco, representados con NA, se consideran ausentes.\nEn el caso de Fecha de inicio, puede comprobar que aproximadamente un 70 % de las filas carecen de fecha de inicio, lo que hace que esta columna sea poco útil para analizar tendencias temporales.\n\ntabyl(is.na(datos_notif_crudos$`Fecha de inicio`))\n\n is.na(datos_notif_crudos$`Fecha de inicio`)   n   percent\n                                       FALSE 296 0.2998987\n                                        TRUE 691 0.7001013\n\n\nLos valores faltantes o las categorías no estandarizadas pueden deberse a muchas razones:\n\nEl diseño de la herramienta de recogida de datos (por ejemplo, si un campo es obligatorio o si se permite texto libre en lugar de listas desplegables),\nLos procesos y normas vigentes (por ejemplo, qué campos prioriza el personal),\nFactores contextuales (como la carga de trabajo o el tiempo disponible para recopilar la información).\n\n\n\n\n\n\n\n\n\n\nIgual que con los datos de vigilancia, utilice skim(), ncol() y nrow() o consulte el panel Entorno para inspeccionar los datos de laboratorio.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué base de datos tiene más columnas: la de notificación o la de laboratorio?\n\n Datos de laboratorio Datos de notificación Tienen el mismo número de columnas\n\n¿Qué base de datos tiene más filas: la de notificación o la de laboratorio?\n\n Datos de laboratorio Datos de notificación Tienen el mismo número de filas\n\nInspeccione los datos de laboratorio con View(). ¿Por qué podría haber más registros en la base de datos de laboratorio?\n\n Puede haber varias pruebas u objetivos por muestra Hay muchos resultados de pruebas de ensayo en los datos No todas las notificaciones tienen resultados de laboratorio todavía\n\n¿Cuál de estas columnas NO está en la base de datos de laboratorio?\n\n ID de notificacion ID de muestra Prueba Fecha de nacimiento Valor\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nAl igual que en la sección 3.1, puede utilizar skim() del paquete {skimr} para visualizar toda la base de datos del laboratorio con los resultados de las pruebas. Esto también le mostrará los distintos nombres de las columnas, poniendo de manifiesto que la base de datos del laboratorio solo contiene información sobre la prueba y no sobre el paciente. No obstante, también incluye un identificador de notificación similar, similar a los datos de notificación.\n\nskim(datos_lab_crudos)\n\nUtilice ncol() y nrow() para imprimir el número de columnas y filas, de la siguiente forma:\n\nncol(datos_lab_crudos)\nnrow(datos_lab_crudos)\n\nEsto mostrará en su consola el número de columnas y de filas, de manera que podrá comprobar que la base de datos de laboratorio tiene más filas que la base de datos de notificación que inspeccionó anteriormente.\n\n\n[1] 7\n\n\n[1] 1314\n\n\nA menudo hay más registros en la base de datos de laboratorio que en los datos clínicos. Si inspecciona los datos con View(datos_lab_crudos) y luego hace clic en la flecha de la parte superior de la columna ID de notificacion para ordenarla alfabéticamente, verá que varias filas comparten el mismo ID de notificacion. Esto puede suceder cuando se analizan varios objetivos de la misma muestra (mismo identificador de muestra), o cuando se repite el análisis de un caso (lo que da lugar a un identificador de muestra diferente).\n\nView(datos_lab_crudos)\n\n\n\nnombre_laboratorioid_notificacionid_muestrafecha_pruebapruebaobjetivovalorHospital General de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue NS.1NHospital General de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgGNHospital General de Feveriaf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgMPHospital General de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue NS.1NHospital General de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgGNHospital General de Feveria6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgMP\n\n\n\n\n\n\n\n\nAl igual que en el caso anterior, utilice las funciones class(), skim()o tabyl(), o inspeccione el Entorno, para observar las columnas con más detalle.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuántas columnas de la base de datos de laboratorio reconoce R como columnas de tipo fecha?\n\n 0 1 2\n\n¿Cuántas columnas de la base de datos de laboratorio tienen datos completos?\n\n 1 3 7 (Todas)\n\n¿Qué prueba detecta múltiples objetivos (y, por lo tanto, tiene varias filas por muestra)?\n\n Paludismo Dengue Fiebre Amarilla Cólera Fiebre tifoidea\n\n¿Cuántos valores posibles de resultado de prueba hay en la columna valor?\n\n 5 3 4\n\n¿Cuál de estos NO es un posible resultado en la prueba de cultivo de heces que detecta la bacteria V. cholerae?\n\n P P01 P0139 N I\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nLos datos de laboratorio tienen una columna de fecha reconocida por R con la clase “IDate”. Se trata de una clase de fecha que suele aparecer al importar CSV con la función import() de {rio}. Igual que la clase “Date” de R base, permite ordenar por fecha y analizar tendencias en el tiempo.\n\nclass(datos_lab_crudos$fecha_prueba)\n\n[1] \"IDate\" \"Date\" \n\n\nEl uso de la función miss_var_summary() del paquete {naniar} muestra que todas las columnas de los datos de laboratorio están completas. Esto puede deberse a que los sistemas de laboratorio utilizan procesos automatizados, por lo que es menos probable que se produzcan errores humanos.\n(Punto importante: Tenga en cuenta que, en la vida real, los datos de laboratorio también presentarían probablemente algunos problemas).\n\nmiss_var_summary(datos_lab_crudos)\n\n# A tibble: 7 × 3\n  variable           n_miss pct_miss\n  &lt;chr&gt;               &lt;int&gt;    &lt;num&gt;\n1 nombre_laboratorio      0        0\n2 id_notificacion         0        0\n3 id_muestra              0        0\n4 fecha_prueba            0        0\n5 prueba                  0        0\n6 objetivo                0        0\n7 valor                   0        0\n\n\nPara ver cuántos objetivos se detectan en cada prueba, puede realizar una tabulación cruzada de las columnas prueba y objetivo con tabyl(). Escriba los nombres de las columnas en la función como dos argumentos separados. La salida muestra que cada prueba se alinea claramente con uno o más objetivos, y solo la prueba de dengue detecta más de un objetivo (IgG, IgM y NS1).\nConsejo: Pruebe a cambiar el orden de los nombres de las columnas en la función para ver el impacto en la tabla.\n\ntabyl(datos_lab_crudos, objetivo, prueba)\n\n             objetivo Cultivo de heces Dengue NS1/IgG/IgM Hemocultivo IgM ELISA\n Bacteria V. cholerae               45                  0           0         0\n   Bacterias S. Typhi                0                  0          33         0\n           Dengue IgG                0                215           0         0\n           Dengue IgM                0                215           0         0\n          Dengue NS.1                0                215           0         0\n  Fiebre amarilla IgM                0                  0           0        88\n           Plasmodium                0                  0           0         0\n Microscopía de sangre total\n                           0\n                           0\n                           0\n                           0\n                           0\n                           0\n                         503\n\n\nPor último, puede inspeccionar los distintos valores de los resultados de las pruebas en la columna valor utilizando de nuevo tabyl(). Verá que hay seis resultados posibles, incluidos N (negativo), P (positivo) e I (indeterminado). En el caso del cólera no aparece P, pero sí pueden aparecer P01 y P0139, que en este ejemplo representan positividad para los serogrupos O1 u O139.\n\ntabyl(datos_lab_crudos, prueba, valor)\n\n                      prueba  I   N   P PO1 PO139\n            Cultivo de heces  5   2   0  22    16\n          Dengue NS1/IgG/IgM  0 354 291   0     0\n                 Hemocultivo  2  24   7   0     0\n                   IgM ELISA 10  45  33   0     0\n Microscopía de sangre total 56 257 190   0     0"
  },
  {
    "objectID": "pages/multidisease_surveillance.es.html#paso-4.-limpiar-y-describir-los-datos-de-notificación",
    "href": "pages/multidisease_surveillance.es.html#paso-4.-limpiar-y-describir-los-datos-de-notificación",
    "title": "Vinculación y análisis de datos de notificación y datos de laboratorio en R",
    "section": "",
    "text": "Los datos de notificación (datos_notif_crudos) contienen información sobre casos sospechosos, junto con datos demográficos básicos (edad, sexo, embarazo, distrito de residencia), e información sobre su fecha de inicio, fecha reportada por el centro de salud, y resultado. Algunas columnas deben limpiarse antes de continuar con el análisis, debido a variaciones en la ortografía de los valores categóricos y a que algunas no se reconocen como fechas.\nAhora comenzará a redactar fragmentos más extensos de código para realizar limpieza de datos, utilizando diversas funciones de {dplyr} encadenadas mediante pipes (que se representan de la siguiente manera: |&gt;).\nNOTA SOBRE PIPES: Los pipes permiten ejecutar varias operaciones en una secuencia continua, “encadenando” diferentes funciones. La salida de una función se convierte en la entrada de la siguiente.\nPara obtener más información sobre el uso de pipes, consultar el Manual de R para Epis.\nCabe destacar que este ejercicio utiliza el pipe de base (|&gt;) en lugar del pipe de magrittr (%&gt;%), ya que resulta más rápido y no requiere instalación de paquetes. Si prefiere, puede utilizar el pipe de magrittr.\n\n\n\n\nDebido a problemas de calidad y de almacenamiento de datos, se recomienda elaborar una lista depurada (linelist) que contenga únicamente la información sobre el identificador único, la ubicación del caso, la enfermedad y la fecha en que la notificación fue reportada al sistema de vigilancia.\nEscribir código en R para generar una nueva base de datos limpio denominado datos_notif, aplicando las siguientes tareas de limpieza:\n\nRenombrar las columnas para que resulten más legibles por las máquinas (eliminando espacios y mayúsculas) mediante la función clean_names() del paquete {janitor}.\nUtilizar la función rename() de {dplyr} para que:\n\nel nombre de la columna con la fecha en la que se notificó el caso se sustituya por un nombre más conciso fecha_notificada.\nel nombre de la columna del identificador de la notificación sea más conciso (id_notificacion).\n\nSeleccionar las columnas relevantes para el análisis con la función select() del paquete {dplyr}.\n\n\n\n\n\n\n\nHaga clic para leer una pista\n\n\n\n\n\nIniciar el código con el nombre de la nueva base de datos, la flecha de asignación y el nombre del objeto de datos en bruto. Esto indica que el resultado del procesamiento de los datos en bruto será asignado a un nuevo objeto denominado datos_notif.\n\ndatos_notif &lt;- datos_notif_crudos\n\nA continuación, construya sobre este código añadiendo funciones adicionales, encadenadas mediante un pipe. Esto permite realizar varias operaciones en una secuencia continua. Primero, utilice clean_names() para estandarizar todos los nombres de columnas. Esta función reemplaza automáticamente los espacios y caracteres especiales por guiones bajos y convierte todo a minúsculas, lo que facilita el manejo de los nombres. Después, utilice rename() para asignar un nombre nuevo a una columna. Recordar que, al usar rename(), la columna ya tendrá la versión transformada por clean_names().\n\n# datos_notif &lt;- datos_notif_crudos |&gt; \n#   clean_names() |&gt; \n#   rename(NOMBRE_NUEVO = NOMBRE_ANTERIOR) |&gt; \n#   select(NOMBRES_VARIABLES)\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nAquí está el código para limpiar los nombres de las columnas y seleccionar las columnas adecuadas para análisis:\n\n# Limpiar datos \ndatos_notif &lt;- datos_notif_crudos |&gt; \n  clean_names() |&gt; \n  rename(\n    fecha_notificada = fecha_notificada_por_el_centro_de_salud_la_comunidad,\n    id_notificacion = id_de_notificacion) |&gt;\n  select(id_notificacion, distrito_residencial, enfermedad_notificada, fecha_notificada)\n\n\n\n\n\n\n\nA partir de la inspección de los datos, ya sabe que los valores de la columna distrito_residencial no están estandarizados.\nAgregar una función mutate() para limpiar la columna distrito_residencial, con el fin de:\n\nEstandarizar la capitalización de la columna.\n\nReemplazar la columna existente distrito_residencial por una columna depurada que contenga únicamente los siguientes valores de distrito: “Lago Minara”, “Feveria Central” y “Kasara”.\n\nConsultar la pista para ver qué funciones se pueden utilizar.\n\n\n\n\n\n\nHaga clic para leer una pista\n\n\n\n\n\nPrueba a utilizar str_to_title() del paquete {stringr} para que la primera letra de cada palabra sea mayúscula y todas las demás letras sean minúsculas. También puede utilizar case_match() para especificar distintas erratas concretas.\nUtilice la función ‘help’ de RStudio para ver cómo utilizar las funciones. Por ejemplo, escriba ?case_match en su consola para obtener la página de ayuda de la función. NOTA en case_match() - se trata de una función muy útil para sustituir o corregir valores, y sustituye a recode().\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nSu código de limpieza debería tener ahora este aspecto:\n\n# Limpiar datos\ndatos_notif &lt;- datos_notif_crudos |&gt; \n  clean_names() |&gt; \n  rename(\n    fecha_notificada = fecha_notificada_por_el_centro_de_salud_la_comunidad,\n    id_notificacion = id_de_notificacion) |&gt;\n  select(id_notificacion, distrito_residencial, enfermedad_notificada, fecha_notificada) |&gt; \n  mutate(distrito_residencial = str_to_title(distrito_residencial)) |&gt; \n  mutate(distrito_residencial = case_match(distrito_residencial,\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\"))\n\nTambién puede envolver str_to_title en la función case_match() para acortar el código, como se indica a continuación:\n\n# Limpiar datos\ndatos_notif &lt;- datos_notif_crudos |&gt; \n  clean_names() |&gt; \n  rename(\n    fecha_notificada = fecha_notificada_por_el_centro_de_salud_la_comunidad,\n    id_notificacion = id_de_notificacion) |&gt; \n  select(id_notificacion, distrito_residencial, enfermedad_notificada, fecha_notificada) |&gt; \n  mutate(distrito_residencial = case_match(str_to_title(distrito_residencial),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\"))\n\n\n\n\n\n\n\nLa columna correspondiente a la fecha de notificación necesita ser transformada para que sea reconocida como una fecha en R. Esto permitirá analizar tendencias a lo largo del tiempo, incluyendo semanas y meses.\nRevisar los valores dentro de la columna fecha_notificada. Luego, agregar una línea al código de limpieza para convertir fecha_notificada en una clase de fecha.\nConocer la estructura de la columna permitirá utilizar la función adecuada para transformarla en clase de fecha. Se recomienda emplear alguna de las funciones del paquete {lubridate}: ymd() (para fechas escritas como año-mes-día), mdy() (para fechas escritas como mes-día-año) o dmy() (para fechas escritas como día-mes-año). Estas funciones reconocerán cualquier formato de escritura de fecha siempre que el orden sea correcto; por ejemplo, “21st August 2025” y “21-08-2024” serían reconocidos por dmy().\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cómo están formateadas actualmente las fechas?\n\n día-mes-año año-mes-día mes-día-año año-día-mes\n\n¿Qué función de mutate() deberías usar para convertir la columna fecha_notificada en una clase de fecha?\n\n mutate(fecha_notificada = ymd(fecha_notificada)) mutate(fecha_notificada = dmy(fecha_notificada)) mutate(fecha_notificada = mdy(fecha_notificada))\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nSe puede utilizar la función head() para visualizar las primeras seis filas de datos de la columna fecha_notificada. Al observarlas, se identifica que están escritas con el año en primer lugar, seguido del mes y, posteriormente, del día.\n\nhead(datos_notif$fecha_notificada)\n\n[1] \"2024-03-08\" \"2024-03-11\" \"2024-03-11\" \"2024-03-18\" \"2024-03-14\"\n[6] \"2024-03-12\"\n\n\nSe puede utilizar la función ymd() dentro de mutate() para convertir la clase de la columna fecha_notificada. Es posible verificar que la clase sea la correcta ejecutando posteriormente la función class().\nEl código de limpieza debería ahora tener el siguiente aspecto:\n\n# Limpiar datos\ndatos_notif &lt;- datos_notif_crudos |&gt; \n  clean_names() |&gt; \n  rename(\n    fecha_notificada = fecha_notificada_por_el_centro_de_salud_la_comunidad,\n    id_notificacion = id_de_notificacion) |&gt;\n  select(id_notificacion, distrito_residencial, enfermedad_notificada, fecha_notificada) |&gt; \n  mutate(distrito_residencial = case_match(str_to_title(distrito_residencial),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\")) |&gt; \n  mutate(fecha_notificada = ymd(fecha_notificada)) \n\nY se puede volver a comprobar la clase con esto:\n\nclass(datos_notif$fecha_notificada)\n\n[1] \"Date\"\n\n\n\n\n\n\n\n\nLos colegas indican que cada id_notificacion representa un caso sospechoso. Ahora se desea crear una tabla para verificar si id_notificacion se encuentra duplicado en las filas de los datos.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Equivale una fila en los datos de notificación a un caso?\n\n Sí No\n\n¿Necesita depurar (eliminar duplicados) sus datos para el análisis epidemiológico de casos?\n\n Sí No\n\n\n\n\n\n\n\n\n\n\nHaga clic para leer una pista\n\n\n\n\n\nExisten varias formas de realizar esta verificación, pero se sugiere utilizar la función count() de {dplyr}. Esta función creará una tabla que contabiliza el número de filas por cada valor único de la columna que se especifique dentro de la función. Posteriormente, emplear tabyl() para observar la distribución de estos conteos.\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nPrimero, encadenar los datos de vigilancia mediante un pipe hacia la función count(), indicando la columna id_notificacion como el único argumento. Esto generará una tabla que contabiliza el número de filas por cada valor único de id_notificacion, mostrando el resultado en una nueva columna denominada n. En este extracto se puede observar, por ejemplo, que existe solo una fila para cada uno de estos seis valores de id_notificacion.\n\ndatos_notif |&gt; \n  count(id_notificacion) \n\n\n\n  id_notificacion n\n1          00399b 1\n2          005c85 1\n3          006f52 1\n4          00cbbb 1\n5          01830d 1\n6          019045 1\n\n\nA continuación, tabular la nueva columna n con la función tabyl(), lo que demuestra que existe únicamente una fila por cada id_notificacion único. Esto significa que una fila equivale a un caso y que no se requiere realizar una deduplicación adicional.\n\ndatos_notif |&gt; \n  count(id_notificacion) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 987       1\n\n\n\n\n\n\n\n\n\nAhora puede proceder cómodamente al análisis descriptivo de los casos, ya que sus datos están limpios y sabe que una fila equivale a un caso. Utilice la función tabyl() para las siguientes tareas.\n\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué enfermedad fue diagnosticada con mayor frecuencia por las clínicas en Feveria en 2024?\n\n Cólera Paludismo Dengue Fiebre tifoidea Fiebre amarilla\n\n¿Qué enfermedad fue diagnosticada con menor frecuencia por las clínicas en Feveria en 2024?\n\n Cólera Paludismo Dengue Fiebre tifoidea Fiebre amarilla\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nUtilizando tabyl() podemos ver que había 533 casos sospechosos de paludismo en Feveria en 2024, y sólo 35 casos sospechosos de fiebre tifoidea.\n\ntabyl(datos_notif, enfermedad_notificada)\n\n enfermedad_notificada   n    percent\n                colera  46 0.04660588\n                dengue 273 0.27659574\n       fiebre amarilla 100 0.10131712\n       fiebre tifoidea  35 0.03546099\n             paludismo 533 0.54002026\n\n\n\n\n\n\n\n\nUtilice tabyl() para cruzar las columnas de enfermedad y distrito de residencia.\nComplete la tabla incorporando diversas funciones adorn del paquete {janitor}, con el fin de visualizar distribuciones porcentuales, por ejemplo: adorn_percentages(), adorn_pct_formatting() y adorn_ns().\nEscribir el nombre de la función precedido de un signo de interrogación en la consola (por ejemplo, ?adorn_ns) para consultar las páginas de ayuda correspondientes. También se puede revisar la sección sobre {janitor} en el manual de R para Epis para obtener una explicación más detallada sobre las funciones adorn_xxx().\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué distrito notificó la mayor cantidad de enfermedades transmitidas por vectores en 2024 (paludismo, dengue, fiebre amarilla)?\n\n Lago Minara Feveria Central Kasara\n\n¿Qué distrito notificó la mayor cantidad de enfermedades diarreicas en 2024 (cólera, fiebre tifoidea)?\n\n Lago Minara Feveria Central Kasara\n\n¿Qué factores contribuyen al aumento de enfermedades diarreicas en este distrito específico (seleccionado en la pregunta anterior)?\n\n Infraestructura deficiente de agua y saneamiento Hacinamiento de mosquitos No lo sabemos\n\n\n\n\n\n\n\n\n\n\nHaga clic para leer una pista\n\n\n\n\n\nAquí se presenta código para comenzar. Primero, se realiza una tabla de contingencia entre enfermedad_notificada y distrito_residencial con tabyl(). Luego, al agregar adorn_percentages(), estos valores se convierten en porcentajes con muchos decimales. A continuación, encadenar mediante pipes hacia adorn_pct_formatting() para aplicar un formato porcentual adecuado y, posteriormente, hacia adorn_ns() para reincorporar los números entre paréntesis.\nTener en cuenta que las funciones adorn_xxx() deben aplicarse en un orden específico.\n\ntabyl(datos_notif, enfermedad_notificada, distrito_residencial) |&gt;\n  adorn_percentages()\n\nPara conocer los factores que contribuyen a un mayor número de diarreas, desplácese hasta el principio del estudio de caso, cuando se presentaron por primera vez los distritos.\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nAl utilizar tabyl(), se observa que la mayoría de los casos sospechosos de dengue, paludismo y fiebre amarilla se localizaron en Lago Minara, el área lacustre con mayor densidad de mosquitos y, por lo tanto, con enfermedades transmitidas por vectores. Mientras tanto, la mayoría de los casos de cólera y fiebre tifoidea se concentraron en Feveria Central, el área urbana sobrepoblada con problemas en la infraestructura de agua y saneamiento que generan un mayor riesgo de inundaciones y de contaminación del agua potable durante la temporada de lluvias.\n\ntabyl(datos_notif, enfermedad_notificada, distrito_residencial) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n enfermedad_notificada Feveria Central      Kasara Lago Minara\n                colera      91.3% (42)  8.7%   (4)  0.0%   (0)\n                dengue       9.5% (26) 17.6%  (48) 72.9% (199)\n       fiebre amarilla      11.0% (11) 21.0%  (21) 68.0%  (68)\n       fiebre tifoidea      68.6% (24) 31.4%  (11)  0.0%   (0)\n             paludismo      13.7% (73) 19.9% (106) 66.4% (354)"
  },
  {
    "objectID": "pages/multidisease_surveillance.es.html#paso-5.-limpiar-consolidar-y-describir-los-datos-de-laboratorio.",
    "href": "pages/multidisease_surveillance.es.html#paso-5.-limpiar-consolidar-y-describir-los-datos-de-laboratorio.",
    "title": "Vinculación y análisis de datos de notificación y datos de laboratorio en R",
    "section": "",
    "text": "A partir del trabajo realizado anteriormente en el paso 3, se identificó que los datos de laboratorio contienen únicamente información de pruebas y no incluyen datos de pacientes. Los datos ya se encuentran muy depurados, por lo que únicamente es necesario estandarizar una columna. Asimismo, se debe procesar el marco de datos de laboratorio para que contenga una fila por cada notificación, de manera que pueda unirse de forma ordenada con la base de datos de notificación.\n\n\n\n\nCrear un nuevo objeto denominado datos_lab. Esto permitirá un análisis y una interpretación de resultados más directos.\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nUtilice case_match() para convertir los distintos valores originales en “Positivo”, “Negativo” o “Indeterminado”:\n\ndatos_lab &lt;- datos_lab_crudos |&gt; \n  mutate(valor = case_match(valor, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positivo\",\n                            \"N\" ~ \"Negativo\",\n                            \"I\" ~ \"Indeterminado\"))\n\nPosteriormente, se puede verificar que los nuevos valores sean correctos mediante la tabulación y la comparación de los valores en la base de datos original y en el depurado. Asegurarse de haber utilizado la letra ‘O’ y no el número ‘0’.\n\ntabyl(datos_lab_crudos, valor)\n\n valor   n    percent\n     I  73 0.05555556\n     N 682 0.51902588\n     P 521 0.39649924\n   PO1  22 0.01674277\n PO139  16 0.01217656\n\n\n\ntabyl(datos_lab, valor)\n\n         valor   n    percent\n Indeterminado  73 0.05555556\n      Negativo 682 0.51902588\n      Positivo 559 0.42541857\n\n\n\n\n\n\n\n\n\n\n\nYa se sabe que algunas muestras tienen varias filas, y que esto se debe a que el ensayo de dengue posee tres objetivos, con un resultado por fila para cada uno de ellos.\nAhora, determinar el número de muestras con varias filas.\nPara ello, proceder de la misma manera que con los datos de notificación, utilizando el objeto datos_lab: primero contar el número de filas por muestra y luego crear una tabla que muestre la distribución de la cantidad de filas. Tener en cuenta que cada muestra se identifica mediante un identificador de muestra (id_muestra).\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuántas muestras (identificadores únicos id_muestra) están repetidas en tres filas?\n\n 200 215 230\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nPrimero, encadenar los datos de laboratorio mediante un pipe hacia la función count(), indicando la columna id_muestra como el único argumento. Esto generará una tabla que contabiliza el número de filas por cada valor único de id_muestra, mostrando el resultado en una nueva columna denominada n. Por ejemplo, se puede observar que el id_muestra “000e8eee” tiene tres filas, mientras que el id_muestra “001e1878” aparece únicamente en una fila.\n\ndatos_lab |&gt; \n  count(id_muestra) \n\n\n\n  id_muestra n\n1   000e8eee 3\n2   001e1878 1\n3   005f39af 1\n4   00b30781 3\n5   00b56d18 1\n6   0110abcd 3\n\n\nA continuación, tabular la nueva columna n utilizando la función tabyl().\n\ndatos_lab |&gt; \n  count(id_muestra) |&gt; \n  tabyl(n)\n\n n n_n   percent\n 1 669 0.7567873\n 3 215 0.2432127\n\n\nIncluso se puede verificar que esto aplica únicamente al ensayo de dengue añadiendo la columna prueba al cálculo. De esta manera, se observa que solo la prueba de dengue presenta tres filas por muestra.\n\ndatos_lab |&gt; \n  count(prueba, id_muestra) |&gt; \n  tabyl(prueba, n)\n\n                      prueba   1   3\n            Cultivo de heces  45   0\n          Dengue NS1/IgG/IgM   0 215\n                 Hemocultivo  33   0\n                   IgM ELISA  88   0\n Microscopía de sangre total 503   0\n\n\n\n\n\n\n\n\nComo se observó en la sección 3.2, la prueba de dengue proporciona resultados para tres objetivos diferentes: IgG, IgM y NS.1. Los resultados de cada uno de estos objetivos pueden ser negativos o positivos. Sin embargo, para simplificar y consolidar los datos, se desea asignar una sola etiqueta (negativa o positiva) a cada muestra, con el fin de indicar si la muestra representa una infección activa.\n\n\nobjetivoNegativoPositivoDengue IgG110105Dengue IgM105110Dengue NS.113976\n\n\nSu colega Ben, quien trabaja en el laboratorio, recomienda lo siguiente para la depuración:\n\nConsiderar una muestra como positiva si NS.1 o IgM son positivos (ambos pueden representar una infección aguda).\n\nIgnorar IgG (porque un resultado positivo en ausencia de NS.1 o IgM positivos es indicativo de inmunidad tras una infección pasada resuelta).\n\nAhora, consolidar los resultados de la prueba de dengue en una fila por prueba, con un único valor de resultado. Utilizar filter(), arrange() y slice(), asegurándose de que cualquier muestra positiva para NS.1 o IgM se considere positiva para dengue.\nCrear un nuevo objeto denominado datos_lab_pruebas.\n\n\n\n\n\n\nHaz clic para leer una pista\n\n\n\n\n\nIntentar aplicar lo siguiente para consolidar conforme a la recomendación de Ben:\n\nEliminar resultados de IgG: filtrar las filas donde el objetivo sea “IgG” utilizando filter() de {dplyr}.\n\nPriorizar resultados positivos de IgM/NS1: agrupar por id_muestra y ordenar las filas con arrange() de modo que cualquier resultado ‘P’ (positivo) aparezca primero.\n\nFiltrar al estado final: conservar únicamente la primera fila utilizando slice(1) para obtener el resultado positivo o negativo de la muestra.\n\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nA continuación se presenta el código para filtrar los resultados de IgG del dengue y, posteriormente, consolidar el resultado de la prueba dentro de cada grupo de filas con el mismo id_muestra, priorizando los resultados positivos. Es necesario especificar desc dentro de arrange(), ya que este ordena en orden alfabético inverso, colocando la letra P en la parte superior. Además, agregar la función ungroup() al final para que la nueva base de datos no quede agrupada, lo cual podría generar confusión en análisis posteriores.\n\ndatos_lab_pruebas &lt;- datos_lab |&gt; \n  filter(objetivo != \"Dengue IgG\") |&gt; \n  group_by(id_muestra) |&gt; \n  arrange(desc(valor)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\nPosteriormente, se puede verificar que el nuevo objeto datos_lab_pruebas contenga una sola fila por prueba utilizando la combinación de count() y tabyl(), tal como se hizo en la Tarea A. Esta tabla muestra que todos los identificadores de muestra únicos aparecen únicamente en una fila cada uno:\n\ndatos_lab_pruebas |&gt; \n  count(id_muestra) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 884       1\n\n\n\n\n\n\n\n\nA continuación, verificar el número de pruebas por identificador de notificación en los datos consolidados.\nSe observa que existen 26 filas con el mismo identificador de notificación que otra fila, pero únicamente en los casos analizados mediante microscopía de sangre total para paludismo.\n\ndatos_lab_pruebas |&gt; \n  count(prueba, id_notificacion) |&gt; \n  tabyl(prueba, n)\n\n                      prueba   1  2\n            Cultivo de heces  45  0\n          Dengue NS1/IgG/IgM 215  0\n                 Hemocultivo  33  0\n                   IgM ELISA  88  0\n Microscopía de sangre total 451 26\n\n\nSe procede a investigar con mayor detalle, examinando un caso de ejemplo con id_notificacion “043228”. Esto muestra que dicho caso fue analizado en dos ocasiones, con dos muestras diferentes tomadas con una semana de diferencia. El primer resultado fue positivo y el segundo resultado fue negativo.\n\ndatos_lab_pruebas |&gt; \n  filter(id_notificacion == \"043228\")\n\n# A tibble: 2 × 7\n  nombre_laboratorio     id_notificacion id_muestra fecha_prueba prueba objetivo\n  &lt;chr&gt;                  &lt;chr&gt;           &lt;chr&gt;      &lt;IDate&gt;      &lt;chr&gt;  &lt;chr&gt;   \n1 Hospital Universitari… 043228          27c37cd8   2024-06-18   Micro… Plasmod…\n2 Hospital Universitari… 043228          d2271be0   2024-06-25   Micro… Plasmod…\n# ℹ 1 more variable: valor &lt;chr&gt;\n\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuál afirmación sobre los datos de laboratorio es correcta?\n\n Todos los casos de diferentes enfermedades se vuelven a analizar Algunos casos de paludismo se vuelven a analizar Todos los casos de paludismo se vuelven a analizar\n\n¿Será necesario depurar (eliminar duplicados) los datos de laboratorio para unirlos con los datos de notificación?\n\n Sí - necesitamos una fila que represente el resultado de laboratorio por notificación No - los datos ya están suficientemente depurados\n\n\n\n\n¡Si la respuesta fue que es necesario deduplicar, es correcto!\nDeduplicar los datos para tener una sola fila por id_notificacion, priorizando los resultados positivos, de modo que puedan unirse con los datos de notificación.\nPara ello, seguir un proceso similar al de la Tarea B, utilizando el cuadro de datos generado en dicha tarea:\n\nAgrupar por id_notificacion.\n\nOrdenar por el valor del resultado de la prueba, de manera que los valores que comienzan con P tengan prioridad en la primera fila, seguidos por N (negativo) y luego I (indeterminado).\n\nConservar únicamente la primera fila dentro de cada grupo de id_notificacion, utilizando slice().\n\nAl realizar esto, crear un nuevo objeto denominado datos_lab_casos.\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡intente hacerlo primero!)\n\n\n\n\n\nA continuación se presenta el código para deduplicar las filas dentro de cada grupo con el mismo id_notificacion, priorizando los resultados positivos. Una vez más, es necesario especificar desc dentro de arrange(). Esto funciona perfectamente porque el orden de prioridad deseado para los resultados —positivo, luego negativo y finalmente indeterminado— coincide con el orden alfabético inverso (P aparece antes que N, que aparece antes que I, al ordenar de forma descendente).\nSi el orden de prioridad fuera más complejo o no coincidiera con el orden alfabético (por ejemplo, si “indeterminado” debiera colocarse antes que “negativo”), sería necesario convertir la columna de resultados en un factor y definir explícitamente el orden deseado de sus niveles. No olvidar desagrupar nuevamente al final.\n\ndatos_lab_casos &lt;- datos_lab_pruebas |&gt; \n  group_by(id_notificacion) |&gt; \n  arrange(desc(valor)) |&gt; \n  slice(1) |&gt;\n  ungroup()\n\nA continuación, puede volver a comprobar que el nuevo objeto datos_lab_casos sólo tiene una fila por prueba, utilizando la combinación de count() y tabyl() como que hizo en la Tarea A. Esta tabla le muestra que todos los ID de muestra únicos son sólo están presentes en una fila cada uno:\n\ndatos_lab_casos |&gt; \n  count(id_notificacion) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 858       1\n\n\n\n\n\n\n\n\n\nAhora tenemos dos objetos que podemos utilizar para el análisis de los datos de laboratorio: datos_lab_pruebas y datos_lab_casos.\n\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué objeto debería usar para analizar las pruebas?\n\n datos_lab_pruebas datos_lab_casos ninguno\n\n¿Cuántas pruebas se realizaron para detectar paludismo (mediante microscopía de sangre completa)?\n\n 215 503 88 190\n\n¿Qué porcentaje de las pruebas para cólera (mediante cultivo de heces) resultaron positivas?\n\n 21% 11% 84% 87%\n\n¿Qué prueba tuvo el mayor porcentaje de resultados indeterminados?\n\n ELISA IgM (para la detección de fiebre amarilla) Cultivo de heces (para la detección de cólera) Hemocultivo (para la detección de fiebre tifoidea)\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nAl utilizar tabyl() se puede ver el número de positivos, negativos y resultados indeterminados por prueba. Se puede añadir una serie de funciones de adorn() para mostrar porcentajes y totales.\n\ntabyl(datos_lab_pruebas, prueba, valor) |&gt; \n  adorn_totals(where = \"col\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n                      prueba Indeterminado    Negativo    Positivo        Total\n            Cultivo de heces    11.1%  (5)  4.4%   (2) 84.4%  (38) 100.0%  (45)\n          Dengue NS1/IgG/IgM     0.0%  (0) 13.5%  (29) 86.5% (186) 100.0% (215)\n                 Hemocultivo     6.1%  (2) 72.7%  (24) 21.2%   (7) 100.0%  (33)\n                   IgM ELISA    11.4% (10) 51.1%  (45) 37.5%  (33) 100.0%  (88)\n Microscopía de sangre total    11.1% (56) 51.1% (257) 37.8% (190) 100.0% (503)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué base de datos de laboratorio debería usar para contar el número de casos sospechosos analizados?\n\n datos_lab_crudos datos_lab_casos datos_lab_pruebas datos_lab\n\n¿Cuántos casos sospechosos fueron analizados en los datos de laboratorio de 2024?\n\n 858 1314 884\n\n¿Hay más casos sospechosos en los datos de notificación o en los datos de laboratorio?\n\n Datos de notificación Datos de laboratorio\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nSe puede consultar el número de filas en la base de datos datos_lab_casos para observar la cantidad de casos sospechosos que fueron analizados.\n\nnrow(datos_lab_casos)\n\n[1] 858\n\n\nEste número es menor al de los casos sospechosos registrados en los datos depurados de vigilancia de enfermedades de notificación obligatoria (datos_notif), lo que sugiere que no todos los casos sospechosos en 2024 fueron analizados al momento en que estos datos estuvieron disponibles.\n\nnrow(datos_notif)\n\n[1] 987"
  },
  {
    "objectID": "pages/multidisease_surveillance.es.html#paso-6.-unión-y-tratamiento-final",
    "href": "pages/multidisease_surveillance.es.html#paso-6.-unión-y-tratamiento-final",
    "title": "Vinculación y análisis de datos de notificación y datos de laboratorio en R",
    "section": "",
    "text": "Ahora que ambas linelists están depuradas y cuentan con una sola fila por caso sospechoso, es posible unirlos para habilitar el análisis completo solicitado por la jefatura.\n\n\n\n\nCrear un nuevo objeto denominado datos_unidos, utilizando una función xxx_join() de {dplyr}. Conservar todas las notificaciones y añadir los resultados de laboratorio cuando estén disponibles para cada caso sospechoso.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué función es la correcta si desea conservar todas las filas de sus datos de notificación e incorporar los resultados de sus datos de laboratorio?\n\n left_join(datos_notif, datos_lab_casos… full_join(datos_notif, datos_lab_casos… right_join(datos_notif, datos_lab_casos…\n\n¿Qué identificador debería usarse para enlazar las dos listas línea?\n\n id_muestra id_notificacion id_muestra y fecha_notificada id_notificacion y fecha_notificada\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡intente hacerlo primero!)\n\n\n\n\n\nUnir los datos utilizando la función left_join(), colocando los datos de notificación como la base de datos principal a la izquierda. Esto permitirá conservar todas las filas de dicha base de datos e incorporar únicamente los resultados de laboratorio provenientes de la base de datos especificado a la derecha de la función.\n\ndatos_unidos &lt;- left_join(datos_notif, datos_lab_casos, \n                         by = \"id_notificacion\")\n\nLa unión se realiza mediante la columna id_notificacion, la cual está presente, completa y depurada en ambas linelists.\nNota: En este caso resulta afortunado contar con un ejemplo tan sencillo de unión. Normalmente sería necesario depurar y verificar exhaustivamente la columna de identificadores, o bien realizar la unión a través de otras variables como el nombre y la fecha de nacimiento. En Feveria, el personal de las clínicas es excelente asignando de manera consistente los identificadores de notificación a cada paciente, incluso en los formularios de muestra enviados al laboratorio; a su vez, el personal de laboratorio es igualmente destacado registrando el identificador de notificación en sus sistemas, lo que permite que los resultados se unan adecuadamente con cada caso.\n\n\n\n\n\n\nAhora comprueba tus datos y revisa.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuántas filas hay en su nueva base de datos datos_unidos?\n\n 987 884 858\n\n¿Cómo se compara esto con sus datos originales de notificación?\n\n más filas que el original el mismo número de filas menos filas\n\n¿Qué término describe mejor la unión que acaba de realizar?\n\n muchos-a-uno uno-a-uno muchos-a-muchos\n\n¿Cuántos resultados de laboratorio NO se unieron (pista: usar anti_join())?\n\n 30 19 0\n\n¿Qué tan afortunado es de que su unión haya sido tan exitosa?\n\n ¿Qué? ¿Acaso no toda unión es así de simple?? ¡Muy afortunado! Usualmente algunos registros no coinciden\n\n¿Cuáles son las razones típicas por las que los datos de laboratorio no coinciden con los datos de enfermedades de notificación obligatoria?\n\n Hay errores tipográficos en las columnas usadas para la unión, por lo que no se reconocen como coincidentes Los datos de laboratorio pueden contener casos adicionales de otras clínicas o países Los datos de laboratorio pueden incluir muestras de prueba Las notificaciones pueden haberse omitido accidentalmente en los datos de vigilancia aunque la muestra haya sido analizada en el laboratorio Todas las anteriores\n\n¿Cuántos casos sospechosos no tienen un resultado?\n\n 83 100 129\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡intente hacerlo primero!)\n\n\n\n\n\nVerificar el número de filas en cada marco de datos con la función nrow(), o consultando la información del objeto en el Entorno. Se puede observar que esta fue simplemente una unión uno-a-uno, ya que cada fila tenía un id_notificacion único; por lo tanto, una fila en los datos de notificación se unió directamente con una fila en los datos de laboratorio.\nNúmero de filas en los datos de notificación\n\nnrow(datos_notif)\n\n[1] 987\n\n\nNúmero de filas en los datos enlazados\n\nnrow(datos_unidos)\n\n[1] 987\n\n\nPara comprobar si existió algún resultado de laboratorio que no se unirá con los datos de notificación, se puede utilizar anti_join(). En este caso, el objeto datos_lab_casos se coloca a la izquierda, ya que la función evalúa cuántas filas de la base de datos de la izquierda no se encuentran en la base de datos de la derecha, haciendo la coincidencia por id_notificacion.\nEn esta ocasión no es necesario generar una nueva base de datos; simplemente se puede encadenar con un nrow() para contar el número de filas. El resultado es 0, lo que demuestra que no hubo resultados no unidos, ¡excelente!\n\nanti_join(datos_lab_casos, datos_notif, \n          by = \"id_notificacion\") |&gt; nrow()\n\n[1] 0\n\n\nPor último, para comprobar el número de notificaciones sin resultado, puede realizar un anti_join en putting datos_notif primero:\n\nanti_join(datos_notif, datos_lab_casos, \n          by = \"id_notificacion\") |&gt; nrow()\n\n[1] 129\n\n\nO bien, puede simplemente tabular el número de valores que faltan en el columna valor en datos_unidos (como la columna valor procede de los datos del laboratorio).\n\ntabyl(is.na(datos_unidos$valor)) \n\n is.na(datos_unidos$valor)   n   percent\n                     FALSE 858 0.8693009\n                      TRUE 129 0.1306991\n\n\nAmbos enfoques muestran que 129 casos sospechosos no tienen un resultado de laboratorio.\n\n\n\n\n\n\n\n\n\nUtilizar mutate() para crear una nueva columna denominada categoria_casos, actualizando la categoría de los casos sospechosos de acuerdo con su resultado de laboratorio. Las categorías deben definirse de la siguiente manera:\n\nSi el resultado fue positivo: Confirmado\n\nSi el resultado fue negativo: Descartado\n\nSi el resultado fue indeterminado o faltante: Sospechoso\n\nEsto implica que todos los casos en los datos de notificación se consideran inicialmente sospechosos al momento de ser reportados, y permanecen como sospechosos si no existe un resultado de prueba concluyente.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuál es la función más apropiada para crear esta nueva columna?\n\n case_when() if_else() case_match()\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡pruébela usted primero!)\n\n\n\n\n\nDebe utilizar case_when() para crear la nueva columna. Esta función es ideal para aplicar múltiples condiciones lógicas para crear múltiples valores, mientras que case_match() es mejor para sustituir valores específicos, y if_else() es mejor si sólo hay dos valores posibles.\n\ndatos_unidos &lt;- datos_unidos |&gt; \n  mutate(categoria_casos = case_when(valor==\"Positivo\" ~ \"Confirmado\",\n                                   valor==\"Negativo\" ~ \"Descartado\",\n                                   valor==\"Indeterminado\" | is.na(valor) ~ \"Sospechoso\"))\n\n\n\n\n\n\n\n\n\n\nUtilizar tabyl() en general, y también la tabulación cruzada por enfermedad para responder a las siguientes preguntas.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuántos casos en los datos de notificación unidos no tenían un resultado positivo ni negativo?\n\n 202 347 250\n\n¿Qué porcentaje de casos en los datos de notificación SÍ tenían un resultado positivo o negativo?\n\n 60.1% 79.5% 92.2%\n\n¿Por qué hay más casos sospechosos restantes que notificaciones no enlazadas?\n\n Los casos sospechosos incluyen notificaciones sin resultado de laboratorio y con un resultado de laboratorio indeterminado Se están incorporando casos sospechosos adicionales desde el laboratorio Hay un problema con los datos\n\n¿Qué enfermedad tuvo el mayor porcentaje de casos que permanecieron como sospechosos después de la unión?\n\n Cólera Paludismo Dengue Fiebre amarilla\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡intente hacerlo primero!)\n\n\n\n\n\nUna vez más se puede utilizar tabyl() para observar la distribución de las categorías de casos en las notificaciones. El número total de casos sospechosos, es decir, aquellos sin resultado de laboratorio o con un resultado indeterminado, es de 202. Esto significa que 785 casos, es decir, el 79.5%, sí contaron con un resultado de laboratorio concluyente.\n\ntabyl(datos_unidos, categoria_casos) \n\n categoria_casos   n   percent\n      Confirmado 438 0.4437690\n      Descartado 347 0.3515704\n      Sospechoso 202 0.2046606\n\n\nTambién se puede realizar una tabla de contingencia entre los resultados originales (indeterminado/negativo/positivo) en la columna valor y la nueva columna categoria_casos, primero para comprobar que la lógica haya funcionado correctamente y, además, para visualizar cómo se asignaron los valores originales a las nuevas categorías. Esto muestra que, además de las 129 notificaciones que no fueron unidas (con NA en la columna valor), 73 tuvieron resultados indeterminados, por lo que fueron clasificadas como casos sospechosos.\n\ntabyl(datos_unidos, categoria_casos, valor) \n\n categoria_casos Indeterminado Negativo Positivo NA_\n      Confirmado             0        0      438   0\n      Descartado             0      347        0   0\n      Sospechoso            73        0        0 129\n\n\nFinalmente, también se puede realizar una tabla de contingencia con el nombre de la enfermedad para observar las categorías de caso por enfermedad. Es posible añadir funciones adicionales adorn_xxx() para aplicar un formato porcentual. La tabla muestra que el 22% de los casos de fiebre amarilla permanecieron como sospechosos, lo cual representó el porcentaje más alto en comparación con las demás enfermedades.\n\ntabyl(datos_unidos, enfermedad_notificada, categoria_casos) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n enfermedad_notificada  Confirmado  Descartado  Sospechoso        Total\n                colera 82.6%  (38)  4.3%   (2) 13.0%   (6) 100.0%  (46)\n                dengue 68.1% (186) 10.6%  (29) 21.2%  (58) 100.0% (273)\n       fiebre amarilla 33.0%  (33) 45.0%  (45) 22.0%  (22) 100.0% (100)\n       fiebre tifoidea 20.0%   (7) 68.6%  (24) 11.4%   (4) 100.0%  (35)\n             paludismo 32.6% (174) 46.3% (247) 21.0% (112) 100.0% (533)\n                 Total 44.4% (438) 35.2% (347) 20.5% (202) 100.0% (987)\n\n\n\n\n\n\n\n\nUtilice tabyl() para ello una vez más, observando los resultados por enfermedad. ¡Piense en el denominador correcto!\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué porcentaje de los casos sospechosos notificados en 2024 fueron casos verdaderos, según sus resultados de laboratorio?\n\n 44% 56% 59%\n\n¿Qué porcentaje de los casos sospechosos de paludismo fueron realmente paludismo?\n\n 86% 41% 23%\n\n¿Qué porcentaje de los casos sospechosos de dengue fueron realmente dengue?\n\n 87% 41% 23%\n\n\n\n\n\n\n\n\n\n\nHaga clic para leer una pista\n\n\n\n\n\nDividir el número de casos confirmados (es decir, aquellos con un resultado positivo) entre el número de casos confirmados más los descartados (es decir, aquellos con resultado positivo o negativo). Esto genera una tasa de positividad, que aproxima el porcentaje de casos sospechosos que realmente fueron casos. Los resultados indeterminados se excluyen porque no aportan un desenlace claro y distorsionarían la tasa de positividad.\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡intente hacerlo primero!)\n\n\n\n\n\nFiltrar los casos sospechosos y luego realizar una tabla de contingencia, para observar el porcentaje de casos inicialmente sospechosos que se convierten en confirmados o descartados, entre aquellos con resultados válidos.\nDado que existe una fila de totales, se puede ver que, en general, el 56% de los casos sospechosos terminaron confirmados, entre aquellos con resultado válido. También se observa que el 41% de los casos de paludismo y el 87% de los casos de dengue fueron confirmados.\n\ndatos_unidos |&gt; \n  filter(categoria_casos != \"Sospechoso\") |&gt; \n  tabyl(enfermedad_notificada, categoria_casos) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n enfermedad_notificada  Confirmado  Descartado        Total\n                colera 95.0%  (38)  5.0%   (2) 100.0%  (40)\n                dengue 86.5% (186) 13.5%  (29) 100.0% (215)\n       fiebre amarilla 42.3%  (33) 57.7%  (45) 100.0%  (78)\n       fiebre tifoidea 22.6%   (7) 77.4%  (24) 100.0%  (31)\n             paludismo 41.3% (174) 58.7% (247) 100.0% (421)\n                 Total 55.8% (438) 44.2% (347) 100.0% (785)\n\n\n\n\n\n\n\n\n\nTarea A: Crear una nueva linelist llamada datos_unidos_confirmados.\nEsto es lo que se utilizará en los informes oficiales de vigilancia.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Por qué estamos optando por reportar solo casos confirmados en nuestros datos de vigilancia?\n\n Reportar casos confirmados puede ser más confiable y preciso cuando el porcentaje de pruebas positivas es bajo y las pruebas de laboratorio son rutinarias, ayudando así a prevenir la sobreestimación de la carga de enfermedad Reportar casos confirmados es más lento, lo que nos da más tiempo para estar seguros de lo que estamos reportando Porque queremos ocultar el número real de casos\n\n¿Qué función es importante para crear la nueva lista de casos (linelist)?\n\n filter() arrange() mutate()\n\n¿Cuántas filas hay en esta nueva base de datos?\n\n 389 438 858\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡intente hacerlo primero!)\n\n\n\n\n\nLa unidad de vigilancia desea centrarse en los casos confirmados en los informes. Esto se debe a que las pruebas de laboratorio son de rutina en Feveria y, por lo tanto, informar los casos sospechosos sería innecesariamente inexacto, ya que un alto porcentaje de estos terminan siendo descartados.\nLa decisión de publicar casos sospechosos puede ser diferente en otros contextos. Por ejemplo, si la tasa de positividad es alta (la mayoría de los casos resultan ser verdaderos al realizar la prueba), y las pruebas no son frecuentes o tardan mucho en realizarse, lo que retrasaría la notificación, se recomendaría que las tendencias de casos sospechosos fueran suficientemente precisas y más oportunas que esperar la confirmación de laboratorio.\nCrear la nueva linelist con la función filter():\ndatos_unidos_confirmados &lt;- datos_unidos |&gt; \n  filter(categoria_casos==\"Confirmado\")\nY compruebe el número de filas consultando la información de su Entorno, o con nrow():\nnrow(datos_unidos_confirmados)\n[1] 438"
  },
  {
    "objectID": "pages/multidisease_surveillance.es.html#paso-7.-análisis-descriptivo-de-los-casos-confirmados",
    "href": "pages/multidisease_surveillance.es.html#paso-7.-análisis-descriptivo-de-los-casos-confirmados",
    "title": "Vinculación y análisis de datos de notificación y datos de laboratorio en R",
    "section": "",
    "text": "Ahora que ya tiene la lista de casos confirmados de enfermedades de notificación obligatoria reportados en Feveria en 2024, está listo o lista para llevar a cabo la parte final de su análisis de vigilancia. Se trata de resumir las cinco enfermedades de notificación obligatoria por zonas geográficas y por épocas.\nSugerencia Normalmente, el análisis de vigilancia también incluye el análisis por persona. Podría ampliar este estudio de caso analizando también los casos por variables demográficas.\n\n\n\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Qué enfermedad de notificación obligatoria se reportó con mayor frecuencia en 2024, al restringirse solo a los casos confirmados?\n\n Dengue Paludismo Fiebre amarilla\n\n¿Por qué la enfermedad más reportada es diferente al comparar los casos confirmados con los sospechosos?\n\n La sensibilidad y especificidad del diagnóstico clínico pueden variar según la enfermedad El desempeño de las pruebas utilizadas en el laboratorio puede variar según la enfermedad Puede haber sesgos en la notificación ¡Todas las anteriores!\n\n¿Qué distrito reportó el mayor número de casos confirmados de cólera en 2024?\n\n Lago Minara Feveria Central Kasara\n\n¿Cuántos casos confirmados de cólera reportados en 2024 correspondieron a residentes de Feveria Central?\n\n 35 42 4\n\n¿Qué distrito reportó el mayor número de casos confirmados de paludismo en 2024?\n\n Lago Minara Feveria Central Kasara\n\n¿Confirman estos datos que el dengue es la enfermedad infecciosa más común en Feveria?\n\n No - otra enfermedad puede estar subnotificada o no ser de notificación obligatoria Sí - si es la más reportada entonces debe ser la más común\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡inténtelo usted primero!)\n\n\n\n\n\nUtilizando tabyl() podemos ver que el dengue fue la enfermedad más reportada en Feveria en 2024 cuando se restringe a casos confirmados, con 186 casos.\n\ndatos_unidos_confirmados |&gt; \n  tabyl(enfermedad_notificada) \n\n enfermedad_notificada   n    percent\n                colera  38 0.08675799\n                dengue 186 0.42465753\n       fiebre amarilla  33 0.07534247\n       fiebre tifoidea   7 0.01598174\n             paludismo 174 0.39726027\n\n\nNótese que esto es diferente a los casos sospechosos, ¡donde el paludismo fue la enfermedad más reportada (con 533 casos sospechosos)! Esto ya se insinuó anteriormente, cuando observamos que la tasa de positividad de los casos sospechosos de dengue era mayor que la de los casos sospechosos de paludismo. Esto puede deberse a diferentes razones, por ejemplo, el método de diagnóstico clínico utilizado para el paludismo puede ser menos específico (lo que podría significar que muchos de los casos sospechosos en realidad se deban a otras enfermedades), o bien la prueba utilizada para el dengue puede ser más sensible.\nPara realizar una tabulación cruzada con el distrito residencial, añada las funciones adorn_xxx().\n\ndatos_unidos_confirmados |&gt; \n  tabyl(enfermedad_notificada, distrito_residencial) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n enfermedad_notificada Feveria Central     Kasara Lago Minara        Total\n                colera      92.1% (35)  7.9%  (3)  0.0%   (0) 100.0%  (38)\n                dengue       8.6% (16) 17.2% (32) 74.2% (138) 100.0% (186)\n       fiebre amarilla       0.0%  (0) 18.2%  (6) 81.8%  (27) 100.0%  (33)\n       fiebre tifoidea      71.4%  (5) 28.6%  (2)  0.0%   (0) 100.0%   (7)\n             paludismo      14.9% (26) 22.4% (39) 62.6% (109) 100.0% (174)\n                 Total      18.7% (82) 18.7% (82) 62.6% (274) 100.0% (438)\n\n\nAl igual que con los casos sospechosos, podemos ver que la mayoría de los casos confirmados de dengue, paludismo y fiebre amarilla se localizaron en el Lago Minara, la zona lacustre con mayor densidad de mosquitos y, por lo tanto, de enfermedades transmitidas por vectores. La mayoría de los casos confirmados de cólera y fiebre tifoidea se observaron en Feveria Central, donde hay problemas de agua y saneamiento.\nLos datos sugieren que las enfermedades transmitidas por vectores (dengue y paludismo) son especialmente preocupantes en este país tropical. Sin embargo, no sabemos con certeza cuál es la enfermedad más común ni cuáles son los patrones subyacentes: sólo cinco enfermedades son de notificación obligatoria, y normalmente los casos notificados sólo representan una fracción de los casos reales en la comunidad.\n\n\n\n\n\n\n\nProducirá esta curva epidémica en las siguientes tareas distintas.\n\n\n\n\n\n\n\n\n\n\n\nAsegúrese de especificar el argumento binwidth=7 para que cada barra del histograma represente el número de casos en un periodo de 7 días.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuándo se reportó el primer caso de fiebre tifoidea en Feveria en 2024?\n\n Enero 2024 Mayo 2024 Octubre 2024\n\nSegún este gráfico, ¿cuál fue el mayor número de casos de dengue reportados en una sola semana en 2024?\n\n 10 20 30 ¡Es muy difícil saberlo según este gráfico apilado!\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡inténtelo usted primero!)\n\n\n\n\n\nEste es un código sencillo para producir la curva epidémica. Tenga en cuenta que aún no especificamos los colores ni en qué día de la semana comienza cada período de 7 días.\n\ndatos_unidos_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = fecha_notificada, fill = enfermedad_notificada)), binwidth=7)\n\n\n\n\n\n\n\n\nConsulte el capítulo de Trabajando con Fechas en el Manual de R para Epis si desea un formato de fecha más específico o que el eje x indique el número de semana (semanas 1 a 52).\nImportante: ¡no es fácil ver las tendencias por enfermedad cuando se grafican apiladas de esta forma! Para visualizar estas tendencias temporales, debe producir un histograma para cada enfermedad.\n\n\n\n\n\n\nUtilice facet_wrap() para crear fácilmente pequeños gráficos multiples, uno por enfermedad. Para entender mejor la función, puede consultar la página Facetas del capítulo sobre ggplot2 en el Manual de R para Epis.\n\n\n\n\n\n\nPreguntas\n\n\n\n\nSegún este gráfico facetado, ¿cuál fue el mayor número de casos notificados de dengue en una sola semana en 2024?\n\n 11 15 29 ¡Todavía no lo puedo determinar!\n\n¿En qué distritos residían los casos de dengue notificados en esa semana?\n\n Los tres distritos Feveria Central Kasara Lago Minara Este gráfico no muestra esa información\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡inténtelo usted primero!)\n\n\n\n\n\nAhora puede ver una curva epidémica por enfermedad. Y puede ver que durante una semana de julio se notificaron 15 casos de dengue. Sin embargo, este gráfico aún no muestra ninguna información geográfica.\n\ndatos_unidos_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = fecha_notificada)), binwidth=7) + \n  facet_wrap(.~enfermedad_notificada)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿En qué distrito residían los 15 casos de dengue notificados en una semana de julio de 2024?\n\n Los tres distritos Feveria Central Kasara Lago Minara\n\n¿En qué distrito se notificó el primer caso de fiebre tifoidea en 2024?\n\n Kasara Feveria Central Lago Minara ¡Todavía no lo puedo determinar!\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡inténtelo usted primero!)\n\n\n\n\n\nAhora puede ver una curva epidémica por enfermedad, con la coloración que refleja el distrito en el que reside el caso.\nSe puede ver que los 15 casos notificados de dengue en una sola semana vivían en tres distritos diferentes. También puede ver que el primer caso de fiebre tifoidea se registró en Feveria Central.\n\ndatos_unidos_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = fecha_notificada, fill = distrito_residencial)), binwidth=7) + \n  facet_wrap(.~enfermedad_notificada)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPuede especificar:\n\nEl tema o diseño predeterminado del gráfico general (por ejemplo, color de fondo, aspecto de las líneas de la cuadrícula)\nEl título y las etiquetas\nLos colores de las barras (con scale_fill_manual())\nEl formato y espaciado de las fechas a lo largo del eje x (con scale_x_date)\n¡Muchas otras cosas!\n\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿El cólera y la fiebre tifoidea parecen endémicas?\n\n No - los datos sugieren brotes pequeños y ocasionales Sí los dos son endémicos\n\n¿Hubo un periodo particular del año en que el paludismo alcanzó su pico en 2024?\n\n Sí - alrededor de noviembre/diciembre Sí - alrededor de julio/agosto (verano) No, se mantuvo constantemente alto\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡inténtelo usted primero!)\n\n\n\n\n\nAquí está el código completo. Puede ver que este ejemplo contiene modificaciones adicionales. Por un lado, dentro de facet_wrap() se ha especificado que el panel tenga dos columnas. Por el otro, dentro de scale_x_date() se ha especificado que se muestre solo el día y el mes en el eje x.\n\ndatos_unidos_confirmados |&gt; \n  ggplot()+\n  geom_histogram((aes(x = fecha_notificada, fill = distrito_residencial)), binwidth=7) +\n  facet_wrap(.~enfermedad_notificada, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"Distrito residencial\",\n       x = \"Fecha notificada por el centro de salud\",\n       y = \"Recuento\",\n       subtitle = \"Número de casos confirmados de cólera, dengue, paludismo, fiebre tifoidea, y fiebre amarilla por semana en Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n\n\n\n\n\n\nTambién podemos observar en la curva epidémica que el cólera y la fiebre tifoidea parecen presentarse como brotes aislados, en lugar de mostrar endemicidad. El paludismo y el dengue, sin embargo, estuvieron presentes en Feveria durante todo el año, con un pico de paludismo más evidente en los meses de verano.\n\n\n\n\n\n\nEsta vez, utilice group_by() y summarize() para producir una tabla por distrito que muestre las fechas más tempranas y más tardías de las notificaciones.\nPuede ajustar la tabla con filter() para crearla para un distrito a la vez.\n\n\n\n\n\n\nPreguntas\n\n\n\n\n¿Cuándo se notificó el primer caso de dengue en Feveria en 2024?\n\n 18 de enero 2024 17 de enero 2024 12 de febrero 2024\n\n¿Cuándo se notificó el último caso de dengue en Feveria Central en 2024?\n\n 22 de agosto 2024 18 de noviembre 2024 25 de diciembre 2024\n\n\n\n\n\n\n\n\n\n\nHaga clic para ver la solución (¡inténtelo usted primero!)\n\n\n\n\n\nAgrupe los datos por enfermedad y luego extraiga la primera y la última fecha para ver la cronología general de cada enfermedad en Feveria.\n\ndatos_unidos_confirmados |&gt; \n  group_by(enfermedad_notificada) |&gt; \n  summarize(primer_reporte = min(fecha_notificada), \n            ultimo_reporte = max(fecha_notificada)) |&gt;\n  ungroup()\n\n# A tibble: 5 × 3\n  enfermedad_notificada primer_reporte ultimo_reporte\n  &lt;chr&gt;                 &lt;date&gt;         &lt;date&gt;        \n1 colera                2024-06-03     2024-09-23    \n2 dengue                2024-01-17     2024-11-18    \n3 fiebre amarilla       2024-03-08     2024-08-23    \n4 fiebre tifoidea       2024-05-02     2024-11-07    \n5 paludismo             2024-01-08     2024-12-25    \n\n\nAñada filter() al código para obtener las fechas de “Feveria Central”.\n\ndatos_unidos_confirmados |&gt; \n  filter(distrito_residencial == \"Feveria Central\") |&gt; \n  group_by(enfermedad_notificada) |&gt; \n  summarize(primer_reporte = min(fecha_notificada), \n            recent_reported = max(fecha_notificada)) |&gt;\n  ungroup()\n\n# A tibble: 4 × 3\n  enfermedad_notificada primer_reporte recent_reported\n  &lt;chr&gt;                 &lt;date&gt;         &lt;date&gt;         \n1 colera                2024-06-03     2024-09-23     \n2 dengue                2024-01-29     2024-08-22     \n3 fiebre tifoidea       2024-05-02     2024-11-07     \n4 paludismo             2024-01-29     2024-12-17"
  },
  {
    "objectID": "pages/multidisease_surveillance.es.html#conclusión",
    "href": "pages/multidisease_surveillance.es.html#conclusión",
    "title": "Vinculación y análisis de datos de notificación y datos de laboratorio en R",
    "section": "",
    "text": "¡Vaya! De acuerdo con los objetivos de este estudio de caso, usted ha hecho lo siguiente:\n\nHa utilizado funciones clave de R para limpiar, procesar y unir bases de datos, además de crear nuevas columnas utilizando condiciones lógicas.\nPara tomar decisiones sobre el procesamiento de datos, ha realizado inspecciones y comprobaciones de los datos.\nRealizó un análisis descriptivo exhaustivo para comprender las notificaciones y los datos de laboratorio, antes y después de unirlos. En relación a las cuatro preguntas originales de su supervisor, puede decir:\n\n¿Cuántos casos sospechosos de las diferentes enfermedades de notificación obligatoria se reportaron en 2024, y cuál fue la más frecuente? Según los registros del sistema de vigilancia de enfermedades de notificación obligatoria, el paludismo fue la enfermedad más común en Feveria en 2024: 533 casos sospechosos de paludismo, 273 casos sospechosos de dengue, 100 de fiebre amarilla, 46 de cólera y 35 de fiebre tifoidea.\n¿Qué porcentaje de ellos acabo confirmándose? Casi el 80% de los casos de notificación obligatoria reportados en 2024 tenían un resultado de pruebas de laboratorio en el momento en que se creó la base de datos, con algunas variaciones según la enfermedad. En total, el 56% de los casos notificados acabaron confirmándose, pero este porcentaje osciló entre sólo el 23% en el caso de la fiebre tifoidea (7 casos confirmados de 31 sospechosos) y el 95% en el caso del cólera (38 casos confirmados de 40 sospechosos). Además, la tasa de positividad fue mayor en los casos sospechosos de dengue que en los de paludismo (87% frente a 41%).\n¿Cuántos casos confirmados de las diferentes enfermedades de notificación obligatoria se reportaron en 2024, y cuál fue la más frecuente? Los casos confirmados siguieron una tendencia ligeramente diferente a la de los casos sospechosos: la infección notificada con más frecuencia fue el dengue, con 186 casos, seguido por el paludismo (174), el cólera (38), la fiebre amarilla (33) y la fiebre tifoidea (7).\n¿Cómo se distribuyeron geográfica y temporalmente los casos confirmados en Feveria? Feveria experimentó transmisión de dengue y paludismo durante todo el año, con un pico en verano, y se concentró en el distrito de Lago Minara. También se registraron brotes pequeños y poco frecuentes de enfermedades diarreicas, como el cólera y la fiebre tifoidea, sobre todo en la zona urbana de Feveria Central, donde podrían existir problemas de agua y saneamiento.\n\nPor último, ha reflexionado sobre cómo la calidad y exhaustividad de los datos están determinados por procesos inherentes a la transferencia de los mismos entre los sistemas de vigilancia y los laboratorios.\n\nTiene un gran potencial por delante. Puede utilizar datos de vigilancia para explorar patrones por edad o sexo, calcular tasas con datos poblacionales e incluso analizar retrasos en la notificación al comparar las diferentes fechas en su base de datos.\nHa construido una base sólida y tiene las herramientas óptimas para llevar su análisis al siguiente nivel. Siga adelante: ¡le esperan descubrimientos emocionantes!\nPara profundizar, consulte los demás estudios de casos o explore el Manual de R para Epis."
  },
  {
    "objectID": "pages/multidisease_surveillance.es.html#código-de-limpieza-y-análisis-de-datos",
    "href": "pages/multidisease_surveillance.es.html#código-de-limpieza-y-análisis-de-datos",
    "title": "Vinculación y análisis de datos de notificación y datos de laboratorio en R",
    "section": "",
    "text": "A continuación encontrará un script con todos los pasos para la limpieza de datos y el análisis descriptivo. Observe cómo los análisis se incluyen al final, en vez de intercalarse entre los pasos de limpieza. Esta es una forma más ordenada de organizar el script.\nPor motivos de brevedad, el código que aparece a continuación no incluye todas las inspecciones y comprobaciones realizadas durante el proceso, pero si desea puede crear una sección con dichas comprobaciones.\nLa parte superior de su script también debería contener información para ayudar al lector a entender cuál es el propósito del script, así como comentarios a lo largo del mismo. Más adelante se agradecerá haber añadido estos comentarios.\n\n\n\n\n\n\nCódigo para limpiar y analizar los datos de notificación y los datos de laboratorio de Feveria, 2024\n\n\n\n\n\n\n# Código para limpiar y analizar los datos de notificación y de laboratorio de Feveria, 2024\n# Fecha:\n# Elaborado por:\n\n# Instalar paquetes -------------------------------------------------\n# Asegurarse que el paquete \"pacman\" está instalado\nif (!require(\"pacman\")) {\n  install.packages(\"pacman\") }\n\n# Instalar (si es necesario) desde CRAN y cargar los paquetes necesarios\npacman::p_load(\n  rio,        # para importar datos  \n  skimr,      # para revisar los datos\n  janitor,    # para limpieza de datos y crear tablas \n  lubridate,  # para limpieza de fechas\n  epikit,     # para crear grupos de edad \n  gtsummary,  # para generar resúmenes estadísticos, pruebas y regresiones\n  apyramid,   # para graficar pirámides de edad  \n  flextable,  # para crear tablas listas para presentar \n  naniar,     # para evaluar los datos faltantes\n  remotes,    # para instalar paquetes necesarios para descargar datos \n  tidyverse   # para gestión y visualización de datos \n)\n\n# Importar datos --------------------------------------------\n\n# Datos de notificación \ndatos_notif_crudos &lt;- import(\"datos/notificaciones_multienfermedad.xlsx\")\n\n# Datos de laboratorio\ndatos_lab_crudos &lt;- import(\"datos/pruebas_multienfermedad.csv\")\n\n# Limpiar datos de notificación --------------------------------\ndatos_notif &lt;- datos_notif_crudos |&gt; \n  clean_names() |&gt; names()\n  rename(\n    fecha_notificada = fecha_notificada_por_el_centro_de_salud_la_comunidad,\n    id_notificacion = id_de_notificacion) |&gt;\n  select(id_notificacion, distrito_residencial, enfermedad_notificada, fecha_notificada) |&gt; \n  mutate(distrito_residencial = case_match(\n    str_to_title(distrito_residencial),\n    c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n    c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n    c(\"L Minara\", \"Lago Minara\", \"Lakeside\") ~ \"Lago Minara\")) |&gt; \n  mutate(fecha_notificada = ymd(fecha_notificada)) \n\n\n# Limpiar datos de laboratorio ---------------------------------\n# Limpiar los valores\ndatos_lab &lt;- datos_lab_crudos |&gt; \n  mutate(valor = case_match(valor, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positivo\",\n                            \"N\" ~ \"Negativo\",\n                            \"I\" ~ \"Indeterminado\"))\n\n# Crear datos de laboratorio a nivel de prueba \ndatos_lab_pruebas &lt;- datos_lab |&gt; \n  filter(objetivo != \"Dengue IgG\") |&gt; \n  group_by(id_muestra) |&gt; \n  arrange(desc(valor)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Crear datos de laboratorio a nivel de caso\ndatos_lab_casos &lt;- datos_lab_pruebas |&gt; \n  group_by(id_notificacion) |&gt; \n  arrange(desc(valor)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Unir datos de notificación y de laboratorio  ----------------------------\ndatos_unidos &lt;- left_join(datos_notif, datos_lab_casos, by = \"id_notificacion\")\n\n# Limpiar base de datos unificada -----------------------------------------\ndatos_unidos &lt;- datos_unidos |&gt; \n  mutate(categoria_casos = case_when(\n    valor==\"Positivo\" ~ \"Confirmado\",\n    valor==\"Negativo\" ~ \"Descartado\",\n    valor==\"Indeterminado\" | is.na(valor) ~ \"Sospechoso\"))\n\ndatos_unidos_confirmados &lt;- datos_unidos |&gt; \n  filter(categoria_casos==\"Confirmado\")\n\n# ANÁLISIS ---------------------------------------------------------\n# Número de casos sospechosos en Feveria \ntabyl(datos_notif, enfermedad_notificada)\n\n# Distribución de casos sospechosos por distrito \ntabyl(datos_notif, enfermedad_notificada, distrito_residencial) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n# Distribución de los resultados por prueba especifíca de cada enfermedad \ntabyl(datos_lab_pruebas, prueba, valor) |&gt; \n  adorn_totals(where = \"col\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n# Distribución de la categoria de caso, en la base de datos unificada \ntabyl(datos_unidos, categoria_casos) \n\n# Distribución de la categoria de caso por enfermedad, en la base de datos unificada\ntabyl(datos_unidos, enfermedad_notificada, categoria_casos) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n# Distribución de la categoria de caso por enfermedad, en la base de datos unificada: \n# solo casos con un resultado válido\ndatos_unidos |&gt; \n  filter(categoria_casos != \"Sospechoso\") |&gt; \n  tabyl(enfermedad_notificada, categoria_casos) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n# Distribución de casos confirmados por distrito \ndatos_unidos_confirmados |&gt; \n  tabyl(enfermedad_notificada, distrito_residencial) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n# Visualizar casos confirmados a lo largo del tiempo \ndatos_unidos_confirmados |&gt; \n  ggplot() +\n  geom_histogram(\n    aes(x = fecha_notificada, fill = distrito_residencial), \n    binwidth=7\n  ) +\n  facet_wrap(.~enfermedad_notificada, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"Distrito residencial\",\n       x = \"Fecha notificada por el centro de salud\",\n       y = \"Recuento\",\n       subtitle = \"Número de casos confirmados de cólera, dengue, paludismo, fiebre tifoidea, y fiebre amarilla por semana en Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n# Primera y última fecha de notificación por enfermedad \ndatos_unidos_confirmados |&gt; \n  group_by(enfermedad_notificada) |&gt; \n  summarize(primer_reporte = min(fecha_notificada), \n            ultimo_reporte = max(fecha_notificada)) |&gt;\n  ungroup()"
  },
  {
    "objectID": "pages/multidisease_surveillance.es.html#información-sobre-casos-de-estudio",
    "href": "pages/multidisease_surveillance.es.html#información-sobre-casos-de-estudio",
    "title": "Vinculación y análisis de datos de notificación y datos de laboratorio en R",
    "section": "",
    "text": "Autores originales Paula Blomquist y Alanah Jansen, con el apoyo técnico de la Subdivisión de Vigilancia Mundial, Laboratorios y Sistemas de Datos de los CDC, en colaboración con TEPHINET.\nFuente de datos Datos ficticios proporcionados por Applied Epi.\n\n\n\n\n\n\n\n\n\n\n\n\nFecha\nCambios realizados\nVersión\nAutor\n\n\n\n\nJulio 2025\nPrimer borrador\n1\nPaula Blomquist y Alanah Jansen, Applied Epi, con el apoyo técnico de la Subdivisión de Vigilancia Mundial, Laboratorios y Sistemas de Datos de los CDC, en colaboración con TEPHINET.\n\n\nAgosto 2025\nVersión en español\n1\nLuis Quezada, Martin Lotto y Shazia Ruybal"
  },
  {
    "objectID": "pages/multidisease_surveillance.es.html#condiciones-de-uso",
    "href": "pages/multidisease_surveillance.es.html#condiciones-de-uso",
    "title": "Vinculación y análisis de datos de notificación y datos de laboratorio en R",
    "section": "",
    "text": "Descargo de responsabilidad La información presentada en este ejercicio y los archivos de datos asociados se han elaborado para ayudar al alumnado a alcanzar los objetivos de aprendizaje previstos. El contenido es responsabilidad de los autores y no refleja necesariamente la opinión oficial de los CDC, del Departamento de Salud y Servicios Humanos de EE. UU. o de TEPHINET.\nLicencia: Este estudio de caso está bajo una licencia CC BY-NC-SA 4.0. Para obtener más información sobre cómo compartir y adaptar este estudio de caso, consulte la página escritura asociada.\nFinanciación Este estudio de caso fue financiado al 100% por el Acuerdo de Cooperación número NU2HGH000044 financiado por los Centros para el Control y la Prevención de Enfermedades (CDC) de EE.UU."
  },
  {
    "objectID": "pages/multidisease_surveillance.html",
    "href": "pages/multidisease_surveillance.html",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Tool: R Technical complexity: Intermediate Methodological complexity: Basic\nPrior knowledge required: R basics (Using Rstudio; R packages, functions and arguments, using pipes) as well as key tidyverse functions and ggplots).\nSource: Applied Epi, with technical support provided by the CDC Global Surveillance, Laboratory, and Data Systems Branch in collaboration with TEPHINET.\n\n\n\nFor instructions on how to use our case studies, see our How-to Guide. We welcome feedback and suggestions via contact@appliedepi.org. You can also discuss the case study or related concepts on the Applied Epi Community.\n\n\n\nYou are an epidemiologist working in the national surveillance office of Feveria, a very small tropical country. There are three districts within Feveria:\n\nFeveria Central: an over-populated urban area, with sometimes unreliable water and sanitation infrastructure.\nLake Minara: a lake area with good infrastructure but many mosquitoes in the warmer months of the year.\nKasara: a more sub-urban area on the other side of Feveria Central.\n\nMap of districts in the country Feveria\n\nIt is January 2025, and your supervisor would like you to transfer the routine processing of notifiable disease data from Excel into R, and to conduct some analyses on the data. She wants to know at least:\n\nHow many suspected cases of the different notifiable diseases were reported in 2024, and which was most common?\nWhat percentage of them ended up being confirmed?\nHow many confirmed cases of different notifiable diseases were reported in 2024, and which was most common?\nHow were confirmed cases geographically and temporally distributed in Feveria?\n\nShe asks that you write code to import, clean, link, and analyse the following linelists:\n\n2024 notifiable disease surveillance data: Referred to also as “notification data”, this is surveillance data on five notifiable diseases reported by clinics in Feveria: dengue, malaria, cholera, typhoid fever, and yellow fever. These are suspected cases, based on patients’ symptoms. Clinicians enter each notification into an online system every weekday.\n2024 laboratory test result data: This data comes from lab test results, from three major labs in Feveria. These results are for samples taken from those suspected notifiable disease cases mentioned above.\n\nLet’s go!\n\n\n\nIn this case study you will:\n\nUse key R functions to clean data, reshape datasets, link data sources, and create new columns using logical conditions to prepare data for analysis.\nConduct data inspections and data quality checks at multiple stages of the project and understand their importance for reliable analysis.\nPerform basic descriptive analyses to compare disease trends across different data sources, before and after linkage.\nInterpret differences in results across data sources and understand how these reflect the structure and design of the overall surveillance system.\n\n\n\n\n\n\nStart by setting up a reproducible and well-organized workflow. This will make it easy to rerun your analysis whenever needed.\nTasks:\n\nSet up an RStudio project\nSet up clear sub-folders where your code, data, and outputs will go\nCreate an R script, or an R Markdown file if you prefer. Make sure the script purpose, date, and author are written as comments at the top.\nExtra: Ensure your working language in RStudio is appropriate (e.g. English for this exercise)\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\n\nCreate a folder where all the work in this case study will go. For example, create ‘multi_disease_lab’ on your computer desktop. Create your RStudio project to be based in this folder.\nWe suggest creating the following sub-folders: scripts (for your code), data (for your data), and outputs (for your analytical outputs).\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nCreate a folder (e.g. ‘multi_disease_lab’ on your Desktop) for your work. To create an Rstudio project in your new folder, click New Project… in the top left of your R Studio, then Existing Directory, then Browse to select your new folder. For more information, look at the R projects section of the Epi R Handbook.\nStart a new R script by clicking New File in the top left of your R Studio, then R Script. Save it immediately in the appropriate place, e.g. in a scripts sub-folder of your R Project.\nAt the top of your new R script, write some essential information like your name, the purpose of the file, and the date.\nYour R locale determines the language and regional settings used for things like date formats and translations. If your locale is different from the language you want for your report (e.g., a French locale vs. an English report), you can change it to English by running Sys.setlocale(\"LC_ALL\", \"English\"). Include this in your script if needed, or skip it if your locale is usually appropriate. This is explained in more detail in the How-to Guide.\n\n\n\n\n\n\nNext in your R script, you need to install and load the necessary R packages. This ensures that the functions you need are available for your analysis.\nYou will need the following packages: {rio} (for importing data),{skimr} (for reviewing data), {janitor} (for cleaning data), {lubridate} (for cleaning dates), {epikit} (for epi-related tasks), {gtsummary} (for summary statistics/tests and regression), {apyramid} (for age-sex pyramids), {flextable} (for presentation-ready tables), {naniar} (for evaluating missing data), and {tidyverse} (for general data manipulation/science tasks).\nYou will also need the {remotes} package to download the data - which we will explain in the download section.\nAs you start, your trusted colleague nudges you and whispers “I’ve heard that a great way to manage your packages is with the {pacman} package”.\nOver to you!\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse the function p_load() from pacman for this task. You provide the function with a list of packages that you want to use. The function will undertake two steps per package:\n\nCheck if the package is installed on your computer, and install it if necessary.\nLoad the package so it can be used during this R session.\n\nIf you don’t already have pacman installed, you will need to install it the “traditional way” first, with install.packages().\nNote that the order of packages in your p_load function can be important. If two packages have the same function names (e.g. select() in the package MASS and select() in tidyverse, which do different things), then R will use the function from the most recently loaded package. To prioritize functions from tidyverse, which are commonly used for data manipulation and visualization, load tidyverse last.\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  flextable,  # Presentation ready tables\n  naniar,     # Evaluating missingness of data\n  remotes,    # Used to install package to download data\n  tidyverse   # data management and visualization\n)\n\n\n\n\n\n\n\n\n\n\nYour office provides you with two files for your analysis, both containing data for 2024 and updated as of 15th January 2025:\n\nA disease notification-level dataset (“multidisease_notifications.xlsx”) with case information from 5 health centers.\nA laboratory test-level dataset (“multidisease_tests.csv”) submitted by three laboratories conducting testing for the 5 health centers.\n\nFor this case study, you can download the data via Applied Epi’s very useful data repository, which you can access using the {appliedepidata} package. Follow these steps:\n\nInstall the {appliedepidata} package from GitHub using the install_github() function in the {remotes} package (which you installed previously)\n\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nSave the two datasets into a specific folder using the save_data() function from {appliedepidata}, by running the code below. The example below saves the data into a data subfolder within the RStudio project. Note that if you do not specify a location within the path argument of the function, a window will pop up asking you to manually select a folder.\n\n\n# Save down the two data files using the save_data() function from appliedepidata\nappliedepidata::save_data(\"multidisease_tests\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"multidisease_notifications\",\n                          path = \"data\")\n\n\n\n\nGreat! Thanks country office and Applied Epi! Now it’s time to import the data from that folder into RStudio, so you can analyse it.\n\n\nIdeally, you will use the same function for importing both datasets, despite one being a .csv and the other an .xlsx file. Note going forward we will simply say “environment” when we mean the environment pane in R Studio.\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nUse the import function from the {rio} package, which can recognize and import different file types. It replaces importing functions that are specific to the file type, such as read.csv() from {base} for .csv files and read_excel() from {readxl} to import .xlsx files.\nIf you feel you need to know more about importing functions, read the Import and export chapter of the Epi R Handbook.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nBelow we use the import function to bring in both files. Note how we are assigning the imported data to two objects, one called data_notif_raw, and one called data_lab_raw. We add the ‘raw’ suffix to distinguish this data from the cleaned versions we will make later.\n\n# Import data\n\n# Notification data\ndata_notif_raw &lt;- import(\"data/multidisease_notifications.xlsx\")\n\n# Lab data\ndata_lab_raw &lt;- import(\"data/multidisease_tests.csv\")\n\n\n\n\n\n\n\n\n\nThe data’s in, and now it’s time to see what story it tells. Take an initial look at your two raw data frames to check their contents and quality.\n\n\n\n\nUse skim() from the {skimr} package, names(), ncol(), and nrow() to inspect your data frame.\nskim() gives you a lot of information on data structure and content, whereas names() will show you the different column names in your data. The ncol() and nrow() functions to simply count the numbers of columns and rows in the data. Do you know what to put inside the parentheses?\nEasiest of all though, is to look at the environment. Remember the object in your environment for the notification data is called data_notif_raw.\nClick on the solution box underneath the questions if you need help.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many columns are there in the notification data?\n\n 10 11 12 13\n\nWhich of these columns are NOT in the data?\n\n Onset date Date reported by Health Facility/Community Date of outcome Date of test Date of birth\n\nWhat is the name of the column in the notification data that identifies each notification?\n\n Notification ID Test ID Health facility code Combination of Notification ID and Sex\n\nHow many rows are there in the notification data?\n\n 987 1314 950 778\n\nWhat type of information can you NOT see in the notification data?\n\n Laboratory test results District of residence Birthday and sex Health facility in which the case was diagnosed Outcome\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse skim() from the {skimr} package to look at a summary of the entire data frame, and View() to look at the whole data frame directly:\n\nskim(data_notif_raw)\n\nOr, you could use names() to print out just the column names. Through either skim() or names() you will be able to see the types of information including: the health facility of the case, birth-date, sex, a flag indicating pregnancy, district of residence, onset date, and date reported by the clinic, and outcome information.\nThere is also a Notification ID which appears to be a unique identifier for a case, but we would want to double check duplicates before we are sure.\nNote that there are NO test results in this data, as these notifications are from clinics diagnosing notifiable diseases based on clinical case definitions.\n\nnames(data_notif_raw)\n\n [1] \"Organisation unit name\"                    \n [2] \"Health facility code\"                      \n [3] \"Notification ID\"                           \n [4] \"Date of Birth\"                             \n [5] \"Sex\"                                       \n [6] \"Pregnant\"                                  \n [7] \"Residential District\"                      \n [8] \"Disease notified\"                          \n [9] \"Onset date\"                                \n[10] \"Date reported by Health Facility/Community\"\n[11] \"Outcome\"                                   \n[12] \"Date of outcome\"                           \n\n\nUse ncol() and nrow() to print the number of columns and rows, like this:\n\nncol(data_notif_raw)\nnrow(data_notif_raw)\n\nThis will print the numbers of columns and rows in your console.\n\n\n[1] 12\n\n\n[1] 987\n\n\nOtherwise, when you look at the environment you can see that the number of observations (which is the same as rows) and columns are listed next to the name of the data frame.\n\n\n\n\n\n\nUse skim() from the {skimr} package or class() to inspect your column classes.\nDo you remember how to specify the column of interest inside the class() function? Alternatively, you can just look at the environment.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many columns in the notification data frame are recognised by R to be date columns?\n\n 0 2 4\n\nWhat is the class of most columns in the raw notification data frame?\n\n character numeric factor\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou can use class like the example below. The $ is an operator used to select a specific column from the data_notif_raw data frame.\nNote that the back-ticks (`) are used around Date of Birth because the column name contains spaces.\n\nclass(data_notif_raw$`Date of Birth`)\n\nTo look at class via the environment, click on the blue arrow next to the data frame name. The column names will appear, with the class next to it (e.g. it says “chr” to show character class).\nYou can see the none of the columns that should be dates are recognized as dates. Instead, they are recognized as character values.\n\n\n\n\n\n\nUse the tabyl() function to inspect the values within categorical columns, specifying the data frame object in the first argument, and the column name in the second argument.\nFor example, this code tabulates the values for the Sex column. The output shows that male and female are inconsistently spelled across the data. This column would need further cleaning before analysis.\n\ntabyl(data_notif_raw, Sex)\n\n    Sex   n    percent valid_percent\n      F  47 0.04761905    0.05452436\n FEMALE 146 0.14792300    0.16937355\n      M  40 0.04052685    0.04640371\n   MALE 172 0.17426545    0.19953596\n      f 154 0.15602837    0.17865429\n female  98 0.09929078    0.11368910\n      m 119 0.12056738    0.13805104\n   male  86 0.08713273    0.09976798\n   &lt;NA&gt; 125 0.12664640            NA\n\n\nTo inspect missingness, you can use the miss_var_summary() function from the {naniar} package:\n\nmiss_var_summary(data_notif_raw)\n\n# A tibble: 12 × 3\n   variable                                   n_miss pct_miss\n   &lt;chr&gt;                                       &lt;int&gt;    &lt;num&gt;\n 1 Onset date                                    691     70.0\n 2 Pregnant                                      510     51.7\n 3 Outcome                                       197     20.0\n 4 Date of outcome                               197     20.0\n 5 Date of Birth                                 168     17.0\n 6 Sex                                           125     12.7\n 7 Organisation unit name                          0      0  \n 8 Health facility code                            0      0  \n 9 Notification ID                                 0      0  \n10 Residential District                            0      0  \n11 Disease notified                                0      0  \n12 Date reported by Health Facility/Community      0      0  \n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nAre the values in the Residential District column standardized?\n\n No - they need cleaning They are standardized and are ready to be used for analysis\n\nAre the values in the Disease notified column standardized?\n\n No - they need cleaning They are standardized and are ready to be used for analysis\n\nWhat does R recognise as a missing value?\n\n Either no value, or just a space, or just a dot No value in a cell, represented with NA The words Unknown and Uncertain\n\nBased on the missingness of its values, is the Onset date column useful?\n\n Yes, the missingness is low so this column is useful Minimally, as the missingness is too high\n\nWhy might some columns in the notification data have different spellings and non-standardized categories?\n\n A bot scrambles the data so it becomes less identifiable Each clinic might use software that is configured slightly differently, or use free-text entries, so there are variations in spelling The surveillance system software used by the clinical settings has lots of bugs\n\nWhy might some columns in the notification data have high missingness?\n\n The clinician does not ask the patient the question during their consultation The patient might not know or want to share the answer The clinician might not have time to prioritise filling in that field in the data, even if they know the information All of the above, and many more reasons\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse the tabyl() function to tabulate the values within the Residential District column. Again, the first argument is the name of the data frame object, and the second argument is the name of the column.\n\ntabyl(data_notif_raw, `Residential District`)\n\n Residential District   n    percent\n            F Central  32 0.03242148\n            FEVERIA C  23 0.02330294\n      FEVERIA CENTRAL  85 0.08611955\n            Feveria C  24 0.02431611\n      Feveria Central  12 0.01215805\n               KASARA  64 0.06484296\n                  KSR  17 0.01722391\n               Kasara 109 0.11043566\n             L MINARA  50 0.05065856\n             L Minara 193 0.19554205\n          LAKE MINARA 185 0.18743668\n          Lake Minara  68 0.06889564\n             Lakeside 125 0.12664640\n\n\nYou can see that each of the three locations (Feveria Central, Lake Minara, and Kasara) are spelled in different ways and with different capitalization. This will need to be cleaned out if we want to analyse the geographic distribution of the notifiable diseases.\nSimilarly, use the tabyl() function to tabulate the values within the Disease notified column. You can see these are spelled out appropriately and consistently, so you can already see the distribution of rows by disease without further cleaning.\n\ntabyl(data_notif_raw, `Disease notified`)\n\n Disease notified   n    percent\n          cholera  46 0.04660588\n           dengue 273 0.27659574\n          malaria 533 0.54002026\n          typhoid  35 0.03546099\n     yellow fever 100 0.10131712\n\n\nA different way of checking missingness is to tabulate the output of the function is.na(). In the example below, the function is.na() evaluates each cell within the column Onset date, returning TRUE for missing ones and FALSE for present ones.\nRunning tabyl() on this TRUE/FALSE output then quickly gives you a clear count and percentage of both missing and non-missing values in that column. Remember, values like a space or the words “Unknown” or “Missing” will not be recognized by R as missing. R will only recognize true blanks as missing, represented by NA.\nFor Onset date, you can see that 70% of cases are missing onset date, suggesting that this column would not be particularly useful for analyzing trends in disease over time.\n\ntabyl(is.na(data_notif_raw$`Onset date`))\n\n is.na(data_notif_raw$`Onset date`)   n   percent\n                              FALSE 296 0.2998987\n                               TRUE 691 0.7001013\n\n\nMissing or non-standardized data can arise for many reasons, including:\n\nthe design of the data collection tool (e.g. whether questions are mandatory or use free text vs. drop-downs),\nthe processes and standards in place (such as which fields staff are instructed to prioritise), and\ncontextual factors (like whether staff have sufficient time to gather the information).\n\n\n\n\n\n\n\n\n\n\nLike with the notification data, use skim(), ncol(), and nrow() functions or check the environment to inspect the lab data.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich linelist has more columns - the notification data or the laboratory data?\n\n Lab data Notification data They have the same number of columns\n\nWhich linelist has more rows?\n\n Lab data Notification data They have the same number of rows\n\nInspect the lab data with View(). Why might the lab data have more records?\n\n There may be several tests or targets per sample There are so many trial test results in the data Not all the notifications have test results yet\n\nWhich of these columns are NOT in the lab data?\n\n Notification ID Sample ID Test type Date of birth Test result\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nJust like in section 3.1, you can use skim() from the {skimr} package to look at the entire laboratory data frame with test results. This will also show you the different column names in the data, showing you that the lab data only contains information about the test and not about the patient. It does however also contain a notification ID, just like the notification data does.\n\nskim(data_lab_raw)\n\nUse ncol() and nrow() to print the number of columns and rows, like this:\n\nncol(data_lab_raw)\nnrow(data_lab_raw)\n\nThis will print the numbers of columns and rows in your console, showing you that the lab data has more rows than the notification data you inspected earlier.\n\n\n[1] 7\n\n\n[1] 1314\n\n\nThere are often more records in the lab data than in the clinical data. If you inspect the data with View(data_lab_raw) and then click on the arrow at the top of the notification_id column to sort it alphabetically, you’ll see that several rows share the same notification_id. This can happen when multiple targets are tested from the same sample (same sample ID), or when a case is retested (resulting in a different sample ID).\n\nView(data_lab_raw)\n\n\n\nlaboratory_namenotification_idsample_iddate_testtesttargetvalueFeveria General Hospitalf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue NS.1NFeveria General Hospitalf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgGNFeveria General Hospitalf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgMPFeveria General Hospital6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue NS.1NFeveria General Hospital6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgGNFeveria General Hospital6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgMP\n\n\n\n\n\n\n\n\nAs above, use the class(), skim(), or tabyl() functions, or inspect the environment, to look at your columns in more detail.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many columns in the laboratory data frame are recognised by R to be date columns?\n\n 0 1 2\n\nHow many columns in the laboratory data frame have complete data?\n\n 1 3 7 (all of them!)\n\nWhich test detects multiple targets (and therefore has multiple rows per sample)?\n\n Malaria Dengue Yellow Fever Cholera Typhoid Fever\n\nHow many possible test result values are there in the column value?\n\n 5 3 4\n\nWhat is NOT a possible test result for the stool culture test which detects V. cholerae bacteria?\n\n P P01 P0139 N I\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nThe laboratory data has one date column, recognized by R as an “IDate” class. This is a date class used by {rio}’s import() when reading csv files. Like base R’s Date class, it allows sorting by date and analyzing trends over time.\n\nclass(data_lab_raw$date_test)\n\n[1] \"IDate\" \"Date\" \n\n\nUse of the miss_var_summary() function from the {naniar} package demonstrates that all columns in the laboratory data are actually complete. This may be because the laboratory systems use automated processes, so are much less likely to have human error.\n(Important point: Note that in real life, the lab data would probably have some issues too!)\n\nmiss_var_summary(data_lab_raw)\n\n# A tibble: 7 × 3\n  variable        n_miss pct_miss\n  &lt;chr&gt;            &lt;int&gt;    &lt;num&gt;\n1 laboratory_name      0        0\n2 notification_id      0        0\n3 sample_id            0        0\n4 date_test            0        0\n5 test                 0        0\n6 target               0        0\n7 value                0        0\n\n\nTo see how many targets are detected by each test, you can cross-tabulate test and target columns with tabyl(). Write the column names into the function as two separate arguments. The output shows that each test clearly aligns with one or more targets, and only the dengue assay detects more than one target (IgG, IgM, and NS.1).\nTip: Experiment with changing the order of the column names in the function to see the impact on the table.\n\ntabyl(data_lab_raw, target, test)\n\n               target Blood culture Dengue NS1/IgG/IgM IgM ELISA Stool Culture\n           Dengue IgG             0                215         0             0\n           Dengue IgM             0                215         0             0\n          Dengue NS.1             0                215         0             0\n           Plasmodium             0                  0         0             0\n    S. Typhi bacteria            33                  0         0             0\n V. cholerae bacteria             0                  0         0            45\n     Yellow Fever IgM             0                  0        88             0\n Whole Blood Microscopy\n                      0\n                      0\n                      0\n                    503\n                      0\n                      0\n                      0\n\n\nFinally, you can inspect the different test result values in the column value, again using tabyl(). You can see that there are six possible results, including N for negative, P for positive, and I for indeterminate. Cholera specifically does not show P, but can show P01 and P0139, which in this case represent being positive for serogroups O1 or O139.\n\ntabyl(data_lab_raw, test, value)\n\n                   test  I   N   P PO1 PO139\n          Blood culture  2  24   7   0     0\n     Dengue NS1/IgG/IgM  0 354 291   0     0\n              IgM ELISA 10  45  33   0     0\n          Stool Culture  5   2   0  22    16\n Whole Blood Microscopy 56 257 190   0     0\n\n\n\n\n\n\n\n\n\n\nYou now know that the notification data (data_notif_raw) contains information about suspected cases, alongside basic demographic information (age, sex, pregnancy, district of residence), and information about their onset date, date reported by the health facility, and outcome. Some columns need cleaning before further analysis, due to variations in spelling of categorical values and some date columns not being recognized as dates.\nYou will now start writing longer chunks of code to clean data, using various {dplyr} functions chained together with pipes (which look like this: |&gt;).\nNOTE ON PIPES: Pipes allow you to perform several operations in one smooth sequence, by “chaining” different functions together. The output from one function becomes the input for the next.\nIf you need more information on piping, please refer to the Epi R Handbook.\nNote that this exercise uses the base pipe (|&gt;) rather than the magrittr pipe (%&gt;%), as it is faster and does not require package installation. Use the magrittr pipe if you prefer it.\n\n\n\n\nDue to quality and data storage issues, your team recommends that you create a clean linelist that only contains information on the unique identifier, location of the case, disease, and the date the notification was reported to the surveillance system.\nWrite R code to produce a new clean data frame called data_notif, applying the following cleaning tasks:\n\nRename columns to be more machine readable (remove spaces and capitalization) using clean_names() from the {janitor} package\nUse the rename() function from {dplyr} so that the column with the date the case was reported is changed to a more concise date_report.\n\nSelect relevant columns for analysis with the select() function from the {dplyr} package.\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nStart your code with the name of the new data frame, the assignment arrow, and the name of the raw data object. This shows that the outcome of the raw data processing will be assigned to a new object called data_notif.\n\ndata_notif &lt;- data_notif_raw\n\nThen build on this code by adding in additional functions, chained together with a pipe. This lets you perform several operations in one smooth sequence. First, you’ll use clean_names() to standardize all your column names. It automatically replaces spaces and special characters with underscores and converts everything to lowercase, making names easier to work with. Then, you can use rename() to give a column a new name. Just remember, when you use rename(), the column will already have its clean_names() version.\n\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(NEW_NAME = OLD_NAME) |&gt; \n  select(VAR_NAMES)\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the code to clean column names and select the right columns for analysis:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report)\n\n\n\n\n\n\n\nYou already know from your data inspection that the values for district are not standardized.\nAdd a mutate() function to clean the residential_district column, to:\n\nStandardize the capitalization of the column\nReplace the existing residential_district column with a clean column that only contains these district values: “Lake Minara”, “Feveria Central”, and “Kasara”.\n\nSee the hint to see what functions you can use.\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTry using str_to_title() from {stringr} package so that the first letter of each word is upper case and all other letters are lower case. You can also use case_match() to specify different specific typos.\nUse the ‘help’ functionality of RStudio to see how to use these functions. For example, type ?case_match in your console to get the help page. NOTE on case_match() - this is a very useful function for replacing or correcting values, and supersedes recode().\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYour cleaning code should now look like this:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = str_to_title(residential_district)) |&gt; \n  mutate(residential_district = case_match(residential_district,\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\"))\n\nYou could also wrap the str_to_title function into the case_match() for shorter code, as follows:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = case_match(str_to_title(residential_district),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\"))\n\n\n\n\n\n\n\nThe column for report date needs to be transformed so that it is recognized as a date in R. This will allow you to analyse trends over time, including over weeks and months.\nReview the values within the date_report column. Then, add a line to your cleaning code to change date_report into a date class.\nKnowing the structure will allow you to use the correct function to convert the column into a date class. We recommend you use one of the functions from the {lubridate} package: either ymd() (for converting dates written as year-month-date), mdy() (for dates written as month-day-year), or dmy() (for dates written as day-month-year). These functions will recognize any way of writing the date as long as it is the correct order, for example “21st August 2025” and “21-08-2024” would both be recognized by dmy().\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow are the dates currently formatted?\n\n day-month-year year-month-day month-day-year year-day-month\n\nWhich mutate() function should you use to convert the date_report column into a date class?\n\n mutate(date_report = ymd(date_report)) mutate(date_report = dmy(date_report)) mutate(date_report = mdy(date_report))\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou can use the head() function to view the first six rows of data for the date_report column. You can see that they are written with the year first, then the month, then the date.\n\nhead(data_notif$date_report)\n\n[1] \"2024-03-08\" \"2024-03-11\" \"2024-03-11\" \"2024-03-18\" \"2024-03-14\"\n[6] \"2024-03-12\"\n\n\nYou can use the ymd() function inside mutate() to convert the class of the date_report function. You can double-check that the class is correct by running a class() function afterwards.\nYour cleaning code should now look like this:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = case_match(str_to_title(residential_district),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\")) |&gt; \n  mutate(date_report = ymd(date_report)) \n\nAnd you can double check the class with this:\n\nclass(data_notif$date_report)\n\n[1] \"Date\"\n\n\n\n\n\n\n\n\nYour colleagues tell you that each notification_id represents one suspected case. You now want to create a table to check if notification_id is duplicated across rows in you data.\n\n\n\n\n\n\nQuestions\n\n\n\n\nDoes one row in the notification data equate to one case?\n\n Yes No\n\nDo you need to deduplicate your data for epidemiological analysis of cases?\n\n Yes No\n\n\n\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nThere are many ways to do this, but try using count() function from {dplyr}. It will create a table that counts the number of rows per unique value of the column that you specify inside the function. Then, use tabyl() to look at the distribution of these counts.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFirst, pipe from the notification data into the count() function, giving the notification_id column as the only argument. This creates a table that counts the number of rows per unique value of notification_id, shown in a new column n. You can see for example in this excerpt that there is only one row per each of these 6 notification_ids.\n\ndata_notif |&gt; \n  count(notification_id) \n\n\n\n  notification_id n\n1          00399b 1\n2          005c85 1\n3          006f52 1\n4          00cbbb 1\n5          01830d 1\n6          019045 1\n\n\nThen tabulate the new column n with the tabyl(), which shows that there is only one row per unique notification_id. This means that one row equates to one case, and no further deduplication is needed.\n\ndata_notif |&gt; \n  count(notification_id) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 987       1\n\n\n\n\n\n\n\n\n\nYou can now comfortably proceed with descriptive analyses of cases, as your data is clean and you know that one row equals one case. Use the tabyl() function for the following tasks.\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich disease was most commonly diagnosed by clinics in Feveria in 2024?\n\n Cholera Malaria Dengue Typhoid Fever Yellow Fever\n\nWhich disease was least commonly diagnosed by clinics in Feveria in 2024?\n\n Cholera Malaria Dengue Typhoid Fever Yellow Fever\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see that there were 533 suspected cases of malaria in Feveria in 2024, and only 35 suspected cases of typhoid fever.\n\ntabyl(data_notif, disease_notified)\n\n disease_notified   n    percent\n          cholera  46 0.04660588\n           dengue 273 0.27659574\n          malaria 533 0.54002026\n          typhoid  35 0.03546099\n     yellow fever 100 0.10131712\n\n\n\n\n\n\n\n\nUse tabyl() to cross-tabulate the disease and district of residence columns.\nBuild on your table by adding various adorn functions from the {janitor} package, to see percentage distributions, e.g. adorn_percentages(), adorn_pct_formatting(), and adorn_ns()\nType the name of the function after a ? in your console (e.g. ?adorn_ns) to see the relevant Help pages. You can also look at the section about {janitor} in the Epi R Handbook for more explanation of adorn_xxx() functions.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich district reported the most vector-borne disease in 2024 (malaria, dengue, yellow fever)?\n\n Lake Minara Feveria Central Kasara\n\nWhich district reported the most diarrhoeal disease in 2024 (cholera, typhoid fever)?\n\n Lake Minara Feveria Central Kasara\n\nWhat factors contribute to increased diarrhoeal disease in this specific district (selected in previous question)?\n\n Unreliable water and sanitation infrastructure Overcrowding of mosquitoes We don't know\n\n\n\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nHere is some code to get you started. It cross-tabulates disease_notified and residential_district with tabyl(), then adding adorn_percentages() converts these numbers to percentages with many decimals. You then need to pipe into adorn_pct_formatting() to convert into actual percentage formatting, and then adorn_ns() to add numbers back in in parentheses.\nNote that adorn_xxx() functions need to be applied in a specific order!\n\ntabyl(data_notif, disease_notified, residential_district) |&gt;\n  adorn_percentages()\n\nFor factors contributing to more diarrhea - scroll up to earlier in the case study when the districts were first introduced!\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see that most suspected cases of dengue, malaria, and yellow fever were located in Lake Minara - the lake area with higher density of mosquitoes and therefore vector-borne disease. Meanwhile the majority of cholera and typhoid fever were in Feveria Central, the over-populated urban area with water and sanitation infrastructure issues that result in higher risk of flooding and drinking water contamination during rainy weather.\n\ntabyl(data_notif, disease_notified, residential_district) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n disease_notified Feveria Central      Kasara Lake Minara\n          cholera      91.3% (42)  8.7%   (4)  0.0%   (0)\n           dengue       9.5% (26) 17.6%  (48) 72.9% (199)\n          malaria      13.7% (73) 19.9% (106) 66.4% (354)\n          typhoid      68.6% (24) 31.4%  (11)  0.0%   (0)\n     yellow fever      11.0% (11) 21.0%  (21) 68.0%  (68)\n\n\n\n\n\n\n\n\n\n\nFrom your earlier work in step 3, you have found that the laboratory data contains only testing data, and no patient information. The data is already very clean, so we only need to standardize one column. We will also want to process the laboratory data frame to be one row per notification, so that it can be neatly linked to the notification data frame.\n\n\n\n\nCreate a new object data_lab. This will allow a more straight-forward analysis and interpretation of results.\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse case_match() to turn the different original values into “Positive”, “Negative”, or “Indeterminate”:\n\ndata_lab &lt;- data_lab_raw |&gt; \n  mutate(value = case_match(value, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positive\",\n                            \"N\" ~ \"Negative\",\n                            \"I\" ~ \"Indeterminate\"))\n\nYou can then double-check that the new values look correct by tabulating and comparing the values in the original data frame and the clean one. Make sure that you used the letter ‘O’ and not the number ‘0’!\n\ntabyl(data_lab_raw, value)\n\n value   n    percent\n     I  73 0.05555556\n     N 682 0.51902588\n     P 521 0.39649924\n   PO1  22 0.01674277\n PO139  16 0.01217656\n\n\n\ntabyl(data_lab, value)\n\n         value   n    percent\n Indeterminate  73 0.05555556\n      Negative 682 0.51902588\n      Positive 559 0.42541857\n\n\n\n\n\n\n\n\n\n\n\nWe already know that some samples have multiple rows, and that this is because the dengue assay has three targets, with one row per target result.\nNow find the number of samples with multiple rows.\nDo this as you did with the notification data, using the data_lab object: first count the number of rows per sample, then create a table to show the distribution of row numbers. Keep in mind that each sample is identified by a sample_ID.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many samples (unique sample_ids) are repeated across three rows?\n\n 200 215 230\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFirst, pipe from the lab data into the count() function, giving the sample_id column as the only argument. This creates a table that counts the number of rows per unique value of sample_id, shown in a new column n. You can see for example that the sample_id “000e8eee” has three rows, whereas the sample_id “001e1878” is only seen on one row.\n\ndata_lab |&gt; \n  count(sample_id) \n\n\n\n  sample_id n\n1  000e8eee 3\n2  001e1878 1\n3  005f39af 1\n4  00b30781 3\n5  00b56d18 1\n6  0110abcd 3\n\n\nThen tabulate the new column n with the tabyl().\n\ndata_lab |&gt; \n  count(sample_id) |&gt; \n  tabyl(n)\n\n n n_n   percent\n 1 669 0.7567873\n 3 215 0.2432127\n\n\nYou can even double-check that this only applies to the dengue assay by adding in the test column to the calculation. You can see that it is only the dengue test that has 3 rows per sample.\n\ndata_lab |&gt; \n  count(test, sample_id) |&gt; \n  tabyl(test, n)\n\n                   test   1   3\n          Blood culture  33   0\n     Dengue NS1/IgG/IgM   0 215\n              IgM ELISA  88   0\n          Stool Culture  45   0\n Whole Blood Microscopy 503   0\n\n\n\n\n\n\n\n\nAs you saw in section 3.2, your dengue test provides results for three different targets: IgG, IgM, and NS.1. The results for each of these targets can be either negative or positive. However, to simplify and consolidate your data, you want to assign a single negative or positive label to each sample, to indicate if the sample represents current infection.\n\n\ntargetNegativePositiveDengue IgG110105Dengue IgM105110Dengue NS.113976\n\n\nYour colleague Ben, who works in the lab, advises you on the cleaning as follows:\n\nA sample can be considered positive if NS.1 or IgM are positive (as both can represent acute infection)\nYou can ignore IgG (because a positive result in the absence of positive NS.1 or IgM is indicative of immunity after a past resolved infection)\n\nNow you need to consolidate the dengue test results to one row per test, with one result value. Use filter(), arrange(), and slice(), making sure any sample positive for NS.1 or IgM is considered positive for dengue. Create a new object called data_lab_tests\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTry to apply the following to consolidate according to Ben’s recommendation:\n\nRemove IgG Results: filter out rows where the target is “IgG” using filter() from {dplyr}.\nPrioritize positive IgM/NS1results: Group by sample_id and arrange rows with arrange() so any ‘P’ (positive) result appears first\nFilter to final status: Keep only the first row using slice(1) to get the positive or negative result for the sample.\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the code to filter out the dengue IgG results, and then consolidate the test result within each group of rows with the same sample_id, prioritizing positive results.\nYou need to specify desc within arrange(), as this means that the results will be in reverse alphabetical order, meaning P will be at the top.\nAlso, add the ungroup() function at the end so that the new data is not grouped, which could confuse further analyses.\n\ndata_lab_tests &lt;- data_lab |&gt; \n  filter(target != \"Dengue IgG\") |&gt; \n  group_by(sample_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\nYou can then double-check that the new object data_lab_tests has only one row per test, using the combination of count() and tabyl() like you did in Task A.\nThis table shows you that all unique sample IDs are only present in one row each:\n\ndata_lab_tests |&gt; \n  count(sample_id) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 884       1\n\n\n\n\n\n\n\n\nNext, you check the number of tests per notification ID in your new consolidated data.\nYou can see that there are 26 rows with the same notification_id as another row, but only among cases tested with whole blood microscopy for malaria.\n\ndata_lab_tests |&gt; \n  count(test, notification_id) |&gt; \n  tabyl(test, n)\n\n                   test   1  2\n          Blood culture  33  0\n     Dengue NS1/IgG/IgM 215  0\n              IgM ELISA  88  0\n          Stool Culture  45  0\n Whole Blood Microscopy 451 26\n\n\nYou investigate further, looking at one example case with notification_id “043228”. This shows you that this one case was tested twice, with two different samples, one week apart. The first result was positive, and the second result was negative.\n\ndata_lab_tests |&gt; \n  filter(notification_id == \"043228\")\n\n# A tibble: 2 × 7\n  laboratory_name        notification_id sample_id date_test  test  target value\n  &lt;chr&gt;                  &lt;chr&gt;           &lt;chr&gt;     &lt;IDate&gt;    &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;\n1 Kasara University Hos… 043228          27c37cd8  2024-06-18 Whol… Plasm… Posi…\n2 Kasara University Hos… 043228          d2271be0  2024-06-25 Whol… Plasm… Nega…\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich statement about the lab data is correct?\n\n All cases of different diseases get retested Some malaria cases get retested All malaria cases get retested\n\nWill you need to deduplicate the lab data, to link with the notification data?\n\n Yes - we need one row representing the lab result per notification No - the data is sufficiently deduplicated\n\n\n\n\nIf you answered that you need to deduplicate, you are correct!\nDeduplicate your data to have one row per notification ID, prioritizing positive results, so that you can link to the notification data.\nTo do this, follow a similar process as you did in Task B, using the data frame produced by task B:\n\nGroup by notification_id\nArrange by the test result value so that values starting with P are prioritized in the top row, followed by N (negative), and then I (indeterminate).\nThen keep the first row within each group of notification_ids, using slice().\nWhen doing this, create a new object called data_lab_cases.\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the code to deduplicate rows within each group of rows with the same notification_id, prioritizing positive results. Once again you need to specify desc within arrange(). This works perfectly because the desired priority order for results — positive, then negative, then indeterminate — happens to align with reverse alphabetical order (P comes before N, which comes before I, when sorted descending).\nIf your priority order was more complex or didn’t match alphabetical sorting (e.g., if “indeterminate” needed to come before “negative”), you’d have to convert the result column into a factor and explicitly define the desired order of its levels. Don’t forget to ungroup again at the end.\n\ndata_lab_cases &lt;- data_lab_tests |&gt; \n  group_by(notification_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt;\n  ungroup()\n\nYou can then double-check that the new object data_lab_cases has only one row per test, using the combination of count() and tabyl() like you did in Task A. This table shows you that all unique sample IDs are only present in one row each:\n\ndata_lab_cases |&gt; \n  count(notification_id) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 858       1\n\n\n\n\n\n\n\n\n\nNow we have two objects that we can use for analysis of laboratory data: data_lab_tests and data_lab_cases.\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich object should you use to analyse tests?\n\n data_lab_tests data_lab_cases neither\n\nHow many tests were conducted to test for malaria (via whole blood microscopy)?\n\n 215 503 88 190\n\nWhat percentage of tests for cholera (via stool culture) were positive?\n\n 21% 11% 84% 87%\n\nWhich test had the highest percentage of indeterminate results?\n\n IgM ELISA (for yellow fever detection) Stool Culture (for cholera detection) Blood culture (for typhoid fever detection)\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see the number of positive, negative, and indeterminate results per test. You can add a series of adorn() functions to show percentages and totals.\n\ntabyl(data_lab_tests, test, value) |&gt; \n  adorn_totals(where = \"col\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n                   test Indeterminate    Negative    Positive        Total\n          Blood culture     6.1%  (2) 72.7%  (24) 21.2%   (7) 100.0%  (33)\n     Dengue NS1/IgG/IgM     0.0%  (0) 13.5%  (29) 86.5% (186) 100.0% (215)\n              IgM ELISA    11.4% (10) 51.1%  (45) 37.5%  (33) 100.0%  (88)\n          Stool Culture    11.1%  (5)  4.4%   (2) 84.4%  (38) 100.0%  (45)\n Whole Blood Microscopy    11.1% (56) 51.1% (257) 37.8% (190) 100.0% (503)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich lab data frame should you use to count the number of suspected cases tested?\n\n data_lab_raw data_lab_cases data_lab_tests data_lab\n\nHow many suspected cases were tested in the 2024 lab data?\n\n 858 1314 884\n\nAre there more suspected cases in the notification data or the lab data?\n\n Notification data Lab data\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou can simply look at the number of rows in the data_lab_cases data frame to see the number of suspected cases who were tested.\n\nnrow(data_lab_cases)\n\n[1] 858\n\n\nThis is less than the number of suspected cases that were in the clean notifiable disease surveillance data (data_notif) - which suggests that not all suspected cases in 2024 were tested by the time this data was available.\n\nnrow(data_notif)\n\n[1] 987\n\n\n\n\n\n\n\n\n\n\nNow that both linelists are clean and have one row per suspected case, you can link them to enable the full analysis requested by your boss.\n\n\n\n\nCreate a new object called data_linked, using a xxx_join() function from {dplyr}. You want to keep all notifications, but add on test results where available for each suspected case.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich function is the correct approach if you want to retain all rows from your notification data and bring in results from your lab data?\n\n left_join(data_notif, data_lab_cases… full_join(data_notif, data_lab_cases… right_join(data_notif, data_lab_cases…\n\nWhat identifier should be used to link the two linelists?\n\n sample_id notification_id sample_id and date of report notification_id and date of report\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nLink the data using the left_join() function, with notification data as the main data frame on the left. This will keep all the rows from this data frame, and will just bring in the test results from the lab data specified on the “right” of the function.\n\ndata_linked &lt;- left_join(data_notif, data_lab_cases, \n                         by = \"notification_id\")\n\nYou are linking on the notification_id column, which is present, complete, and clean in both linelists.\nNote: You are lucky to work with such a straight-forward example of linkage! Usually you would need to really clean and check the ID column, or link on other columns like name and date fo birth. In Feveria, clinic staff are fantastic at consistently allocating notification IDs to each patient, including on the sample forms sent to the lab, and then the lab staff are equally brilliant at recording the notification ID in their lab systems so that the results can be linked back to the case.\n\n\n\n\n\n\nNow check your data and review a few things.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many rows are in your new data_linked data frame?\n\n 987 884 858\n\nHow does this compare to your original notification data?\n\n more rows than the original same number of rows fewer rows\n\nWhat term best describes the linkage you just did?\n\n many-to-one one-to-one many-to-many\n\nHow many lab results were NOT linked (hint: use anti-join())?\n\n 30 19 0\n\nHow fortunate are you that your linkage is so successful?\n\n What? Isn't all linkage this simple?? Very! Usually some records don't match\n\nWhat are typical reasons that lab data doesn’t match to the notifiable diseases data?\n\n There are typos in the columns used for linkage, so they are not recognised as matching The lab data may contain additional cases from other clinics or countries The lab data may include test samples Notifications may have been accidentally missed in the notification data even though the sample was tested in the lab All of the above\n\nHow many suspected cases do not have a result?\n\n 83 100 129\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nCheck the number of rows in each data frame with the nrow() function, or by checking the object information in your environment. You can see that this was simply a one-to-one merge, because each row had a unique notification_id, so one row in the notification data linked directly to one row in the lab data.\nNumber of rows in notification data\n\nnrow(data_notif)\n\n[1] 987\n\n\nNumber of rows in linked data\n\nnrow(data_linked)\n\n[1] 987\n\n\nTo check if there were any lab result that were not linked to the notification data, you can use anti_join(). This time the data_lab_cases object is on the left, as the function assess how many rows from the left data frame were not found in the right data frame, matching by notification_id. Here you do not need to generate a new data frame, you can simply pipe into an nrow() to count the number of rows. The output is 0, which shows there were no unlinked results - amazing!\n\nanti_join(data_lab_cases, data_notif, \n          by = \"notification_id\") |&gt; nrow()\n\n[1] 0\n\n\nFinally, to check the number of notifications without a result, you can either conduct an anti_join in putting data_notif first:\n\nanti_join(data_notif, data_lab_cases, \n          by = \"notification_id\") |&gt; nrow()\n\n[1] 129\n\n\nOr, you can simply tabulate the number of missing values in the value column in data_linked (as the value column comes from the lab data).\n\ntabyl(is.na(data_linked$value)) \n\n is.na(data_linked$value)   n   percent\n                    FALSE 858 0.8693009\n                     TRUE 129 0.1306991\n\n\nBoth of these approaches show that 129 suspected cases do not have a lab test result.\n\n\n\n\n\n\n\n\n\nUse mutate() to create a new column case_category, updating the label of suspected cases according to their lab result. The categories should be as follows:\n\nIf the result was positive: Confirmed\nIf the result was negative: Discarded\nIf the result was indeterminate or missing: Suspected\n\nThis means that all cases in the notification data are initially suspected when reported, and then remain suspected if there is no conclusive test result.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich is the most appropriate function for creating this new column?\n\n case_when() if_else() case_match()\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou should use case_when() to create the new column. This function is ideal for applying multiple logical conditions to create multiple values, whereas case_match() is better for replacing specific values, and if_else() is better if there are only two possible values.\n\ndata_linked &lt;- data_linked |&gt; \n  mutate(case_category = case_when(value==\"Positive\" ~ \"Confirmed\",\n                                   value==\"Negative\" ~ \"Discarded\",\n                                   value==\"Indeterminate\" | is.na(value) ~ \"Suspected\"))\n\n\n\n\n\n\n\n\n\n\nUse tabyl() overall, and also cross-tabulate by disease to answer the questions below.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many cases in the linked notification data did not have a positive or negative result?\n\n 202 347 250\n\nWhat percentage of cases in the notification data DID have a positive or negative result?\n\n 60.1% 79.5% 92.2%\n\nWhy are there more remaining suspected cases than there are unlinked notifications?\n\n Suspected cases include notifications without a lab result and with an indeterminate lab result There are additional suspected cases being brought in from the lab There is an issue with the data\n\nWhich disease had the highest percentage of cases that remained suspected after linkage?\n\n Cholera Malaria Dengue Yellow fever\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nOnce again you can use tabyl() to see the distribution of case categories across notifications. The total number of suspected cases, i.e. those with either no lab result at all or with an indeterminate result, is 202. This means 785 cases, i.e. 79.5%, did have a definitive laboratory result.\n\ntabyl(data_linked, case_category) \n\n case_category   n   percent\n     Confirmed 438 0.4437690\n     Discarded 347 0.3515704\n     Suspected 202 0.2046606\n\n\nYou can also cross-tabulate the original results (indeterminate/negative/positive) in the value column with the new case_category column, firstly to check your logic worked, and to see how the original values map to the new column values. This shows that in addition to the 129 notifications that were not linked (with NA in the value column), 73 had indeterminate results, so were categorized as suspected cases.\n\ntabyl(data_linked, case_category, value) \n\n case_category Indeterminate Negative Positive NA_\n     Confirmed             0        0      438   0\n     Discarded             0      347        0   0\n     Suspected            73        0        0 129\n\n\nFinally, you can also cross-tabulate with the disease name to see the case categories by disease. Add additional adorn_xxx() functions for percentage formatting. The table shows you that 22% of yellow fever cases remained suspected, which was the highest percentage compared to the other diseases.\n\ntabyl(data_linked, disease_notified, case_category) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n disease_notified   Confirmed   Discarded   Suspected        Total\n          cholera 82.6%  (38)  4.3%   (2) 13.0%   (6) 100.0%  (46)\n           dengue 68.1% (186) 10.6%  (29) 21.2%  (58) 100.0% (273)\n          malaria 32.6% (174) 46.3% (247) 21.0% (112) 100.0% (533)\n          typhoid 20.0%   (7) 68.6%  (24) 11.4%   (4) 100.0%  (35)\n     yellow fever 33.0%  (33) 45.0%  (45) 22.0%  (22) 100.0% (100)\n            Total 44.4% (438) 35.2% (347) 20.5% (202) 100.0% (987)\n\n\n\n\n\n\n\n\nUse tabyl() for this once again, looking at the results by disease. Think about the correct denominator!\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhat percentage of suspected cases reported in 2024 were true cases, according to their test results?\n\n 44% 56% 59%\n\nWhat percentage of suspected malaria cases were really malaria?\n\n 86% 41% 23%\n\nWhat percentage of suspected dengue cases were really dengue?\n\n 87% 41% 23%\n\n\n\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nDivide the number of confirmed cases (i.e. those with a positive result) by the number of confirmed plus discarded cases (i.e. those with either a positive or negative result). This gives a positivity rate, which approximates the percentage of suspected cases that were truly cases. Indeterminate results are excluded because they don’t provide a clear outcome and would skew the positivity rate.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFilter out suspected cases and then cross-tabulate, to see the percentage of originally suspected cases that become confirmed or discarded, among those with valid test results.\nBecause there is a totals row, you can see that 56% of suspected cases overall became confirmed, among those with a valid result. You can also see that 41% and 87% of malaria and dengue cases respectively were confirmed.\n\ndata_linked |&gt; \n  filter(case_category != \"Suspected\") |&gt; \n  tabyl(disease_notified, case_category) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n disease_notified   Confirmed   Discarded        Total\n          cholera 95.0%  (38)  5.0%   (2) 100.0%  (40)\n           dengue 86.5% (186) 13.5%  (29) 100.0% (215)\n          malaria 41.3% (174) 58.7% (247) 100.0% (421)\n          typhoid 22.6%   (7) 77.4%  (24) 100.0%  (31)\n     yellow fever 42.3%  (33) 57.7%  (45) 100.0%  (78)\n            Total 55.8% (438) 44.2% (347) 100.0% (785)\n\n\n\n\n\n\n\n\n\nTask A: Create a new linelist called data_linked_confirmed.\nThis is what you will use in official surveillance reporting.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhy are we opting to report only confirmed cases in our surveillance data?\n\n Reporting confirmed cases can be more reliable and accurate when the percentage testing positive is low and lab testing is routine, thereby helping prevent over-estimation of disease burden Reporting confirmed cases is slower, which gives us more time to be sure of what we are reporting Because we want to hide the true number of cases\n\nWhat function is important for creating the new linelist?\n\n filter() arrange() mutate()\n\nHow many rows are in this new data frame?\n\n 389 438 858\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYour surveillance unit wants to focus on confirmed cases in reporting. This is because lab testing is routine in Feveria, and so reporting suspected cases would be unnecessarily inaccurate, with a high percentage of suspected cases getting discarded.\nThe decision to publish suspected cases may be different in other contexts. For example, if the positivity rate is high (most cases are true cases if tested), and testing itself is not common, or testing takes a long time and would result in delayed reporting, this would suggest that suspected case trends are sufficiently accurate and also more timely than waiting for laboratory confirmation.\nCreate the new linelist with the filter() function:\ndata_linked_confirmed &lt;- data_linked |&gt; \n  filter(case_category==\"Confirmed\")\nAnd check the number of rows by looking at the information in your environment, or with nrow():\nnrow(data_linked_confirmed)\n[1] 438\n\n\n\n\n\n\n\nNow that you have your linelist of confirmed notifiable disease cases reported in Feveria in 2024, you are ready to conduct the final part of your surveillance analysis! Namely, this is to summarize the five notifiable diseases by geography and time.\nTip: Typically surveillance analysis would also include analysis by person. You could expand on this case study by also analyzing by demographic variables.\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich notifiable disease was most commonly reported in 2024, when restricting to only confirmed cases?\n\n Dengue Malaria Yellow Fever\n\nWhy is the most commonly reported disease different when looking at confirmed and suspected cases?\n\n The sensitivity and specificity of the clinical diagnosis may differ by disease The performance of the tests used in the lab may differ by disease There may be reporting biases All of the above!\n\nWhich district reported the most confirmed cholera cases in 2024?\n\n Lake Minara Feveria Central Kasara\n\nHow many confirmed cases of cholera reported in 2024 were among residents of Feveria Central?\n\n 35 42 4\n\nWhich district reported the most confirmed malaria cases in 2024?\n\n Lake Minara Feveria Central Kasara\n\nDoes this data confirm that dengue is the most common infectious disease in Feveria?\n\n No - a different disease may be under-reported and/or not notifiable Yes - if it's most reported then it must be most common\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see that dengue was the most commonly reported disease in Feveria in 2024 when restricting to confirmed cases, with 186 cases.\n\ndata_linked_confirmed |&gt; \n  tabyl(disease_notified) \n\n disease_notified   n    percent\n          cholera  38 0.08675799\n           dengue 186 0.42465753\n          malaria 174 0.39726027\n          typhoid   7 0.01598174\n     yellow fever  33 0.07534247\n\n\nNote that this is different from the suspected cases, where malaria was most commonly reported (with 533 suspected cases)! This was hinted at previously, when you saw that the positivity rate for suspected dengue cases was higher than for suspected malaria cases. This can be for different reasons, for instance the clinical diagnosis method used for malaria may be less specific (so many of the suspected cases are actually other diseases), or the test used for dengue may be more sensitive.\nTo cross-tabulate with residential district, add the relevant adorn_xxx() functions.\n\ndata_linked_confirmed |&gt; \n  tabyl(disease_notified, residential_district) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n disease_notified Feveria Central     Kasara Lake Minara        Total\n          cholera      92.1% (35)  7.9%  (3)  0.0%   (0) 100.0%  (38)\n           dengue       8.6% (16) 17.2% (32) 74.2% (138) 100.0% (186)\n          malaria      14.9% (26) 22.4% (39) 62.6% (109) 100.0% (174)\n          typhoid      71.4%  (5) 28.6%  (2)  0.0%   (0) 100.0%   (7)\n     yellow fever       0.0%  (0) 18.2%  (6) 81.8%  (27) 100.0%  (33)\n            Total      18.7% (82) 18.7% (82) 62.6% (274) 100.0% (438)\n\n\nLike with the suspected cases, we can see that most confirmed cases of dengue, malaria, and yellow fever were located in Lake Minara - the lake area with higher density of mosquitoes and therefore vector-borne disease. The majority of confirmed cholera and typhoid fever cases were in Feveria Central, where there are water and sanitation issues.\nThe data suggests that vector-borne disease (dengue and malaria) are a particular concern in this tropical country. However, we don’t know for sure which is the most common disease and what the underlying patterns are - only five diseases are notifiable, and typically the reported cases only represent a fraction of true cases in the community.\n\n\n\n\n\n\n\nYou are going to work towards producing this epicurve, over the various tasks below.\n\n\n\n\n\n\n\n\n\n\n\nMake sure you specify the argument binwidth=7 so that each bar in the histogram represents the number of cases within a 7 day period.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhen was the first case of typhoid fever reported in Feveria in 2024?\n\n January 2024 May 2024 October 2024\n\nAccording to this graph, what was the highest number of dengue cases reported in a single week in 2024?\n\n 10 20 30 It's very hard to tell from this stacked graph!\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is some simple code to produce the epicurve. Note that you are not controlling the colors just yet, or specifying what day of the week each 7-day period starts on.\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = disease_notified)), binwidth=7)\n\n\n\n\n\n\n\n\nRefer to the dates chapter in the Epi R Handbook if you want more specific date formatting, for instance so that each bar represents a Monday-Sunday week, or the x axis labels the week number (weeks 1 - 52).\nImportantly - it is not straight forward to see the trends per disease when stacked this way! To see such temporal trends, you should produce one histogram per disease.\n\n\n\n\n\n\nUse facet_wrap() to easily create several mini-plots, one per disease. To understand this further, you can look at the facet section of the ggplot2 chapter in the Epi R Handbook\n\n\n\n\n\n\nQuestions\n\n\n\n\nAccording to this faceted graph, what was the highest number of dengue cases reported in a single week in 2024?\n\n 11 15 29 I still can't tell!\n\nAmong the dengue cases reported that week, what districts did they live in?\n\n All three districts Feveria Central Kasara Lake Minara This graph does not show this information\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nNow you can see an epicurve per disease! And you can see that during one week in July, 15 cases of dengue were reported. However, this graph does not show any geographical information yet.\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report)), binwidth=7) + \n  facet_wrap(.~disease_notified)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nAmong the 15 dengue cases reported in one week in July 2024, what districts did they live in?\n\n All three districts Feveria Central Kasara Lake Minara\n\nIn what district was the first typhoid fever case reported in 2024?\n\n Kasara Feveria Central Lake Minara I still can't tell!\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nNow you can see an epicurve per disease, with the coloring reflecting the district the case is a resident of.\nYou can see that among the 15 dengue cases reported in a single week, they lived across the three different districts. You can also see that the first case of typhoid was reported in Feveria Central.\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = residential_district)), binwidth=7) + \n  facet_wrap(.~disease_notified)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can specify:\n\nThe theme/appearance of the overall graph (e.g. background color, appearance of grid lines)\nThe title and labels\nThe colors of the bars (with scale_fill_manual())\nThe formatting and spacing of dates along the x-axis (with scale_x_date)\nMany other things!\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nDo cholera and typhoid fever appear endemic?\n\n No - the data suggests smaller occasional outbreaks Yes they are both endemic\n\nIs there a particular time of the year when malaria peaked in 2024?\n\n Yes - around November/December time Yes - around July/August (summer) time No, it is consistently high\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the fully formatted code. Note some other changes include specifying that we only want two columns of mini-plots within facet_wrap(), and that the date label along the x axis should only show day and month (not year, since all cases are in 2024 anyway).\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = residential_district)), binwidth=7) +\n  facet_wrap(.~disease_notified, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"District of residence\",\n       x = \"Date reported by clinic\",\n       y = \"Count\",\n       subtitle = \"Number of confirmed cholera, dengue, malaria, typhoid fever, and yellow fever cases by week in Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n\n\n\n\n\n\nWe can also see from the epicurve that cholera and typhoid appear to be occurring as isolated outbreaks, rather than showing endemicity. Malaria and dengue however were present in Feveria throughout the year, with malaria more obviously peaking in the summer months.\n\n\n\n\n\n\nThis time, use group_by() and summarize() to produce a table by district showing the earliest and latest report dates.\nYou can adjust your table with a filter() function to create this table for one district at a time.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhen was the first dengue case reported in Feveria in 2024?\n\n 18th January 2024 17th January 2024 12th February 2024\n\nWhen was the last dengue case reported in Feveria Central in 2024?\n\n 22nd August 2024 18th November 2024 25th December 2024\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nGroup the data by disease and then summarize the first and last date to look at the overall timeline of each disease in Feveria.\n\ndata_linked_confirmed |&gt; \n  group_by(disease_notified) |&gt; \n  summarize(first_reported = min(date_report), \n            last_reported = max(date_report)) |&gt;\n  ungroup()\n\n# A tibble: 5 × 3\n  disease_notified first_reported last_reported\n  &lt;chr&gt;            &lt;date&gt;         &lt;date&gt;       \n1 cholera          2024-06-03     2024-09-23   \n2 dengue           2024-01-17     2024-11-18   \n3 malaria          2024-01-08     2024-12-25   \n4 typhoid          2024-05-02     2024-11-07   \n5 yellow fever     2024-03-08     2024-08-23   \n\n\nAdd a filter() to the code to look at first and most recent report dates for the district you’re interested in.\n\ndata_linked_confirmed |&gt; \n  filter(residential_district == \"Feveria Central\") |&gt; \n  group_by(disease_notified) |&gt; \n  summarize(first_reported = min(date_report), \n            recent_reported = max(date_report)) |&gt;\n  ungroup()\n\n# A tibble: 4 × 3\n  disease_notified first_reported recent_reported\n  &lt;chr&gt;            &lt;date&gt;         &lt;date&gt;         \n1 cholera          2024-06-03     2024-09-23     \n2 dengue           2024-01-29     2024-08-22     \n3 malaria          2024-01-29     2024-12-17     \n4 typhoid          2024-05-02     2024-11-07     \n\n\n\n\n\n\n\n\n\n\nWow! In line with the objectives for this case study, you have done the following:\n\nYou used key R functions to clean, reshape, and link data frames, plus created new columns using logical conditions.\nTo inform the data processing, you conducted data inspections and checks along the way\nYou conducted a thorough descriptive analysis to understand the testing and notification data, before and after linkage. In response to your supervisor’s original four questions, you can say:\n\nHow many suspected cases of the different notifiable diseases were reported in 2024, and which was most common? Malaria was the most common notifiable disease in Feveria in 2024, reported through the notifiable disease surveillance system: There were 533 suspected cases of malaria reported, 273 suspected cases of dengue, 100 yellow fever, 46 cholera, and 35 typhoid.\nWhat percentage of them ended up being confirmed? Almost 80% of notifiable cases reported in 2024 had a laboratory test result by the time the linked dataset was created, with some variation by disease. In total, 56% of notified cases were eventually confirmed, but this ranged from only 23% for typhoid fever (7 confirmed of 31 suspected cases with test results), to 95% for cholera (38 confirmed of 40 suspected cases with rest results). Additionally, the positivity rate was higher for suspected dengue than for suspected malaria (87% vs 41%).\nHow many confirmed cases of different notifiable diseases were reported in 2024, and which was most common? Confirmed cases followed a slightly different trend to suspected cases: the most commonly reported infection was dengue with 186 cases, followed by malaria (174), then cholera (38), yellow fever (33), and typhoid fever (7).\nHow are confirmed cases geographically and temporally distributed in Feveria? Feveria experienced dengue and malaria transmission throughout the year, peaking in the summer, and concentrated in the Lake Minara district. Feveria also experienced small and infrequent outbreaks of diarrhoeal disease, e.g. cholera and typhoid fever, particularly in the urban Feveria Central where there can be issues with water and sanitation.\n\nFinally, you have reflected on how the processes involved in notifiable disease surveillance systems and lab testing, for instance the transfer of data between clinics to labs, can affect data quality and completeness, and therefore your results.\n\nThere is so much more potential ahead. You can explore disease patterns by age or sex, calculate disease rates with population data, and even analyze reporting delays by examining the different dates in your datasets.\nYou have built a strong foundation and are well equipped to take your analysis to the next level. Keep going — exciting discoveries await!\nTo learn more, check out the other case studies or dive into the Epi R Handbook.\n\n\n\nSee below a script of all data cleaning steps and descriptive analyses. Note how the analyses are combined at the end rather than interspersed in between cleaning steps. This is a tidier way to organize your script.\nFor brevity, the code below does not include all inspections and checks made along the way, but you may decide to create a sections with such checks.\nThe top of your script should also contain information to help the reader understand what the script is for, as well as comments throughout. You will thank yourself later for adding these comments!\n\n\n\n\n\n\nCode to clean and analyse notification data and lab data from Feveria, 2024\n\n\n\n\n\n\n# Code to clean and analyse notification data and lab data from Feveria, 2024\n# Date:\n# Author:\n\n# Install packages -------------------------------------------------\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  flextable,  # Presentation ready tables\n  naniar,     # Evaluating missingness of data\n  remotes,    # Used to install package to download data\n  tidyverse   # data management and visualization\n)\n\n# Import data --------------------------------------------\n\n# Notification data\ndata_notif_raw &lt;- import(\"data/multidisease_notifications.xlsx\")\n\n# Lab data\ndata_lab_raw &lt;- import(\"data/multidisease_tests.csv\")\n\n# Clean notification data --------------------------------\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = case_match(str_to_title(residential_district),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\")) |&gt; \n  mutate(date_report = ymd(date_report)) \n\n\n# Clean and consolidate lab data  ---------------------------------------\n# Clean values\ndata_lab &lt;- data_lab_raw |&gt; \n  mutate(value = case_match(value, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positive\",\n                            \"N\" ~ \"Negative\",\n                            \"I\" ~ \"Indeterminate\"))\n\n# Create test-level lab data\ndata_lab_tests &lt;- data_lab |&gt; \n  filter(target != \"Dengue IgG\") |&gt; \n  group_by(sample_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Create case-level lab data\ndata_lab_cases &lt;- data_lab_tests |&gt; \n  group_by(notification_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Link notification and lab data  ---------------------------------------\ndata_linked &lt;- left_join(data_notif, data_lab_cases, by = \"notification_id\")\n\n# Clean data--------------------------------------------------------------\ndata_linked &lt;- data_linked |&gt; \n  mutate(case_category = case_when(value==\"Positive\" ~ \"Confirmed\",\n                                   value==\"Negative\" ~ \"Discarded\",\n                                   value==\"Indeterminate\" | is.na(value) ~ \"Suspected\"))\n\ndata_linked_confirmed &lt;- data_linked |&gt; \n  filter(case_category==\"Confirmed\")\n\n# ANALYSIS ---------------------------------------------------------\n# Number of suspected cases in Feveria\ntabyl(data_notif, disease_notified)\n\n# Distribution of suspected cases by district\ntabyl(data_notif, disease_notified, residential_district) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n# Distribution of results per disease-specific test\ntabyl(data_lab_tests, test, value) |&gt; \n    adorn_totals(where = \"col\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution of case category, in linked data: all cases\ntabyl(data_linked, case_category) \n\n# Distribution of case category by diseases, in linked data: all cases\ntabyl(data_linked, disease_notified, case_category) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution of case category by disease, in linked data: only cases with a valid result\ndata_linked |&gt; \n    filter(case_category != \"Suspected\") |&gt; \n    tabyl(disease_notified, case_category) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution of confirmed cases by district\ndata_linked_confirmed |&gt; \n  tabyl(disease_notified, residential_district) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n\n# Visualize confirmed cases over time\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = residential_district)), binwidth=7) +\n  facet_wrap(.~disease_notified, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"District of residence\",\n       x = \"Date reported by clinic\",\n       y = \"Count\",\n       subtitle = \"Number of confirmed cholera, dengue, malaria, typhoid fever, and yellow fever cases by week in Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n# First and last report date per disease\ndata_linked_confirmed |&gt; \n  group_by(disease_notified) |&gt; \n  summarize(first_reported = min(date_report), \n            last_reported = max(date_report)) |&gt;\n  ungroup()\n\n\n\n\n\n\n\n\n\n\n\n\n\nOriginal authors: Paula Blomquist and Alanah Jansen, with technical support provided by the CDC Global Surveillance, Laboratory, and Data Systems Branch in collaboration with TEPHINET.\nData source: Fictional data provided by Applied Epi.\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nJuly 2025\nFirst draft\n1\nPaula Blomquist and Alanah Jansen, Applied Epi, with technical support by the CDC Global Surveillance, Laboratory, and Data Systems Branch in collaboration with TEPHINET\n\n\n\n\n\n\nDisclaimer: The information presented in this exercise and the associated data files have been developed to help learners achieve the intended learning objectives. The contents are those of the author(s) and do not necessarily represent the official views of CDC, the US Department of Health and Human Services, or TEPHINET.\nLicense: This case study is under a CC BY-NC-SA 4.0 license. For more information about sharing and adapting this case study, see the associated deed.\nFunding: This case study was 100% supported by Cooperative Agreement number NU2HGH000044 funded by the US Centers for Disease Control and Prevention (CDC)."
  },
  {
    "objectID": "pages/multidisease_surveillance.html#scenario",
    "href": "pages/multidisease_surveillance.html#scenario",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "You are an epidemiologist working in the national surveillance office of Feveria, a very small tropical country. There are three districts within Feveria:\n\nFeveria Central: an over-populated urban area, with sometimes unreliable water and sanitation infrastructure.\nLake Minara: a lake area with good infrastructure but many mosquitoes in the warmer months of the year.\nKasara: a more sub-urban area on the other side of Feveria Central.\n\nMap of districts in the country Feveria\n\nIt is January 2025, and your supervisor would like you to transfer the routine processing of notifiable disease data from Excel into R, and to conduct some analyses on the data. She wants to know at least:\n\nHow many suspected cases of the different notifiable diseases were reported in 2024, and which was most common?\nWhat percentage of them ended up being confirmed?\nHow many confirmed cases of different notifiable diseases were reported in 2024, and which was most common?\nHow were confirmed cases geographically and temporally distributed in Feveria?\n\nShe asks that you write code to import, clean, link, and analyse the following linelists:\n\n2024 notifiable disease surveillance data: Referred to also as “notification data”, this is surveillance data on five notifiable diseases reported by clinics in Feveria: dengue, malaria, cholera, typhoid fever, and yellow fever. These are suspected cases, based on patients’ symptoms. Clinicians enter each notification into an online system every weekday.\n2024 laboratory test result data: This data comes from lab test results, from three major labs in Feveria. These results are for samples taken from those suspected notifiable disease cases mentioned above.\n\nLet’s go!"
  },
  {
    "objectID": "pages/multidisease_surveillance.html#objectives",
    "href": "pages/multidisease_surveillance.html#objectives",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "In this case study you will:\n\nUse key R functions to clean data, reshape datasets, link data sources, and create new columns using logical conditions to prepare data for analysis.\nConduct data inspections and data quality checks at multiple stages of the project and understand their importance for reliable analysis.\nPerform basic descriptive analyses to compare disease trends across different data sources, before and after linkage.\nInterpret differences in results across data sources and understand how these reflect the structure and design of the overall surveillance system."
  },
  {
    "objectID": "pages/multidisease_surveillance.html#step-1.-set-up",
    "href": "pages/multidisease_surveillance.html#step-1.-set-up",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Start by setting up a reproducible and well-organized workflow. This will make it easy to rerun your analysis whenever needed.\nTasks:\n\nSet up an RStudio project\nSet up clear sub-folders where your code, data, and outputs will go\nCreate an R script, or an R Markdown file if you prefer. Make sure the script purpose, date, and author are written as comments at the top.\nExtra: Ensure your working language in RStudio is appropriate (e.g. English for this exercise)\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\n\nCreate a folder where all the work in this case study will go. For example, create ‘multi_disease_lab’ on your computer desktop. Create your RStudio project to be based in this folder.\nWe suggest creating the following sub-folders: scripts (for your code), data (for your data), and outputs (for your analytical outputs).\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nCreate a folder (e.g. ‘multi_disease_lab’ on your Desktop) for your work. To create an Rstudio project in your new folder, click New Project… in the top left of your R Studio, then Existing Directory, then Browse to select your new folder. For more information, look at the R projects section of the Epi R Handbook.\nStart a new R script by clicking New File in the top left of your R Studio, then R Script. Save it immediately in the appropriate place, e.g. in a scripts sub-folder of your R Project.\nAt the top of your new R script, write some essential information like your name, the purpose of the file, and the date.\nYour R locale determines the language and regional settings used for things like date formats and translations. If your locale is different from the language you want for your report (e.g., a French locale vs. an English report), you can change it to English by running Sys.setlocale(\"LC_ALL\", \"English\"). Include this in your script if needed, or skip it if your locale is usually appropriate. This is explained in more detail in the How-to Guide.\n\n\n\n\n\n\nNext in your R script, you need to install and load the necessary R packages. This ensures that the functions you need are available for your analysis.\nYou will need the following packages: {rio} (for importing data),{skimr} (for reviewing data), {janitor} (for cleaning data), {lubridate} (for cleaning dates), {epikit} (for epi-related tasks), {gtsummary} (for summary statistics/tests and regression), {apyramid} (for age-sex pyramids), {flextable} (for presentation-ready tables), {naniar} (for evaluating missing data), and {tidyverse} (for general data manipulation/science tasks).\nYou will also need the {remotes} package to download the data - which we will explain in the download section.\nAs you start, your trusted colleague nudges you and whispers “I’ve heard that a great way to manage your packages is with the {pacman} package”.\nOver to you!\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse the function p_load() from pacman for this task. You provide the function with a list of packages that you want to use. The function will undertake two steps per package:\n\nCheck if the package is installed on your computer, and install it if necessary.\nLoad the package so it can be used during this R session.\n\nIf you don’t already have pacman installed, you will need to install it the “traditional way” first, with install.packages().\nNote that the order of packages in your p_load function can be important. If two packages have the same function names (e.g. select() in the package MASS and select() in tidyverse, which do different things), then R will use the function from the most recently loaded package. To prioritize functions from tidyverse, which are commonly used for data manipulation and visualization, load tidyverse last.\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  flextable,  # Presentation ready tables\n  naniar,     # Evaluating missingness of data\n  remotes,    # Used to install package to download data\n  tidyverse   # data management and visualization\n)"
  },
  {
    "objectID": "pages/multidisease_surveillance.html#step-2.-download-and-import-the-data",
    "href": "pages/multidisease_surveillance.html#step-2.-download-and-import-the-data",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Your office provides you with two files for your analysis, both containing data for 2024 and updated as of 15th January 2025:\n\nA disease notification-level dataset (“multidisease_notifications.xlsx”) with case information from 5 health centers.\nA laboratory test-level dataset (“multidisease_tests.csv”) submitted by three laboratories conducting testing for the 5 health centers.\n\nFor this case study, you can download the data via Applied Epi’s very useful data repository, which you can access using the {appliedepidata} package. Follow these steps:\n\nInstall the {appliedepidata} package from GitHub using the install_github() function in the {remotes} package (which you installed previously)\n\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n\n\nSave the two datasets into a specific folder using the save_data() function from {appliedepidata}, by running the code below. The example below saves the data into a data subfolder within the RStudio project. Note that if you do not specify a location within the path argument of the function, a window will pop up asking you to manually select a folder.\n\n\n# Save down the two data files using the save_data() function from appliedepidata\nappliedepidata::save_data(\"multidisease_tests\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"multidisease_notifications\",\n                          path = \"data\")\n\n\n\n\nGreat! Thanks country office and Applied Epi! Now it’s time to import the data from that folder into RStudio, so you can analyse it.\n\n\nIdeally, you will use the same function for importing both datasets, despite one being a .csv and the other an .xlsx file. Note going forward we will simply say “environment” when we mean the environment pane in R Studio.\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nUse the import function from the {rio} package, which can recognize and import different file types. It replaces importing functions that are specific to the file type, such as read.csv() from {base} for .csv files and read_excel() from {readxl} to import .xlsx files.\nIf you feel you need to know more about importing functions, read the Import and export chapter of the Epi R Handbook.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nBelow we use the import function to bring in both files. Note how we are assigning the imported data to two objects, one called data_notif_raw, and one called data_lab_raw. We add the ‘raw’ suffix to distinguish this data from the cleaned versions we will make later.\n\n# Import data\n\n# Notification data\ndata_notif_raw &lt;- import(\"data/multidisease_notifications.xlsx\")\n\n# Lab data\ndata_lab_raw &lt;- import(\"data/multidisease_tests.csv\")"
  },
  {
    "objectID": "pages/multidisease_surveillance.html#step-3.-inspect-the-data",
    "href": "pages/multidisease_surveillance.html#step-3.-inspect-the-data",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "The data’s in, and now it’s time to see what story it tells. Take an initial look at your two raw data frames to check their contents and quality.\n\n\n\n\nUse skim() from the {skimr} package, names(), ncol(), and nrow() to inspect your data frame.\nskim() gives you a lot of information on data structure and content, whereas names() will show you the different column names in your data. The ncol() and nrow() functions to simply count the numbers of columns and rows in the data. Do you know what to put inside the parentheses?\nEasiest of all though, is to look at the environment. Remember the object in your environment for the notification data is called data_notif_raw.\nClick on the solution box underneath the questions if you need help.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many columns are there in the notification data?\n\n 10 11 12 13\n\nWhich of these columns are NOT in the data?\n\n Onset date Date reported by Health Facility/Community Date of outcome Date of test Date of birth\n\nWhat is the name of the column in the notification data that identifies each notification?\n\n Notification ID Test ID Health facility code Combination of Notification ID and Sex\n\nHow many rows are there in the notification data?\n\n 987 1314 950 778\n\nWhat type of information can you NOT see in the notification data?\n\n Laboratory test results District of residence Birthday and sex Health facility in which the case was diagnosed Outcome\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse skim() from the {skimr} package to look at a summary of the entire data frame, and View() to look at the whole data frame directly:\n\nskim(data_notif_raw)\n\nOr, you could use names() to print out just the column names. Through either skim() or names() you will be able to see the types of information including: the health facility of the case, birth-date, sex, a flag indicating pregnancy, district of residence, onset date, and date reported by the clinic, and outcome information.\nThere is also a Notification ID which appears to be a unique identifier for a case, but we would want to double check duplicates before we are sure.\nNote that there are NO test results in this data, as these notifications are from clinics diagnosing notifiable diseases based on clinical case definitions.\n\nnames(data_notif_raw)\n\n [1] \"Organisation unit name\"                    \n [2] \"Health facility code\"                      \n [3] \"Notification ID\"                           \n [4] \"Date of Birth\"                             \n [5] \"Sex\"                                       \n [6] \"Pregnant\"                                  \n [7] \"Residential District\"                      \n [8] \"Disease notified\"                          \n [9] \"Onset date\"                                \n[10] \"Date reported by Health Facility/Community\"\n[11] \"Outcome\"                                   \n[12] \"Date of outcome\"                           \n\n\nUse ncol() and nrow() to print the number of columns and rows, like this:\n\nncol(data_notif_raw)\nnrow(data_notif_raw)\n\nThis will print the numbers of columns and rows in your console.\n\n\n[1] 12\n\n\n[1] 987\n\n\nOtherwise, when you look at the environment you can see that the number of observations (which is the same as rows) and columns are listed next to the name of the data frame.\n\n\n\n\n\n\nUse skim() from the {skimr} package or class() to inspect your column classes.\nDo you remember how to specify the column of interest inside the class() function? Alternatively, you can just look at the environment.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many columns in the notification data frame are recognised by R to be date columns?\n\n 0 2 4\n\nWhat is the class of most columns in the raw notification data frame?\n\n character numeric factor\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou can use class like the example below. The $ is an operator used to select a specific column from the data_notif_raw data frame.\nNote that the back-ticks (`) are used around Date of Birth because the column name contains spaces.\n\nclass(data_notif_raw$`Date of Birth`)\n\nTo look at class via the environment, click on the blue arrow next to the data frame name. The column names will appear, with the class next to it (e.g. it says “chr” to show character class).\nYou can see the none of the columns that should be dates are recognized as dates. Instead, they are recognized as character values.\n\n\n\n\n\n\nUse the tabyl() function to inspect the values within categorical columns, specifying the data frame object in the first argument, and the column name in the second argument.\nFor example, this code tabulates the values for the Sex column. The output shows that male and female are inconsistently spelled across the data. This column would need further cleaning before analysis.\n\ntabyl(data_notif_raw, Sex)\n\n    Sex   n    percent valid_percent\n      F  47 0.04761905    0.05452436\n FEMALE 146 0.14792300    0.16937355\n      M  40 0.04052685    0.04640371\n   MALE 172 0.17426545    0.19953596\n      f 154 0.15602837    0.17865429\n female  98 0.09929078    0.11368910\n      m 119 0.12056738    0.13805104\n   male  86 0.08713273    0.09976798\n   &lt;NA&gt; 125 0.12664640            NA\n\n\nTo inspect missingness, you can use the miss_var_summary() function from the {naniar} package:\n\nmiss_var_summary(data_notif_raw)\n\n# A tibble: 12 × 3\n   variable                                   n_miss pct_miss\n   &lt;chr&gt;                                       &lt;int&gt;    &lt;num&gt;\n 1 Onset date                                    691     70.0\n 2 Pregnant                                      510     51.7\n 3 Outcome                                       197     20.0\n 4 Date of outcome                               197     20.0\n 5 Date of Birth                                 168     17.0\n 6 Sex                                           125     12.7\n 7 Organisation unit name                          0      0  \n 8 Health facility code                            0      0  \n 9 Notification ID                                 0      0  \n10 Residential District                            0      0  \n11 Disease notified                                0      0  \n12 Date reported by Health Facility/Community      0      0  \n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nAre the values in the Residential District column standardized?\n\n No - they need cleaning They are standardized and are ready to be used for analysis\n\nAre the values in the Disease notified column standardized?\n\n No - they need cleaning They are standardized and are ready to be used for analysis\n\nWhat does R recognise as a missing value?\n\n Either no value, or just a space, or just a dot No value in a cell, represented with NA The words Unknown and Uncertain\n\nBased on the missingness of its values, is the Onset date column useful?\n\n Yes, the missingness is low so this column is useful Minimally, as the missingness is too high\n\nWhy might some columns in the notification data have different spellings and non-standardized categories?\n\n A bot scrambles the data so it becomes less identifiable Each clinic might use software that is configured slightly differently, or use free-text entries, so there are variations in spelling The surveillance system software used by the clinical settings has lots of bugs\n\nWhy might some columns in the notification data have high missingness?\n\n The clinician does not ask the patient the question during their consultation The patient might not know or want to share the answer The clinician might not have time to prioritise filling in that field in the data, even if they know the information All of the above, and many more reasons\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse the tabyl() function to tabulate the values within the Residential District column. Again, the first argument is the name of the data frame object, and the second argument is the name of the column.\n\ntabyl(data_notif_raw, `Residential District`)\n\n Residential District   n    percent\n            F Central  32 0.03242148\n            FEVERIA C  23 0.02330294\n      FEVERIA CENTRAL  85 0.08611955\n            Feveria C  24 0.02431611\n      Feveria Central  12 0.01215805\n               KASARA  64 0.06484296\n                  KSR  17 0.01722391\n               Kasara 109 0.11043566\n             L MINARA  50 0.05065856\n             L Minara 193 0.19554205\n          LAKE MINARA 185 0.18743668\n          Lake Minara  68 0.06889564\n             Lakeside 125 0.12664640\n\n\nYou can see that each of the three locations (Feveria Central, Lake Minara, and Kasara) are spelled in different ways and with different capitalization. This will need to be cleaned out if we want to analyse the geographic distribution of the notifiable diseases.\nSimilarly, use the tabyl() function to tabulate the values within the Disease notified column. You can see these are spelled out appropriately and consistently, so you can already see the distribution of rows by disease without further cleaning.\n\ntabyl(data_notif_raw, `Disease notified`)\n\n Disease notified   n    percent\n          cholera  46 0.04660588\n           dengue 273 0.27659574\n          malaria 533 0.54002026\n          typhoid  35 0.03546099\n     yellow fever 100 0.10131712\n\n\nA different way of checking missingness is to tabulate the output of the function is.na(). In the example below, the function is.na() evaluates each cell within the column Onset date, returning TRUE for missing ones and FALSE for present ones.\nRunning tabyl() on this TRUE/FALSE output then quickly gives you a clear count and percentage of both missing and non-missing values in that column. Remember, values like a space or the words “Unknown” or “Missing” will not be recognized by R as missing. R will only recognize true blanks as missing, represented by NA.\nFor Onset date, you can see that 70% of cases are missing onset date, suggesting that this column would not be particularly useful for analyzing trends in disease over time.\n\ntabyl(is.na(data_notif_raw$`Onset date`))\n\n is.na(data_notif_raw$`Onset date`)   n   percent\n                              FALSE 296 0.2998987\n                               TRUE 691 0.7001013\n\n\nMissing or non-standardized data can arise for many reasons, including:\n\nthe design of the data collection tool (e.g. whether questions are mandatory or use free text vs. drop-downs),\nthe processes and standards in place (such as which fields staff are instructed to prioritise), and\ncontextual factors (like whether staff have sufficient time to gather the information).\n\n\n\n\n\n\n\n\n\n\nLike with the notification data, use skim(), ncol(), and nrow() functions or check the environment to inspect the lab data.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich linelist has more columns - the notification data or the laboratory data?\n\n Lab data Notification data They have the same number of columns\n\nWhich linelist has more rows?\n\n Lab data Notification data They have the same number of rows\n\nInspect the lab data with View(). Why might the lab data have more records?\n\n There may be several tests or targets per sample There are so many trial test results in the data Not all the notifications have test results yet\n\nWhich of these columns are NOT in the lab data?\n\n Notification ID Sample ID Test type Date of birth Test result\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nJust like in section 3.1, you can use skim() from the {skimr} package to look at the entire laboratory data frame with test results. This will also show you the different column names in the data, showing you that the lab data only contains information about the test and not about the patient. It does however also contain a notification ID, just like the notification data does.\n\nskim(data_lab_raw)\n\nUse ncol() and nrow() to print the number of columns and rows, like this:\n\nncol(data_lab_raw)\nnrow(data_lab_raw)\n\nThis will print the numbers of columns and rows in your console, showing you that the lab data has more rows than the notification data you inspected earlier.\n\n\n[1] 7\n\n\n[1] 1314\n\n\nThere are often more records in the lab data than in the clinical data. If you inspect the data with View(data_lab_raw) and then click on the arrow at the top of the notification_id column to sort it alphabetically, you’ll see that several rows share the same notification_id. This can happen when multiple targets are tested from the same sample (same sample ID), or when a case is retested (resulting in a different sample ID).\n\nView(data_lab_raw)\n\n\n\nlaboratory_namenotification_idsample_iddate_testtesttargetvalueFeveria General Hospitalf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue NS.1NFeveria General Hospitalf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgGNFeveria General Hospitalf2170848b003132024-06-07Dengue NS1/IgG/IgMDengue IgMPFeveria General Hospital6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue NS.1NFeveria General Hospital6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgGNFeveria General Hospital6a47a3ca5e865b2024-06-15Dengue NS1/IgG/IgMDengue IgMP\n\n\n\n\n\n\n\n\nAs above, use the class(), skim(), or tabyl() functions, or inspect the environment, to look at your columns in more detail.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many columns in the laboratory data frame are recognised by R to be date columns?\n\n 0 1 2\n\nHow many columns in the laboratory data frame have complete data?\n\n 1 3 7 (all of them!)\n\nWhich test detects multiple targets (and therefore has multiple rows per sample)?\n\n Malaria Dengue Yellow Fever Cholera Typhoid Fever\n\nHow many possible test result values are there in the column value?\n\n 5 3 4\n\nWhat is NOT a possible test result for the stool culture test which detects V. cholerae bacteria?\n\n P P01 P0139 N I\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nThe laboratory data has one date column, recognized by R as an “IDate” class. This is a date class used by {rio}’s import() when reading csv files. Like base R’s Date class, it allows sorting by date and analyzing trends over time.\n\nclass(data_lab_raw$date_test)\n\n[1] \"IDate\" \"Date\" \n\n\nUse of the miss_var_summary() function from the {naniar} package demonstrates that all columns in the laboratory data are actually complete. This may be because the laboratory systems use automated processes, so are much less likely to have human error.\n(Important point: Note that in real life, the lab data would probably have some issues too!)\n\nmiss_var_summary(data_lab_raw)\n\n# A tibble: 7 × 3\n  variable        n_miss pct_miss\n  &lt;chr&gt;            &lt;int&gt;    &lt;num&gt;\n1 laboratory_name      0        0\n2 notification_id      0        0\n3 sample_id            0        0\n4 date_test            0        0\n5 test                 0        0\n6 target               0        0\n7 value                0        0\n\n\nTo see how many targets are detected by each test, you can cross-tabulate test and target columns with tabyl(). Write the column names into the function as two separate arguments. The output shows that each test clearly aligns with one or more targets, and only the dengue assay detects more than one target (IgG, IgM, and NS.1).\nTip: Experiment with changing the order of the column names in the function to see the impact on the table.\n\ntabyl(data_lab_raw, target, test)\n\n               target Blood culture Dengue NS1/IgG/IgM IgM ELISA Stool Culture\n           Dengue IgG             0                215         0             0\n           Dengue IgM             0                215         0             0\n          Dengue NS.1             0                215         0             0\n           Plasmodium             0                  0         0             0\n    S. Typhi bacteria            33                  0         0             0\n V. cholerae bacteria             0                  0         0            45\n     Yellow Fever IgM             0                  0        88             0\n Whole Blood Microscopy\n                      0\n                      0\n                      0\n                    503\n                      0\n                      0\n                      0\n\n\nFinally, you can inspect the different test result values in the column value, again using tabyl(). You can see that there are six possible results, including N for negative, P for positive, and I for indeterminate. Cholera specifically does not show P, but can show P01 and P0139, which in this case represent being positive for serogroups O1 or O139.\n\ntabyl(data_lab_raw, test, value)\n\n                   test  I   N   P PO1 PO139\n          Blood culture  2  24   7   0     0\n     Dengue NS1/IgG/IgM  0 354 291   0     0\n              IgM ELISA 10  45  33   0     0\n          Stool Culture  5   2   0  22    16\n Whole Blood Microscopy 56 257 190   0     0"
  },
  {
    "objectID": "pages/multidisease_surveillance.html#step-4.-clean-and-describe-the-notification-data",
    "href": "pages/multidisease_surveillance.html#step-4.-clean-and-describe-the-notification-data",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "You now know that the notification data (data_notif_raw) contains information about suspected cases, alongside basic demographic information (age, sex, pregnancy, district of residence), and information about their onset date, date reported by the health facility, and outcome. Some columns need cleaning before further analysis, due to variations in spelling of categorical values and some date columns not being recognized as dates.\nYou will now start writing longer chunks of code to clean data, using various {dplyr} functions chained together with pipes (which look like this: |&gt;).\nNOTE ON PIPES: Pipes allow you to perform several operations in one smooth sequence, by “chaining” different functions together. The output from one function becomes the input for the next.\nIf you need more information on piping, please refer to the Epi R Handbook.\nNote that this exercise uses the base pipe (|&gt;) rather than the magrittr pipe (%&gt;%), as it is faster and does not require package installation. Use the magrittr pipe if you prefer it.\n\n\n\n\nDue to quality and data storage issues, your team recommends that you create a clean linelist that only contains information on the unique identifier, location of the case, disease, and the date the notification was reported to the surveillance system.\nWrite R code to produce a new clean data frame called data_notif, applying the following cleaning tasks:\n\nRename columns to be more machine readable (remove spaces and capitalization) using clean_names() from the {janitor} package\nUse the rename() function from {dplyr} so that the column with the date the case was reported is changed to a more concise date_report.\n\nSelect relevant columns for analysis with the select() function from the {dplyr} package.\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nStart your code with the name of the new data frame, the assignment arrow, and the name of the raw data object. This shows that the outcome of the raw data processing will be assigned to a new object called data_notif.\n\ndata_notif &lt;- data_notif_raw\n\nThen build on this code by adding in additional functions, chained together with a pipe. This lets you perform several operations in one smooth sequence. First, you’ll use clean_names() to standardize all your column names. It automatically replaces spaces and special characters with underscores and converts everything to lowercase, making names easier to work with. Then, you can use rename() to give a column a new name. Just remember, when you use rename(), the column will already have its clean_names() version.\n\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(NEW_NAME = OLD_NAME) |&gt; \n  select(VAR_NAMES)\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the code to clean column names and select the right columns for analysis:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report)\n\n\n\n\n\n\n\nYou already know from your data inspection that the values for district are not standardized.\nAdd a mutate() function to clean the residential_district column, to:\n\nStandardize the capitalization of the column\nReplace the existing residential_district column with a clean column that only contains these district values: “Lake Minara”, “Feveria Central”, and “Kasara”.\n\nSee the hint to see what functions you can use.\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTry using str_to_title() from {stringr} package so that the first letter of each word is upper case and all other letters are lower case. You can also use case_match() to specify different specific typos.\nUse the ‘help’ functionality of RStudio to see how to use these functions. For example, type ?case_match in your console to get the help page. NOTE on case_match() - this is a very useful function for replacing or correcting values, and supersedes recode().\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYour cleaning code should now look like this:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = str_to_title(residential_district)) |&gt; \n  mutate(residential_district = case_match(residential_district,\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\"))\n\nYou could also wrap the str_to_title function into the case_match() for shorter code, as follows:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = case_match(str_to_title(residential_district),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\"))\n\n\n\n\n\n\n\nThe column for report date needs to be transformed so that it is recognized as a date in R. This will allow you to analyse trends over time, including over weeks and months.\nReview the values within the date_report column. Then, add a line to your cleaning code to change date_report into a date class.\nKnowing the structure will allow you to use the correct function to convert the column into a date class. We recommend you use one of the functions from the {lubridate} package: either ymd() (for converting dates written as year-month-date), mdy() (for dates written as month-day-year), or dmy() (for dates written as day-month-year). These functions will recognize any way of writing the date as long as it is the correct order, for example “21st August 2025” and “21-08-2024” would both be recognized by dmy().\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow are the dates currently formatted?\n\n day-month-year year-month-day month-day-year year-day-month\n\nWhich mutate() function should you use to convert the date_report column into a date class?\n\n mutate(date_report = ymd(date_report)) mutate(date_report = dmy(date_report)) mutate(date_report = mdy(date_report))\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou can use the head() function to view the first six rows of data for the date_report column. You can see that they are written with the year first, then the month, then the date.\n\nhead(data_notif$date_report)\n\n[1] \"2024-03-08\" \"2024-03-11\" \"2024-03-11\" \"2024-03-18\" \"2024-03-14\"\n[6] \"2024-03-12\"\n\n\nYou can use the ymd() function inside mutate() to convert the class of the date_report function. You can double-check that the class is correct by running a class() function afterwards.\nYour cleaning code should now look like this:\n\n# Clean data\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = case_match(str_to_title(residential_district),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\")) |&gt; \n  mutate(date_report = ymd(date_report)) \n\nAnd you can double check the class with this:\n\nclass(data_notif$date_report)\n\n[1] \"Date\"\n\n\n\n\n\n\n\n\nYour colleagues tell you that each notification_id represents one suspected case. You now want to create a table to check if notification_id is duplicated across rows in you data.\n\n\n\n\n\n\nQuestions\n\n\n\n\nDoes one row in the notification data equate to one case?\n\n Yes No\n\nDo you need to deduplicate your data for epidemiological analysis of cases?\n\n Yes No\n\n\n\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nThere are many ways to do this, but try using count() function from {dplyr}. It will create a table that counts the number of rows per unique value of the column that you specify inside the function. Then, use tabyl() to look at the distribution of these counts.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFirst, pipe from the notification data into the count() function, giving the notification_id column as the only argument. This creates a table that counts the number of rows per unique value of notification_id, shown in a new column n. You can see for example in this excerpt that there is only one row per each of these 6 notification_ids.\n\ndata_notif |&gt; \n  count(notification_id) \n\n\n\n  notification_id n\n1          00399b 1\n2          005c85 1\n3          006f52 1\n4          00cbbb 1\n5          01830d 1\n6          019045 1\n\n\nThen tabulate the new column n with the tabyl(), which shows that there is only one row per unique notification_id. This means that one row equates to one case, and no further deduplication is needed.\n\ndata_notif |&gt; \n  count(notification_id) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 987       1\n\n\n\n\n\n\n\n\n\nYou can now comfortably proceed with descriptive analyses of cases, as your data is clean and you know that one row equals one case. Use the tabyl() function for the following tasks.\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich disease was most commonly diagnosed by clinics in Feveria in 2024?\n\n Cholera Malaria Dengue Typhoid Fever Yellow Fever\n\nWhich disease was least commonly diagnosed by clinics in Feveria in 2024?\n\n Cholera Malaria Dengue Typhoid Fever Yellow Fever\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see that there were 533 suspected cases of malaria in Feveria in 2024, and only 35 suspected cases of typhoid fever.\n\ntabyl(data_notif, disease_notified)\n\n disease_notified   n    percent\n          cholera  46 0.04660588\n           dengue 273 0.27659574\n          malaria 533 0.54002026\n          typhoid  35 0.03546099\n     yellow fever 100 0.10131712\n\n\n\n\n\n\n\n\nUse tabyl() to cross-tabulate the disease and district of residence columns.\nBuild on your table by adding various adorn functions from the {janitor} package, to see percentage distributions, e.g. adorn_percentages(), adorn_pct_formatting(), and adorn_ns()\nType the name of the function after a ? in your console (e.g. ?adorn_ns) to see the relevant Help pages. You can also look at the section about {janitor} in the Epi R Handbook for more explanation of adorn_xxx() functions.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich district reported the most vector-borne disease in 2024 (malaria, dengue, yellow fever)?\n\n Lake Minara Feveria Central Kasara\n\nWhich district reported the most diarrhoeal disease in 2024 (cholera, typhoid fever)?\n\n Lake Minara Feveria Central Kasara\n\nWhat factors contribute to increased diarrhoeal disease in this specific district (selected in previous question)?\n\n Unreliable water and sanitation infrastructure Overcrowding of mosquitoes We don't know\n\n\n\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nHere is some code to get you started. It cross-tabulates disease_notified and residential_district with tabyl(), then adding adorn_percentages() converts these numbers to percentages with many decimals. You then need to pipe into adorn_pct_formatting() to convert into actual percentage formatting, and then adorn_ns() to add numbers back in in parentheses.\nNote that adorn_xxx() functions need to be applied in a specific order!\n\ntabyl(data_notif, disease_notified, residential_district) |&gt;\n  adorn_percentages()\n\nFor factors contributing to more diarrhea - scroll up to earlier in the case study when the districts were first introduced!\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see that most suspected cases of dengue, malaria, and yellow fever were located in Lake Minara - the lake area with higher density of mosquitoes and therefore vector-borne disease. Meanwhile the majority of cholera and typhoid fever were in Feveria Central, the over-populated urban area with water and sanitation infrastructure issues that result in higher risk of flooding and drinking water contamination during rainy weather.\n\ntabyl(data_notif, disease_notified, residential_district) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n disease_notified Feveria Central      Kasara Lake Minara\n          cholera      91.3% (42)  8.7%   (4)  0.0%   (0)\n           dengue       9.5% (26) 17.6%  (48) 72.9% (199)\n          malaria      13.7% (73) 19.9% (106) 66.4% (354)\n          typhoid      68.6% (24) 31.4%  (11)  0.0%   (0)\n     yellow fever      11.0% (11) 21.0%  (21) 68.0%  (68)"
  },
  {
    "objectID": "pages/multidisease_surveillance.html#step-5.-clean-consolidate-and-describe-the-laboratory-data",
    "href": "pages/multidisease_surveillance.html#step-5.-clean-consolidate-and-describe-the-laboratory-data",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "From your earlier work in step 3, you have found that the laboratory data contains only testing data, and no patient information. The data is already very clean, so we only need to standardize one column. We will also want to process the laboratory data frame to be one row per notification, so that it can be neatly linked to the notification data frame.\n\n\n\n\nCreate a new object data_lab. This will allow a more straight-forward analysis and interpretation of results.\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUse case_match() to turn the different original values into “Positive”, “Negative”, or “Indeterminate”:\n\ndata_lab &lt;- data_lab_raw |&gt; \n  mutate(value = case_match(value, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positive\",\n                            \"N\" ~ \"Negative\",\n                            \"I\" ~ \"Indeterminate\"))\n\nYou can then double-check that the new values look correct by tabulating and comparing the values in the original data frame and the clean one. Make sure that you used the letter ‘O’ and not the number ‘0’!\n\ntabyl(data_lab_raw, value)\n\n value   n    percent\n     I  73 0.05555556\n     N 682 0.51902588\n     P 521 0.39649924\n   PO1  22 0.01674277\n PO139  16 0.01217656\n\n\n\ntabyl(data_lab, value)\n\n         value   n    percent\n Indeterminate  73 0.05555556\n      Negative 682 0.51902588\n      Positive 559 0.42541857\n\n\n\n\n\n\n\n\n\n\n\nWe already know that some samples have multiple rows, and that this is because the dengue assay has three targets, with one row per target result.\nNow find the number of samples with multiple rows.\nDo this as you did with the notification data, using the data_lab object: first count the number of rows per sample, then create a table to show the distribution of row numbers. Keep in mind that each sample is identified by a sample_ID.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many samples (unique sample_ids) are repeated across three rows?\n\n 200 215 230\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFirst, pipe from the lab data into the count() function, giving the sample_id column as the only argument. This creates a table that counts the number of rows per unique value of sample_id, shown in a new column n. You can see for example that the sample_id “000e8eee” has three rows, whereas the sample_id “001e1878” is only seen on one row.\n\ndata_lab |&gt; \n  count(sample_id) \n\n\n\n  sample_id n\n1  000e8eee 3\n2  001e1878 1\n3  005f39af 1\n4  00b30781 3\n5  00b56d18 1\n6  0110abcd 3\n\n\nThen tabulate the new column n with the tabyl().\n\ndata_lab |&gt; \n  count(sample_id) |&gt; \n  tabyl(n)\n\n n n_n   percent\n 1 669 0.7567873\n 3 215 0.2432127\n\n\nYou can even double-check that this only applies to the dengue assay by adding in the test column to the calculation. You can see that it is only the dengue test that has 3 rows per sample.\n\ndata_lab |&gt; \n  count(test, sample_id) |&gt; \n  tabyl(test, n)\n\n                   test   1   3\n          Blood culture  33   0\n     Dengue NS1/IgG/IgM   0 215\n              IgM ELISA  88   0\n          Stool Culture  45   0\n Whole Blood Microscopy 503   0\n\n\n\n\n\n\n\n\nAs you saw in section 3.2, your dengue test provides results for three different targets: IgG, IgM, and NS.1. The results for each of these targets can be either negative or positive. However, to simplify and consolidate your data, you want to assign a single negative or positive label to each sample, to indicate if the sample represents current infection.\n\n\ntargetNegativePositiveDengue IgG110105Dengue IgM105110Dengue NS.113976\n\n\nYour colleague Ben, who works in the lab, advises you on the cleaning as follows:\n\nA sample can be considered positive if NS.1 or IgM are positive (as both can represent acute infection)\nYou can ignore IgG (because a positive result in the absence of positive NS.1 or IgM is indicative of immunity after a past resolved infection)\n\nNow you need to consolidate the dengue test results to one row per test, with one result value. Use filter(), arrange(), and slice(), making sure any sample positive for NS.1 or IgM is considered positive for dengue. Create a new object called data_lab_tests\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nTry to apply the following to consolidate according to Ben’s recommendation:\n\nRemove IgG Results: filter out rows where the target is “IgG” using filter() from {dplyr}.\nPrioritize positive IgM/NS1results: Group by sample_id and arrange rows with arrange() so any ‘P’ (positive) result appears first\nFilter to final status: Keep only the first row using slice(1) to get the positive or negative result for the sample.\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the code to filter out the dengue IgG results, and then consolidate the test result within each group of rows with the same sample_id, prioritizing positive results.\nYou need to specify desc within arrange(), as this means that the results will be in reverse alphabetical order, meaning P will be at the top.\nAlso, add the ungroup() function at the end so that the new data is not grouped, which could confuse further analyses.\n\ndata_lab_tests &lt;- data_lab |&gt; \n  filter(target != \"Dengue IgG\") |&gt; \n  group_by(sample_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\nYou can then double-check that the new object data_lab_tests has only one row per test, using the combination of count() and tabyl() like you did in Task A.\nThis table shows you that all unique sample IDs are only present in one row each:\n\ndata_lab_tests |&gt; \n  count(sample_id) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 884       1\n\n\n\n\n\n\n\n\nNext, you check the number of tests per notification ID in your new consolidated data.\nYou can see that there are 26 rows with the same notification_id as another row, but only among cases tested with whole blood microscopy for malaria.\n\ndata_lab_tests |&gt; \n  count(test, notification_id) |&gt; \n  tabyl(test, n)\n\n                   test   1  2\n          Blood culture  33  0\n     Dengue NS1/IgG/IgM 215  0\n              IgM ELISA  88  0\n          Stool Culture  45  0\n Whole Blood Microscopy 451 26\n\n\nYou investigate further, looking at one example case with notification_id “043228”. This shows you that this one case was tested twice, with two different samples, one week apart. The first result was positive, and the second result was negative.\n\ndata_lab_tests |&gt; \n  filter(notification_id == \"043228\")\n\n# A tibble: 2 × 7\n  laboratory_name        notification_id sample_id date_test  test  target value\n  &lt;chr&gt;                  &lt;chr&gt;           &lt;chr&gt;     &lt;IDate&gt;    &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;\n1 Kasara University Hos… 043228          27c37cd8  2024-06-18 Whol… Plasm… Posi…\n2 Kasara University Hos… 043228          d2271be0  2024-06-25 Whol… Plasm… Nega…\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich statement about the lab data is correct?\n\n All cases of different diseases get retested Some malaria cases get retested All malaria cases get retested\n\nWill you need to deduplicate the lab data, to link with the notification data?\n\n Yes - we need one row representing the lab result per notification No - the data is sufficiently deduplicated\n\n\n\n\nIf you answered that you need to deduplicate, you are correct!\nDeduplicate your data to have one row per notification ID, prioritizing positive results, so that you can link to the notification data.\nTo do this, follow a similar process as you did in Task B, using the data frame produced by task B:\n\nGroup by notification_id\nArrange by the test result value so that values starting with P are prioritized in the top row, followed by N (negative), and then I (indeterminate).\nThen keep the first row within each group of notification_ids, using slice().\nWhen doing this, create a new object called data_lab_cases.\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the code to deduplicate rows within each group of rows with the same notification_id, prioritizing positive results. Once again you need to specify desc within arrange(). This works perfectly because the desired priority order for results — positive, then negative, then indeterminate — happens to align with reverse alphabetical order (P comes before N, which comes before I, when sorted descending).\nIf your priority order was more complex or didn’t match alphabetical sorting (e.g., if “indeterminate” needed to come before “negative”), you’d have to convert the result column into a factor and explicitly define the desired order of its levels. Don’t forget to ungroup again at the end.\n\ndata_lab_cases &lt;- data_lab_tests |&gt; \n  group_by(notification_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt;\n  ungroup()\n\nYou can then double-check that the new object data_lab_cases has only one row per test, using the combination of count() and tabyl() like you did in Task A. This table shows you that all unique sample IDs are only present in one row each:\n\ndata_lab_cases |&gt; \n  count(notification_id) |&gt; \n  tabyl(n)\n\n n n_n percent\n 1 858       1\n\n\n\n\n\n\n\n\n\nNow we have two objects that we can use for analysis of laboratory data: data_lab_tests and data_lab_cases.\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich object should you use to analyse tests?\n\n data_lab_tests data_lab_cases neither\n\nHow many tests were conducted to test for malaria (via whole blood microscopy)?\n\n 215 503 88 190\n\nWhat percentage of tests for cholera (via stool culture) were positive?\n\n 21% 11% 84% 87%\n\nWhich test had the highest percentage of indeterminate results?\n\n IgM ELISA (for yellow fever detection) Stool Culture (for cholera detection) Blood culture (for typhoid fever detection)\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see the number of positive, negative, and indeterminate results per test. You can add a series of adorn() functions to show percentages and totals.\n\ntabyl(data_lab_tests, test, value) |&gt; \n  adorn_totals(where = \"col\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n                   test Indeterminate    Negative    Positive        Total\n          Blood culture     6.1%  (2) 72.7%  (24) 21.2%   (7) 100.0%  (33)\n     Dengue NS1/IgG/IgM     0.0%  (0) 13.5%  (29) 86.5% (186) 100.0% (215)\n              IgM ELISA    11.4% (10) 51.1%  (45) 37.5%  (33) 100.0%  (88)\n          Stool Culture    11.1%  (5)  4.4%   (2) 84.4%  (38) 100.0%  (45)\n Whole Blood Microscopy    11.1% (56) 51.1% (257) 37.8% (190) 100.0% (503)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich lab data frame should you use to count the number of suspected cases tested?\n\n data_lab_raw data_lab_cases data_lab_tests data_lab\n\nHow many suspected cases were tested in the 2024 lab data?\n\n 858 1314 884\n\nAre there more suspected cases in the notification data or the lab data?\n\n Notification data Lab data\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou can simply look at the number of rows in the data_lab_cases data frame to see the number of suspected cases who were tested.\n\nnrow(data_lab_cases)\n\n[1] 858\n\n\nThis is less than the number of suspected cases that were in the clean notifiable disease surveillance data (data_notif) - which suggests that not all suspected cases in 2024 were tested by the time this data was available.\n\nnrow(data_notif)\n\n[1] 987"
  },
  {
    "objectID": "pages/multidisease_surveillance.html#step-6.-linkage-and-final-processing",
    "href": "pages/multidisease_surveillance.html#step-6.-linkage-and-final-processing",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Now that both linelists are clean and have one row per suspected case, you can link them to enable the full analysis requested by your boss.\n\n\n\n\nCreate a new object called data_linked, using a xxx_join() function from {dplyr}. You want to keep all notifications, but add on test results where available for each suspected case.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich function is the correct approach if you want to retain all rows from your notification data and bring in results from your lab data?\n\n left_join(data_notif, data_lab_cases… full_join(data_notif, data_lab_cases… right_join(data_notif, data_lab_cases…\n\nWhat identifier should be used to link the two linelists?\n\n sample_id notification_id sample_id and date of report notification_id and date of report\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nLink the data using the left_join() function, with notification data as the main data frame on the left. This will keep all the rows from this data frame, and will just bring in the test results from the lab data specified on the “right” of the function.\n\ndata_linked &lt;- left_join(data_notif, data_lab_cases, \n                         by = \"notification_id\")\n\nYou are linking on the notification_id column, which is present, complete, and clean in both linelists.\nNote: You are lucky to work with such a straight-forward example of linkage! Usually you would need to really clean and check the ID column, or link on other columns like name and date fo birth. In Feveria, clinic staff are fantastic at consistently allocating notification IDs to each patient, including on the sample forms sent to the lab, and then the lab staff are equally brilliant at recording the notification ID in their lab systems so that the results can be linked back to the case.\n\n\n\n\n\n\nNow check your data and review a few things.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many rows are in your new data_linked data frame?\n\n 987 884 858\n\nHow does this compare to your original notification data?\n\n more rows than the original same number of rows fewer rows\n\nWhat term best describes the linkage you just did?\n\n many-to-one one-to-one many-to-many\n\nHow many lab results were NOT linked (hint: use anti-join())?\n\n 30 19 0\n\nHow fortunate are you that your linkage is so successful?\n\n What? Isn't all linkage this simple?? Very! Usually some records don't match\n\nWhat are typical reasons that lab data doesn’t match to the notifiable diseases data?\n\n There are typos in the columns used for linkage, so they are not recognised as matching The lab data may contain additional cases from other clinics or countries The lab data may include test samples Notifications may have been accidentally missed in the notification data even though the sample was tested in the lab All of the above\n\nHow many suspected cases do not have a result?\n\n 83 100 129\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nCheck the number of rows in each data frame with the nrow() function, or by checking the object information in your environment. You can see that this was simply a one-to-one merge, because each row had a unique notification_id, so one row in the notification data linked directly to one row in the lab data.\nNumber of rows in notification data\n\nnrow(data_notif)\n\n[1] 987\n\n\nNumber of rows in linked data\n\nnrow(data_linked)\n\n[1] 987\n\n\nTo check if there were any lab result that were not linked to the notification data, you can use anti_join(). This time the data_lab_cases object is on the left, as the function assess how many rows from the left data frame were not found in the right data frame, matching by notification_id. Here you do not need to generate a new data frame, you can simply pipe into an nrow() to count the number of rows. The output is 0, which shows there were no unlinked results - amazing!\n\nanti_join(data_lab_cases, data_notif, \n          by = \"notification_id\") |&gt; nrow()\n\n[1] 0\n\n\nFinally, to check the number of notifications without a result, you can either conduct an anti_join in putting data_notif first:\n\nanti_join(data_notif, data_lab_cases, \n          by = \"notification_id\") |&gt; nrow()\n\n[1] 129\n\n\nOr, you can simply tabulate the number of missing values in the value column in data_linked (as the value column comes from the lab data).\n\ntabyl(is.na(data_linked$value)) \n\n is.na(data_linked$value)   n   percent\n                    FALSE 858 0.8693009\n                     TRUE 129 0.1306991\n\n\nBoth of these approaches show that 129 suspected cases do not have a lab test result.\n\n\n\n\n\n\n\n\n\nUse mutate() to create a new column case_category, updating the label of suspected cases according to their lab result. The categories should be as follows:\n\nIf the result was positive: Confirmed\nIf the result was negative: Discarded\nIf the result was indeterminate or missing: Suspected\n\nThis means that all cases in the notification data are initially suspected when reported, and then remain suspected if there is no conclusive test result.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich is the most appropriate function for creating this new column?\n\n case_when() if_else() case_match()\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYou should use case_when() to create the new column. This function is ideal for applying multiple logical conditions to create multiple values, whereas case_match() is better for replacing specific values, and if_else() is better if there are only two possible values.\n\ndata_linked &lt;- data_linked |&gt; \n  mutate(case_category = case_when(value==\"Positive\" ~ \"Confirmed\",\n                                   value==\"Negative\" ~ \"Discarded\",\n                                   value==\"Indeterminate\" | is.na(value) ~ \"Suspected\"))\n\n\n\n\n\n\n\n\n\n\nUse tabyl() overall, and also cross-tabulate by disease to answer the questions below.\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow many cases in the linked notification data did not have a positive or negative result?\n\n 202 347 250\n\nWhat percentage of cases in the notification data DID have a positive or negative result?\n\n 60.1% 79.5% 92.2%\n\nWhy are there more remaining suspected cases than there are unlinked notifications?\n\n Suspected cases include notifications without a lab result and with an indeterminate lab result There are additional suspected cases being brought in from the lab There is an issue with the data\n\nWhich disease had the highest percentage of cases that remained suspected after linkage?\n\n Cholera Malaria Dengue Yellow fever\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nOnce again you can use tabyl() to see the distribution of case categories across notifications. The total number of suspected cases, i.e. those with either no lab result at all or with an indeterminate result, is 202. This means 785 cases, i.e. 79.5%, did have a definitive laboratory result.\n\ntabyl(data_linked, case_category) \n\n case_category   n   percent\n     Confirmed 438 0.4437690\n     Discarded 347 0.3515704\n     Suspected 202 0.2046606\n\n\nYou can also cross-tabulate the original results (indeterminate/negative/positive) in the value column with the new case_category column, firstly to check your logic worked, and to see how the original values map to the new column values. This shows that in addition to the 129 notifications that were not linked (with NA in the value column), 73 had indeterminate results, so were categorized as suspected cases.\n\ntabyl(data_linked, case_category, value) \n\n case_category Indeterminate Negative Positive NA_\n     Confirmed             0        0      438   0\n     Discarded             0      347        0   0\n     Suspected            73        0        0 129\n\n\nFinally, you can also cross-tabulate with the disease name to see the case categories by disease. Add additional adorn_xxx() functions for percentage formatting. The table shows you that 22% of yellow fever cases remained suspected, which was the highest percentage compared to the other diseases.\n\ntabyl(data_linked, disease_notified, case_category) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n disease_notified   Confirmed   Discarded   Suspected        Total\n          cholera 82.6%  (38)  4.3%   (2) 13.0%   (6) 100.0%  (46)\n           dengue 68.1% (186) 10.6%  (29) 21.2%  (58) 100.0% (273)\n          malaria 32.6% (174) 46.3% (247) 21.0% (112) 100.0% (533)\n          typhoid 20.0%   (7) 68.6%  (24) 11.4%   (4) 100.0%  (35)\n     yellow fever 33.0%  (33) 45.0%  (45) 22.0%  (22) 100.0% (100)\n            Total 44.4% (438) 35.2% (347) 20.5% (202) 100.0% (987)\n\n\n\n\n\n\n\n\nUse tabyl() for this once again, looking at the results by disease. Think about the correct denominator!\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhat percentage of suspected cases reported in 2024 were true cases, according to their test results?\n\n 44% 56% 59%\n\nWhat percentage of suspected malaria cases were really malaria?\n\n 86% 41% 23%\n\nWhat percentage of suspected dengue cases were really dengue?\n\n 87% 41% 23%\n\n\n\n\n\n\n\n\n\n\nClick to read a hint\n\n\n\n\n\nDivide the number of confirmed cases (i.e. those with a positive result) by the number of confirmed plus discarded cases (i.e. those with either a positive or negative result). This gives a positivity rate, which approximates the percentage of suspected cases that were truly cases. Indeterminate results are excluded because they don’t provide a clear outcome and would skew the positivity rate.\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nFilter out suspected cases and then cross-tabulate, to see the percentage of originally suspected cases that become confirmed or discarded, among those with valid test results.\nBecause there is a totals row, you can see that 56% of suspected cases overall became confirmed, among those with a valid result. You can also see that 41% and 87% of malaria and dengue cases respectively were confirmed.\n\ndata_linked |&gt; \n  filter(case_category != \"Suspected\") |&gt; \n  tabyl(disease_notified, case_category) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns()\n\n disease_notified   Confirmed   Discarded        Total\n          cholera 95.0%  (38)  5.0%   (2) 100.0%  (40)\n           dengue 86.5% (186) 13.5%  (29) 100.0% (215)\n          malaria 41.3% (174) 58.7% (247) 100.0% (421)\n          typhoid 22.6%   (7) 77.4%  (24) 100.0%  (31)\n     yellow fever 42.3%  (33) 57.7%  (45) 100.0%  (78)\n            Total 55.8% (438) 44.2% (347) 100.0% (785)\n\n\n\n\n\n\n\n\n\nTask A: Create a new linelist called data_linked_confirmed.\nThis is what you will use in official surveillance reporting.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhy are we opting to report only confirmed cases in our surveillance data?\n\n Reporting confirmed cases can be more reliable and accurate when the percentage testing positive is low and lab testing is routine, thereby helping prevent over-estimation of disease burden Reporting confirmed cases is slower, which gives us more time to be sure of what we are reporting Because we want to hide the true number of cases\n\nWhat function is important for creating the new linelist?\n\n filter() arrange() mutate()\n\nHow many rows are in this new data frame?\n\n 389 438 858\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nYour surveillance unit wants to focus on confirmed cases in reporting. This is because lab testing is routine in Feveria, and so reporting suspected cases would be unnecessarily inaccurate, with a high percentage of suspected cases getting discarded.\nThe decision to publish suspected cases may be different in other contexts. For example, if the positivity rate is high (most cases are true cases if tested), and testing itself is not common, or testing takes a long time and would result in delayed reporting, this would suggest that suspected case trends are sufficiently accurate and also more timely than waiting for laboratory confirmation.\nCreate the new linelist with the filter() function:\ndata_linked_confirmed &lt;- data_linked |&gt; \n  filter(case_category==\"Confirmed\")\nAnd check the number of rows by looking at the information in your environment, or with nrow():\nnrow(data_linked_confirmed)\n[1] 438"
  },
  {
    "objectID": "pages/multidisease_surveillance.html#step-7.-descriptive-analysis-of-confirmed-cases",
    "href": "pages/multidisease_surveillance.html#step-7.-descriptive-analysis-of-confirmed-cases",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Now that you have your linelist of confirmed notifiable disease cases reported in Feveria in 2024, you are ready to conduct the final part of your surveillance analysis! Namely, this is to summarize the five notifiable diseases by geography and time.\nTip: Typically surveillance analysis would also include analysis by person. You could expand on this case study by also analyzing by demographic variables.\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich notifiable disease was most commonly reported in 2024, when restricting to only confirmed cases?\n\n Dengue Malaria Yellow Fever\n\nWhy is the most commonly reported disease different when looking at confirmed and suspected cases?\n\n The sensitivity and specificity of the clinical diagnosis may differ by disease The performance of the tests used in the lab may differ by disease There may be reporting biases All of the above!\n\nWhich district reported the most confirmed cholera cases in 2024?\n\n Lake Minara Feveria Central Kasara\n\nHow many confirmed cases of cholera reported in 2024 were among residents of Feveria Central?\n\n 35 42 4\n\nWhich district reported the most confirmed malaria cases in 2024?\n\n Lake Minara Feveria Central Kasara\n\nDoes this data confirm that dengue is the most common infectious disease in Feveria?\n\n No - a different disease may be under-reported and/or not notifiable Yes - if it's most reported then it must be most common\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nUsing tabyl(), we can see that dengue was the most commonly reported disease in Feveria in 2024 when restricting to confirmed cases, with 186 cases.\n\ndata_linked_confirmed |&gt; \n  tabyl(disease_notified) \n\n disease_notified   n    percent\n          cholera  38 0.08675799\n           dengue 186 0.42465753\n          malaria 174 0.39726027\n          typhoid   7 0.01598174\n     yellow fever  33 0.07534247\n\n\nNote that this is different from the suspected cases, where malaria was most commonly reported (with 533 suspected cases)! This was hinted at previously, when you saw that the positivity rate for suspected dengue cases was higher than for suspected malaria cases. This can be for different reasons, for instance the clinical diagnosis method used for malaria may be less specific (so many of the suspected cases are actually other diseases), or the test used for dengue may be more sensitive.\nTo cross-tabulate with residential district, add the relevant adorn_xxx() functions.\n\ndata_linked_confirmed |&gt; \n  tabyl(disease_notified, residential_district) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n disease_notified Feveria Central     Kasara Lake Minara        Total\n          cholera      92.1% (35)  7.9%  (3)  0.0%   (0) 100.0%  (38)\n           dengue       8.6% (16) 17.2% (32) 74.2% (138) 100.0% (186)\n          malaria      14.9% (26) 22.4% (39) 62.6% (109) 100.0% (174)\n          typhoid      71.4%  (5) 28.6%  (2)  0.0%   (0) 100.0%   (7)\n     yellow fever       0.0%  (0) 18.2%  (6) 81.8%  (27) 100.0%  (33)\n            Total      18.7% (82) 18.7% (82) 62.6% (274) 100.0% (438)\n\n\nLike with the suspected cases, we can see that most confirmed cases of dengue, malaria, and yellow fever were located in Lake Minara - the lake area with higher density of mosquitoes and therefore vector-borne disease. The majority of confirmed cholera and typhoid fever cases were in Feveria Central, where there are water and sanitation issues.\nThe data suggests that vector-borne disease (dengue and malaria) are a particular concern in this tropical country. However, we don’t know for sure which is the most common disease and what the underlying patterns are - only five diseases are notifiable, and typically the reported cases only represent a fraction of true cases in the community.\n\n\n\n\n\n\n\nYou are going to work towards producing this epicurve, over the various tasks below.\n\n\n\n\n\n\n\n\n\n\n\nMake sure you specify the argument binwidth=7 so that each bar in the histogram represents the number of cases within a 7 day period.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhen was the first case of typhoid fever reported in Feveria in 2024?\n\n January 2024 May 2024 October 2024\n\nAccording to this graph, what was the highest number of dengue cases reported in a single week in 2024?\n\n 10 20 30 It's very hard to tell from this stacked graph!\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is some simple code to produce the epicurve. Note that you are not controlling the colors just yet, or specifying what day of the week each 7-day period starts on.\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = disease_notified)), binwidth=7)\n\n\n\n\n\n\n\n\nRefer to the dates chapter in the Epi R Handbook if you want more specific date formatting, for instance so that each bar represents a Monday-Sunday week, or the x axis labels the week number (weeks 1 - 52).\nImportantly - it is not straight forward to see the trends per disease when stacked this way! To see such temporal trends, you should produce one histogram per disease.\n\n\n\n\n\n\nUse facet_wrap() to easily create several mini-plots, one per disease. To understand this further, you can look at the facet section of the ggplot2 chapter in the Epi R Handbook\n\n\n\n\n\n\nQuestions\n\n\n\n\nAccording to this faceted graph, what was the highest number of dengue cases reported in a single week in 2024?\n\n 11 15 29 I still can't tell!\n\nAmong the dengue cases reported that week, what districts did they live in?\n\n All three districts Feveria Central Kasara Lake Minara This graph does not show this information\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nNow you can see an epicurve per disease! And you can see that during one week in July, 15 cases of dengue were reported. However, this graph does not show any geographical information yet.\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report)), binwidth=7) + \n  facet_wrap(.~disease_notified)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nAmong the 15 dengue cases reported in one week in July 2024, what districts did they live in?\n\n All three districts Feveria Central Kasara Lake Minara\n\nIn what district was the first typhoid fever case reported in 2024?\n\n Kasara Feveria Central Lake Minara I still can't tell!\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nNow you can see an epicurve per disease, with the coloring reflecting the district the case is a resident of.\nYou can see that among the 15 dengue cases reported in a single week, they lived across the three different districts. You can also see that the first case of typhoid was reported in Feveria Central.\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = residential_district)), binwidth=7) + \n  facet_wrap(.~disease_notified)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can specify:\n\nThe theme/appearance of the overall graph (e.g. background color, appearance of grid lines)\nThe title and labels\nThe colors of the bars (with scale_fill_manual())\nThe formatting and spacing of dates along the x-axis (with scale_x_date)\nMany other things!\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nDo cholera and typhoid fever appear endemic?\n\n No - the data suggests smaller occasional outbreaks Yes they are both endemic\n\nIs there a particular time of the year when malaria peaked in 2024?\n\n Yes - around November/December time Yes - around July/August (summer) time No, it is consistently high\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nHere is the fully formatted code. Note some other changes include specifying that we only want two columns of mini-plots within facet_wrap(), and that the date label along the x axis should only show day and month (not year, since all cases are in 2024 anyway).\n\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = residential_district)), binwidth=7) +\n  facet_wrap(.~disease_notified, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"District of residence\",\n       x = \"Date reported by clinic\",\n       y = \"Count\",\n       subtitle = \"Number of confirmed cholera, dengue, malaria, typhoid fever, and yellow fever cases by week in Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n\n\n\n\n\n\nWe can also see from the epicurve that cholera and typhoid appear to be occurring as isolated outbreaks, rather than showing endemicity. Malaria and dengue however were present in Feveria throughout the year, with malaria more obviously peaking in the summer months.\n\n\n\n\n\n\nThis time, use group_by() and summarize() to produce a table by district showing the earliest and latest report dates.\nYou can adjust your table with a filter() function to create this table for one district at a time.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhen was the first dengue case reported in Feveria in 2024?\n\n 18th January 2024 17th January 2024 12th February 2024\n\nWhen was the last dengue case reported in Feveria Central in 2024?\n\n 22nd August 2024 18th November 2024 25th December 2024\n\n\n\n\n\n\n\n\n\n\nClick to see the solution (try it yourself first!)\n\n\n\n\n\nGroup the data by disease and then summarize the first and last date to look at the overall timeline of each disease in Feveria.\n\ndata_linked_confirmed |&gt; \n  group_by(disease_notified) |&gt; \n  summarize(first_reported = min(date_report), \n            last_reported = max(date_report)) |&gt;\n  ungroup()\n\n# A tibble: 5 × 3\n  disease_notified first_reported last_reported\n  &lt;chr&gt;            &lt;date&gt;         &lt;date&gt;       \n1 cholera          2024-06-03     2024-09-23   \n2 dengue           2024-01-17     2024-11-18   \n3 malaria          2024-01-08     2024-12-25   \n4 typhoid          2024-05-02     2024-11-07   \n5 yellow fever     2024-03-08     2024-08-23   \n\n\nAdd a filter() to the code to look at first and most recent report dates for the district you’re interested in.\n\ndata_linked_confirmed |&gt; \n  filter(residential_district == \"Feveria Central\") |&gt; \n  group_by(disease_notified) |&gt; \n  summarize(first_reported = min(date_report), \n            recent_reported = max(date_report)) |&gt;\n  ungroup()\n\n# A tibble: 4 × 3\n  disease_notified first_reported recent_reported\n  &lt;chr&gt;            &lt;date&gt;         &lt;date&gt;         \n1 cholera          2024-06-03     2024-09-23     \n2 dengue           2024-01-29     2024-08-22     \n3 malaria          2024-01-29     2024-12-17     \n4 typhoid          2024-05-02     2024-11-07"
  },
  {
    "objectID": "pages/multidisease_surveillance.html#conclusion",
    "href": "pages/multidisease_surveillance.html#conclusion",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Wow! In line with the objectives for this case study, you have done the following:\n\nYou used key R functions to clean, reshape, and link data frames, plus created new columns using logical conditions.\nTo inform the data processing, you conducted data inspections and checks along the way\nYou conducted a thorough descriptive analysis to understand the testing and notification data, before and after linkage. In response to your supervisor’s original four questions, you can say:\n\nHow many suspected cases of the different notifiable diseases were reported in 2024, and which was most common? Malaria was the most common notifiable disease in Feveria in 2024, reported through the notifiable disease surveillance system: There were 533 suspected cases of malaria reported, 273 suspected cases of dengue, 100 yellow fever, 46 cholera, and 35 typhoid.\nWhat percentage of them ended up being confirmed? Almost 80% of notifiable cases reported in 2024 had a laboratory test result by the time the linked dataset was created, with some variation by disease. In total, 56% of notified cases were eventually confirmed, but this ranged from only 23% for typhoid fever (7 confirmed of 31 suspected cases with test results), to 95% for cholera (38 confirmed of 40 suspected cases with rest results). Additionally, the positivity rate was higher for suspected dengue than for suspected malaria (87% vs 41%).\nHow many confirmed cases of different notifiable diseases were reported in 2024, and which was most common? Confirmed cases followed a slightly different trend to suspected cases: the most commonly reported infection was dengue with 186 cases, followed by malaria (174), then cholera (38), yellow fever (33), and typhoid fever (7).\nHow are confirmed cases geographically and temporally distributed in Feveria? Feveria experienced dengue and malaria transmission throughout the year, peaking in the summer, and concentrated in the Lake Minara district. Feveria also experienced small and infrequent outbreaks of diarrhoeal disease, e.g. cholera and typhoid fever, particularly in the urban Feveria Central where there can be issues with water and sanitation.\n\nFinally, you have reflected on how the processes involved in notifiable disease surveillance systems and lab testing, for instance the transfer of data between clinics to labs, can affect data quality and completeness, and therefore your results.\n\nThere is so much more potential ahead. You can explore disease patterns by age or sex, calculate disease rates with population data, and even analyze reporting delays by examining the different dates in your datasets.\nYou have built a strong foundation and are well equipped to take your analysis to the next level. Keep going — exciting discoveries await!\nTo learn more, check out the other case studies or dive into the Epi R Handbook."
  },
  {
    "objectID": "pages/multidisease_surveillance.html#data-cleaning-and-analysis-code",
    "href": "pages/multidisease_surveillance.html#data-cleaning-and-analysis-code",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "See below a script of all data cleaning steps and descriptive analyses. Note how the analyses are combined at the end rather than interspersed in between cleaning steps. This is a tidier way to organize your script.\nFor brevity, the code below does not include all inspections and checks made along the way, but you may decide to create a sections with such checks.\nThe top of your script should also contain information to help the reader understand what the script is for, as well as comments throughout. You will thank yourself later for adding these comments!\n\n\n\n\n\n\nCode to clean and analyse notification data and lab data from Feveria, 2024\n\n\n\n\n\n\n# Code to clean and analyse notification data and lab data from Feveria, 2024\n# Date:\n# Author:\n\n# Install packages -------------------------------------------------\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  flextable,  # Presentation ready tables\n  naniar,     # Evaluating missingness of data\n  remotes,    # Used to install package to download data\n  tidyverse   # data management and visualization\n)\n\n# Import data --------------------------------------------\n\n# Notification data\ndata_notif_raw &lt;- import(\"data/multidisease_notifications.xlsx\")\n\n# Lab data\ndata_lab_raw &lt;- import(\"data/multidisease_tests.csv\")\n\n# Clean notification data --------------------------------\ndata_notif &lt;- data_notif_raw |&gt; \n  clean_names() |&gt; \n  rename(date_report = date_reported_by_health_facility_community) |&gt; \n  select(notification_id, residential_district, disease_notified, date_report) |&gt; \n  mutate(residential_district = case_match(str_to_title(residential_district),\n                                           c(\"F Central\", \"Feveria C\", \"Feveria Central\") ~ \"Feveria Central\",\n                                           c(\"Kasara\", \"Ksr\") ~ \"Kasara\",\n                                           c(\"L Minara\", \"Lake Minara\", \"Lakeside\") ~ \"Lake Minara\")) |&gt; \n  mutate(date_report = ymd(date_report)) \n\n\n# Clean and consolidate lab data  ---------------------------------------\n# Clean values\ndata_lab &lt;- data_lab_raw |&gt; \n  mutate(value = case_match(value, \n                            c(\"P\", \"PO1\", \"PO139\") ~ \"Positive\",\n                            \"N\" ~ \"Negative\",\n                            \"I\" ~ \"Indeterminate\"))\n\n# Create test-level lab data\ndata_lab_tests &lt;- data_lab |&gt; \n  filter(target != \"Dengue IgG\") |&gt; \n  group_by(sample_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Create case-level lab data\ndata_lab_cases &lt;- data_lab_tests |&gt; \n  group_by(notification_id) |&gt; \n  arrange(desc(value)) |&gt; \n  slice(1) |&gt; \n  ungroup()\n\n# Link notification and lab data  ---------------------------------------\ndata_linked &lt;- left_join(data_notif, data_lab_cases, by = \"notification_id\")\n\n# Clean data--------------------------------------------------------------\ndata_linked &lt;- data_linked |&gt; \n  mutate(case_category = case_when(value==\"Positive\" ~ \"Confirmed\",\n                                   value==\"Negative\" ~ \"Discarded\",\n                                   value==\"Indeterminate\" | is.na(value) ~ \"Suspected\"))\n\ndata_linked_confirmed &lt;- data_linked |&gt; \n  filter(case_category==\"Confirmed\")\n\n# ANALYSIS ---------------------------------------------------------\n# Number of suspected cases in Feveria\ntabyl(data_notif, disease_notified)\n\n# Distribution of suspected cases by district\ntabyl(data_notif, disease_notified, residential_district) |&gt;\n  adorn_percentages() |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns()\n\n# Distribution of results per disease-specific test\ntabyl(data_lab_tests, test, value) |&gt; \n    adorn_totals(where = \"col\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution of case category, in linked data: all cases\ntabyl(data_linked, case_category) \n\n# Distribution of case category by diseases, in linked data: all cases\ntabyl(data_linked, disease_notified, case_category) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution of case category by disease, in linked data: only cases with a valid result\ndata_linked |&gt; \n    filter(case_category != \"Suspected\") |&gt; \n    tabyl(disease_notified, case_category) |&gt; \n    adorn_totals(where = \"both\") |&gt; \n    adorn_percentages() |&gt; \n    adorn_pct_formatting() |&gt; \n    adorn_ns()\n\n# Distribution of confirmed cases by district\ndata_linked_confirmed |&gt; \n  tabyl(disease_notified, residential_district) |&gt; \n  adorn_totals(where = \"both\") |&gt; \n  adorn_percentages() |&gt; \n  adorn_pct_formatting() |&gt; \n  adorn_ns() \n\n\n# Visualize confirmed cases over time\ndata_linked_confirmed |&gt; \n  ggplot()+\n  geom_histogram((aes(x = date_report, fill = residential_district)), binwidth=7) +\n  facet_wrap(.~disease_notified, ncol=2) +\n  theme_minimal() + \n  labs(fill = \"District of residence\",\n       x = \"Date reported by clinic\",\n       y = \"Count\",\n       subtitle = \"Number of confirmed cholera, dengue, malaria, typhoid fever, and yellow fever cases by week in Feveria, 2024\") +\n  scale_fill_manual(values = c(\"navy\", \"lightblue\", \"seagreen\")) +\n  scale_x_date(date_breaks = \"1 month\", \n               date_labels = \"%d %b\") +\n  theme(legend.position=\"bottom\",\n        axis.text.x = element_text(angle=90)) \n\n\n# First and last report date per disease\ndata_linked_confirmed |&gt; \n  group_by(disease_notified) |&gt; \n  summarize(first_reported = min(date_report), \n            last_reported = max(date_report)) |&gt;\n  ungroup()"
  },
  {
    "objectID": "pages/multidisease_surveillance.html#case-study-information",
    "href": "pages/multidisease_surveillance.html#case-study-information",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Original authors: Paula Blomquist and Alanah Jansen, with technical support provided by the CDC Global Surveillance, Laboratory, and Data Systems Branch in collaboration with TEPHINET.\nData source: Fictional data provided by Applied Epi.\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nJuly 2025\nFirst draft\n1\nPaula Blomquist and Alanah Jansen, Applied Epi, with technical support by the CDC Global Surveillance, Laboratory, and Data Systems Branch in collaboration with TEPHINET"
  },
  {
    "objectID": "pages/multidisease_surveillance.html#terms-of-use",
    "href": "pages/multidisease_surveillance.html#terms-of-use",
    "title": "Linking and analysing notification data and laboratory data in R",
    "section": "",
    "text": "Disclaimer: The information presented in this exercise and the associated data files have been developed to help learners achieve the intended learning objectives. The contents are those of the author(s) and do not necessarily represent the official views of CDC, the US Department of Health and Human Services, or TEPHINET.\nLicense: This case study is under a CC BY-NC-SA 4.0 license. For more information about sharing and adapting this case study, see the associated deed.\nFunding: This case study was 100% supported by Cooperative Agreement number NU2HGH000044 funded by the US Centers for Disease Control and Prevention (CDC)."
  },
  {
    "objectID": "index.es.html",
    "href": "index.es.html",
    "title": "Estudios de caso Repositorio abierto",
    "section": "",
    "text": "Objetivo En este repositorio puede ayudarle a desarrollar su epidemiología a través de estudios de casos que cubren situaciones y métodos epidemiológicos comunes.\nEscrito por epidemiólogos, para epidemiólogos\nEpidemiología aplicada es una organización sin ánimo de lucro y un movimiento de base de epis de primera línea de todo el mundo. Escribimos en nuestro tiempo libre para ofrecer este recurso a la comunidad. Su aliento y sus comentarios son muy bienvenidos:\n\nVisite nuestra página web y únase a nuestra lista de contactos\ncontact@appliedepi.org tuitear @appliedepi o LinkedIn\nEnvíe temas a nuestro repositorio Github"
  },
  {
    "objectID": "index.es.html#autores",
    "href": "index.es.html#autores",
    "title": "Estudios de caso Repositorio abierto",
    "section": "Autores",
    "text": "Autores"
  }
]