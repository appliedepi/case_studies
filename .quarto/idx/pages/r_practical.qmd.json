{"title":"Descriptive analysis of the 2022 Mpox outbreak in Europe","markdown":{"yaml":{"output":"html_document","editor_options":{"chunk_output_type":"console"},"execute":{"warning":false,"error":false},"format":{"html":{"css":"webex.css","include-after-body":"webex.js"}},"editor":{"markdown":{"wrap":72}}},"headingText":"Descriptive analysis of the 2022 Mpox outbreak in Europe","headingAttr":{"id":"sec-rpractical","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Tool**: R \\| **Technical complexity**: Basic \\| **Methodological\ncomplexity**: Basic\\\n**Source:** ECDC EI Group (simulated data)\\\n**Prior knowledge required:** [R\nbasics](https://epirhandbook.com/en/new_pages/basics.html) (Using\nRstudio; R packages, functions and arguments, using pipes)\n:::\n\n::: {.callout-important title=\"WEBSITE UNDER CONSTRUCTION\"}\nThis is a draft version of this page. The content and URL will change.\n:::\n\nFor instructions on how to use our case studies, see our [How-to\nGuide](instructions.html). We welcome feedback and suggestions via\n[contact\\@appliedepi.org](mailto:contact@appliedepi.org). You can also\ndiscuss the case study or related concepts on the [Applied Epi\nCommunity](https://community.appliedepi.org/).\n\n\\pagebreak\n\n## Scenario\n\nIt is May 2022 and Mpox has just been reported for the first time across\n5 countries in Europe: Countries \"A\", \"B\", \"C\", \"D\", and \"E\". You have\nbeen requested to provide a basic descriptive analysis to the European\nCentre for Disease Prevention and Control (ECDC).\n\nYou are given access to:\n\n-   A dataset with aggregate case counts, submitted to ECDC by the five\n    countries as part of routine European reporting\n-   A linelist with cases, submitted by the five countries to ECDC for\n    this particular analysis\n\nLet's go!\n\n## Objectives\n\nIn this case study you will:\n\n1.  Explore different types of files and how they can be imported in R.\n2.  Perform basic data cleaning, e.g., changing the variable type,\n    recoding variables, aggregating and filtering.\n3.  Perform a basic descriptive analysis using tables and graphs\n\n## Step 1. Set up\n\n### 1.1 Get started in RStudio\n\nStart by setting up a reproducible and well-organized workflow. This\nwill make it easy to rerun your analysis whenever needed.\n\n**Tasks:**\n\n-   Set up an RStudio project\n-   Set up clear sub-folders where your code, data, and outputs will go\n-   Create an R script, or an R Markdown file if you prefer. Make sure\n    the script purpose, date, and author are written as comments at the\n    top.\n-   Extra: Ensure your working language in RStudio is appropriate (e.g.\n    English for this exercise)\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\n-   Create a folder where all the work in this case study will go. For\n    example, create 'mpox_analysis' on your computer desktop. Create\n    your RStudio project to be based in this folder.\n\n-   We suggest creating the following sub-folders: `scripts` (for your\n    code), `data` (for your data), and `outputs` (for your analytical\n    outputs).\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nCreate a folder (e.g. 'mpox_analysis' on your Desktop) for your work. To\ncreate an Rstudio project in your new folder, click `New Project…` in\nthe top left of your R Studio, then `Existing Directory`, then `Browse`\nto select your new folder. For more information, look at the [R\nprojects](https://epirhandbook.com/new_pages/r_projects.html) section of\nthe Epi R Handbook.\n\nStart a new R script by clicking `New File…` in the top left of your R\nStudio, then `R Script`. Save it immediately in the appropriate place,\ne.g. in a 'scripts' subfolder of your R Project.\n\nAt the top of your new R script, write some essential information like\nyour name, the purpose of the file, and the date.\n\nYour R locale determines the language and regional settings used for\nthings like date formats and translations. If your locale is different\nfrom the language you want for your report (e.g., a French locale vs. an\nEnglish report), you can change it to English by running\n`Sys.setlocale(\"LC_ALL\", \"English\")`. Include this in your script if\nneeded, or skip it if your locale is usually appropriate. This is\nexplained in more detail in the [How-to Guide](pages/instructions.qmd_).\n\n</details>\n\n### 1.2 Install/load packages\n\nNext in your R script, you need to install and load the necessary R\npackages. This ensures that the functions you need are available for\nyour analysis.\n\nYou will need the following packages: `rio` (for importing data),\n`janitor` (for cleaning data), `lubridate` (for cleaning dates), `skimr`\n(for reviewing data), `epikit` (for epi-related tasks), `gtsummary` (for\npresentation-ready tables), `apyramid` (for age-sex pyramids), and\n`tidyverse` (for general data manipulation/science tasks).\n\nAs you start, your trusted colleague nudges you and whispers \"I've heard\nthat a great way to manage your packages is with the `pacman` package\".\n\nOver to you!\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nUse the function `p_load()` from `pacman` for this task. You provide the\nfunction with a list of packages that you want to use. It will take two\nsteps per package: 1) Check if the package is installed on your\ncomputer, and install it if necessary, then 2) Load the package so it\ncan be used during this R session.\n\nIf you don't already have `pacman` installed, you will need to install\nit the \"traditional way\" first, with `install.packages()`.\n\nNote that the order of packages in your p_load function can be\nimportant. If two packages have the same function names (e.g. `select()`\nin the package `MASS` and `select()` in `tidyverse`, which do different\nthings), then R will use the function from the most recently loaded\npackage. To prioritize functions from tidyverse, which are commonly used\nfor data manipulation and visualization, load tidyverse last.\n\n</detail>\n\n```{r, echo=TRUE, eval=TRUE}\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\n```\n\n## Step 2: Download and import the data\n\n### 2.1: Download the data\n\nECDC provides you with two files for your analysis, both updated as of\n31st August 2022:\n\n-   A case-level linelist (*\"mpox_linelist.xlsx\"*) with case information\n    from five countries (countries A - E)\n-   An aggregate table (*\"mpox_aggregate_table.csv\"*) for those\n    countries with cumulative case counts per day.\n\nThey provide it to you via AppliedEpi's very useful data repository,\nwhich you can access using the `{appliedepidata}` package. So first you\nneed to download these two files to your own computer, as follows:\n\n1)  Install the `{appliedepidata}` package from GitHub using the\n    `install_github()` function in the `{remotes}` package. Install\n    `{remotes}` if you need to first.\n\n```{r , echo=TRUE, eval=FALSE}\n# Install remotes if you need to (so you can install a package from GitHub)\npacman::p_load(\"remotes\")\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n```\n\n2)  Save the two datasets into a specific folder using the `save_data()`\n    function from `{appliedepidata}`, by running the code below. The\n    example below saves the data into a 'data' subfolder within the\n    RStudio project. Note that if you do not specify a location within\n    the 'path' argument of the function, a window will pop up asking you\n    to manually select a folder.\n\n```{r , echo=TRUE, eval=FALSE}\n# Save down the two mpox files using the save_data() function from appliedepidata\nappliedepidata::save_data(\"mpox_linelist\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"mpox_aggregate_table\",\n                          path = \"data\")\n```\n\n### 2.2 Import the data\n\nGreat! Thanks ECDC and Applied Epi! Now it's time to import the data\nfrom that folder into RStudio, so you can analyse it.\n\n**Task:** Import the downloaded case-based and aggregated data into your\nR environment. Ideally you want to use one function for both datasets,\ndespite one being a csv and the other an xlsx file.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nUse the `import` function from the `{rio}` package, which can recognize\nand import different file types. It replaces importing functions that\nare specific to the file type, such as `read.csv()` from `{base}` for\n.csv files and `read_excel()` from `{readxl}` to import .xlsx files.\n\nIf you feel you need to know more about importing functions, read the\n[Import and export](https://epirhandbook.com/new_pages/importing.html)\nchapter of the EpiRhandbook.\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\nBelow we use the import function to bring in both files. Note how we are\nassigning the imported data to two objects, one called\n*mpox_linelist_raw*, and one called *mpox_agg_raw*. We add the 'raw'\nsuffix to distinguish this data from the cleaned versions we will make\nlater.\n\n```{r , echo=TRUE, eval=FALSE}\n# Import data  --------------\n\n# Case-based data\nmpox_linelist_raw <- import(\"data/mpox_linelist.xlsx\")\n\n# Aggregated data\nmpox_agg_raw <- import(\"data/mpox_aggregate_table.csv\")\n\n```\n\n```{r, include = FALSE}\n# This code is actually run; the prior chunk is just for show for simplicity\n\npacman::p_load(\"remotes\")\n\nif (!requireNamespace(\"appliedepidata\", quietly = TRUE)) {\n  remotes::install_github(\"appliedepi/appliedepidata\")\n}\n\nappliedepidata::get_data(\"mpox_linelist\")\nmpox_linelist_raw <- mpox_linelist\n\n\nappliedepidata::get_data(\"mpox_aggregate_table\")\nmpox_agg_raw <- mpox_aggregate_table\n\nrm(mpox_linelist, mpox_aggregate_table)\n\n```\n\n</details>\n\n## Step 3: Explore the data\n\nThe data's in, and now it's time to see what story it tells. Take an\ninitial look at your data to check its quality and how you can best use\nit.\n\n**Tasks:** Take a look at the different data frames and determine:\n\n-   The number of columns and observations (e.g. their *dimensions*)\n-   The class of their columns and whether it matches its nature (e.g.,\n    are \"dates\" considered \"dates\" by R?)\n-   If the contents of columns are clean and standardized in the mpox\n    linelist (e.g. gender, clinical symptoms, outcome, hiv status and\n    sexual orientation). Do you need to recode any of them?\n-   How unknown or missing data is categorized in these columns. Do\n    these values need to be standardized?\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nAn efficient function for initial data exploring is `skim()` from the\n`{skimr}` package, as it gives you a lot of information on data\nstructure and content, including the classes of columns.\n\nYou can use the function `tabyl()` from `{janitor}`, to get counts and\npercentages of every category in the data column, one by one. These get\nprinted to your RStudio console.\n\nAlso - we recommend just looking at the data itself! A good function for\nthis is `view()`, a baseR function.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nUsing the `skim` commands you can see the rows and columns of each\ndataset, and you can see how most of the columns in *mpox_linelist_raw*\n(including those containing dates) are character classes. (Results not\nshown on this exercise page)\n\n```{r , echo=TRUE, results='hide'}\n# Explore the dimensions of the two data objects \nskim(mpox_linelist_raw)\nskim(mpox_agg_raw)\n```\n\nTake a look at the overall data using `view()`. It will pop up in the\nData Viewer tab and you will get a good sense of how clean the data is\nand what the missingness is like. This preview shows just 5 rows from\nthe linelist data.\n\n```{r , echo=TRUE, results='hide'}\nview(mpox_linelist_raw)\n```\n\n```{r , echo=FALSE, eval = TRUE}\n#head(mpox_linelist_raw) %>% flextable::flextable()\nDT::datatable(mpox_linelist_raw %>% filter(row_number()<6))\n```\n\n\\br\n\nBelow is an example of using the `tabyl()` function from `{janitor},` to\nlook at the distribution of clinical symptoms. You can see 12 cases have\nmissing clinical information and that many cases have a mix of symptoms.\n\n```{r , echo=TRUE}\n\ntabyl(mpox_linelist_raw, HIVStatus)  \n```\n\nYou can explore further columns one by one (results not shown):\n\n```{r , echo=TRUE, results='hide'}\n# Explore the values of different categorical columns in the mpox linelist: with tabyl\ntabyl(mpox_linelist_raw, Gender)\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms)\n\ntabyl(mpox_linelist_raw, Outcome)\n\ntabyl(mpox_linelist_raw, SexualOrientation)\n\n```\n\nYou could add extra arguments to `tabyl()` to customize the tables, such\nas adding totals and changing the proportions to percentages so they are\neasier to read. See the table on clinical symptoms below. But remember -\nthis is just an initial look so don't go too crazy.\n\n```{r , echo=TRUE}\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms) %>%    # Tabulate symptoms \n  adorn_totals() %>%                              # Add totals to bottom of table\n  adorn_pct_formatting(digits = 2)                # Format percentages\n```\n\nFinally, as an alternative approach to `tabyl()`, you could use\n`tbl_summary()` from the `{gtsummary}` package. We will describe this\nlater.\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"2000\", \"13\", answer = \"3\", \"101\"\n)\n\ncat(\"How many columns does the aggregated data have?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Date\", answer = \"Character\", \"Numeric\", \"Factor\"\n)\n\n\ncat(\"What is the class of the column DateOfNotification in the mpox linelist?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"1168\",\n  \"722\",\n  \"900\",\n  \"446\"\n)\n\n\ncat(\"For how many cases is the HIV status Unknown or missing?\", longmcq(opts))\n\n```\n:::\n:::\n\n## Step 4: Clean the data\n\n### 4.1: Clean the case-based data\n\nSo! The good news: you have information on geography, dates, demographic\ncharacteristics, and clinical details. A promising descriptive analysis\nlies ahead.\n\nBUT! You may noticed that there are a few things to fix before the real\ndetective work begins.\n\nFor example:\n\n-   Column names have capital letters. This isn't outright a problem,\n    but can lead to mistakes since R treats ColumnName and Columnname as\n    different.\n-   Date columns are recognized as character classes, not dates, which\n    would cause issues like incorrect ordering (alphabetical) in\n    epicurves.\n-   Some columns have values that are unclear or unsuitable for\n    presentation. For example gender is categorized with \"F\", \"M\", \"O\"\n    and \"UNK\". The column Outcome is \"A\" and \"UNK\".\n-   Missing data is inconsistently handled, for instance with both \"UNK\"\n    and NA in the HIV status column. R thinks \"UNK\" is a valid value,\n    which it treats differently to true missing data (indicated by NA)\n\n**Tasks**:\n\n-   Create a clean version of your case-based data making all cleaning\n    changes in a single piping command\n-   Change all column names to lower case.\n-   Convert all date columns to class \"Date\".\n-   Convert all missing/unknown values to NA (to be recognized by R as\n    missing)\n-   Recode non-missing \"Gender\" categories into: \"Female\", \"Male\", and\n    \"Other\"\n-   Recode non-misising HIV status into: \"Positive\", \"Negative\" and\n    \"Unknown\"\n-   Recode non-missing sexual orientation into: \"Bisexual\",\n    \"Heterosexual\", and \"MSM/homo or bisexual male\".\n-   Recode non-missing \"outcome\" categories into: \"Alive\" and \"Dead\".\n-   Check that all changes have been made correctly\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo convert all column names to lower case at once rather than renaming\neach column, use the function `clean_names()` from the `{janitor}`\npackage.\n\nUse `{lubridate}` functions to transform date columns into \"Date\" class.\nYou can do this one by one, or you could do all at the same time using\nthe `across()` function from `{dplyr}.` If you feel you need to know\nmore about transforming dates read the chapter [Working with\nDates](https://epirhandbook.com/en/new_pages/dates.html) from the\nEpiRhandbook. If you are not sure how to use the across() function, you\ncan also read the section on [Transform multiple\ncolumns](https://epirhandbook.com/en/new_pages/cleaning.html#clean_across).\n\nThere are different functions that we can use to recode values. We\npropose three: The function `recode()` from `{dplyr}`, the function\n`ifelse()` from `{base}` and the function `case_when()` from `{dplyr}`.\nIf you want to know more about these functions, look that the section on\n[Re-code\nvalues](https://epirhandbook.com/en/new_pages/cleaning.html#re-code-values)\nfrom the EpiRhandbook.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nHere we clean the data using a 'chain' of commands connected by pipes\n(%\\>%), which is the grammar of the functions in the {Tidyverse}. The\noutput is assigned to a new object called mpox_linelist to differentiate\nit from the raw data. It can be helpful to have both the cleaned and raw\ndata available in the environment to compare to the original data if\nneeded.\n\nSee the series of functions and the explanation in the comments.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Create a new object called mpox_linelist which is the clean version of the raw data\nmpox_linelist <- mpox_linelist_raw %>% \n  \n  # standardises names and puts all into lower case \n  clean_names() %>% \n  \n  #transform ONE column into date (note the column names are lower case now)\n  mutate(date_of_notification = ymd(date_of_notification)) %>%  \n\n  #transforms ALL columns starting with \"date\" into dates\n  mutate(across(starts_with(\"date\"), \n                .fns = ~ ymd(.x))) %>%  \n  \n  #transforms UNK to NA across all character columns \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x %in% c(\"UNK\", \"Unknown\"), NA_character_, .x)))  %>% \n\n  # Recode the gender values to be more obvious  \n  mutate(gender = recode(gender,\n                         \"F\" = \"Female\",\n                         \"M\" = \"Male\",\n                         \"O\" = \"Other\")) %>%\n  \n  #recode with ifelse to change only one or two categories based on a rule. \n  mutate(outcome = ifelse(outcome == \"A\", \"Alive\", outcome)) %>%   \n  \n  #recode with case_when for more complex recoding \n  mutate(hiv_status = case_when(hiv_status == \"NEG\" ~ \"Negative\",    \n                                hiv_status == \"POS\" ~ \"Positive\")) %>% \n  \n  mutate(sexual_orientation = case_when(sexual_orientation == \"BISEXUAL\" ~ \"Bisexual\",\n                                        sexual_orientation == \"HETERO\" ~ \"Heterosexual\",\n                                        sexual_orientation == \"MSM\" ~ \"MSM/homo or bisexual male\")) \n```\n\nYou can then review your data by tabulating across all the different\ncolumns you have cleaned. See the preview of the HIV table below - it\nlooks tidier now with more understandable categories, and all missing\ndata is classified as 'Unknown'.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Check that all changes have been made correctly\n\nskim(mpox_linelist)\n\ntabyl(mpox_linelist, gender)\n\ntabyl(mpox_linelist, clinical_symptoms)\n\ntabyl(mpox_linelist, outcome)\n\ntabyl(mpox_linelist, hiv_status)\n\ntabyl(mpox_linelist, sexual_orientation)\n\n\n```\n\n```{r , echo=FALSE, eval= TRUE}\n\ntabyl(mpox_linelist, hiv_status)\n\n```\n\n**IMPORTANT**: If 'unknown' and NA had meaningful differences, combining\nthem wouldn't be appropriate (e.g., if 'unknown' meant the case was\nasked but didn't want to respond, while NA meant they weren't asked).\nHere, we assume no meaningful difference and want R to recognize them as\nmissing.\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Yes\",\n  answer = \"Depends on the meaning of those values\",\n  \"No - never do this\"\n)\n\n\ncat(\"Is it always appropriate to combine different types of unknown data? (e.g. missing, unknown, did not respond, NA)\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"36\",\n  answer = \"1960\",\n  \"65\",\n  \"1523\"\n)\n\n\ncat(\"How many male cases do we have in the data frame?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"1405\",\n  \"None\",\n  \"595\"\n)\n\ncat(\"How many cases have 'alive' as an outcome?\", longmcq(opts))\n\n```\n:::\n:::\n\n### 4.2: Clean the aggregated data\n\nIn a similar way, clean the aggregated data by:\n\n-   Standardising names to lower case\n-   Ensuring that date of reporting is of class \"Date\"\n-   Creating a column called \"week_date\" with the week of reporting\n    starting on Monday\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nWe can first check the class of the DateRep column, which shows us that\nit was already recognized as a date column on import.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Check class of date of reporting column\nclass(mpox_agg_raw$DateRep)\n\n```\n\nThen create a new object for the clean aggregate data, and write your\ncleaning coded connected with pipes.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Create a new object called mpox_agg which is the clean version of the raw data, applying the cleaning functions\n\nmpox_agg <- mpox_agg_raw %>% \n  \n  # standardises names and puts all into lower case\n  clean_names() %>%  \n  \n  # create week column with Monday start\n  mutate(week_date = floor_date(date_rep, \n                              unit = \"week\",\n                              week_start = \"Monday\")) \n\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"Country A\",\n  \"Country B\",\n  \"Country C\",\n  \"Country D\",\n  \"Country E\"\n)\n\n\ncat(\"Take a look at the aggreate data. Which country reported the largest cumulative number of cases during the week 2022-04-11?\", longmcq(opts))\n\n```\n:::\n:::\n\n## Step 5: Describe outbreak by person, place, and time\n\nNow we're getting to the heart of the investigation. Who is affected?\nWhich locations are most affected, and how quickly is it spreading? Your\nability to tell the classic \"person, place, and time\" story will be\ncrucial to guiding the response. Pinpoint those hotspots and trends!\n\n### 5.1: Describe total case counts by country\n\n**Task**: Using the mpox case linelist, create a table showing the total\nnumber of cases by country. This time, make the table more\npublication-friendly.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nYou could use `tabyl()` like before, but an easy way to produce\npublication-ready tables is with the function tbl_summary() from\n{gtsummary} package. This formats the table for you. It will print to\nyour Viewer rather than the console.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nCreate a new object with the table output - as this is a key output that\nyou can then integrate into a document later rather than just viewing\nfor now.\n\n```{r , echo=TRUE}\n# Create an object with the table\ncb_country_table <- mpox_linelist %>%\n\n  #select the column that we want to use in the table\n  select(country) %>% \n  \n  # create the table. No need to specify columns; it will tabulate all available columns (selected above)\n  tbl_summary() \n\n# Print the table\ncb_country_table\n\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Country C\",\n  \"Country D\",\n  \"Country B\",\n  \"Country E\",\n  answer = \"Country A\"\n)\n\n\ncat(\"What country has the largest percentage of cases?\", longmcq(opts))\n\n```\n:::\n:::\n\n### 5.2: Describe cases over time\n\nOkay so Country A has the most cases in total based on most recent data.\nBut how does that change look over time?\n\n**Tasks**:\n\n-   Using the mpox case linelist, create an epicurve by week of\n    notification\n-   Using the mpox case linelist, create an epicurve by week of\n    notification to enable a comparison of trends by country.\n-   Using the mpox case linelist, create a heat plot with the number of\n    cases by country and week of notification.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nPrepare your data for the epicurve first. You can create a \"week_date\"\ncolumn using the function `floor_date()` from `{lubridate}`. Take a look\nat the documentation to understand how it works and how to pick the\nstarting day of the week.\n\nTo create the epicurve, you can use `ggplot()` and `geom_bar()`, which\nvisualizes the number of rows within a group - e.g. number of cases per\nweek. To compare trends in different countries, consider using the\n`facet_wrap()` function. If you are unsure on how `ggplot()` works, read\nthe EpiRhandbook chapter on [Epidemic\ncurves](https://epirhandbook.com/en/new_pages/epicurves.html).\n\nTo create a heatmap, you will need to create a table of counts by\ncountry and week of notification. You can do this using the functions\n`group_by()` and `summarise()` from `{dplyr}`. If you are unsure on how\nto do this, review the Grouping data chapter of the EpiRhandbook. Then,\nuse the geom geom_tile() to create a heat plot. If you're unsure on how\nto do this, read the EpiRhanbook section on [Heat\nPlots](https://epirhandbook.com/en/new_pages/heatmaps.html)\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nPrepare your data by creating the new column using `mutate()` and\n`floor_date()`:\n\n```{r , echo=TRUE}\n\nmpox_linelist <- mpox_linelist %>% \n  # create week column with Monday start \n  mutate(week_date = floor_date(date_of_notification, unit = \"week\", week_start = \"Monday\")) \n```\n\nThe code below creates an epicurve using `ggplot()` and the `geom_bar()`\nfunction, then applies further formatting. With `geom_bar()`, you only\nneed to specify the x axis, and the function will visualize the number\nof rows per unique x axis value.\n\n```{r , echo=TRUE}\n\n# Open up the plot production with ggplot() function, specifying object and columns\nepicurve_mpox <- ggplot(data = mpox_linelist,          \n                        aes(x = week_date)) +    \n  \n  geom_bar(fill=\"darkgreen\",                     #colour inside the bins\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  labs(title=\"Mpox cases reported in 2022 in Countries A, B, C, D, and E\",\n       subtitle = \"Date as of August 31st 2022\") +  #add a title\n  \n  theme_minimal() +                             #assign a predefined theme\n  \n  theme(axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n           \n# Print the epicurve\nepicurve_mpox\n\n```\n\nTo examine how the outbreak spread by country, add `facet_wrap()` to\nyour ggplot code. This splits the graph into multiple smaller ones. As\nshown below, you can even simply add the function to the national\nepicurve object.\n\nAn alternative approach would be to create a stacked epicurve, i.e.\nretain the single epicurve but split each bar into colors per country.\nYou would do this by adding `fill = country` to the aes() in the\nepicurve code. However, we don't recommend this for comparing trends, as\nstacked bars make it harder to see individual patterns.\n\n```{r , echo=TRUE}\nepicurve_epox_country <- epicurve_mpox + \n \n   # Facet wrap to make mini-plots, specifying that you want two columns of plots. \n  facet_wrap(.~country,\n             ncol = 1) \n\n# Print the epicurve\nepicurve_epox_country\n```\n\nFinally, if you want to demonstrate this as a weekly heatmap, you can\nuse geom_tile(). First, aggregate the data by week. Then pipe into a\nggplot(), as shown below.\n\n```{r , echo=TRUE}\n\n# Assign the output of your ggplot code to a new object\nhp_mpox <- mpox_linelist %>% \n  \n  #first count the number of cases by country and notification week\n  count(country, week_date) %>% \n\n  #you can pipe directly into the ggplot\n    ggplot(aes(x = week_date, # notification week along the x axis\n           y = country,       # country along the y axis\n           fill = n)) +       # colour in the heatmap tiles by number\n  \n  # specify that you want this to be a heatmap with geom_tile()\n  geom_tile(colour = \"black\") +   # black is the outline of each tile\n  \n  #define the gradient of the colours\n  scale_fill_gradient(            \n    low = \"lightgreen\",\n    high = \"red\") +\n  \n  #set the x axis labels to two week intervals\n  scale_x_date(breaks = \"2 weeks\") +             \n  \n  # Add titles\n  labs(\n    title= \"Mpox cases by country and week of notification\",\n    fill = \"Number of cases\"                               \n  ) +\n  \n  # Apply an overall theme to your plot\n  theme_bw() +\n  \n  # Customize other appearance details\n  theme(legend.position = \"bottom\",       #legend position to bottom\n        axis.text = element_text(size=9),     #define axis font \n        axis.title = element_blank(),         #remove the axis titles\n        axis.text.x = element_text(angle=90)) #rotate the x axis text\n    \n\n# Print the heatmap\nhp_mpox \n\n```\n\n</br>\n\n</details>\n\n### 5.3: Describe demographic characteristics\n\nNext, describe the age, gender, and sexual orientation of cases. What is\ninteresting?\n\n**Task**:\n\n-   Create a single table showing overall distribution of age, gender,\n    and sexual orientation\n-   Create an age-gender pyramid showing age as 10-year age bands\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo quickly create a presentation-ready table showing the breakdowns for\nthree different columns, consider using the function tbl_summary() from\n{gtsummary}.\n\nTo create an age-gender pyramid, first create a new column with the\nfunction `age_categories()` from the `{epikit}` package. Then explore\nthe function age_pyramid() from the {apyramid} package.You can find more\nabout this function in the EpiRhandbook chapter [Demographic pyramids\nand\nLikert-scales](https://epirhandbook.com/en/new_pages/age_pyramid.html)\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nSee below the code to quickly generate one table with the breakdown of\ndifferent variables. The function `tbl_summary()` by default summarizes\ncolumns differently depending on their class:\n\n-   Age is a numeric column, so is summarized with a median and\n    interquartile range.\n-   Gender and sexual orientation are character values, so are described\n    in terms of counts and percentages.\n\nYou can customize this further; explore the documentation by typing\n`?tbl_summary()` in your console.\n\nNote that `tbl_summary()` by default does not include NAs in the counts\nand percentages, allowing you to see the distribution of non-missing\nvalues.\n\n```{r , echo=TRUE}\n\n# Create table of all three variables\ntab_demographics <- mpox_linelist %>% \n  \n  # select the columns of interest for\n  select(age, gender, sexual_orientation) %>% \n  \n  # use tbl_summary() to create the table\n  tbl_summary() \n\ntab_demographics\n```\n\nCreate the new age group column as follows. You can add this to the\ncleaning section of your script (which we covered 4.1).\n\n```{r , echo=TRUE}\n  \nmpox_linelist <- mpox_linelist %>% \n  # Use the age_categories function to create age categories\n  mutate(age_group = age_categories(age, lower = 0, #set up the lower age\n                                    upper = 70, #set up the upper age\n                                    by = 10)) #set up the age breaks\n```\n\nThen make the age-gender pyramid using the `age_pyramid()` function. It\nis a function that builds on ggplot, so you can then continue to add on\ncustomization, such as the `theme_bw()` below.\n\n```{r , echo=TRUE}\n\n# Create table of all three variables\nfigure_agesex <- mpox_linelist %>% \n  \n  # Filter to male and female only\n  filter(gender %in% c(\"Male\", \"Female\")) %>% \n  \n  # select the columns of interest for\n  age_pyramid(age_group = \"age_group\",\n              split_by = \"gender\") +\n  \n  # change theme\n  theme_bw()\n\nfigure_agesex\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Females 60-69\",\n  \"Males 40-49\",\n  \"Females 10-19\",\n  answer = \"Males 30-39\"\n)\n\n\ncat(\"Which demographic group is more affected by Mpox?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"41%\",\n  \"42%\",\n  \"5%\",\n  answer = \"94%\"\n)\n\n\ncat(\"What proportion of mpox cases were homosexual or bisexual men?\", longmcq(opts))\n\n```\n:::\n:::\n\n### 5.4: Describe clinical characteristics\n\nThe media is starting to call your office and are asking what symptoms\nthe public should look out for. Just in luck - you can check that out in\nthe data too!\n\n**Tasks**:\n\n-   Create a table with the distribution of different symptoms and\n    outcomes.\n\nNo hints! You should know this one by now!\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n\n# Table with number and percentage of cases by outcome\n\ntab_outcome <- mpox_linelist %>% \n  \n  # Select the columns for tabulation\n  select(outcome, clinical_symptoms) %>% \n  \n  # Use tbl_summary() - note that this time we are adding on labels to change how the column name is displayed\n  tbl_summary(label = list(\n    clinical_symptoms = \"Symptoms\",\n    outcome = \"Reported outcome\")) \n\ntab_outcome\n\n\n```\n\n</br>\n\n</details>\n\n## **Step 6: Reviewing data quality**\n\nYou've described a lot now, but you want to make sure you understand how\ntimely and complete your mpox linelist is, especially if it will be the\nbasis of making decisions.\n\nFor example - is it possible that there are very different reporting\ndelays between countries, meaning current case counts are not directly\ncomparable? Oh dear, must check.\n\n### 6.1: Delay between date of onset, diagnosis and notification\n\n**Tasks**\n\n-   Calculate median time from symptom onset to diagnosis and from\n    diagnosis to notification, both overall and by country\n\n-   Assess visually the number of cases by calendar period and type of\n    date (onset, diagnosis and notification)\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo plot together the different dates you may need to transform your data\nfrom \"wide\" to \"long\" form. What we call \"pivoting\" in R. The objective\nis to have a column with the different date categories (onset, diagnosis\nand notification) and another column with their date value. If you are\nunsure on how to do this, have a look at the [Pivoting\ndata](https://epirhandbook.com/en/new_pages/pivoting.html) chapter of\nthe EpiRhandbook. Then, try to plot with the daily values, but if that's\nnot easy to interpret you may want to aggregate cases by week.\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Yes\",\n  answer = \"No\"\n)\n\n\ncat(\"Is there a difference in the delay from diagnosis to notification by country?\", longmcq(opts))\n\n```\n:::\n:::\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nFirst create the required columns for this analysis.\n\n```{r , echo=TRUE}\n\n# Create two columns in linelist to assess delays\ndelay_db <- mpox_linelist %>% \n  \n  # Time between onset and diagnosis (converted to a number)\n  mutate(delay_diag = as.numeric(date_of_diagnosis - date_of_onset)) %>%   \n\n  # Time between diagnosis and notification (converted to a number)\n  mutate(delay_not = as.numeric(date_of_notification - date_of_diagnosis)) \n```\n\nUse the summary function from base R to quickly view the median, mean,\ninterquartile range, and rang.\n\n```{r , echo=TRUE}\n\n# Summarize the delays to diagnosis\nsummary(delay_db$delay_diag) \n\n# Summarize the delays from diagnosis to notification\nsummary(delay_db$delay_not)\n```\n\nUse group_by() and summarize() to create a table with median delays per\ncountry.\n\n```{r , echo=TRUE}\ndelay_country <- delay_db %>% \n  \n  # Group by country\n  group_by(country) %>% \n  \n  # Create columns for each delay\n  summarise(median_delay_diag = median(delay_diag, na.rm = T),\n            median_delay_not = median(delay_not, na.rm = T))\n\ndelay_country\n```\n\nTo explore how the trends in cases over time differ when using different\ndates, you can reshape the linelist to create a dataset with one row per\ndate type per case.\n\n```{r , echo=TRUE}\n# Prepare the data\ndates_longer <- mpox_linelist %>% \n  \n  select(age, gender, sexual_orientation, starts_with(\"date_\")) %>% \n\n  pivot_longer(\n    \n      # all columns starting with \"date_\" will be pivoted from wide to long \n      cols=starts_with(\"date_\"),         \n    \n      # put names of the columns into a single column called \"indicator\"\n      names_to = \"indicator\",   \n      \n      # the date values will be placed in a column called \"date\"\n      values_to = \"date\")                \n```\n\nThe data will then look like this, with three rows per case:\n\n```{r, echo = F, eval = T}\n\nDT::datatable(dates_longer %>% filter(row_number()<7))\n\n\n```\n\nThen tabulate cases by week per indicator\n\n```{r , echo=TRUE}\n\n# Create new object\ndates_longer_week <- dates_longer  %>% \n\n  # Create a new week column\n  mutate(week_date = floor_date(date, unit = \"week\", week_start = \"Monday\")) %>%  \n  \n  # Within each combination of indicator and week, calculate the number of cases\n  group_by(indicator, week_date) %>% \n  summarise(n=n()) %>%   \n  \n  # drop the cases with no data on dates  \n  drop_na(week_date)                     \n```\n\nThe data will then look like this, with three rows per case:\n\n```{r, echo = F, eval = T}\n\nDT::datatable(dates_longer_week %>% filter(row_number()<4))\n\n```\n\nFinally, create a plot with ggplot() and geom_line().\n\n```{r, echo = T, eval = T}\nplot_date_delay <-   ggplot(data = dates_longer_week,\n                            aes(x = week_date, \n                                y = n, \n                                color=indicator)) +\n  \n  geom_line(linewidth = 1.5) +\n  \n  scale_x_date(breaks = \"2 weeks\")+\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\", \n        axis.text = element_text(size=9),\n        axis.title = element_blank(),\n        axis.text.x = element_text(angle=90),\n        legend.title = element_blank()) +\n  labs(title=\"Mpox cases reported in 2022, by date of onset, diagnosis and notification.\")\n\nplot_date_delay\n```\n\n</br>\n\n</details>\n\n### 6.2: Compare case-based and aggregated data\n\nFinally, you remember that all-along you've had these aggregate counts\nfrom routine surveillance. You find out that these numbers are actually\nalready being published.\n\nBefore you share your own numbers, you'd better check how different they\nare from already-published statistics!\n\n**Task**: Create a plot comparing the number of cases reported to\nthrough the case-based flow and through the aggregated flow in each\ncountry.\n\nNOTE: Take into consideration that the column on cases in the aggregated\ndata frame reports the *cumulative* number of cases.\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"A\",\n  \"B\",\n  answer = \"C\",\n  \"D\",\n  \"E\"\n)\n\n\ncat(\"Which country is not reporting aggregated data?\", longmcq(opts))\n\n```\n:::\n:::\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nFirst, create a data frame of country totals from the aggregate data.\n\n```{r , echo=TRUE}\nmpox_agg_country <- mpox_agg %>% \n \n  # as we have cumulative data, we keep only the last week per country \n  group_by(country) %>% \n  filter(date_rep == max(date_rep)) %>% \n  \n  # remove unnecessary columns\n  select(-date_rep, -week_date) %>%     \n\n  # create this column to distinguish the numbers from the linelist data\n  mutate(source = \"aggregated\")         \n```\n\nThen create a data frame of country totals from the case linelist, and\nappend it to the totals from the aggregate data.\n\n```{r , echo=TRUE}\n\nmpox_linelist_country <- mpox_linelist %>%\n  \n  # count cases by country, use the same column name as in the aggregate data\n  group_by(country) %>% \n  summarise(cases = n()) %>% \n  \n  # create this column to distinguish the numbers from the linelist data\n  mutate(source = \"case_based\")       \n  \n\n# Append both data frames. Remember this is different from merging\ntotal_data <- bind_rows(mpox_linelist_country, mpox_agg_country)\n```\n\nYou can now use this data to compare the cases reported in both sources,\nusing `ggplot()`.\n\n```{r , echo=TRUE}\n\ngraph_comp <- ggplot(data = total_data,\n                     aes(x = source, \n                         y = cases, \n                         fill = source)) +\n  \n  #position dodge puts bars one next to each other, instead of \"stacked\"\n  geom_col(position = \"dodge\") +            \n  \n  # this command gives us one graph per country. The argument scales allows each y axis scales to adjust to the data\n  facet_wrap(~ country, scales = \"free_y\") +  \n\n  # changes the colours, but with the argument \"labels\" we can change the text of each fill.\n  scale_fill_viridis_d(\n    labels = c(\"Aggregated\", \"Case-based\")) +\n  \n  labs(\n    title = \"Number of cases of Mpox reported in 2022 according to source of data\",\n    fill = \"Source\",\n    x = \"\",\n    y = \"Total number of cases\"\n  ) + \n  \n  theme_bw() +\n  \n  # we remove the text of the x axis because it is already present in the legend\n  theme(axis.text.x = element_blank(),   \n        \n   # we also remove the ticks for aesthetic purposes\n        axis.ticks.x = element_blank())    \n\ngraph_comp\n```\n\n</br>\n\nInteresting! There are some differences - and this probably will be\nworth flagging with stakeholders and/or explaining in a footnote\nsomewhere.\n\n</details>\n\n## Final thoughts\n\nWell done! Through your analysis you now understand the magnitude of the\noutbreak so far, where and when it spread, which demographic groups are\nmost affected, and how the disease actually manifests in terms of\nsymptoms and severity. ECDC is very happy with your work.\n\nBy coding this up in R, this analysis should be reproducible, meaning\nyou can quickly update it with new data and keep monitoring the\noutbreak.\n\nOf course, the above data is not real. If you want to see a paper on the\nactual outbreak that occured in Europe in 2022, you can take a look at\nthis [Eurosurveillance\npaper](https://www.eurosurveillance.org/content/10.2807/1560-7917.ES.2022.27.36.2200620).\nThis [ECDC page on Mpox](https://www.ecdc.europa.eu/en/mpox) also\npublishes updates on the status of mpox in Europe.\n\nTo further practise reproducible reports, \\[link to RMarkdown\\].\n\n## Case study information\n\n**Authorship**\n\nOriginal authors: Xanthi Andrianou, Gianfranco Spiteri (ECDC EI Group)\\\nData source: Fictional data provided by ECDC EI Group for training\npurposes\\\n\n| Date           | Changes made                     | Version | Author                            |\n|------------------|:------------------|-----------------:|------------------|\n| October 2021   | First draft                      |       1 | Xanthi Andrianou                  |\n| June 2024      | Adapted to case study template   |     1.1 | Alberto Mateo Urdiales            |\n| September 2024 | Revise for case study repository |     1.2 | Paula Blomquist and Alanah Jansen |\n\n## Terms of Use\n\n**Disclaimer**: The information presented in this exercise and the\nassociated data files have been deliberately changed so as to facilitate\nthe acquisition of the learning objectives for fellows of EPIET, EUPHEM\nand EPIET-associated programmes. This case study was first introduced in\n2022 (see Copyright and Licence agreement for more information).\n\nYou are free:\n\n-   to Share: to copy and distribute the work\n-   to Remix: to adapt and build upon the material\n\nUnder the following conditions:\n\n-   Attribution: You must attribute the work in the manner specified by\n    the author or licensor (but not in any way that suggests that they\n    endorse you or your use of the work). The best way to do this is to\n    keep as it is the list of contributors: sources, authors and\n    reviewers.\n\n-   Share Alike: If you alter, transform, or build upon this work, you\n    may distribute the resulting work only under the same or similar\n    license to this one. Your changes must be documented. Under that\n    condition, you are allowed to add your name to the list of\n    contributors.\n\n-   Notification: If you use the work in the manner specified by the\n    author or licensor, [Walter\\@rki.de](mailto:Walterj@rki.de)\n\n-   You cannot sell this work alone but you can use it as part of a\n    teaching.\n\nWith the understanding that:\n\n-   Waiver: Any of the above conditions can be waived if you get\n    permission from the copyright holder.\n\n-   Public Domain: Where the work or any of its elements is in the\n    public domain under applicable law, that status is in no way\n    affected by the license.\n\n-   Other Rights: In no way are any of the following rights affected by\n    the license:\n\n    -   Your fair dealing or fair use rights, or other applicable\n        copyright exceptions and limitations;\n\n    -   The author's moral rights;\n\n    -   Rights other persons may have either in the work itself or in\n        how the work is used, such as publicity or privacy rights.\n\n-   Notice: For any reuse or distribution, you must make clear to others\n    the license terms of this work by keeping together this work and the\n    current license.\n\nThis licence is based on\n<http://creativecommons.org/licenses/by-sa/3.0/>\n","srcMarkdownNoYaml":"\n\n# Descriptive analysis of the 2022 Mpox outbreak in Europe {#sec-rpractical}\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Tool**: R \\| **Technical complexity**: Basic \\| **Methodological\ncomplexity**: Basic\\\n**Source:** ECDC EI Group (simulated data)\\\n**Prior knowledge required:** [R\nbasics](https://epirhandbook.com/en/new_pages/basics.html) (Using\nRstudio; R packages, functions and arguments, using pipes)\n:::\n\n::: {.callout-important title=\"WEBSITE UNDER CONSTRUCTION\"}\nThis is a draft version of this page. The content and URL will change.\n:::\n\nFor instructions on how to use our case studies, see our [How-to\nGuide](instructions.html). We welcome feedback and suggestions via\n[contact\\@appliedepi.org](mailto:contact@appliedepi.org). You can also\ndiscuss the case study or related concepts on the [Applied Epi\nCommunity](https://community.appliedepi.org/).\n\n\\pagebreak\n\n## Scenario\n\nIt is May 2022 and Mpox has just been reported for the first time across\n5 countries in Europe: Countries \"A\", \"B\", \"C\", \"D\", and \"E\". You have\nbeen requested to provide a basic descriptive analysis to the European\nCentre for Disease Prevention and Control (ECDC).\n\nYou are given access to:\n\n-   A dataset with aggregate case counts, submitted to ECDC by the five\n    countries as part of routine European reporting\n-   A linelist with cases, submitted by the five countries to ECDC for\n    this particular analysis\n\nLet's go!\n\n## Objectives\n\nIn this case study you will:\n\n1.  Explore different types of files and how they can be imported in R.\n2.  Perform basic data cleaning, e.g., changing the variable type,\n    recoding variables, aggregating and filtering.\n3.  Perform a basic descriptive analysis using tables and graphs\n\n## Step 1. Set up\n\n### 1.1 Get started in RStudio\n\nStart by setting up a reproducible and well-organized workflow. This\nwill make it easy to rerun your analysis whenever needed.\n\n**Tasks:**\n\n-   Set up an RStudio project\n-   Set up clear sub-folders where your code, data, and outputs will go\n-   Create an R script, or an R Markdown file if you prefer. Make sure\n    the script purpose, date, and author are written as comments at the\n    top.\n-   Extra: Ensure your working language in RStudio is appropriate (e.g.\n    English for this exercise)\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\n-   Create a folder where all the work in this case study will go. For\n    example, create 'mpox_analysis' on your computer desktop. Create\n    your RStudio project to be based in this folder.\n\n-   We suggest creating the following sub-folders: `scripts` (for your\n    code), `data` (for your data), and `outputs` (for your analytical\n    outputs).\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nCreate a folder (e.g. 'mpox_analysis' on your Desktop) for your work. To\ncreate an Rstudio project in your new folder, click `New Project…` in\nthe top left of your R Studio, then `Existing Directory`, then `Browse`\nto select your new folder. For more information, look at the [R\nprojects](https://epirhandbook.com/new_pages/r_projects.html) section of\nthe Epi R Handbook.\n\nStart a new R script by clicking `New File…` in the top left of your R\nStudio, then `R Script`. Save it immediately in the appropriate place,\ne.g. in a 'scripts' subfolder of your R Project.\n\nAt the top of your new R script, write some essential information like\nyour name, the purpose of the file, and the date.\n\nYour R locale determines the language and regional settings used for\nthings like date formats and translations. If your locale is different\nfrom the language you want for your report (e.g., a French locale vs. an\nEnglish report), you can change it to English by running\n`Sys.setlocale(\"LC_ALL\", \"English\")`. Include this in your script if\nneeded, or skip it if your locale is usually appropriate. This is\nexplained in more detail in the [How-to Guide](pages/instructions.qmd_).\n\n</details>\n\n### 1.2 Install/load packages\n\nNext in your R script, you need to install and load the necessary R\npackages. This ensures that the functions you need are available for\nyour analysis.\n\nYou will need the following packages: `rio` (for importing data),\n`janitor` (for cleaning data), `lubridate` (for cleaning dates), `skimr`\n(for reviewing data), `epikit` (for epi-related tasks), `gtsummary` (for\npresentation-ready tables), `apyramid` (for age-sex pyramids), and\n`tidyverse` (for general data manipulation/science tasks).\n\nAs you start, your trusted colleague nudges you and whispers \"I've heard\nthat a great way to manage your packages is with the `pacman` package\".\n\nOver to you!\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nUse the function `p_load()` from `pacman` for this task. You provide the\nfunction with a list of packages that you want to use. It will take two\nsteps per package: 1) Check if the package is installed on your\ncomputer, and install it if necessary, then 2) Load the package so it\ncan be used during this R session.\n\nIf you don't already have `pacman` installed, you will need to install\nit the \"traditional way\" first, with `install.packages()`.\n\nNote that the order of packages in your p_load function can be\nimportant. If two packages have the same function names (e.g. `select()`\nin the package `MASS` and `select()` in `tidyverse`, which do different\nthings), then R will use the function from the most recently loaded\npackage. To prioritize functions from tidyverse, which are commonly used\nfor data manipulation and visualization, load tidyverse last.\n\n</detail>\n\n```{r, echo=TRUE, eval=TRUE}\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\n```\n\n## Step 2: Download and import the data\n\n### 2.1: Download the data\n\nECDC provides you with two files for your analysis, both updated as of\n31st August 2022:\n\n-   A case-level linelist (*\"mpox_linelist.xlsx\"*) with case information\n    from five countries (countries A - E)\n-   An aggregate table (*\"mpox_aggregate_table.csv\"*) for those\n    countries with cumulative case counts per day.\n\nThey provide it to you via AppliedEpi's very useful data repository,\nwhich you can access using the `{appliedepidata}` package. So first you\nneed to download these two files to your own computer, as follows:\n\n1)  Install the `{appliedepidata}` package from GitHub using the\n    `install_github()` function in the `{remotes}` package. Install\n    `{remotes}` if you need to first.\n\n```{r , echo=TRUE, eval=FALSE}\n# Install remotes if you need to (so you can install a package from GitHub)\npacman::p_load(\"remotes\")\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n```\n\n2)  Save the two datasets into a specific folder using the `save_data()`\n    function from `{appliedepidata}`, by running the code below. The\n    example below saves the data into a 'data' subfolder within the\n    RStudio project. Note that if you do not specify a location within\n    the 'path' argument of the function, a window will pop up asking you\n    to manually select a folder.\n\n```{r , echo=TRUE, eval=FALSE}\n# Save down the two mpox files using the save_data() function from appliedepidata\nappliedepidata::save_data(\"mpox_linelist\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"mpox_aggregate_table\",\n                          path = \"data\")\n```\n\n### 2.2 Import the data\n\nGreat! Thanks ECDC and Applied Epi! Now it's time to import the data\nfrom that folder into RStudio, so you can analyse it.\n\n**Task:** Import the downloaded case-based and aggregated data into your\nR environment. Ideally you want to use one function for both datasets,\ndespite one being a csv and the other an xlsx file.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nUse the `import` function from the `{rio}` package, which can recognize\nand import different file types. It replaces importing functions that\nare specific to the file type, such as `read.csv()` from `{base}` for\n.csv files and `read_excel()` from `{readxl}` to import .xlsx files.\n\nIf you feel you need to know more about importing functions, read the\n[Import and export](https://epirhandbook.com/new_pages/importing.html)\nchapter of the EpiRhandbook.\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\nBelow we use the import function to bring in both files. Note how we are\nassigning the imported data to two objects, one called\n*mpox_linelist_raw*, and one called *mpox_agg_raw*. We add the 'raw'\nsuffix to distinguish this data from the cleaned versions we will make\nlater.\n\n```{r , echo=TRUE, eval=FALSE}\n# Import data  --------------\n\n# Case-based data\nmpox_linelist_raw <- import(\"data/mpox_linelist.xlsx\")\n\n# Aggregated data\nmpox_agg_raw <- import(\"data/mpox_aggregate_table.csv\")\n\n```\n\n```{r, include = FALSE}\n# This code is actually run; the prior chunk is just for show for simplicity\n\npacman::p_load(\"remotes\")\n\nif (!requireNamespace(\"appliedepidata\", quietly = TRUE)) {\n  remotes::install_github(\"appliedepi/appliedepidata\")\n}\n\nappliedepidata::get_data(\"mpox_linelist\")\nmpox_linelist_raw <- mpox_linelist\n\n\nappliedepidata::get_data(\"mpox_aggregate_table\")\nmpox_agg_raw <- mpox_aggregate_table\n\nrm(mpox_linelist, mpox_aggregate_table)\n\n```\n\n</details>\n\n## Step 3: Explore the data\n\nThe data's in, and now it's time to see what story it tells. Take an\ninitial look at your data to check its quality and how you can best use\nit.\n\n**Tasks:** Take a look at the different data frames and determine:\n\n-   The number of columns and observations (e.g. their *dimensions*)\n-   The class of their columns and whether it matches its nature (e.g.,\n    are \"dates\" considered \"dates\" by R?)\n-   If the contents of columns are clean and standardized in the mpox\n    linelist (e.g. gender, clinical symptoms, outcome, hiv status and\n    sexual orientation). Do you need to recode any of them?\n-   How unknown or missing data is categorized in these columns. Do\n    these values need to be standardized?\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nAn efficient function for initial data exploring is `skim()` from the\n`{skimr}` package, as it gives you a lot of information on data\nstructure and content, including the classes of columns.\n\nYou can use the function `tabyl()` from `{janitor}`, to get counts and\npercentages of every category in the data column, one by one. These get\nprinted to your RStudio console.\n\nAlso - we recommend just looking at the data itself! A good function for\nthis is `view()`, a baseR function.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nUsing the `skim` commands you can see the rows and columns of each\ndataset, and you can see how most of the columns in *mpox_linelist_raw*\n(including those containing dates) are character classes. (Results not\nshown on this exercise page)\n\n```{r , echo=TRUE, results='hide'}\n# Explore the dimensions of the two data objects \nskim(mpox_linelist_raw)\nskim(mpox_agg_raw)\n```\n\nTake a look at the overall data using `view()`. It will pop up in the\nData Viewer tab and you will get a good sense of how clean the data is\nand what the missingness is like. This preview shows just 5 rows from\nthe linelist data.\n\n```{r , echo=TRUE, results='hide'}\nview(mpox_linelist_raw)\n```\n\n```{r , echo=FALSE, eval = TRUE}\n#head(mpox_linelist_raw) %>% flextable::flextable()\nDT::datatable(mpox_linelist_raw %>% filter(row_number()<6))\n```\n\n\\br\n\nBelow is an example of using the `tabyl()` function from `{janitor},` to\nlook at the distribution of clinical symptoms. You can see 12 cases have\nmissing clinical information and that many cases have a mix of symptoms.\n\n```{r , echo=TRUE}\n\ntabyl(mpox_linelist_raw, HIVStatus)  \n```\n\nYou can explore further columns one by one (results not shown):\n\n```{r , echo=TRUE, results='hide'}\n# Explore the values of different categorical columns in the mpox linelist: with tabyl\ntabyl(mpox_linelist_raw, Gender)\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms)\n\ntabyl(mpox_linelist_raw, Outcome)\n\ntabyl(mpox_linelist_raw, SexualOrientation)\n\n```\n\nYou could add extra arguments to `tabyl()` to customize the tables, such\nas adding totals and changing the proportions to percentages so they are\neasier to read. See the table on clinical symptoms below. But remember -\nthis is just an initial look so don't go too crazy.\n\n```{r , echo=TRUE}\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms) %>%    # Tabulate symptoms \n  adorn_totals() %>%                              # Add totals to bottom of table\n  adorn_pct_formatting(digits = 2)                # Format percentages\n```\n\nFinally, as an alternative approach to `tabyl()`, you could use\n`tbl_summary()` from the `{gtsummary}` package. We will describe this\nlater.\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"2000\", \"13\", answer = \"3\", \"101\"\n)\n\ncat(\"How many columns does the aggregated data have?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Date\", answer = \"Character\", \"Numeric\", \"Factor\"\n)\n\n\ncat(\"What is the class of the column DateOfNotification in the mpox linelist?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"1168\",\n  \"722\",\n  \"900\",\n  \"446\"\n)\n\n\ncat(\"For how many cases is the HIV status Unknown or missing?\", longmcq(opts))\n\n```\n:::\n:::\n\n## Step 4: Clean the data\n\n### 4.1: Clean the case-based data\n\nSo! The good news: you have information on geography, dates, demographic\ncharacteristics, and clinical details. A promising descriptive analysis\nlies ahead.\n\nBUT! You may noticed that there are a few things to fix before the real\ndetective work begins.\n\nFor example:\n\n-   Column names have capital letters. This isn't outright a problem,\n    but can lead to mistakes since R treats ColumnName and Columnname as\n    different.\n-   Date columns are recognized as character classes, not dates, which\n    would cause issues like incorrect ordering (alphabetical) in\n    epicurves.\n-   Some columns have values that are unclear or unsuitable for\n    presentation. For example gender is categorized with \"F\", \"M\", \"O\"\n    and \"UNK\". The column Outcome is \"A\" and \"UNK\".\n-   Missing data is inconsistently handled, for instance with both \"UNK\"\n    and NA in the HIV status column. R thinks \"UNK\" is a valid value,\n    which it treats differently to true missing data (indicated by NA)\n\n**Tasks**:\n\n-   Create a clean version of your case-based data making all cleaning\n    changes in a single piping command\n-   Change all column names to lower case.\n-   Convert all date columns to class \"Date\".\n-   Convert all missing/unknown values to NA (to be recognized by R as\n    missing)\n-   Recode non-missing \"Gender\" categories into: \"Female\", \"Male\", and\n    \"Other\"\n-   Recode non-misising HIV status into: \"Positive\", \"Negative\" and\n    \"Unknown\"\n-   Recode non-missing sexual orientation into: \"Bisexual\",\n    \"Heterosexual\", and \"MSM/homo or bisexual male\".\n-   Recode non-missing \"outcome\" categories into: \"Alive\" and \"Dead\".\n-   Check that all changes have been made correctly\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo convert all column names to lower case at once rather than renaming\neach column, use the function `clean_names()` from the `{janitor}`\npackage.\n\nUse `{lubridate}` functions to transform date columns into \"Date\" class.\nYou can do this one by one, or you could do all at the same time using\nthe `across()` function from `{dplyr}.` If you feel you need to know\nmore about transforming dates read the chapter [Working with\nDates](https://epirhandbook.com/en/new_pages/dates.html) from the\nEpiRhandbook. If you are not sure how to use the across() function, you\ncan also read the section on [Transform multiple\ncolumns](https://epirhandbook.com/en/new_pages/cleaning.html#clean_across).\n\nThere are different functions that we can use to recode values. We\npropose three: The function `recode()` from `{dplyr}`, the function\n`ifelse()` from `{base}` and the function `case_when()` from `{dplyr}`.\nIf you want to know more about these functions, look that the section on\n[Re-code\nvalues](https://epirhandbook.com/en/new_pages/cleaning.html#re-code-values)\nfrom the EpiRhandbook.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nHere we clean the data using a 'chain' of commands connected by pipes\n(%\\>%), which is the grammar of the functions in the {Tidyverse}. The\noutput is assigned to a new object called mpox_linelist to differentiate\nit from the raw data. It can be helpful to have both the cleaned and raw\ndata available in the environment to compare to the original data if\nneeded.\n\nSee the series of functions and the explanation in the comments.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Create a new object called mpox_linelist which is the clean version of the raw data\nmpox_linelist <- mpox_linelist_raw %>% \n  \n  # standardises names and puts all into lower case \n  clean_names() %>% \n  \n  #transform ONE column into date (note the column names are lower case now)\n  mutate(date_of_notification = ymd(date_of_notification)) %>%  \n\n  #transforms ALL columns starting with \"date\" into dates\n  mutate(across(starts_with(\"date\"), \n                .fns = ~ ymd(.x))) %>%  \n  \n  #transforms UNK to NA across all character columns \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x %in% c(\"UNK\", \"Unknown\"), NA_character_, .x)))  %>% \n\n  # Recode the gender values to be more obvious  \n  mutate(gender = recode(gender,\n                         \"F\" = \"Female\",\n                         \"M\" = \"Male\",\n                         \"O\" = \"Other\")) %>%\n  \n  #recode with ifelse to change only one or two categories based on a rule. \n  mutate(outcome = ifelse(outcome == \"A\", \"Alive\", outcome)) %>%   \n  \n  #recode with case_when for more complex recoding \n  mutate(hiv_status = case_when(hiv_status == \"NEG\" ~ \"Negative\",    \n                                hiv_status == \"POS\" ~ \"Positive\")) %>% \n  \n  mutate(sexual_orientation = case_when(sexual_orientation == \"BISEXUAL\" ~ \"Bisexual\",\n                                        sexual_orientation == \"HETERO\" ~ \"Heterosexual\",\n                                        sexual_orientation == \"MSM\" ~ \"MSM/homo or bisexual male\")) \n```\n\nYou can then review your data by tabulating across all the different\ncolumns you have cleaned. See the preview of the HIV table below - it\nlooks tidier now with more understandable categories, and all missing\ndata is classified as 'Unknown'.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Check that all changes have been made correctly\n\nskim(mpox_linelist)\n\ntabyl(mpox_linelist, gender)\n\ntabyl(mpox_linelist, clinical_symptoms)\n\ntabyl(mpox_linelist, outcome)\n\ntabyl(mpox_linelist, hiv_status)\n\ntabyl(mpox_linelist, sexual_orientation)\n\n\n```\n\n```{r , echo=FALSE, eval= TRUE}\n\ntabyl(mpox_linelist, hiv_status)\n\n```\n\n**IMPORTANT**: If 'unknown' and NA had meaningful differences, combining\nthem wouldn't be appropriate (e.g., if 'unknown' meant the case was\nasked but didn't want to respond, while NA meant they weren't asked).\nHere, we assume no meaningful difference and want R to recognize them as\nmissing.\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Yes\",\n  answer = \"Depends on the meaning of those values\",\n  \"No - never do this\"\n)\n\n\ncat(\"Is it always appropriate to combine different types of unknown data? (e.g. missing, unknown, did not respond, NA)\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"36\",\n  answer = \"1960\",\n  \"65\",\n  \"1523\"\n)\n\n\ncat(\"How many male cases do we have in the data frame?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"1405\",\n  \"None\",\n  \"595\"\n)\n\ncat(\"How many cases have 'alive' as an outcome?\", longmcq(opts))\n\n```\n:::\n:::\n\n### 4.2: Clean the aggregated data\n\nIn a similar way, clean the aggregated data by:\n\n-   Standardising names to lower case\n-   Ensuring that date of reporting is of class \"Date\"\n-   Creating a column called \"week_date\" with the week of reporting\n    starting on Monday\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nWe can first check the class of the DateRep column, which shows us that\nit was already recognized as a date column on import.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Check class of date of reporting column\nclass(mpox_agg_raw$DateRep)\n\n```\n\nThen create a new object for the clean aggregate data, and write your\ncleaning coded connected with pipes.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Create a new object called mpox_agg which is the clean version of the raw data, applying the cleaning functions\n\nmpox_agg <- mpox_agg_raw %>% \n  \n  # standardises names and puts all into lower case\n  clean_names() %>%  \n  \n  # create week column with Monday start\n  mutate(week_date = floor_date(date_rep, \n                              unit = \"week\",\n                              week_start = \"Monday\")) \n\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"Country A\",\n  \"Country B\",\n  \"Country C\",\n  \"Country D\",\n  \"Country E\"\n)\n\n\ncat(\"Take a look at the aggreate data. Which country reported the largest cumulative number of cases during the week 2022-04-11?\", longmcq(opts))\n\n```\n:::\n:::\n\n## Step 5: Describe outbreak by person, place, and time\n\nNow we're getting to the heart of the investigation. Who is affected?\nWhich locations are most affected, and how quickly is it spreading? Your\nability to tell the classic \"person, place, and time\" story will be\ncrucial to guiding the response. Pinpoint those hotspots and trends!\n\n### 5.1: Describe total case counts by country\n\n**Task**: Using the mpox case linelist, create a table showing the total\nnumber of cases by country. This time, make the table more\npublication-friendly.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nYou could use `tabyl()` like before, but an easy way to produce\npublication-ready tables is with the function tbl_summary() from\n{gtsummary} package. This formats the table for you. It will print to\nyour Viewer rather than the console.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nCreate a new object with the table output - as this is a key output that\nyou can then integrate into a document later rather than just viewing\nfor now.\n\n```{r , echo=TRUE}\n# Create an object with the table\ncb_country_table <- mpox_linelist %>%\n\n  #select the column that we want to use in the table\n  select(country) %>% \n  \n  # create the table. No need to specify columns; it will tabulate all available columns (selected above)\n  tbl_summary() \n\n# Print the table\ncb_country_table\n\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Country C\",\n  \"Country D\",\n  \"Country B\",\n  \"Country E\",\n  answer = \"Country A\"\n)\n\n\ncat(\"What country has the largest percentage of cases?\", longmcq(opts))\n\n```\n:::\n:::\n\n### 5.2: Describe cases over time\n\nOkay so Country A has the most cases in total based on most recent data.\nBut how does that change look over time?\n\n**Tasks**:\n\n-   Using the mpox case linelist, create an epicurve by week of\n    notification\n-   Using the mpox case linelist, create an epicurve by week of\n    notification to enable a comparison of trends by country.\n-   Using the mpox case linelist, create a heat plot with the number of\n    cases by country and week of notification.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nPrepare your data for the epicurve first. You can create a \"week_date\"\ncolumn using the function `floor_date()` from `{lubridate}`. Take a look\nat the documentation to understand how it works and how to pick the\nstarting day of the week.\n\nTo create the epicurve, you can use `ggplot()` and `geom_bar()`, which\nvisualizes the number of rows within a group - e.g. number of cases per\nweek. To compare trends in different countries, consider using the\n`facet_wrap()` function. If you are unsure on how `ggplot()` works, read\nthe EpiRhandbook chapter on [Epidemic\ncurves](https://epirhandbook.com/en/new_pages/epicurves.html).\n\nTo create a heatmap, you will need to create a table of counts by\ncountry and week of notification. You can do this using the functions\n`group_by()` and `summarise()` from `{dplyr}`. If you are unsure on how\nto do this, review the Grouping data chapter of the EpiRhandbook. Then,\nuse the geom geom_tile() to create a heat plot. If you're unsure on how\nto do this, read the EpiRhanbook section on [Heat\nPlots](https://epirhandbook.com/en/new_pages/heatmaps.html)\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nPrepare your data by creating the new column using `mutate()` and\n`floor_date()`:\n\n```{r , echo=TRUE}\n\nmpox_linelist <- mpox_linelist %>% \n  # create week column with Monday start \n  mutate(week_date = floor_date(date_of_notification, unit = \"week\", week_start = \"Monday\")) \n```\n\nThe code below creates an epicurve using `ggplot()` and the `geom_bar()`\nfunction, then applies further formatting. With `geom_bar()`, you only\nneed to specify the x axis, and the function will visualize the number\nof rows per unique x axis value.\n\n```{r , echo=TRUE}\n\n# Open up the plot production with ggplot() function, specifying object and columns\nepicurve_mpox <- ggplot(data = mpox_linelist,          \n                        aes(x = week_date)) +    \n  \n  geom_bar(fill=\"darkgreen\",                     #colour inside the bins\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  labs(title=\"Mpox cases reported in 2022 in Countries A, B, C, D, and E\",\n       subtitle = \"Date as of August 31st 2022\") +  #add a title\n  \n  theme_minimal() +                             #assign a predefined theme\n  \n  theme(axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n           \n# Print the epicurve\nepicurve_mpox\n\n```\n\nTo examine how the outbreak spread by country, add `facet_wrap()` to\nyour ggplot code. This splits the graph into multiple smaller ones. As\nshown below, you can even simply add the function to the national\nepicurve object.\n\nAn alternative approach would be to create a stacked epicurve, i.e.\nretain the single epicurve but split each bar into colors per country.\nYou would do this by adding `fill = country` to the aes() in the\nepicurve code. However, we don't recommend this for comparing trends, as\nstacked bars make it harder to see individual patterns.\n\n```{r , echo=TRUE}\nepicurve_epox_country <- epicurve_mpox + \n \n   # Facet wrap to make mini-plots, specifying that you want two columns of plots. \n  facet_wrap(.~country,\n             ncol = 1) \n\n# Print the epicurve\nepicurve_epox_country\n```\n\nFinally, if you want to demonstrate this as a weekly heatmap, you can\nuse geom_tile(). First, aggregate the data by week. Then pipe into a\nggplot(), as shown below.\n\n```{r , echo=TRUE}\n\n# Assign the output of your ggplot code to a new object\nhp_mpox <- mpox_linelist %>% \n  \n  #first count the number of cases by country and notification week\n  count(country, week_date) %>% \n\n  #you can pipe directly into the ggplot\n    ggplot(aes(x = week_date, # notification week along the x axis\n           y = country,       # country along the y axis\n           fill = n)) +       # colour in the heatmap tiles by number\n  \n  # specify that you want this to be a heatmap with geom_tile()\n  geom_tile(colour = \"black\") +   # black is the outline of each tile\n  \n  #define the gradient of the colours\n  scale_fill_gradient(            \n    low = \"lightgreen\",\n    high = \"red\") +\n  \n  #set the x axis labels to two week intervals\n  scale_x_date(breaks = \"2 weeks\") +             \n  \n  # Add titles\n  labs(\n    title= \"Mpox cases by country and week of notification\",\n    fill = \"Number of cases\"                               \n  ) +\n  \n  # Apply an overall theme to your plot\n  theme_bw() +\n  \n  # Customize other appearance details\n  theme(legend.position = \"bottom\",       #legend position to bottom\n        axis.text = element_text(size=9),     #define axis font \n        axis.title = element_blank(),         #remove the axis titles\n        axis.text.x = element_text(angle=90)) #rotate the x axis text\n    \n\n# Print the heatmap\nhp_mpox \n\n```\n\n</br>\n\n</details>\n\n### 5.3: Describe demographic characteristics\n\nNext, describe the age, gender, and sexual orientation of cases. What is\ninteresting?\n\n**Task**:\n\n-   Create a single table showing overall distribution of age, gender,\n    and sexual orientation\n-   Create an age-gender pyramid showing age as 10-year age bands\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo quickly create a presentation-ready table showing the breakdowns for\nthree different columns, consider using the function tbl_summary() from\n{gtsummary}.\n\nTo create an age-gender pyramid, first create a new column with the\nfunction `age_categories()` from the `{epikit}` package. Then explore\nthe function age_pyramid() from the {apyramid} package.You can find more\nabout this function in the EpiRhandbook chapter [Demographic pyramids\nand\nLikert-scales](https://epirhandbook.com/en/new_pages/age_pyramid.html)\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nSee below the code to quickly generate one table with the breakdown of\ndifferent variables. The function `tbl_summary()` by default summarizes\ncolumns differently depending on their class:\n\n-   Age is a numeric column, so is summarized with a median and\n    interquartile range.\n-   Gender and sexual orientation are character values, so are described\n    in terms of counts and percentages.\n\nYou can customize this further; explore the documentation by typing\n`?tbl_summary()` in your console.\n\nNote that `tbl_summary()` by default does not include NAs in the counts\nand percentages, allowing you to see the distribution of non-missing\nvalues.\n\n```{r , echo=TRUE}\n\n# Create table of all three variables\ntab_demographics <- mpox_linelist %>% \n  \n  # select the columns of interest for\n  select(age, gender, sexual_orientation) %>% \n  \n  # use tbl_summary() to create the table\n  tbl_summary() \n\ntab_demographics\n```\n\nCreate the new age group column as follows. You can add this to the\ncleaning section of your script (which we covered 4.1).\n\n```{r , echo=TRUE}\n  \nmpox_linelist <- mpox_linelist %>% \n  # Use the age_categories function to create age categories\n  mutate(age_group = age_categories(age, lower = 0, #set up the lower age\n                                    upper = 70, #set up the upper age\n                                    by = 10)) #set up the age breaks\n```\n\nThen make the age-gender pyramid using the `age_pyramid()` function. It\nis a function that builds on ggplot, so you can then continue to add on\ncustomization, such as the `theme_bw()` below.\n\n```{r , echo=TRUE}\n\n# Create table of all three variables\nfigure_agesex <- mpox_linelist %>% \n  \n  # Filter to male and female only\n  filter(gender %in% c(\"Male\", \"Female\")) %>% \n  \n  # select the columns of interest for\n  age_pyramid(age_group = \"age_group\",\n              split_by = \"gender\") +\n  \n  # change theme\n  theme_bw()\n\nfigure_agesex\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Females 60-69\",\n  \"Males 40-49\",\n  \"Females 10-19\",\n  answer = \"Males 30-39\"\n)\n\n\ncat(\"Which demographic group is more affected by Mpox?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"41%\",\n  \"42%\",\n  \"5%\",\n  answer = \"94%\"\n)\n\n\ncat(\"What proportion of mpox cases were homosexual or bisexual men?\", longmcq(opts))\n\n```\n:::\n:::\n\n### 5.4: Describe clinical characteristics\n\nThe media is starting to call your office and are asking what symptoms\nthe public should look out for. Just in luck - you can check that out in\nthe data too!\n\n**Tasks**:\n\n-   Create a table with the distribution of different symptoms and\n    outcomes.\n\nNo hints! You should know this one by now!\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n\n# Table with number and percentage of cases by outcome\n\ntab_outcome <- mpox_linelist %>% \n  \n  # Select the columns for tabulation\n  select(outcome, clinical_symptoms) %>% \n  \n  # Use tbl_summary() - note that this time we are adding on labels to change how the column name is displayed\n  tbl_summary(label = list(\n    clinical_symptoms = \"Symptoms\",\n    outcome = \"Reported outcome\")) \n\ntab_outcome\n\n\n```\n\n</br>\n\n</details>\n\n## **Step 6: Reviewing data quality**\n\nYou've described a lot now, but you want to make sure you understand how\ntimely and complete your mpox linelist is, especially if it will be the\nbasis of making decisions.\n\nFor example - is it possible that there are very different reporting\ndelays between countries, meaning current case counts are not directly\ncomparable? Oh dear, must check.\n\n### 6.1: Delay between date of onset, diagnosis and notification\n\n**Tasks**\n\n-   Calculate median time from symptom onset to diagnosis and from\n    diagnosis to notification, both overall and by country\n\n-   Assess visually the number of cases by calendar period and type of\n    date (onset, diagnosis and notification)\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo plot together the different dates you may need to transform your data\nfrom \"wide\" to \"long\" form. What we call \"pivoting\" in R. The objective\nis to have a column with the different date categories (onset, diagnosis\nand notification) and another column with their date value. If you are\nunsure on how to do this, have a look at the [Pivoting\ndata](https://epirhandbook.com/en/new_pages/pivoting.html) chapter of\nthe EpiRhandbook. Then, try to plot with the daily values, but if that's\nnot easy to interpret you may want to aggregate cases by week.\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Yes\",\n  answer = \"No\"\n)\n\n\ncat(\"Is there a difference in the delay from diagnosis to notification by country?\", longmcq(opts))\n\n```\n:::\n:::\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nFirst create the required columns for this analysis.\n\n```{r , echo=TRUE}\n\n# Create two columns in linelist to assess delays\ndelay_db <- mpox_linelist %>% \n  \n  # Time between onset and diagnosis (converted to a number)\n  mutate(delay_diag = as.numeric(date_of_diagnosis - date_of_onset)) %>%   \n\n  # Time between diagnosis and notification (converted to a number)\n  mutate(delay_not = as.numeric(date_of_notification - date_of_diagnosis)) \n```\n\nUse the summary function from base R to quickly view the median, mean,\ninterquartile range, and rang.\n\n```{r , echo=TRUE}\n\n# Summarize the delays to diagnosis\nsummary(delay_db$delay_diag) \n\n# Summarize the delays from diagnosis to notification\nsummary(delay_db$delay_not)\n```\n\nUse group_by() and summarize() to create a table with median delays per\ncountry.\n\n```{r , echo=TRUE}\ndelay_country <- delay_db %>% \n  \n  # Group by country\n  group_by(country) %>% \n  \n  # Create columns for each delay\n  summarise(median_delay_diag = median(delay_diag, na.rm = T),\n            median_delay_not = median(delay_not, na.rm = T))\n\ndelay_country\n```\n\nTo explore how the trends in cases over time differ when using different\ndates, you can reshape the linelist to create a dataset with one row per\ndate type per case.\n\n```{r , echo=TRUE}\n# Prepare the data\ndates_longer <- mpox_linelist %>% \n  \n  select(age, gender, sexual_orientation, starts_with(\"date_\")) %>% \n\n  pivot_longer(\n    \n      # all columns starting with \"date_\" will be pivoted from wide to long \n      cols=starts_with(\"date_\"),         \n    \n      # put names of the columns into a single column called \"indicator\"\n      names_to = \"indicator\",   \n      \n      # the date values will be placed in a column called \"date\"\n      values_to = \"date\")                \n```\n\nThe data will then look like this, with three rows per case:\n\n```{r, echo = F, eval = T}\n\nDT::datatable(dates_longer %>% filter(row_number()<7))\n\n\n```\n\nThen tabulate cases by week per indicator\n\n```{r , echo=TRUE}\n\n# Create new object\ndates_longer_week <- dates_longer  %>% \n\n  # Create a new week column\n  mutate(week_date = floor_date(date, unit = \"week\", week_start = \"Monday\")) %>%  \n  \n  # Within each combination of indicator and week, calculate the number of cases\n  group_by(indicator, week_date) %>% \n  summarise(n=n()) %>%   \n  \n  # drop the cases with no data on dates  \n  drop_na(week_date)                     \n```\n\nThe data will then look like this, with three rows per case:\n\n```{r, echo = F, eval = T}\n\nDT::datatable(dates_longer_week %>% filter(row_number()<4))\n\n```\n\nFinally, create a plot with ggplot() and geom_line().\n\n```{r, echo = T, eval = T}\nplot_date_delay <-   ggplot(data = dates_longer_week,\n                            aes(x = week_date, \n                                y = n, \n                                color=indicator)) +\n  \n  geom_line(linewidth = 1.5) +\n  \n  scale_x_date(breaks = \"2 weeks\")+\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\", \n        axis.text = element_text(size=9),\n        axis.title = element_blank(),\n        axis.text.x = element_text(angle=90),\n        legend.title = element_blank()) +\n  labs(title=\"Mpox cases reported in 2022, by date of onset, diagnosis and notification.\")\n\nplot_date_delay\n```\n\n</br>\n\n</details>\n\n### 6.2: Compare case-based and aggregated data\n\nFinally, you remember that all-along you've had these aggregate counts\nfrom routine surveillance. You find out that these numbers are actually\nalready being published.\n\nBefore you share your own numbers, you'd better check how different they\nare from already-published statistics!\n\n**Task**: Create a plot comparing the number of cases reported to\nthrough the case-based flow and through the aggregated flow in each\ncountry.\n\nNOTE: Take into consideration that the column on cases in the aggregated\ndata frame reports the *cumulative* number of cases.\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"A\",\n  \"B\",\n  answer = \"C\",\n  \"D\",\n  \"E\"\n)\n\n\ncat(\"Which country is not reporting aggregated data?\", longmcq(opts))\n\n```\n:::\n:::\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nFirst, create a data frame of country totals from the aggregate data.\n\n```{r , echo=TRUE}\nmpox_agg_country <- mpox_agg %>% \n \n  # as we have cumulative data, we keep only the last week per country \n  group_by(country) %>% \n  filter(date_rep == max(date_rep)) %>% \n  \n  # remove unnecessary columns\n  select(-date_rep, -week_date) %>%     \n\n  # create this column to distinguish the numbers from the linelist data\n  mutate(source = \"aggregated\")         \n```\n\nThen create a data frame of country totals from the case linelist, and\nappend it to the totals from the aggregate data.\n\n```{r , echo=TRUE}\n\nmpox_linelist_country <- mpox_linelist %>%\n  \n  # count cases by country, use the same column name as in the aggregate data\n  group_by(country) %>% \n  summarise(cases = n()) %>% \n  \n  # create this column to distinguish the numbers from the linelist data\n  mutate(source = \"case_based\")       \n  \n\n# Append both data frames. Remember this is different from merging\ntotal_data <- bind_rows(mpox_linelist_country, mpox_agg_country)\n```\n\nYou can now use this data to compare the cases reported in both sources,\nusing `ggplot()`.\n\n```{r , echo=TRUE}\n\ngraph_comp <- ggplot(data = total_data,\n                     aes(x = source, \n                         y = cases, \n                         fill = source)) +\n  \n  #position dodge puts bars one next to each other, instead of \"stacked\"\n  geom_col(position = \"dodge\") +            \n  \n  # this command gives us one graph per country. The argument scales allows each y axis scales to adjust to the data\n  facet_wrap(~ country, scales = \"free_y\") +  \n\n  # changes the colours, but with the argument \"labels\" we can change the text of each fill.\n  scale_fill_viridis_d(\n    labels = c(\"Aggregated\", \"Case-based\")) +\n  \n  labs(\n    title = \"Number of cases of Mpox reported in 2022 according to source of data\",\n    fill = \"Source\",\n    x = \"\",\n    y = \"Total number of cases\"\n  ) + \n  \n  theme_bw() +\n  \n  # we remove the text of the x axis because it is already present in the legend\n  theme(axis.text.x = element_blank(),   \n        \n   # we also remove the ticks for aesthetic purposes\n        axis.ticks.x = element_blank())    \n\ngraph_comp\n```\n\n</br>\n\nInteresting! There are some differences - and this probably will be\nworth flagging with stakeholders and/or explaining in a footnote\nsomewhere.\n\n</details>\n\n## Final thoughts\n\nWell done! Through your analysis you now understand the magnitude of the\noutbreak so far, where and when it spread, which demographic groups are\nmost affected, and how the disease actually manifests in terms of\nsymptoms and severity. ECDC is very happy with your work.\n\nBy coding this up in R, this analysis should be reproducible, meaning\nyou can quickly update it with new data and keep monitoring the\noutbreak.\n\nOf course, the above data is not real. If you want to see a paper on the\nactual outbreak that occured in Europe in 2022, you can take a look at\nthis [Eurosurveillance\npaper](https://www.eurosurveillance.org/content/10.2807/1560-7917.ES.2022.27.36.2200620).\nThis [ECDC page on Mpox](https://www.ecdc.europa.eu/en/mpox) also\npublishes updates on the status of mpox in Europe.\n\nTo further practise reproducible reports, \\[link to RMarkdown\\].\n\n## Case study information\n\n**Authorship**\n\nOriginal authors: Xanthi Andrianou, Gianfranco Spiteri (ECDC EI Group)\\\nData source: Fictional data provided by ECDC EI Group for training\npurposes\\\n\n| Date           | Changes made                     | Version | Author                            |\n|------------------|:------------------|-----------------:|------------------|\n| October 2021   | First draft                      |       1 | Xanthi Andrianou                  |\n| June 2024      | Adapted to case study template   |     1.1 | Alberto Mateo Urdiales            |\n| September 2024 | Revise for case study repository |     1.2 | Paula Blomquist and Alanah Jansen |\n\n## Terms of Use\n\n**Disclaimer**: The information presented in this exercise and the\nassociated data files have been deliberately changed so as to facilitate\nthe acquisition of the learning objectives for fellows of EPIET, EUPHEM\nand EPIET-associated programmes. This case study was first introduced in\n2022 (see Copyright and Licence agreement for more information).\n\nYou are free:\n\n-   to Share: to copy and distribute the work\n-   to Remix: to adapt and build upon the material\n\nUnder the following conditions:\n\n-   Attribution: You must attribute the work in the manner specified by\n    the author or licensor (but not in any way that suggests that they\n    endorse you or your use of the work). The best way to do this is to\n    keep as it is the list of contributors: sources, authors and\n    reviewers.\n\n-   Share Alike: If you alter, transform, or build upon this work, you\n    may distribute the resulting work only under the same or similar\n    license to this one. Your changes must be documented. Under that\n    condition, you are allowed to add your name to the list of\n    contributors.\n\n-   Notification: If you use the work in the manner specified by the\n    author or licensor, [Walter\\@rki.de](mailto:Walterj@rki.de)\n\n-   You cannot sell this work alone but you can use it as part of a\n    teaching.\n\nWith the understanding that:\n\n-   Waiver: Any of the above conditions can be waived if you get\n    permission from the copyright holder.\n\n-   Public Domain: Where the work or any of its elements is in the\n    public domain under applicable law, that status is in no way\n    affected by the license.\n\n-   Other Rights: In no way are any of the following rights affected by\n    the license:\n\n    -   Your fair dealing or fair use rights, or other applicable\n        copyright exceptions and limitations;\n\n    -   The author's moral rights;\n\n    -   Rights other persons may have either in the work itself or in\n        how the work is used, such as publicity or privacy rights.\n\n-   Notice: For any reuse or distribution, you must make clear to others\n    the license terms of this work by keeping together this work and the\n    current license.\n\nThis licence is based on\n<http://creativecommons.org/licenses/by-sa/3.0/>\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":"html_document","warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":false,"css":["webex.css"],"include-after-body":["webex.js"],"output-file":"r_practical.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","babelquarto":{"languagecodes":[{"name":"es","text":"Español"},{"name":"en","text":"English"}],"mainlanguage":"en","languages":["es"],"languagelinks":"sidebar"},"title-es":"Estudios de casos de AppliedEpi","theme":{"light":"sandstone","dark":["darkly","../theme-dark.scss"]},"toc-location":"left","number-depth":0,"grid":{"body-width":"1000px","margin-width":"50px"},"editor_options":{"chunk_output_type":"console"},"editor":{"markdown":{"wrap":72}}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}