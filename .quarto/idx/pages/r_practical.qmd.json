{"title":"Descriptive analysis of the 2022 Mpox outbreak in Europe","markdown":{"yaml":{"output":"html_document","editor_options":{"chunk_output_type":"console"},"execute":{"warning":false,"error":false},"format":{"html":{"css":"webex.css","include-after-body":"webex.js"}},"editor":{"markdown":{"wrap":72}}},"headingText":"Descriptive analysis of the 2022 Mpox outbreak in Europe","headingAttr":{"id":"sec-rpractical","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Tool**: R \\| **Technical complexity**: Basic \\| **Methodological\ncomplexity**: Basic\\\n**Source:** ECDC EI Group (simulated data)\\\n**Prior knowledge required:** [R\nbasics](https://epirhandbook.com/en/new_pages/basics.html) (Using\nRstudio; R packages, functions and arguments, using pipes)\n:::\n\nFor instructions on how to use our case studies, see our [How-to\nGuide](pages/instructions.qmd_). We welcome feedback and suggestions via\n[contact\\@appliedepi.org](mailto:contact@appliedepi.org). You can also\ndiscuss the case study or related concepts on the [Applied Epi\nCommunity](https://community.appliedepi.org/).\n\n\\pagebreak\n\n## Scenario\n\nIt is May 2022 and Mpox has just been reported for the first time across\n5 countries in Europe: Countries \"A\", \"B\", \"C\", \"D\", and \"E\". You have\nbeen requested to provide a basic descriptive analysis to the European\nCentre for Disease Prevention and Control (ECDC).\n\nYou are given access to:\n\n-   A dataset with aggregate case counts, submitted to ECDC by the five\n    countries as part of routine European reporting\n-   A linelist with cases, submitted by the five countries to ECDC for\n    this particular analysis\n\nLet's go!\n\n## Objectives\n\nIn this case study you will:\n\n1.  Explore different types of files and how they can be imported in R.\n2.  Perform basic data cleaning, e.g., changing the variable type,\n    recoding variables, aggregating and filtering.\n3.  Perform a basic descriptive analysis using tables and graphs\n\n## Step 1. Set up\n\n### 1.1 Get started in RStudio\n\nStart by setting up a reproducible and well-organized workflow. This\nwill make it easy to rerun your analysis whenever needed.\n\n**Tasks:**\n\n-   Set up an RStudio project\n-   Set up clear sub-folders where your code, data, and outputs will go\n-   Create an R script, or an R Markdown file if you prefer. Make sure\n    the script purpose, date, and author are written as comments at the\n    top.\n-   Extra: Ensure your working language in RStudio is appropriate (e.g.\n    English for this exercise)\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\n-   Create a folder where all the work in this case study will go. For\n    example, create 'mpox_analysis' on your computer desktop. Create\n    your RStudio project to be based in this folder.\n\n-   We suggest creating the following sub-folders: `scripts` (for your\n    code), `data` (for your data), and `outputs` (for your analytical\n    outputs).\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nCreate a folder (e.g. 'mpox_analysis' on your Desktop) for your work. To\ncreate an Rstudio project in your new folder, click `New Project…` in\nthe top left of your R Studio, then `Existing Directory`, then `Browse`\nto select your new folder. For more information, look at the [R\nprojects](https://epirhandbook.com/new_pages/r_projects.html) section of\nthe Epi R Handbook.\n\nStart a new R script by clicking `New File…` in the top left of your R\nStudio, then `R Script`. Save it immediately in the appropriate place,\ne.g. in a 'scripts' subfolder of your R Project.\n\nAt the top of your new R script, write some essential information like\nyour name, the purpose of the file, and the date.\n\nYour R locale determines the language and regional settings used for\nthings like date formats and translations. If your locale is different\nfrom the language you want for your report (e.g., a French locale vs. an\nEnglish report), you can change it to English by running\n`Sys.setlocale(\"LC_ALL\", \"English\")`. Include this in your script if\nneeded, or skip it if your locale is usually appropriate. This is\nexplained in more detail in the [How-to Guide](pages/instructions.qmd_).\n\n</details>\n\n### 1.2 Install/load packages\n\nNext in your R script, you need to install and load the necessary R\npackages. This ensures that the functions you need are available for\nyour analysis.\n\nYou will need the following packages: `rio` (for importing data),\n`janitor` (for cleaning data), `lubridate` (for cleaning dates), `skimr`\n(for reviewing data), `epikit` (for epi-related tasks), `gtsummary` (for\npresentation-ready tables), `apyramid` (for age-sex pyramids), and\n`tidyverse` (for general data manipulation/science tasks).\n\nAs you start, your trusted colleague nudges you and whispers \"I've heard\nthat a great way to manage your packages is with the `pacman` package\".\n\nOver to you!\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nUse the function `p_load()` from `pacman` for this task. You provide the\nfunction with a list of packages that you want to use. It will take two\nsteps per package: 1) Check if the package is installed on your\ncomputer, and install it if necessary, then 2) Load the package so it\ncan be used during this R session.\n\nIf you don't already have `pacman` installed, you will need to install\nit the \"traditional way\" first, with `install.packages()`.\n\nNote that the order of packages in your p_load function can be\nimportant. If two packages have the same function names (e.g. `select()`\nin the package `MASS` and `select()` in `tidyverse`, which do different\nthings), then R will use the function from the most recently loaded\npackage. To prioritize functions from tidyverse, which are commonly used\nfor data manipulation and visualization, load tidyverse last.\n\n</detail>\n\n```{r, echo=TRUE, eval=TRUE}\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\n```\n\n## Step 2: Download and import the data\n\n### 2.1: Download the data\n\nECDC provides you with two files for your analysis, both updated as of 31st August 2022:\n\n-   A case-level linelist (*\"mpox_linelist.xlsx\"*) with case information\n    from five countries (countries A - E)\n-   An aggregate table (*\"mpox_aggregate_table.csv\"*) for those\n    countries with cumulative case counts per day.\n\nThey provide it to you via AppliedEpi's very useful data repository,\nwhich you can access using the `{appliedepidata}` package. So first you\nneed to download these two files to your own computer, as follows:\n\n1)  Install the `{appliedepidata}` package from GitHub using the\n    `install_github()` function in the `{remotes}` package. Install\n    `{remotes}` if you need to first.\n\n```{r , echo=TRUE, eval=FALSE}\n# Install remotes if you need to (so you can install a package from GitHub)\npacman::p_load(\"remotes\")\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n```\n\n2)  Save the two datasets into a specific folder using the `save_data()`\n    function from `{appliedepidata}`, by running the code below. The\n    example below saves the data into a 'data' subfolder within the\n    RStudio project. Note that if you do not specify a location within\n    the 'path' argument of the function, a window will pop up asking you\n    to manually select a folder.\n\n```{r , echo=TRUE, eval=FALSE}\n# Save down the two mpox files using the save_data() function from appliedepidata\nappliedepidata::save_data(\"mpox_linelist\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"mpox_aggregate_table\",\n                          path = \"data\")\n```\n\n### 2.2 Import the data\n\nGreat! Thanks ECDC and Applied Epi! Now it's time to import the data\nfrom that folder into RStudio, so you can analyse it.\n\n**Task:** Import the downloaded case-based and aggregated data into your\nR environment. Ideally you want to use one function for both datasets,\ndespite one being a csv and the other an xlsx file.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nUse the `import` function from the `{rio}` package, which can recognize\nand import different file types. It replaces importing functions that\nare specific to the file type, such as `read.csv()` from `{base}` for\n.csv files and `read_excel()` from `{readxl}` to import .xlsx files.\n\nIf you feel you need to know more about importing functions, read the\n[Import and export](https://epirhandbook.com/new_pages/importing.html)\nchapter of the EpiRhandbook.\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\nBelow we use the import function to bring in both files. Note how we are\nassigning the imported data to two objects, one called\n*mpox_linelist_raw*, and one called *mpox_agg_raw*. We add the 'raw'\nsuffix to distinguish this data from the cleaned versions we will make\nlater.\n\n```{r , echo=TRUE, eval=FALSE}\n# Import data  --------------\n\n# Case-based data\nmpox_linelist_raw <- import(\"data/mpox_linelist.xlsx\")\n\n# Aggregated data\nmpox_agg_raw <- import(\"data/mpox_aggregate_table.csv\")\n\n```\n\n```{r, include = FALSE}\n# This code is actually run; the prior chunk is just for show for simplicity\n\npacman::p_load(\"remotes\")\n\nif (!requireNamespace(\"appliedepidata\", quietly = TRUE)) {\n  remotes::install_github(\"appliedepi/appliedepidata\")\n}\n\nappliedepidata::get_data(\"mpox_linelist\")\nmpox_linelist_raw <- mpox_linelist\n\n\nappliedepidata::get_data(\"mpox_aggregate_table\")\nmpox_agg_raw <- mpox_aggregate_table\n\nrm(mpox_linelist, mpox_aggregate_table)\n\n```\n\n</details>\n\n## Step 3: Explore the data\n\nYou need to understand what the data looks like as a first step, to\ninform your analysis.\n\n**Tasks:** Take a look at the different data frames and determine:\n\n-   The number of columns and observations (e.g. their *dimensions*)\n-   The class of their columns and whether it matches its nature (e.g.,\n    are \"dates\" considered \"dates\" by R?)\n-   If the contents of columns are clean and standardized in the mpox\n    linelist (e.g. gender, clinical symptoms, outcome, hiv status and\n    sexual orientation). Do you need to recode any of them?\n-   How unknown or missing data is categorised in these columns. Do\n    these values need to be standardized?\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nAn efficient function for initial data exploring is `skim()` from the\n`{skimr}` package, as it gives you a lot of information on data\nstructure and content, including the classes of columns.\n\nYou can use the function `tabyl()` from `{janitor}`, to get counts and\npercentages of every category in the data column, one by one. These get\nprinted to your RStudio console.\n\nAlso - we recommend just looking at the data itself! A good function for\nthis is `view()`, a baseR function.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nUsing the `skim` commands you can see the rows and columns of each\ndataset, and you can see how most of the columns in *mpox_linelist_raw*\n(including those containing dates) are character classes. (Results not\nshown on this exercise page)\n\n```{r , echo=TRUE, results='hide'}\n# Explore the dimensions of the two data objects \nskim(mpox_linelist_raw)\nskim(mpox_agg_raw)\n```\n\nTake a look at the overall data using `view()`. It will pop up in the\nData Viewer tab and you will get a good sense of how clean the data is\nand what the missingness is like. This preview shows just 5 rows from\nthe linelist data.\n\n```{r , echo=TRUE, results='hide'}\nview(mpox_linelist_raw)\n```\n\n```{r , echo=FALSE, eval = TRUE}\n#head(mpox_linelist_raw) %>% flextable::flextable()\nDT::datatable(mpox_linelist_raw %>% filter(row_number()<6))\n```\n\n\\br\n\nBelow is an example of using the `tabyl()` function from `{janitor},` to\nlook at the distribution of clinical symptoms. You can see 12 cases have\nmissing clinical information and that many cases have a mix of symptoms.\n\n```{r , echo=TRUE}\n\ntabyl(mpox_linelist_raw, HIVStatus)  \n```\n\nYou can explore further columns one by one (results not shown):\n\n```{r , echo=TRUE, results='hide'}\n# Explore the values of different categorical columns in the mpox linelist: with tabyl\ntabyl(mpox_linelist_raw, Gender)\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms)\n\ntabyl(mpox_linelist_raw, Outcome)\n\ntabyl(mpox_linelist_raw, SexualOrientation)\n\n```\n\nYou could add extra arguments to `tabyl()` to customize the tables, such\nas adding totals and changing the proportions to percentages so they are\neasier to read. See the table on clinical symptoms below. But remember -\nthis is just an initial look so don't go too crazy.\n\n```{r , echo=TRUE}\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms) %>%    # Tabulate symptoms \n  adorn_totals() %>%                              # Add totals to bottom of table\n  adorn_pct_formatting(digits = 2)                # Format percentages\n```\n\nFinally, as an alternative approach to `tabyl()`, you could use\n`tbl_summary()` from the `{gtsummary}` package. We will describe this\nlater.\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"2000\", \"13\", answer = \"3\", \"101\"\n)\n\ncat(\"How many columns does the aggregated data have?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Date\", answer = \"Character\", \"Numeric\", \"Factor\"\n)\n\n\ncat(\"What is the class of the column DateOfNotification in the mpox linelist?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"1168\",\n  \"722\",\n  \"900\",\n  \"446\"\n)\n\n\ncat(\"For how many cases is the HIV status Unknown or missing?\", longmcq(opts))\n\n```\n:::\n:::\n\n## Step 4: Clean the data\n\n### 4.1: Clean the case-based data\n\n**Cleaning column names and values**\n\nGreat! From your exploration, you know that you can describe the\ngeographic distribution of cases by country, trends over time, their\ndemographic details, their sexual orientation and hiv status, plus their\noutcome and clinical symptoms.\n\nYou plan to make some tables and graphs to describe those variables.\n\nBUT! You may noticed that there are a few things that you need to clean\nup before really diving into the analysis.\n\nFor example:\n\n-   Column names have capital letters. This isn't outright a problem,\n    but can lead to mistakes since R treats ColumnName and Columnname as\n    different.\n-   Date columns are recognized as character classes, not dates, which\n    would cause issues like incorrect ordering (alphabetical) in\n    epicurves.\n-   Some columns have values that are unclear or unsuitable for\n    presentation. For example gender is categorized with \"F\", \"M\", \"O\"\n    and \"UNK\". The column Outcome is \"A\" and \"UNK\".\n-   Missing data is inconsistently handled, for instance with both \"UNK\"\n    and NA in the HIV status column. R thinks \"UNK\" is a valid value,\n    which it treats differently to true missing data (indicated by NA)\n\n**Tasks**:\n\n-   Create a clean version of your case-based data making all cleaning\n    changes in a single piping command\n-   Change all column names to lower case.\n-   Convert all date columns to class \"Date\".\n-   Recode \"Gender\" categories into: \"Female\", \"Male\", \"Other\", and\n    \"Unknown\"\n-   Recode \"Outcome\" categories into: \"Alive\" and \"Unknown\"\n-   Recode HIV status into: \"Positive\", \"Negative\" and \"Unknown\"\n-   Recode Sexual orientation into: \"Bisexual\", \"Heterosexual\",\n    \"MSM/homo or bisexual male\" and \"Unknown\".\n-   Check that all changes have been made correctly\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo convert all column names to lower case at once rather than renaming\neach column, use the function `clean_names()` from the `{janitor}`\npackage.\n\nUse `{lubridate}` functions to transform date columns into \"Date\" class.\nYou can do this one by one, or you could do all at the same time using\nthe `across()` function from `{dplyr}.` If you feel you need to know\nmore about transforming dates read the chapter [Working with\nDates](https://epirhandbook.com/en/new_pages/dates.html) from the\nEpiRhandbook. If you are not sure how to use the across() function, you\ncan also read the section on [Transform multiple\ncolumns](https://epirhandbook.com/en/new_pages/cleaning.html#clean_across).\n\nThere are different functions that we can use to recode values. We\npropose three: The function `recode()` from `{dplyr}`, the function\n`ifelse()` from `{base}` and the function `case_when()` from `{dplyr}`.\nIf you want to know more about these functions, look that the section on\n[Re-code\nvalues](https://epirhandbook.com/en/new_pages/cleaning.html#re-code-values)\nfrom the EpiRhandbook.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nHere we clean the data using a 'chain' of commands connected by pipes\n(%\\>%), which is the grammar of the functions in the {Tidyverse}. The\noutput is assigned to a new object called mpox_linelist to differentiate\nit from the raw data. It can be helpful to have both the cleaned and raw\ndata available in the environment to compare to the original data if\nneeded.\n\nSee the series of functions and the explanation in the comments.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Create a new object called mpox_linelist which is the clean version of the raw data\nmpox_linelist <- mpox_linelist_raw %>% \n  \n  # standardises names and puts all into lower case \n  clean_names() %>% \n  \n  #transform ONE column into date (note the column names are lower case now)\n  mutate(date_of_notification = ymd(date_of_notification)) %>%  \n\n  #transforms ALL columns starting with \"date\" into dates\n  mutate(across(starts_with(\"date\"), \n                .fns = ~ ymd(.x))) %>%  \n  \n\n  # Recode the gender values to be more obvious  \n  mutate(gender = recode(gender,\n                         \"F\" = \"Female\",\n                         \"M\" = \"Male\",\n                         \"O\" = \"Other\",\n                         \"UNK\" = \"Unknown\")) %>%\n  \n  #transforms UNK to Unknown across all character columns \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x == \"UNK\", \"Unknown\", .x)))  %>% \n  \n  #recode with ifelse to change only one or two categories based on a rule. \n  mutate(outcome = ifelse(outcome == \"A\", \"Alive\", outcome)) %>%   \n  \n  #recode with case_when for more complex recoding \n  mutate(hiv_status = case_when(hiv_status == \"NEG\" ~ \"Negative\",    \n                                hiv_status == \"POS\" ~ \"Positive\",\n                                TRUE                ~ \"Unknown\")) %>% \n  \n  mutate(sexual_orientation = case_when(sexual_orientation == \"BISEXUAL\" ~ \"Bisexual\",\n                                        sexual_orientation == \"HETERO\" ~ \"Heterosexual\",\n                                        sexual_orientation == \"MSM\" ~ \"MSM/homo or bisexual male\",\n                                        TRUE                        ~  \"Unknown\")) \n```\n\nYou can then review your data by tabulating across all the different\ncolumns you have cleaned. See the preview of the HIV table below - it\nlooks tidier now with more understandable categories, and all missing\ndata is classified as 'Unknown'.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Check that all changes have been made correctly\n\nskim(mpox_linelist)\n\ntabyl(mpox_linelist, gender)\n\ntabyl(mpox_linelist, clinical_symptoms)\n\ntabyl(mpox_linelist, outcome)\n\ntabyl(mpox_linelist, hiv_status)\n\ntabyl(mpox_linelist, sexual_orientation)\n\n\n```\n\n```{r , echo=FALSE, eval= TRUE}\n\ntabyl(mpox_linelist, hiv_status)\n\n```\n\n**IMPORTANT**: If 'unknown' and NA had meaningful differences, combining\nthem wouldn't be appropriate (e.g., 'unknown' means the case was asked\nbut didn't want to respond, while NA means they weren't asked). Here, we\nassume no meaningful difference and combine them for simplicity.\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Yes\",\n  answer = \"Depends on the meaning of those values\",\n  \"No - never do this\"\n)\n\n\ncat(\"Is it always appropriate to combine different types of unknown data? (e.g. missing, unknown, did not respond, NA)\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"36\",\n  answer = \"1960\",\n  \"65\",\n  \"1523\"\n)\n\n\ncat(\"How many male cases do we have in the data frame?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"1405\",\n  \"None\",\n  \"595\"\n)\n\ncat(\"How many cases have 'alive' as an outcome?\", longmcq(opts))\n\n```\n:::\n:::\n\n**Creating new columns for analysis**\n\nFabulous, you're getting there. Now, because you plan to create weekly\nepicurves and an age-sex pyramid, you need to ensure your data has the\nright columns for this.\n\n***Tasks:***\n\n-   Use the column \"DateOfNotification\" to create a column called\n    \"week_date\" which has the week of notification, starting on Mondays.\n\n-   Create a column called \"age_group\" with ten year age groups and the\n    oldest group being 70+\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo create the age groups, explore the function called `age_categories()`\nfrom the `{epikit}` package.\n\nOne simple way to create the \"week_date\" column would be to use the\nfunction `floor_date()` from `{lubridate}`. Take a look at the\ndocumentation to understand how it works and how to make Monday the\nstarting day of the week.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nAdd the creation of these columns to your cleaning code:\n\n```{r , echo=TRUE, results = 'hide'}\n\nmpox_linelist <- mpox_linelist %>% \n  # create week column with Monday start \n  mutate(week_date = floor_date(date_of_notification, unit = \"week\", week_start = \"Monday\")) %>%\n  \n  # Use the age_categories function to create age categories\n  mutate(age_group = age_categories(age, lower = 0, #set up the lower age\n                                    upper = 70, #set up the upper age\n                                    by = 10)) #set up the age breaks\n```\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"2022-04-11\",\n  \"2022-07-25\",\n  \"2022-02-28\",\n  \"2022-05-09\"\n)\n\n\ncat(\"Which week has the largest number of cases?\", longmcq(opts))\n\n```\n:::\n:::\n\n### 4.2: Clean the aggregated data\n\nIn a similar way, clean the aggregated data by:\n\n-   Standardising names to lower case\n-   Ensuring that date of reporting is of class \"Date\"\n-   Creating a column called \"week_date\" with the week of reporting\n    starting on Monday\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nWe can first check the class of the DateRep column, which shows us that\nit was already recognized as a date column on import.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Check class of date of reporting column\nclass(mpox_agg_raw$DateRep)\n\n```\n\nThen create a new object for the clean aggregate data, and write your\ncleaning coded connected with pipes.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Create a new object called mpox_agg which is the clean version of the raw data, applying the cleaning functions\n\nmpox_agg <- mpox_agg_raw %>% \n  \n  # standardises names and puts all into lower case\n  clean_names() %>%  \n  \n  # create week column with Monday start\n  mutate(week_date = floor_date(date_rep, \n                              unit = \"week\",\n                              week_start = \"Monday\")) \n\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"Country A\",\n  \"Country B\",\n  \"Country C\",\n  \"Country D\",\n  \"Country E\"\n)\n\n\ncat(\"Take a look at the aggreate data. Which country reported the largest cumulative number of cases during the week 2022-04-11?\", longmcq(opts))\n\n```\n:::\n:::\n\n## Step 5: Describe outbreak by person, place, and time\n\n### 5.1: Describe total case counts by country\n\n**Task**: Using the mpox case linelist, create a table showing the total\nnumber of cases by country. This time, make the table more\npublication-friendly.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nYou could use `tabyl()` like before, but an easy way to produce\npublication-ready tables is with the function tbl_summary() from\n{gtsummary} package. This formats the table for you. It will print to\nyour Viewer rather than the console.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nCreate a new object with the table output - as this is a key output that you can then integrate into a document later rather than just viewing for now. \n\n```{r , echo=TRUE}\n# Create an object with the table\ncb_country_table <- mpox_linelist %>%\n\n  #select the column that we want to use in the table\n  select(country) %>% \n  \n  # create the table. No need to specify columns; it will tabulate all available columns (selected above)\n  tbl_summary() \n\n# Print the table\ncb_country_table\n\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Country C\",\n  \"Country D\",\n  \"Country B\",\n  \"Country E\",\n  answer = \"Country A\"\n)\n\n\ncat(\"What country has the largest percentage of cases?\", longmcq(opts))\n\n```\n:::\n:::\n\n### 5.2: Describe cases over time\n\nOkay so Country A has the most cases in total based on most recent data. But how does that change look over time? \n\n**Tasks**:\n\n-   Using the mpox case linelist, create an epicurve by week of\n    notification\n-   Using the mpox case linelist, create an epicurve by week of\n    notification to enable a comparison of trends by country.\n-   Using the mpox case linelist, create a heat plot with the number of\n    cases by country and week of notification.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo do the epicurve, you can use ggplot() and geom_histogram(), which\nwill automatically aggregate your data. If you are unsure on how\nggplot() works, read the EpiRhandbook chapter on [Epidemic\ncurves](https://epirhandbook.com/en/new_pages/epicurves.html).\n\nAn alternative approach is to first aggregate the number of cases by\nweek of notification. You can do this using the functions group_by() and\nsummarise() from {dplyr}. If you are unsure on how to do this, review\nthe [Grouping data](https://epirhandbook.com/en/new_pages/grouping.html)\nchapter of the EpiRhandbook.\n\nOnce you have an object with aggregated cases by week of notification,\ncreate the epicurve using ggplot(). If want a dynamic colour inside the\nbins, you need to assign the fill to the column you want to use\n(country) and place it inside the aesthetics\n\nHeat plots can be useful to understand how the epidemic evolved in\ndifferent countries. You will need to aggregate your data by country and\nweek of notification. You can do this using the functions group_by() and\nsummarise() from {dplyr}. If you are unsure on how to do this, review\nthe Grouping data chapter of the EpiRhandbook. Then, use the geom\ngeom_tile() to create a heat plot. If you're unsure on how to do this,\nread the EpiRhanbook section on [Heat\nPlots](https://epirhandbook.com/en/new_pages/heatmaps.html)\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nThe code below creates an epicurve using ggplot() and the geom_bar() function and applies further formatting. You can plug in the column you created during the data cleaning step for the x axis. With geom_bar(), you do not need to specify the y axis as the function counts the number of rows per x axis value. \n\n```{r , echo=TRUE}\n\n# Open up the plot production with ggplot() function, specifying object and columns\nepicurve_mpox <- ggplot(data = mpox_linelist,          \n                        aes(x = week_date)) +    \n  \n  geom_bar(fill=\"darkgreen\",                     #colour inside the bins\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  labs(title=\"Mpox cases reported in 2022 in Countries A, B, C, D, and E\",\n       subtitle = \"Date as of August 31st 2022\") +  #add a title\n  \n  theme_bw() +                                  #assign a predefined theme\n  \n  theme(axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n           \n# Print the epicurve\nepicurve_mpox\n\n```\n\nTo examine how the outbreak spread by country, add `facet_wrap()` to your ggplot code. This splits the graph into multiple smaller ones. Below, we show how we can even simply add the function to the national epicurve object. Alternatively, you could add fill = country to the aes() in the epicurve code to keep a single curve but color each bar by country. However, we don't recommend this for comparing trends, as stacked bars make it harder to see individual patterns.\n\n```{r , echo=TRUE}\nepicurve_epox_country <- epicurve_mpox + \n \n   # Facet wrap to make mini-plots, specifying that you want two columns of plots. \n  facet_wrap(.~country,\n             ncol = 1) \n\n# Print the epicurve\nepicurve_epox_country\n```\n\n```{r , echo=TRUE}\n\n# Heatmap of cases by country over time\n\nhp_epox <- mpox_linelist %>% #we first group the data by country and week of notification\n  \n  group_by(country, week_date) %>% \n  \n  summarise(n_cases = n(), .groups = \"drop\") %>% \n\n  #now we can use the pipe to directly plot the resulting data from the grouping\n  \n  ggplot(aes(x = week_date,\n           y = country,           #we want the countries to be in the y axis\n           fill = n_cases)) +     #the colour of the tiles should depend on the number of cases\n  \n  geom_tile(colour = \"black\") +   #this is the outline colour of each tile\n  \n  scale_fill_gradient(            #here we define the colours we want to use in the gradient\n    low = \"lightgreen\",\n    high = \"red\") +\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n  \n  labs(\n    title= \"Mpox cases by country and week of notification\",\n    fill = \"Number of cases\"                               \n  ) +\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\",             #legend position to the bottom\n        axis.text = element_text(size=9),       #define the font size of the axis\n        axis.title = element_blank(),           #remove the titles of the x and y \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n    \nhp_epox \n\n```\n\n</br>\n\n</details>\n\n### 5.3: Describe demographic characteristics\n\nNow that we have created some outputs by time and place, we should focus\non the \"person\" element. The two most important demographic\ncharacteristics are usually age and gender. In the case we are seeing,\nwe may also want to explore the sexual orientation of cases.\n\n**Task**:\n\n-   Explore the number of cases by age group and gender.\n-   Create a table with number and percentages of cases by sexual\n    orientation\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nThe easiest way to explore both columns (age_group and gender) would be\nto use the tabyl() function from {janitor}. Then, to create the age\npyramid explore the function age_pyramid() from the {apyramid} package.\nYou can find more about this function in the EpiRhandbook chapter\n[Demographic pyramids and\nLikert-scales](https://epirhandbook.com/en/new_pages/age_pyramid.html)\n\nTo create the table by sexual orientation, consider using the function\ntbl_summary() from {gtsummary}\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Explore gender and age group columns\ntabyl(mpox_linelist, gender)\ntabyl(mpox_linelist, age_group)\n\n# Table with sexual orientation \n\ntab_sor <- mpox_linelist %>% \n  \n  select(sexual_orientation) %>% \n  \n  tbl_summary(label = list(sexual_orientation ~ \"Sexual Orientation\")) \n\ntab_sor\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Females 60-69\",\n  \"Males 40-49\",\n  \"Females 10-19\",\n  answer = \"Males 30-39\"\n)\n\n\ncat(\"Which demographic group is more affected by Mpox?\", longmcq(opts))\n\n```\n:::\n:::\n\n### 5.4: Describe clinical characteristics\n\nNow, let's summarise the main clinical information that we have in our\ncase-based data frame.\n\n**Tasks**:\n\n-   Create a bar plot with the proportion of each type clinical symptoms\n\n-   Create a table with the number and percentage of cases by outcome\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo create bar plots we can use geom_bar() or geom_col() depending on the\nnature of our data. If we aggregate first, we can use geom_col(),\notherwise we should use geom_bar(). There is a function of the\n{gtsummary} package called add_p() which enables you to easy calculate a\nstatistical test across groups. If you want to know more read the\nsection on [gtsummary\npackage](https://epirhandbook.com/en/new_pages/stat_tests.html#stats_gt)\nof the EpiRhandbook.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Bar plot with clinical symptoms\n\nbar_clinical <- mpox_linelist %>% \n  \n  drop_na(clinical_symptoms) %>%   # we remove those with missing clinical symptoms\n  \n  group_by(clinical_symptoms) %>% \n  \n  summarise(n_cases = n(), .groups = \"drop\") %>%\n  \n  mutate(prop=(n_cases/sum(n_cases))*100) %>%  # we create a column with proportions\n  \n  ggplot(aes(y = reorder(clinical_symptoms, prop), x = prop)) +  # the reorder function ensures that categories are ordered by proportion in the graph\n  \n  geom_col(fill = \"darkgreen\") + \n  \n  labs(\n    title= \"Frequency of clinical symptoms in Mpox cases\",\n    y = \"\",\n    x = \"Number of cases\"\n  ) +\n  \n  theme_bw() +\n  \n  theme(axis.text = element_text(size=9))       #define the font size of the axis\n\nbar_clinical  \n\n\n# Table with number and percentage of cases by outcome\n\ntab_outcome <- mpox_linelist %>% \n  \n  select(outcome) %>% \n  \n  tbl_summary(label = list(outcome = \"Reported outcome\")) # with the argument \"label\" we can change how the column name is displayed\n\ntab_outcome\n\n\n```\n\n</br>\n\n</details>\n\n## **Step 6: Reviewing data quality**\n\nIt is important to understand how timely, complete, and valid your data\nis, if it will be the basis of understanding an outbreak and making\ndecisions. For example - you will need to be mindful of reporting delays\nwhen interpreting epicurves, and be aware of how complete different\nsources of data are compared to each other.\n\n### 6.1: Delay between date of onset, diagnosis and notification\n\n**Tasks**\n\n-   Calculate median time from symptom onset to diagnosis and from\n    diagnosis to notification, both overall and by country\n\n-   Assess visually the number of cases by calendar period and type of\n    date (onset, diagnosis and notification)\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo plot together the different dates you may need to transform your data\nfrom \"wide\" to \"long\" form. What we call \"pivoting\" in R. The objective\nis to have a column with the different date categories (onset, diagnosis\nand notification) and another column with their date value. If you are\nunsure on how to do this, have a look at the [Pivoting\ndata](https://epirhandbook.com/en/new_pages/pivoting.html) chapter of\nthe EpiRhandbook. Then, try to plot with the daily values, but if that's\nnot easy to interpret you may want to aggregate cases by week.\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Yes\",\n  answer = \"No\"\n)\n\n\ncat(\"Is there a difference in the delay from diagnosis to notification by country?\", longmcq(opts))\n\n```\n:::\n:::\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Estimate delay between onset and diagnosis, and between diagnosis and notification\n\ndelay_db <- mpox_linelist %>% \n  \n  mutate(delay_diag = as.numeric(date_of_diagnosis - date_of_onset)) %>%   #we create variables with difference between dates, we transform them in numeric to be able to then calculate measures of central tendency\n  \n  mutate(delay_not = as.numeric(date_of_notification - date_of_diagnosis))\n\nsummary(delay_db$delay_diag) #the summary will give us measures of central tendency and dispersion\nsummary(delay_db$delay_not)\n\n\ndelay_country <- delay_db %>% #here, we group by country and summarise the median to compare across countries\n  \n  group_by(country) %>% \n  \n  summarise(median_delay_diag = median(delay_diag, na.rm = T),\n            median_delay_not = median(delay_not, na.rm = T))\n\ndelay_country\n\n# Line graph with the different dates \n\ndates_longer <- mpox_linelist %>% # use the variables of the dates and make a longer dataset. In the pivot_longer() command we select the columns which we want to expand in long format and transform the dataset\n   \n  pivot_longer(\n    \n    cols=starts_with(\"date_\"),         # all columns starting with \"date_\" will be taken \n\n    names_to = \"indicator\",            #the names of the columns will be placed in a single column called \"indicator\"\n\n    values_to = \"date\")                # the values (which are dates in this case) will be placed in a column called \"date\"\n  \n\ndates_longer_week <- dates_longer  %>% \n\n  mutate(week_date = floor_date(date, unit = \"week\", week_start = \"Monday\")) %>%  # we create a week column\n    \n  group_by(indicator, week_date) %>% \n    \n  summarise(n=n(), .groups=\"drop\") %>%   # we group and summarise to have the number of cases by date type and week\n    \n  drop_na(week_date)                     # we drop the cases with no data on dates\n\n\n\n\nplot_date_delay <-   ggplot(data = dates_longer_week,\n                            aes(x = week_date, \n                                y = n, \n                                color=indicator)) +\n  \n  geom_line(linewidth = 1.5) +\n  \n  scale_x_date(breaks = \"2 weeks\")+\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\", \n        axis.text = element_text(size=9),\n        axis.title = element_blank(),\n        axis.text.x = element_text(angle=90),\n        legend.title = element_blank()) +\n  labs(title=\"Mpox cases reported in 2022, by date of onset, diagnosis and notification.\")\n\nplot_date_delay\n```\n\n</br>\n\n</details>\n\n### 6.2: Compare case-based and aggregated data\n\n**Task**: Create a plot comparing the number of cases reported to\nthrough the case-based flow and through the aggregated flow in each\ncountry.\n\nNOTE: Take into consideration that the column on cases in the aggregated\ndata frame reports the *cumulative* number of cases.\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"A\",\n  \"B\",\n  answer = \"C\",\n  \"D\",\n  \"E\"\n)\n\n\ncat(\"Which country is not reporting aggregated data?\", longmcq(opts))\n\n```\n:::\n:::\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Create a data frame with the overall number of cases reported through the aggregated flux\n\nmpox_agg_country <- mpox_agg %>% \n  \n  group_by(country) %>% \n  \n  filter(date_rep == max(date_rep)) %>% # as we have cumulative data, we keep only the last week (after grouping by country)\n  \n  select(-date_rep, -week_date) %>%     # remove unnecessary columns\n\n  mutate(source = \"aggregated\")         # we create this column to distinguish the numbers from the case-based flux\n\n\n# Create a data frame with the overall number of cases reported through the case-based flux\n\nmpox_linelist_country <- mpox_linelist %>%\n  \n  group_by(country) %>% \n  \n  summarise(cases = n(), .groups = \"drop\") %>% \n  \n  mutate(source = \"case_based\")       # we create this column to distinguish the numbers from the\n  \n\n# We append both data frames. Remember this is different from merging\n\ntotal_data <- bind_rows(mpox_linelist_country, mpox_agg_country)\n\n\n# We create a graph to compare the cases reported in both sources\n\ngraph_comp <- ggplot(data = total_data,\n                     aes(x = source, \n                         y = cases, \n                         fill = source)) +\n  \n  geom_col(position = \"dodge\") +            #position dodge puts bars one next to each other, instead of \"stacked\"\n  \n  facet_wrap(~ country, scales = \"free_y\") +  # this command gives us one graph per country. The argument scales is used to allow each y axis scales to adjust to the data\n\n  scale_fill_viridis_d(\n    labels = c(\"Aggregated\", \"Case-based\")  # this function changes the colours, but with the argument \"labels\" we can change the text of each fill.\n     ) +\n  \n  \n  labs(\n    title = \"Number of cases of Mpox reported in 2022 according to source of data\",\n    fill = \"Source\",\n    x = \"\",\n    y = \"Total number of cases\"\n  ) + \n  \n  theme_bw() +\n  \n  theme(axis.text.x = element_blank(),      # we remove the text of the x axis because it is already present in the legend\n        axis.ticks.x = element_blank())     # we also remove the ticks for aesthetic purposes\n\ngraph_comp\n```\n\n</br>\n\n</details>\n\n## Final thoughts\n\nWell done! Through your analysis you now understand the magnitude of the\noutbreak so far, where and when it spread, which demographic groups are\nmost affected, and how the disease actually manifests in terms of\nsymptoms and severity. ECDC is very happy with your work.\n\nBy coding this up in R, this analysis should be reproducible, meaning\nyou can quickly update it with new data and keep monitoring the\noutbreak. To further practise reproducible reports, \\[link to\nRMarkdown\\].\n\n## Case study information\n\n**Authorship**\n\nOriginal authors: Xanthi Andrianou, Gianfranco Spiteri (ECDC EI Group)\\\nData source: Fictional data provided by ECDC EI Group for training\npurposes\\\n\n| Date         | Changes made                   | Version | Author                 |\n|------------------|:------------------|-----------------:|------------------|\n| October 2021 | First draft                    |       1 | Xanthi Andrianou       |\n| June 2024    | Adapted to case study template |     1.1 | Alberto Mateo Urdiales |\n\n**Terms of Use**\n\n<!-- Describe the licencing and other appropriate information about Terms of use or any other disclaimer -->\n","srcMarkdownNoYaml":"\n\n# Descriptive analysis of the 2022 Mpox outbreak in Europe {#sec-rpractical}\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Tool**: R \\| **Technical complexity**: Basic \\| **Methodological\ncomplexity**: Basic\\\n**Source:** ECDC EI Group (simulated data)\\\n**Prior knowledge required:** [R\nbasics](https://epirhandbook.com/en/new_pages/basics.html) (Using\nRstudio; R packages, functions and arguments, using pipes)\n:::\n\nFor instructions on how to use our case studies, see our [How-to\nGuide](pages/instructions.qmd_). We welcome feedback and suggestions via\n[contact\\@appliedepi.org](mailto:contact@appliedepi.org). You can also\ndiscuss the case study or related concepts on the [Applied Epi\nCommunity](https://community.appliedepi.org/).\n\n\\pagebreak\n\n## Scenario\n\nIt is May 2022 and Mpox has just been reported for the first time across\n5 countries in Europe: Countries \"A\", \"B\", \"C\", \"D\", and \"E\". You have\nbeen requested to provide a basic descriptive analysis to the European\nCentre for Disease Prevention and Control (ECDC).\n\nYou are given access to:\n\n-   A dataset with aggregate case counts, submitted to ECDC by the five\n    countries as part of routine European reporting\n-   A linelist with cases, submitted by the five countries to ECDC for\n    this particular analysis\n\nLet's go!\n\n## Objectives\n\nIn this case study you will:\n\n1.  Explore different types of files and how they can be imported in R.\n2.  Perform basic data cleaning, e.g., changing the variable type,\n    recoding variables, aggregating and filtering.\n3.  Perform a basic descriptive analysis using tables and graphs\n\n## Step 1. Set up\n\n### 1.1 Get started in RStudio\n\nStart by setting up a reproducible and well-organized workflow. This\nwill make it easy to rerun your analysis whenever needed.\n\n**Tasks:**\n\n-   Set up an RStudio project\n-   Set up clear sub-folders where your code, data, and outputs will go\n-   Create an R script, or an R Markdown file if you prefer. Make sure\n    the script purpose, date, and author are written as comments at the\n    top.\n-   Extra: Ensure your working language in RStudio is appropriate (e.g.\n    English for this exercise)\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\n-   Create a folder where all the work in this case study will go. For\n    example, create 'mpox_analysis' on your computer desktop. Create\n    your RStudio project to be based in this folder.\n\n-   We suggest creating the following sub-folders: `scripts` (for your\n    code), `data` (for your data), and `outputs` (for your analytical\n    outputs).\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nCreate a folder (e.g. 'mpox_analysis' on your Desktop) for your work. To\ncreate an Rstudio project in your new folder, click `New Project…` in\nthe top left of your R Studio, then `Existing Directory`, then `Browse`\nto select your new folder. For more information, look at the [R\nprojects](https://epirhandbook.com/new_pages/r_projects.html) section of\nthe Epi R Handbook.\n\nStart a new R script by clicking `New File…` in the top left of your R\nStudio, then `R Script`. Save it immediately in the appropriate place,\ne.g. in a 'scripts' subfolder of your R Project.\n\nAt the top of your new R script, write some essential information like\nyour name, the purpose of the file, and the date.\n\nYour R locale determines the language and regional settings used for\nthings like date formats and translations. If your locale is different\nfrom the language you want for your report (e.g., a French locale vs. an\nEnglish report), you can change it to English by running\n`Sys.setlocale(\"LC_ALL\", \"English\")`. Include this in your script if\nneeded, or skip it if your locale is usually appropriate. This is\nexplained in more detail in the [How-to Guide](pages/instructions.qmd_).\n\n</details>\n\n### 1.2 Install/load packages\n\nNext in your R script, you need to install and load the necessary R\npackages. This ensures that the functions you need are available for\nyour analysis.\n\nYou will need the following packages: `rio` (for importing data),\n`janitor` (for cleaning data), `lubridate` (for cleaning dates), `skimr`\n(for reviewing data), `epikit` (for epi-related tasks), `gtsummary` (for\npresentation-ready tables), `apyramid` (for age-sex pyramids), and\n`tidyverse` (for general data manipulation/science tasks).\n\nAs you start, your trusted colleague nudges you and whispers \"I've heard\nthat a great way to manage your packages is with the `pacman` package\".\n\nOver to you!\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nUse the function `p_load()` from `pacman` for this task. You provide the\nfunction with a list of packages that you want to use. It will take two\nsteps per package: 1) Check if the package is installed on your\ncomputer, and install it if necessary, then 2) Load the package so it\ncan be used during this R session.\n\nIf you don't already have `pacman` installed, you will need to install\nit the \"traditional way\" first, with `install.packages()`.\n\nNote that the order of packages in your p_load function can be\nimportant. If two packages have the same function names (e.g. `select()`\nin the package `MASS` and `select()` in `tidyverse`, which do different\nthings), then R will use the function from the most recently loaded\npackage. To prioritize functions from tidyverse, which are commonly used\nfor data manipulation and visualization, load tidyverse last.\n\n</detail>\n\n```{r, echo=TRUE, eval=TRUE}\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\n```\n\n## Step 2: Download and import the data\n\n### 2.1: Download the data\n\nECDC provides you with two files for your analysis, both updated as of 31st August 2022:\n\n-   A case-level linelist (*\"mpox_linelist.xlsx\"*) with case information\n    from five countries (countries A - E)\n-   An aggregate table (*\"mpox_aggregate_table.csv\"*) for those\n    countries with cumulative case counts per day.\n\nThey provide it to you via AppliedEpi's very useful data repository,\nwhich you can access using the `{appliedepidata}` package. So first you\nneed to download these two files to your own computer, as follows:\n\n1)  Install the `{appliedepidata}` package from GitHub using the\n    `install_github()` function in the `{remotes}` package. Install\n    `{remotes}` if you need to first.\n\n```{r , echo=TRUE, eval=FALSE}\n# Install remotes if you need to (so you can install a package from GitHub)\npacman::p_load(\"remotes\")\n\n# Use the install_github function from remotes to install appliedepidata\nremotes::install_github(\"appliedepi/appliedepidata\")\n```\n\n2)  Save the two datasets into a specific folder using the `save_data()`\n    function from `{appliedepidata}`, by running the code below. The\n    example below saves the data into a 'data' subfolder within the\n    RStudio project. Note that if you do not specify a location within\n    the 'path' argument of the function, a window will pop up asking you\n    to manually select a folder.\n\n```{r , echo=TRUE, eval=FALSE}\n# Save down the two mpox files using the save_data() function from appliedepidata\nappliedepidata::save_data(\"mpox_linelist\",\n                        path = \"data\")\n\nappliedepidata::save_data(\"mpox_aggregate_table\",\n                          path = \"data\")\n```\n\n### 2.2 Import the data\n\nGreat! Thanks ECDC and Applied Epi! Now it's time to import the data\nfrom that folder into RStudio, so you can analyse it.\n\n**Task:** Import the downloaded case-based and aggregated data into your\nR environment. Ideally you want to use one function for both datasets,\ndespite one being a csv and the other an xlsx file.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nUse the `import` function from the `{rio}` package, which can recognize\nand import different file types. It replaces importing functions that\nare specific to the file type, such as `read.csv()` from `{base}` for\n.csv files and `read_excel()` from `{readxl}` to import .xlsx files.\n\nIf you feel you need to know more about importing functions, read the\n[Import and export](https://epirhandbook.com/new_pages/importing.html)\nchapter of the EpiRhandbook.\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\nBelow we use the import function to bring in both files. Note how we are\nassigning the imported data to two objects, one called\n*mpox_linelist_raw*, and one called *mpox_agg_raw*. We add the 'raw'\nsuffix to distinguish this data from the cleaned versions we will make\nlater.\n\n```{r , echo=TRUE, eval=FALSE}\n# Import data  --------------\n\n# Case-based data\nmpox_linelist_raw <- import(\"data/mpox_linelist.xlsx\")\n\n# Aggregated data\nmpox_agg_raw <- import(\"data/mpox_aggregate_table.csv\")\n\n```\n\n```{r, include = FALSE}\n# This code is actually run; the prior chunk is just for show for simplicity\n\npacman::p_load(\"remotes\")\n\nif (!requireNamespace(\"appliedepidata\", quietly = TRUE)) {\n  remotes::install_github(\"appliedepi/appliedepidata\")\n}\n\nappliedepidata::get_data(\"mpox_linelist\")\nmpox_linelist_raw <- mpox_linelist\n\n\nappliedepidata::get_data(\"mpox_aggregate_table\")\nmpox_agg_raw <- mpox_aggregate_table\n\nrm(mpox_linelist, mpox_aggregate_table)\n\n```\n\n</details>\n\n## Step 3: Explore the data\n\nYou need to understand what the data looks like as a first step, to\ninform your analysis.\n\n**Tasks:** Take a look at the different data frames and determine:\n\n-   The number of columns and observations (e.g. their *dimensions*)\n-   The class of their columns and whether it matches its nature (e.g.,\n    are \"dates\" considered \"dates\" by R?)\n-   If the contents of columns are clean and standardized in the mpox\n    linelist (e.g. gender, clinical symptoms, outcome, hiv status and\n    sexual orientation). Do you need to recode any of them?\n-   How unknown or missing data is categorised in these columns. Do\n    these values need to be standardized?\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nAn efficient function for initial data exploring is `skim()` from the\n`{skimr}` package, as it gives you a lot of information on data\nstructure and content, including the classes of columns.\n\nYou can use the function `tabyl()` from `{janitor}`, to get counts and\npercentages of every category in the data column, one by one. These get\nprinted to your RStudio console.\n\nAlso - we recommend just looking at the data itself! A good function for\nthis is `view()`, a baseR function.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nUsing the `skim` commands you can see the rows and columns of each\ndataset, and you can see how most of the columns in *mpox_linelist_raw*\n(including those containing dates) are character classes. (Results not\nshown on this exercise page)\n\n```{r , echo=TRUE, results='hide'}\n# Explore the dimensions of the two data objects \nskim(mpox_linelist_raw)\nskim(mpox_agg_raw)\n```\n\nTake a look at the overall data using `view()`. It will pop up in the\nData Viewer tab and you will get a good sense of how clean the data is\nand what the missingness is like. This preview shows just 5 rows from\nthe linelist data.\n\n```{r , echo=TRUE, results='hide'}\nview(mpox_linelist_raw)\n```\n\n```{r , echo=FALSE, eval = TRUE}\n#head(mpox_linelist_raw) %>% flextable::flextable()\nDT::datatable(mpox_linelist_raw %>% filter(row_number()<6))\n```\n\n\\br\n\nBelow is an example of using the `tabyl()` function from `{janitor},` to\nlook at the distribution of clinical symptoms. You can see 12 cases have\nmissing clinical information and that many cases have a mix of symptoms.\n\n```{r , echo=TRUE}\n\ntabyl(mpox_linelist_raw, HIVStatus)  \n```\n\nYou can explore further columns one by one (results not shown):\n\n```{r , echo=TRUE, results='hide'}\n# Explore the values of different categorical columns in the mpox linelist: with tabyl\ntabyl(mpox_linelist_raw, Gender)\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms)\n\ntabyl(mpox_linelist_raw, Outcome)\n\ntabyl(mpox_linelist_raw, SexualOrientation)\n\n```\n\nYou could add extra arguments to `tabyl()` to customize the tables, such\nas adding totals and changing the proportions to percentages so they are\neasier to read. See the table on clinical symptoms below. But remember -\nthis is just an initial look so don't go too crazy.\n\n```{r , echo=TRUE}\n\ntabyl(mpox_linelist_raw, ClinicalSymptoms) %>%    # Tabulate symptoms \n  adorn_totals() %>%                              # Add totals to bottom of table\n  adorn_pct_formatting(digits = 2)                # Format percentages\n```\n\nFinally, as an alternative approach to `tabyl()`, you could use\n`tbl_summary()` from the `{gtsummary}` package. We will describe this\nlater.\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"2000\", \"13\", answer = \"3\", \"101\"\n)\n\ncat(\"How many columns does the aggregated data have?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Date\", answer = \"Character\", \"Numeric\", \"Factor\"\n)\n\n\ncat(\"What is the class of the column DateOfNotification in the mpox linelist?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"1168\",\n  \"722\",\n  \"900\",\n  \"446\"\n)\n\n\ncat(\"For how many cases is the HIV status Unknown or missing?\", longmcq(opts))\n\n```\n:::\n:::\n\n## Step 4: Clean the data\n\n### 4.1: Clean the case-based data\n\n**Cleaning column names and values**\n\nGreat! From your exploration, you know that you can describe the\ngeographic distribution of cases by country, trends over time, their\ndemographic details, their sexual orientation and hiv status, plus their\noutcome and clinical symptoms.\n\nYou plan to make some tables and graphs to describe those variables.\n\nBUT! You may noticed that there are a few things that you need to clean\nup before really diving into the analysis.\n\nFor example:\n\n-   Column names have capital letters. This isn't outright a problem,\n    but can lead to mistakes since R treats ColumnName and Columnname as\n    different.\n-   Date columns are recognized as character classes, not dates, which\n    would cause issues like incorrect ordering (alphabetical) in\n    epicurves.\n-   Some columns have values that are unclear or unsuitable for\n    presentation. For example gender is categorized with \"F\", \"M\", \"O\"\n    and \"UNK\". The column Outcome is \"A\" and \"UNK\".\n-   Missing data is inconsistently handled, for instance with both \"UNK\"\n    and NA in the HIV status column. R thinks \"UNK\" is a valid value,\n    which it treats differently to true missing data (indicated by NA)\n\n**Tasks**:\n\n-   Create a clean version of your case-based data making all cleaning\n    changes in a single piping command\n-   Change all column names to lower case.\n-   Convert all date columns to class \"Date\".\n-   Recode \"Gender\" categories into: \"Female\", \"Male\", \"Other\", and\n    \"Unknown\"\n-   Recode \"Outcome\" categories into: \"Alive\" and \"Unknown\"\n-   Recode HIV status into: \"Positive\", \"Negative\" and \"Unknown\"\n-   Recode Sexual orientation into: \"Bisexual\", \"Heterosexual\",\n    \"MSM/homo or bisexual male\" and \"Unknown\".\n-   Check that all changes have been made correctly\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo convert all column names to lower case at once rather than renaming\neach column, use the function `clean_names()` from the `{janitor}`\npackage.\n\nUse `{lubridate}` functions to transform date columns into \"Date\" class.\nYou can do this one by one, or you could do all at the same time using\nthe `across()` function from `{dplyr}.` If you feel you need to know\nmore about transforming dates read the chapter [Working with\nDates](https://epirhandbook.com/en/new_pages/dates.html) from the\nEpiRhandbook. If you are not sure how to use the across() function, you\ncan also read the section on [Transform multiple\ncolumns](https://epirhandbook.com/en/new_pages/cleaning.html#clean_across).\n\nThere are different functions that we can use to recode values. We\npropose three: The function `recode()` from `{dplyr}`, the function\n`ifelse()` from `{base}` and the function `case_when()` from `{dplyr}`.\nIf you want to know more about these functions, look that the section on\n[Re-code\nvalues](https://epirhandbook.com/en/new_pages/cleaning.html#re-code-values)\nfrom the EpiRhandbook.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nHere we clean the data using a 'chain' of commands connected by pipes\n(%\\>%), which is the grammar of the functions in the {Tidyverse}. The\noutput is assigned to a new object called mpox_linelist to differentiate\nit from the raw data. It can be helpful to have both the cleaned and raw\ndata available in the environment to compare to the original data if\nneeded.\n\nSee the series of functions and the explanation in the comments.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Create a new object called mpox_linelist which is the clean version of the raw data\nmpox_linelist <- mpox_linelist_raw %>% \n  \n  # standardises names and puts all into lower case \n  clean_names() %>% \n  \n  #transform ONE column into date (note the column names are lower case now)\n  mutate(date_of_notification = ymd(date_of_notification)) %>%  \n\n  #transforms ALL columns starting with \"date\" into dates\n  mutate(across(starts_with(\"date\"), \n                .fns = ~ ymd(.x))) %>%  \n  \n\n  # Recode the gender values to be more obvious  \n  mutate(gender = recode(gender,\n                         \"F\" = \"Female\",\n                         \"M\" = \"Male\",\n                         \"O\" = \"Other\",\n                         \"UNK\" = \"Unknown\")) %>%\n  \n  #transforms UNK to Unknown across all character columns \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x == \"UNK\", \"Unknown\", .x)))  %>% \n  \n  #recode with ifelse to change only one or two categories based on a rule. \n  mutate(outcome = ifelse(outcome == \"A\", \"Alive\", outcome)) %>%   \n  \n  #recode with case_when for more complex recoding \n  mutate(hiv_status = case_when(hiv_status == \"NEG\" ~ \"Negative\",    \n                                hiv_status == \"POS\" ~ \"Positive\",\n                                TRUE                ~ \"Unknown\")) %>% \n  \n  mutate(sexual_orientation = case_when(sexual_orientation == \"BISEXUAL\" ~ \"Bisexual\",\n                                        sexual_orientation == \"HETERO\" ~ \"Heterosexual\",\n                                        sexual_orientation == \"MSM\" ~ \"MSM/homo or bisexual male\",\n                                        TRUE                        ~  \"Unknown\")) \n```\n\nYou can then review your data by tabulating across all the different\ncolumns you have cleaned. See the preview of the HIV table below - it\nlooks tidier now with more understandable categories, and all missing\ndata is classified as 'Unknown'.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Check that all changes have been made correctly\n\nskim(mpox_linelist)\n\ntabyl(mpox_linelist, gender)\n\ntabyl(mpox_linelist, clinical_symptoms)\n\ntabyl(mpox_linelist, outcome)\n\ntabyl(mpox_linelist, hiv_status)\n\ntabyl(mpox_linelist, sexual_orientation)\n\n\n```\n\n```{r , echo=FALSE, eval= TRUE}\n\ntabyl(mpox_linelist, hiv_status)\n\n```\n\n**IMPORTANT**: If 'unknown' and NA had meaningful differences, combining\nthem wouldn't be appropriate (e.g., 'unknown' means the case was asked\nbut didn't want to respond, while NA means they weren't asked). Here, we\nassume no meaningful difference and combine them for simplicity.\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Yes\",\n  answer = \"Depends on the meaning of those values\",\n  \"No - never do this\"\n)\n\n\ncat(\"Is it always appropriate to combine different types of unknown data? (e.g. missing, unknown, did not respond, NA)\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"36\",\n  answer = \"1960\",\n  \"65\",\n  \"1523\"\n)\n\n\ncat(\"How many male cases do we have in the data frame?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"1405\",\n  \"None\",\n  \"595\"\n)\n\ncat(\"How many cases have 'alive' as an outcome?\", longmcq(opts))\n\n```\n:::\n:::\n\n**Creating new columns for analysis**\n\nFabulous, you're getting there. Now, because you plan to create weekly\nepicurves and an age-sex pyramid, you need to ensure your data has the\nright columns for this.\n\n***Tasks:***\n\n-   Use the column \"DateOfNotification\" to create a column called\n    \"week_date\" which has the week of notification, starting on Mondays.\n\n-   Create a column called \"age_group\" with ten year age groups and the\n    oldest group being 70+\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo create the age groups, explore the function called `age_categories()`\nfrom the `{epikit}` package.\n\nOne simple way to create the \"week_date\" column would be to use the\nfunction `floor_date()` from `{lubridate}`. Take a look at the\ndocumentation to understand how it works and how to make Monday the\nstarting day of the week.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nAdd the creation of these columns to your cleaning code:\n\n```{r , echo=TRUE, results = 'hide'}\n\nmpox_linelist <- mpox_linelist %>% \n  # create week column with Monday start \n  mutate(week_date = floor_date(date_of_notification, unit = \"week\", week_start = \"Monday\")) %>%\n  \n  # Use the age_categories function to create age categories\n  mutate(age_group = age_categories(age, lower = 0, #set up the lower age\n                                    upper = 70, #set up the upper age\n                                    by = 10)) #set up the age breaks\n```\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"2022-04-11\",\n  \"2022-07-25\",\n  \"2022-02-28\",\n  \"2022-05-09\"\n)\n\n\ncat(\"Which week has the largest number of cases?\", longmcq(opts))\n\n```\n:::\n:::\n\n### 4.2: Clean the aggregated data\n\nIn a similar way, clean the aggregated data by:\n\n-   Standardising names to lower case\n-   Ensuring that date of reporting is of class \"Date\"\n-   Creating a column called \"week_date\" with the week of reporting\n    starting on Monday\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nWe can first check the class of the DateRep column, which shows us that\nit was already recognized as a date column on import.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Check class of date of reporting column\nclass(mpox_agg_raw$DateRep)\n\n```\n\nThen create a new object for the clean aggregate data, and write your\ncleaning coded connected with pipes.\n\n```{r , echo=TRUE, results = 'hide'}\n\n# Create a new object called mpox_agg which is the clean version of the raw data, applying the cleaning functions\n\nmpox_agg <- mpox_agg_raw %>% \n  \n  # standardises names and puts all into lower case\n  clean_names() %>%  \n  \n  # create week column with Monday start\n  mutate(week_date = floor_date(date_rep, \n                              unit = \"week\",\n                              week_start = \"Monday\")) \n\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"Country A\",\n  \"Country B\",\n  \"Country C\",\n  \"Country D\",\n  \"Country E\"\n)\n\n\ncat(\"Take a look at the aggreate data. Which country reported the largest cumulative number of cases during the week 2022-04-11?\", longmcq(opts))\n\n```\n:::\n:::\n\n## Step 5: Describe outbreak by person, place, and time\n\n### 5.1: Describe total case counts by country\n\n**Task**: Using the mpox case linelist, create a table showing the total\nnumber of cases by country. This time, make the table more\npublication-friendly.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nYou could use `tabyl()` like before, but an easy way to produce\npublication-ready tables is with the function tbl_summary() from\n{gtsummary} package. This formats the table for you. It will print to\nyour Viewer rather than the console.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nCreate a new object with the table output - as this is a key output that you can then integrate into a document later rather than just viewing for now. \n\n```{r , echo=TRUE}\n# Create an object with the table\ncb_country_table <- mpox_linelist %>%\n\n  #select the column that we want to use in the table\n  select(country) %>% \n  \n  # create the table. No need to specify columns; it will tabulate all available columns (selected above)\n  tbl_summary() \n\n# Print the table\ncb_country_table\n\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Country C\",\n  \"Country D\",\n  \"Country B\",\n  \"Country E\",\n  answer = \"Country A\"\n)\n\n\ncat(\"What country has the largest percentage of cases?\", longmcq(opts))\n\n```\n:::\n:::\n\n### 5.2: Describe cases over time\n\nOkay so Country A has the most cases in total based on most recent data. But how does that change look over time? \n\n**Tasks**:\n\n-   Using the mpox case linelist, create an epicurve by week of\n    notification\n-   Using the mpox case linelist, create an epicurve by week of\n    notification to enable a comparison of trends by country.\n-   Using the mpox case linelist, create a heat plot with the number of\n    cases by country and week of notification.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo do the epicurve, you can use ggplot() and geom_histogram(), which\nwill automatically aggregate your data. If you are unsure on how\nggplot() works, read the EpiRhandbook chapter on [Epidemic\ncurves](https://epirhandbook.com/en/new_pages/epicurves.html).\n\nAn alternative approach is to first aggregate the number of cases by\nweek of notification. You can do this using the functions group_by() and\nsummarise() from {dplyr}. If you are unsure on how to do this, review\nthe [Grouping data](https://epirhandbook.com/en/new_pages/grouping.html)\nchapter of the EpiRhandbook.\n\nOnce you have an object with aggregated cases by week of notification,\ncreate the epicurve using ggplot(). If want a dynamic colour inside the\nbins, you need to assign the fill to the column you want to use\n(country) and place it inside the aesthetics\n\nHeat plots can be useful to understand how the epidemic evolved in\ndifferent countries. You will need to aggregate your data by country and\nweek of notification. You can do this using the functions group_by() and\nsummarise() from {dplyr}. If you are unsure on how to do this, review\nthe Grouping data chapter of the EpiRhandbook. Then, use the geom\ngeom_tile() to create a heat plot. If you're unsure on how to do this,\nread the EpiRhanbook section on [Heat\nPlots](https://epirhandbook.com/en/new_pages/heatmaps.html)\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nThe code below creates an epicurve using ggplot() and the geom_bar() function and applies further formatting. You can plug in the column you created during the data cleaning step for the x axis. With geom_bar(), you do not need to specify the y axis as the function counts the number of rows per x axis value. \n\n```{r , echo=TRUE}\n\n# Open up the plot production with ggplot() function, specifying object and columns\nepicurve_mpox <- ggplot(data = mpox_linelist,          \n                        aes(x = week_date)) +    \n  \n  geom_bar(fill=\"darkgreen\",                     #colour inside the bins\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  labs(title=\"Mpox cases reported in 2022 in Countries A, B, C, D, and E\",\n       subtitle = \"Date as of August 31st 2022\") +  #add a title\n  \n  theme_bw() +                                  #assign a predefined theme\n  \n  theme(axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n           \n# Print the epicurve\nepicurve_mpox\n\n```\n\nTo examine how the outbreak spread by country, add `facet_wrap()` to your ggplot code. This splits the graph into multiple smaller ones. Below, we show how we can even simply add the function to the national epicurve object. Alternatively, you could add fill = country to the aes() in the epicurve code to keep a single curve but color each bar by country. However, we don't recommend this for comparing trends, as stacked bars make it harder to see individual patterns.\n\n```{r , echo=TRUE}\nepicurve_epox_country <- epicurve_mpox + \n \n   # Facet wrap to make mini-plots, specifying that you want two columns of plots. \n  facet_wrap(.~country,\n             ncol = 1) \n\n# Print the epicurve\nepicurve_epox_country\n```\n\n```{r , echo=TRUE}\n\n# Heatmap of cases by country over time\n\nhp_epox <- mpox_linelist %>% #we first group the data by country and week of notification\n  \n  group_by(country, week_date) %>% \n  \n  summarise(n_cases = n(), .groups = \"drop\") %>% \n\n  #now we can use the pipe to directly plot the resulting data from the grouping\n  \n  ggplot(aes(x = week_date,\n           y = country,           #we want the countries to be in the y axis\n           fill = n_cases)) +     #the colour of the tiles should depend on the number of cases\n  \n  geom_tile(colour = \"black\") +   #this is the outline colour of each tile\n  \n  scale_fill_gradient(            #here we define the colours we want to use in the gradient\n    low = \"lightgreen\",\n    high = \"red\") +\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n  \n  labs(\n    title= \"Mpox cases by country and week of notification\",\n    fill = \"Number of cases\"                               \n  ) +\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\",             #legend position to the bottom\n        axis.text = element_text(size=9),       #define the font size of the axis\n        axis.title = element_blank(),           #remove the titles of the x and y \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n    \nhp_epox \n\n```\n\n</br>\n\n</details>\n\n### 5.3: Describe demographic characteristics\n\nNow that we have created some outputs by time and place, we should focus\non the \"person\" element. The two most important demographic\ncharacteristics are usually age and gender. In the case we are seeing,\nwe may also want to explore the sexual orientation of cases.\n\n**Task**:\n\n-   Explore the number of cases by age group and gender.\n-   Create a table with number and percentages of cases by sexual\n    orientation\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nThe easiest way to explore both columns (age_group and gender) would be\nto use the tabyl() function from {janitor}. Then, to create the age\npyramid explore the function age_pyramid() from the {apyramid} package.\nYou can find more about this function in the EpiRhandbook chapter\n[Demographic pyramids and\nLikert-scales](https://epirhandbook.com/en/new_pages/age_pyramid.html)\n\nTo create the table by sexual orientation, consider using the function\ntbl_summary() from {gtsummary}\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Explore gender and age group columns\ntabyl(mpox_linelist, gender)\ntabyl(mpox_linelist, age_group)\n\n# Table with sexual orientation \n\ntab_sor <- mpox_linelist %>% \n  \n  select(sexual_orientation) %>% \n  \n  tbl_summary(label = list(sexual_orientation ~ \"Sexual Orientation\")) \n\ntab_sor\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Females 60-69\",\n  \"Males 40-49\",\n  \"Females 10-19\",\n  answer = \"Males 30-39\"\n)\n\n\ncat(\"Which demographic group is more affected by Mpox?\", longmcq(opts))\n\n```\n:::\n:::\n\n### 5.4: Describe clinical characteristics\n\nNow, let's summarise the main clinical information that we have in our\ncase-based data frame.\n\n**Tasks**:\n\n-   Create a bar plot with the proportion of each type clinical symptoms\n\n-   Create a table with the number and percentage of cases by outcome\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo create bar plots we can use geom_bar() or geom_col() depending on the\nnature of our data. If we aggregate first, we can use geom_col(),\notherwise we should use geom_bar(). There is a function of the\n{gtsummary} package called add_p() which enables you to easy calculate a\nstatistical test across groups. If you want to know more read the\nsection on [gtsummary\npackage](https://epirhandbook.com/en/new_pages/stat_tests.html#stats_gt)\nof the EpiRhandbook.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Bar plot with clinical symptoms\n\nbar_clinical <- mpox_linelist %>% \n  \n  drop_na(clinical_symptoms) %>%   # we remove those with missing clinical symptoms\n  \n  group_by(clinical_symptoms) %>% \n  \n  summarise(n_cases = n(), .groups = \"drop\") %>%\n  \n  mutate(prop=(n_cases/sum(n_cases))*100) %>%  # we create a column with proportions\n  \n  ggplot(aes(y = reorder(clinical_symptoms, prop), x = prop)) +  # the reorder function ensures that categories are ordered by proportion in the graph\n  \n  geom_col(fill = \"darkgreen\") + \n  \n  labs(\n    title= \"Frequency of clinical symptoms in Mpox cases\",\n    y = \"\",\n    x = \"Number of cases\"\n  ) +\n  \n  theme_bw() +\n  \n  theme(axis.text = element_text(size=9))       #define the font size of the axis\n\nbar_clinical  \n\n\n# Table with number and percentage of cases by outcome\n\ntab_outcome <- mpox_linelist %>% \n  \n  select(outcome) %>% \n  \n  tbl_summary(label = list(outcome = \"Reported outcome\")) # with the argument \"label\" we can change how the column name is displayed\n\ntab_outcome\n\n\n```\n\n</br>\n\n</details>\n\n## **Step 6: Reviewing data quality**\n\nIt is important to understand how timely, complete, and valid your data\nis, if it will be the basis of understanding an outbreak and making\ndecisions. For example - you will need to be mindful of reporting delays\nwhen interpreting epicurves, and be aware of how complete different\nsources of data are compared to each other.\n\n### 6.1: Delay between date of onset, diagnosis and notification\n\n**Tasks**\n\n-   Calculate median time from symptom onset to diagnosis and from\n    diagnosis to notification, both overall and by country\n\n-   Assess visually the number of cases by calendar period and type of\n    date (onset, diagnosis and notification)\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo plot together the different dates you may need to transform your data\nfrom \"wide\" to \"long\" form. What we call \"pivoting\" in R. The objective\nis to have a column with the different date categories (onset, diagnosis\nand notification) and another column with their date value. If you are\nunsure on how to do this, have a look at the [Pivoting\ndata](https://epirhandbook.com/en/new_pages/pivoting.html) chapter of\nthe EpiRhandbook. Then, try to plot with the daily values, but if that's\nnot easy to interpret you may want to aggregate cases by week.\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Yes\",\n  answer = \"No\"\n)\n\n\ncat(\"Is there a difference in the delay from diagnosis to notification by country?\", longmcq(opts))\n\n```\n:::\n:::\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Estimate delay between onset and diagnosis, and between diagnosis and notification\n\ndelay_db <- mpox_linelist %>% \n  \n  mutate(delay_diag = as.numeric(date_of_diagnosis - date_of_onset)) %>%   #we create variables with difference between dates, we transform them in numeric to be able to then calculate measures of central tendency\n  \n  mutate(delay_not = as.numeric(date_of_notification - date_of_diagnosis))\n\nsummary(delay_db$delay_diag) #the summary will give us measures of central tendency and dispersion\nsummary(delay_db$delay_not)\n\n\ndelay_country <- delay_db %>% #here, we group by country and summarise the median to compare across countries\n  \n  group_by(country) %>% \n  \n  summarise(median_delay_diag = median(delay_diag, na.rm = T),\n            median_delay_not = median(delay_not, na.rm = T))\n\ndelay_country\n\n# Line graph with the different dates \n\ndates_longer <- mpox_linelist %>% # use the variables of the dates and make a longer dataset. In the pivot_longer() command we select the columns which we want to expand in long format and transform the dataset\n   \n  pivot_longer(\n    \n    cols=starts_with(\"date_\"),         # all columns starting with \"date_\" will be taken \n\n    names_to = \"indicator\",            #the names of the columns will be placed in a single column called \"indicator\"\n\n    values_to = \"date\")                # the values (which are dates in this case) will be placed in a column called \"date\"\n  \n\ndates_longer_week <- dates_longer  %>% \n\n  mutate(week_date = floor_date(date, unit = \"week\", week_start = \"Monday\")) %>%  # we create a week column\n    \n  group_by(indicator, week_date) %>% \n    \n  summarise(n=n(), .groups=\"drop\") %>%   # we group and summarise to have the number of cases by date type and week\n    \n  drop_na(week_date)                     # we drop the cases with no data on dates\n\n\n\n\nplot_date_delay <-   ggplot(data = dates_longer_week,\n                            aes(x = week_date, \n                                y = n, \n                                color=indicator)) +\n  \n  geom_line(linewidth = 1.5) +\n  \n  scale_x_date(breaks = \"2 weeks\")+\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\", \n        axis.text = element_text(size=9),\n        axis.title = element_blank(),\n        axis.text.x = element_text(angle=90),\n        legend.title = element_blank()) +\n  labs(title=\"Mpox cases reported in 2022, by date of onset, diagnosis and notification.\")\n\nplot_date_delay\n```\n\n</br>\n\n</details>\n\n### 6.2: Compare case-based and aggregated data\n\n**Task**: Create a plot comparing the number of cases reported to\nthrough the case-based flow and through the aggregated flow in each\ncountry.\n\nNOTE: Take into consideration that the column on cases in the aggregated\ndata frame reports the *cumulative* number of cases.\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"A\",\n  \"B\",\n  answer = \"C\",\n  \"D\",\n  \"E\"\n)\n\n\ncat(\"Which country is not reporting aggregated data?\", longmcq(opts))\n\n```\n:::\n:::\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Create a data frame with the overall number of cases reported through the aggregated flux\n\nmpox_agg_country <- mpox_agg %>% \n  \n  group_by(country) %>% \n  \n  filter(date_rep == max(date_rep)) %>% # as we have cumulative data, we keep only the last week (after grouping by country)\n  \n  select(-date_rep, -week_date) %>%     # remove unnecessary columns\n\n  mutate(source = \"aggregated\")         # we create this column to distinguish the numbers from the case-based flux\n\n\n# Create a data frame with the overall number of cases reported through the case-based flux\n\nmpox_linelist_country <- mpox_linelist %>%\n  \n  group_by(country) %>% \n  \n  summarise(cases = n(), .groups = \"drop\") %>% \n  \n  mutate(source = \"case_based\")       # we create this column to distinguish the numbers from the\n  \n\n# We append both data frames. Remember this is different from merging\n\ntotal_data <- bind_rows(mpox_linelist_country, mpox_agg_country)\n\n\n# We create a graph to compare the cases reported in both sources\n\ngraph_comp <- ggplot(data = total_data,\n                     aes(x = source, \n                         y = cases, \n                         fill = source)) +\n  \n  geom_col(position = \"dodge\") +            #position dodge puts bars one next to each other, instead of \"stacked\"\n  \n  facet_wrap(~ country, scales = \"free_y\") +  # this command gives us one graph per country. The argument scales is used to allow each y axis scales to adjust to the data\n\n  scale_fill_viridis_d(\n    labels = c(\"Aggregated\", \"Case-based\")  # this function changes the colours, but with the argument \"labels\" we can change the text of each fill.\n     ) +\n  \n  \n  labs(\n    title = \"Number of cases of Mpox reported in 2022 according to source of data\",\n    fill = \"Source\",\n    x = \"\",\n    y = \"Total number of cases\"\n  ) + \n  \n  theme_bw() +\n  \n  theme(axis.text.x = element_blank(),      # we remove the text of the x axis because it is already present in the legend\n        axis.ticks.x = element_blank())     # we also remove the ticks for aesthetic purposes\n\ngraph_comp\n```\n\n</br>\n\n</details>\n\n## Final thoughts\n\nWell done! Through your analysis you now understand the magnitude of the\noutbreak so far, where and when it spread, which demographic groups are\nmost affected, and how the disease actually manifests in terms of\nsymptoms and severity. ECDC is very happy with your work.\n\nBy coding this up in R, this analysis should be reproducible, meaning\nyou can quickly update it with new data and keep monitoring the\noutbreak. To further practise reproducible reports, \\[link to\nRMarkdown\\].\n\n## Case study information\n\n**Authorship**\n\nOriginal authors: Xanthi Andrianou, Gianfranco Spiteri (ECDC EI Group)\\\nData source: Fictional data provided by ECDC EI Group for training\npurposes\\\n\n| Date         | Changes made                   | Version | Author                 |\n|------------------|:------------------|-----------------:|------------------|\n| October 2021 | First draft                    |       1 | Xanthi Andrianou       |\n| June 2024    | Adapted to case study template |     1.1 | Alberto Mateo Urdiales |\n\n**Terms of Use**\n\n<!-- Describe the licencing and other appropriate information about Terms of use or any other disclaimer -->\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":"html_document","warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":false,"css":["webex.css"],"include-after-body":["webex.js"],"output-file":"r_practical.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","babelquarto":{"languagecodes":[{"name":"es","text":"Español"},{"name":"en","text":"English"}],"mainlanguage":"en","languages":["es"],"languagelinks":"sidebar"},"title-es":"Estudios de casos de AppliedEpi","theme":{"light":"sandstone","dark":["darkly","../theme-dark.scss"]},"toc-location":"left","number-depth":0,"grid":{"body-width":"1000px","margin-width":"50px"},"editor_options":{"chunk_output_type":"console"},"editor":{"markdown":{"wrap":72}}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}