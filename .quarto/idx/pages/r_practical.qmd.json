{"title":"Descriptive analysis of the 2022 Mpox outbreak in Europe","markdown":{"yaml":{"output":"html_document","editor_options":{"chunk_output_type":"console"},"execute":{"warning":false,"error":false},"format":{"html":{"css":"webex.css","include-after-body":"webex.js"}},"editor":{"markdown":{"wrap":72}}},"headingText":"Descriptive analysis of the 2022 Mpox outbreak in Europe","headingAttr":{"id":"sec-rpractical","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Tool**: R \\| **Technical complexity**: Basic \\| **Methodological\ncomplexity**: Basic\\\n**Source:** ECDC EI Group (simulated data)\\\n**Prior knowledge required:** [R\nbasics](https://epirhandbook.com/en/new_pages/basics.html) (Using\nRstudio; R packages, functions and arguments)\n:::\n\nFor instructions on how to use our case studies, [see here.] We welcome feedback and suggestions via [contact\\@appliedepi.org](mailto:contact@appliedepi.org). Discuss the case study at [community].\n\n\\pagebreak\n\n## Objectives\n\n1.  Explore different types of files and how they can be imported in R.\n2.  Perform basic data cleaning, e.g., changing the variable type, recode variables, aggregate and filter.\n3.  Perform a basic descriptive analysis using tables and graphs\n\n## Scenario\n\nIt is May 2022 and Mpox has just been reported for the first time across 5 countries in Europe. You have been requested to provide a basic descriptive analysis to the European Centre for Disease Prevention and Control (ECDC).\n\nYou are given access to:\n\n-   Linelists with cases collated by the five countries\n-   Datasets with aggregate cases from open sources\n\nLet's go!\n\n## Step 1. Set up\n\n### 1.1 Get started in R Studio\n\nYou want to create a reproducible workflow, so you need a place to save your code so you can run it again if you need to. You want all your files easily organised so you don't get lost later on. \n\n**Tasks:**\n\n-   Ensure your working language in RStudio is English\n-   Set up a R Studio project\n-   Create an R script, or an Rmarkdown file if you prefer. Make sure\n    the script purpose, date, and author are written as comments at the\n    top.\n-   Make sure your folders/subfolders are well-organised\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\n- Download folder named r_practical and extract contents in the local laptop\n\n- Create an Rstudio project in the folder r_practical. If you are unsure on how to do that, read the EpiRhandbook on R projects\n\n- Inside \"r_practical\": Subfolder \"data\" contains the raw data you will use in this case study. You should see six different files, three called E_pox_aggregated_data and three E_pox_case_based_data. Each has a specific file type.\n\n- Inside \"r_practical\": Subfolder \"scripts\" should be used to save any scripts related to the analysis. Inside scripts there is another subfolder called \"backup\" where you can find a solution R script for each step in case you are stuck at any point or if you want to compare your own script with the solution one.\n\n- Inside \"r_practical\": Subfolder \"outputs\" can be used to store any outputs (tables, graphs, documents) that are the result of the analysis.\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r, include=FALSE}\n# To see your language locale \nSys.getlocale() \n\n# To change it into English \nSys.setlocale(\"LC_ALL\", \"English\")  \n```\n\n</details>\n\n### 1.2 Install/load packages\n\nThe first part of your code is to install and load packages. You've heard that a great way to do this is with the {pacman} package, so that's where you start.\n\nYou know that you will need to use rio (for importing data), janitor (for cleaning data), lubridate (for cleaning dates), skimr (for reviewing data), epikit, gtsummary, apyramid, and tidyverse.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nThe function p_load() from {pacman} will check each listed package. If not already installed it will install install them. Then, it will load it for use in your R session.\n\nNote you may end up using a long list of packages. Unfortunately different\npackages have functions with the same name. For example, the package {dplyr} (already installed with {tidyverse}) has a function called select() which we frequently use to subset columns of a data frame. But\nother packages such as {MASS} do also have a function called select(). This could create headaches if you want to subset columns using dplyr's select() but R thinks you're calling MASS's select() (we call this masking - dplyr's select() is masked by MASS's select()). Given that you\nare more likely to use functions from {tidyverse}, ensure that this is\nthe last package in your p_load() list so that functions from {tidyverse} (including {dplyr} functions) will always \"prevail\".\n\n```{r, echo=TRUE, eval=TRUE}\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\n```\n\n## Step 2: Import the data\n\nECDC provides you with six files for your analysis: Three case-based linelists with case information from X, X, X, and the three aggregate datasets summarising total case counts. They are available as three different types of files: csv, json and excel, and are located inside “data/raw”.\n\n**Task:** Import the three case-based data frames and the three aggregated data frames into your R environment \n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nThis function will recognise the file type and import it accordingly. It replaces the use of file-type specific functions, such as read.csv() from {base} for .csv files, JSON() function from {jsonlite} to import .json files, and read_excel() from {readxl} to import .xlsx files.\n\nIf you feel you need to know more about importing functions, read the Import and export chapter of the EpiRhandbook.\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n```{r , echo=TRUE, eval=FALSE}\n# Importing ------------------------------------------------------\n# Case-based data\ncb_data_raw_csv <- import(\"data/E_pox_case_based_data.csv\")\ncb_data_raw_json <- import(\"data/E_pox_case_based_data.json\")\ncb_data_raw_xlsx <- import(\"data/E_pox_case_based_data.xlsx\")\n\n# Aggregated data\nagg_data_raw_csv <- import(\"data/E_pox_aggregated_data.csv\")\nagg_data_raw_json <- import(\"data/E_pox_aggregated_data.json\")\nagg_data_raw_xlsx <- import(\"data/E_pox_aggregated_data.xlsx\")\n\n```\n\n```{r , include = FALSE}\ncb_data_raw_csv <- import(\"../case_studies_to_translate/ENG/r_practical/data/E_pox_case_based_data.csv\")\ncb_data_raw_json <- import(\"../case_studies_to_translate/ENG/r_practical/data/E_pox_case_based_data.json\")\ncb_data_raw_xlsx <- import(\"../case_studies_to_translate/ENG/r_practical/data/E_pox_case_based_data.xlsx\")\n\nagg_data_raw_csv <- import(\"../case_studies_to_translate/ENG/r_practical/data/E_pox_aggregated_data.csv\")\nagg_data_raw_json <- import(\"../case_studies_to_translate/ENG/r_practical/data/E_pox_aggregated_data.json\")\nagg_data_raw_xlsx <- import(\"../case_studies_to_translate/ENG/r_practical/data/E_pox_aggregated_data.xlsx\")\n```\n</details>\n\n## Step 3: Explore the data\n\nYou need to understand what the data looks like as a first step, to inform your analysis. \n\nTasks: Take a look at the different data frames and try to find out:\n\n-   The number of columns and observations\n\n-   The class of their columns and whether it matches its nature (e.g., are \"dates\" considered \"dates\" by R?)\n\n-   Look at the different categories of the columns about gender, clinical symptoms, outcome, hiv status and sexual orientation existing in the case-based data. Do you need to recode any of them?\n\n-   How is unknown or missing data being categorised in these columns? Should you standardise this category?\n\n-   If case-based and aggregated data from file types (.csv, .json and .xlsx) are exactly the same, remove the .json and .xlsx data frames from your environment.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nAn efficient way to explore data is to use the function skim() from the {skimr} package, as it gives you all the information needed with only\none command. Of course, there are several alternatives. To know the different categories in a column, you can use the function tabyl() from {janitor}, which will give you counts and percentages of every category in the data column.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE, results = 'hide'}\n# Explore the different case-based data frames\n\nskim(cb_data_raw_csv)\nskim(cb_data_raw_json)\nskim(cb_data_raw_xlsx)\n\n# Explore the different categories of gender and clinical columns in one of the cb data frames\ntabyl(cb_data_raw_csv, Gender)\n\ntabyl(cb_data_raw_csv, ClinicalSymptoms)\n\ntabyl(cb_data_raw_csv, Outcome)\n\ntabyl(cb_data_raw_csv, HIVStatus)\n\ntabyl(cb_data_raw_csv, SexualOrientation)\n\n# Explore the different aggregated data frames\n\nskim(agg_data_raw_csv)\nskim(agg_data_raw_json)\nskim(agg_data_raw_xlsx)\n\n# Remove json and xlsx files as they are exactly the same as the csv ones. Within rm() we ask for the objects containing the pattern \"json\" or \"xlsx\" to be removed from the environment\nrm(list = ls(pattern = \"json|xlsx\"))\n\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"2000\",\n  \"13\",\n  answer = \"3\",\n  \"101\"\n)\n\n\ncat(\"How many columns does the aggregated data frame have?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Date\",\n  answer = \"Character\",\n  \"Numeric\",\n  \"Factor\"\n)\n\n\ncat(\"What is the class of the column DateOfNotification in the case-based data?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"1168\",\n  \"722\",\n  \"900\",\n  \"446\"\n)\n\n\ncat(\"For how many cases is the HIV status Unknown or missing?\", longmcq(opts))\n\n```\n:::\n:::\n\n## Step 4: Clean the data\n\n### 4.1: Clean the case-based data\n\nWhen exploring the case-based data, you may have noticed that there are\na few things that we need to take care of before we can start doing further analysis. Firstly, names contain a mixture of upper and lower case letters. Whilst this isn't in itself a problem, R is case-sensitive, so having all names in lower case may make our life easier. Also, date columns are not consider \"Dates\" by R, but instead they are being consider as \"Character\", which means they are being considered as nominal data. This would give us problems when plotting by Dates. Another issue is that some columns have categories that may not be intuitive for all. For example, Gender is categorised with \"F\", \"M\", \"O\" and \"UNK\". The column Outcome as \"A\" and \"UNK\". We should give them more appropriate categories. Finally, it is important that missing data is considered as \"missing\" in R. That means that R treats it as \"NA\". In\nthe column clinical symptoms, for example, missing data is an empty cell, not \"NA\". R is considering this as another nominal category instead of missing, and will consider it this way in any analysis or\noutput you produce.\n\n**Tasks**:\n\n-   Create a clean version of your case-based data making all cleaning changes in a single piping command\n-   Change all column names to lower case.\n-   Convert all date columns to class \"Date\".\n-   Use the column \"DateOfNotification\" to create a column called \"week_date\" which has the week of notification, starting on Mondays.\n-   Transform all empty cells into \"NA\"\n-   Recode \"Gender\" categories into: \"Female\", \"Male\", \"Other\" and \"Unknown\"\n-   Recode \"Outcome\" categories into: \"Alive\" and \"Unknown\"\n-   Recode HIV status into: \"Positive\", \"Negative\" and \"Unknown/Missing\"\n-   Recode Sexual orientation into: \"Bisexual\", \"Heterosexual\", \"MSM/homo or bisexual male\" and \"Unknown/missing\".\n-   Create a column called \"age_group\" with ten year age groups and the oldest group being 70+\n-   Check that all changes have been made correctly\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo convert all names to lower case, rather than renaming each column you may use the function clean_names() from the {janitor} package, which will do it automatically for all columns. Use lubridate functions to\ntransform date columns into \"Date\" class, you can do this one by one, or you could do all at the same time using the across() function from {dplyr}. If you feel you need to know more about transforming dates read\nthe chapter [Working with\nDates](https://epirhandbook.com/en/new_pages/dates.html) from the EpiRhandbook. If you are not sure how to use the across() function, you can also read the section on [Transform multiple columns](https://epirhandbook.com/en/new_pages/cleaning.html#clean_across).\n\nOne simple way to create the \"week_date\" column would be to use the function floor_date() from {lubridate}. Take a look at the documentation to understand how it works and how to make Monday the starting day of the week.\n\nThere are different functions that we can use to recode. We propose three: The function recode() from {dplyr}, the function ifelse() from {base} and the function case_when() from {dplyr}. If you want to know more about these functions, look that the section on [Re-code\nvalues](https://epirhandbook.com/en/new_pages/cleaning.html#re-code-values)\nfrom the EpiRhandbook.\n\nTo create the age groups, explore the function called age_categories()\nfrom the {epikit} package.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE, results = 'hide'}\n# Create a new object called cb_data which is the clean version of the raw data, applying the cleaning functions\n\n\ncb_data <- cb_data_raw_csv %>% \n  \n  clean_names() %>% # standardises names and puts all into lower case \n  \n  #(Note: after this point all column names have changed)\n  \n  mutate(date_of_notification = ymd(date_of_notification)) %>%  #transform ONE column into date\n\n  mutate(across(starts_with(\"date\"), \n                .fns = ~ ymd(.x))) %>%  #transforms ALL columns starting with \"date\" into dates\n  \n  mutate(week_date = floor_date(date_of_notification, # create week column with Monday start\n                              unit = \"week\",\n                              week_start = \"Monday\")) %>% \n  \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x == \"\", NA, .x)))  %>% #transforms empty cells into NA across all character columns\n  \n  mutate(gender = recode(gender,\n                         \"F\" = \"Female\",\n                         \"M\" = \"Male\",\n                         \"O\" = \"Other\",\n                         \"UNK\" = \"Unknown\")) %>%\n  \n    \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x == \"UNK\", \"Unknown\", .x)))  %>% #transforms UNK to Unknown across all character columns\n  \n  mutate(outcome = ifelse(outcome == \"A\", \"Alive\", outcome)) %>%   #we can recode as well with ifelse if we want to change only one or two categories\n  \n  mutate(hiv_status = case_when(hiv_status == \"NEG\" ~ \"Negative\",    #for more complex recoding better case_when\n                                hiv_status == \"POS\" ~ \"Positive\",\n                                TRUE                ~ \"Unknown/missing\")) %>% \n  \n  mutate(sexual_orientation = case_when(sexual_orientation == \"BISEXUAL\" ~ \"Bisexual\",\n                                        sexual_orientation == \"HETERO\" ~ \"Heterosexual\",\n                                        sexual_orientation == \"MSM\" ~ \"MSM/homo or bisexual male\",\n                                        TRUE                        ~  \"Unknown/missing\")) %>% \n  \n  mutate(age_group = age_categories(age, \n                                    lower = 0,      #set up the lower age\n                                    upper = 70,     #set up the upper age\n                                    by = 10))       #set up the age breaks\n\n\n\n\n# Check that all changes have been made correctly\n\nskim(cb_data)\n\ntabyl(cb_data, gender)\n\ntabyl(cb_data, clinical_symptoms)\n\ntabyl(cb_data, outcome)\n\ntabyl(cb_data, hiv_status)\n\ntabyl(cb_data, sexual_orientation)\n\ntabyl(cb_data, week_date)\n\ntabyl(cb_data, age_group)\n\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"36\",\n  answer = \"1960\",\n  \"65\",\n  \"1523\"\n)\n\n\ncat(\"How many male cases we have in the data frame?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"2022-04-11\",\n  \"2022-07-25\",\n  \"2022-02-28\",\n  \"2022-05-09\"\n)\n\n\ncat(\"Which week has the largest number of cases?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"1\",\n  answer = \"3\",\n  \"None\",\n  \"396\"\n)\n\ncat(\"How many cases with missing age are present?\", longmcq(opts))\n\n```\n:::\n\n::: \n\n### 4.2: Clean the aggregated data\n\nIn a similar way, clean the aggregated data by:\n\n-   Standardising names to lower case\n-   Ensure that date of reporting is of class \"Date\"\n-   Create a column called \"week_date\" with the week of reporting starting on Monday\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE, results = 'hide'}\n# Check class of date of reporting column\n\nclass(agg_data_raw_csv$DateRep) #It is a date, so we do not need to change its class\n\n# Create a new object called agg_data which is the clean version of the raw data, applying the cleaning functions\n\nagg_data <- agg_data_raw_csv %>% \n  \n  clean_names() %>% # standardises names and puts all into lower case \n  \n  #(Note: after this point all column names have changed)\n  \n  mutate(week_date = floor_date(date_rep, # create week column with Monday start\n                              unit = \"week\",\n                              week_start = \"Monday\")) \n\n```\n\n</br>\n\n</details>\n\n## Step 5: Describe outbreak by person, place, and time\n\nYou’re now aware that you have information on region of residence, dates of notification, age, and sex of cases. You can use this to build a picture of how the outbreak is progressing in Europe.\n\n### 5.1: Describe geographic distribution of cases\n\n**Task**: Using the case-based data, create a table with the number of cases by country\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nAn easy way to produce tables is using the function tbl_summary() from\n{gtsummary} package\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"C\",\n  \"D\",\n  \"B\",\n  answer = \"A\"\n)\n\n\ncat(\"What's the country with the largest percentage of cases?\", longmcq(opts))\n\n```\n:::\n:::\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Create an object with the table\ncb_country_table <- cb_data %>%\n\n  select(country) %>% #select the column that we want to use in the table\n  \n  gtsummary::tbl_summary() # create the table\n\n# Ask R to print the table\ncb_country_table\n\n```\n\n</br>\n\n</details>\n\n### 5.2: Describe cases over time\n\n**Tasks**: \n\n- Using the case-based data, create an epicurve by week of notification\n- Using the case-based data, create an epicurve by week of notification in which the colour of the bins represents the number of cases by country\n- Using the case-based data, create a heat plot with the number of cases by country and week of notification.\n\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo do the epicurve, you can use ggplot() and geom_histogram(), which will automatically aggregate your data. If you are unsure on how ggplot() works, read the EpiRhandbook chapter on [Epidemic\ncurves](https://epirhandbook.com/en/new_pages/epicurves.html).\n\nAn alternative approach is to first aggregate the number of cases by week of notification. You can do this using the functions group_by() and summarise() from {dplyr}. If you are unsure on how to do this, review the [Grouping data](https://epirhandbook.com/en/new_pages/grouping.html) chapter of the EpiRhandbook.\n\nOnce you have an object with aggregated cases by week of notification, create the epicurve using ggplot().\nIf want a dynamic colour inside the bins, you need to assign the fill to the column you want to use (country) and place it inside the aesthetics\n\nHeat plots can be useful to understand how the epidemic evolved in different countries. You will need to aggregate your data by country and week of notification. You can do this using the functions group_by() and summarise() from {dplyr}. If you are unsure on how to do this, review the Grouping data chapter of the EpiRhandbook. Then, use the geom geom_tile() to create a heat plot. If you’re unsure on how to do this, read the EpiRhanbook section on [Heat Plots](https://epirhandbook.com/en/new_pages/heatmaps.html)\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Epicurve by notification\n\nepicurve_epox <- ggplot(data = cb_data,          #data to be used\n                        aes(x = week_date)) +    #with geom_histogram() you only need to assign the x axis\n  \n  geom_histogram(binwidth = 7,                   #binwidth 7 ensures that the width represents 7 days\n                 fill=\"darkgreen\",               #colour inside the bins\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  \n  labs(title=\"Mpox cases reported in 2022\") +  #add a title\n  \n  theme_bw() +                                  #assign a predefined theme\n  \n  theme(axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n           \n  \nepicurve_epox\n\n# Epicurve by notification and country \n\nepicurve_epox_country <- ggplot(data = cb_data,  #data to be used\n                        aes(x = week_date,       \n                            fill = country)) +   #now the fill needs to be inside aes()  \n  \n  geom_histogram(binwidth = 7,                   #binwidth 7 ensures that the width represents 7 days\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_fill_viridis_d() +                       #we change the predefined colours\n\n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  \n  labs(title=\"Mpox cases reported by country in 2022\") +  #add a title\n  \n  theme_bw() +                                  #assign a predefined theme\n  \n  theme(legend.position = \"bottom\",             #legend position to the bottom\n        axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90),   #rotate the x axis text\n        legend.title = element_blank())         #remove title of legend\n           \n  \nepicurve_epox_country\n\n# Heatmap of cases by country over time\n\nhp_epox <- cb_data %>% #we first group the data by country and week of notification\n  \n  group_by(country, week_date) %>% \n  \n  summarise(n_cases = n(), .groups = \"drop\") %>% \n\n  #now we can use the pipe to directly plot the resulting data from the grouping\n  \n  ggplot(aes(x = week_date,\n           y = country,           #we want the countries to be in the y axis\n           fill = n_cases)) +     #the colour of the tiles should depend on the number of cases\n  \n  geom_tile(colour = \"black\") +   #this is the outline colour of each tile\n  \n  scale_fill_gradient(            #here we define the colours we want to use in the gradient\n    low = \"lightgreen\",\n    high = \"red\") +\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n  \n  labs(\n    title= \"Mpox cases by country and week of notification\",\n    fill = \"Number of cases\"                               \n  ) +\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\",             #legend position to the bottom\n        axis.text = element_text(size=9),       #define the font size of the axis\n        axis.title = element_blank(),           #remove the titles of the x and y \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n    \nhp_epox \n\n```\n\n</br>\n\n</details>\n\n### 5.3: Describe demographic characteristics\n\nNow that we have created some outputs by time and place, we should focus on the \"person\" element. The two most important demographic characteristics are usually age and gender. In the case we are seeing,\nwe may also want to explore the sexual orientation of cases.\n\n**Task**:\n\n-   Explore the number of cases by age group and gender.\n-   Create a table with number and percentages of cases by sexual orientation\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nThe easiest way to explore both columns (age_group and gender) would be to use the tabyl() function from {janitor}. Then, to create the age\npyramid explore the function age_pyramid() from the {apyramid} package. You can find more about this function in the EpiRhandbook chapter [Demographic pyramids and Likert-scales](https://epirhandbook.com/en/new_pages/age_pyramid.html)\n\nTo create the table by sexual orientation, consider using the function tbl_summary() from {gtsummary}\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Explore gender and age group columns\ntabyl(cb_data, gender)\ntabyl(cb_data, age_group)\n\n# Table with sexual orientation \n\ntab_sor <- cb_data %>% \n  \n  select(sexual_orientation) %>% \n  \n  tbl_summary(label = list(sexual_orientation ~ \"Sexual Orientation\")) \n\ntab_sor\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Females 60-69\",\n  \"Males 40-49\",\n  \"Females 10-19\",\n  answer = \"Males 30-39\"\n)\n\n\ncat(\"Which demographic group is more affected by Mpox?\", longmcq(opts))\n\n```\n:::\n:::\n\n\n### 5.4: Describe clinical characteristics\n\nNow, let's summarise the main clinical information that we have in our case-based data frame.\n\n**Tasks**:\n\n-   Create a bar plot with the proportion of each type clinical symptoms\n\n-   Create a table with the number and percentage of cases by outcome\n\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo create bar plots we can use geom_bar() or geom_col() depending on the nature of our data. If we aggregate first, we can use geom_col(), otherwise we should use geom_bar(). There is a function of the {gtsummary} package called add_p() which enables you to easy calculate a statistical test across groups. If you want to know more read the section on [gtsummary package](https://epirhandbook.com/en/new_pages/stat_tests.html#stats_gt) of the EpiRhandbook.\n\n</br>\n\n</details>\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Bar plot with clinical symptoms\n\nbar_clinical <- cb_data %>% \n  \n  drop_na(clinical_symptoms) %>%   # we remove those with missing clinical symptoms\n  \n  group_by(clinical_symptoms) %>% \n  \n  summarise(n_cases = n(), .groups = \"drop\") %>%\n  \n  mutate(prop=(n_cases/sum(n_cases))*100) %>%  # we create a column with proportions\n  \n  ggplot(aes(y = reorder(clinical_symptoms, prop), x = prop)) +  # the reorder function ensures that categories are ordered by proportion in the graph\n  \n  geom_col(fill = \"darkgreen\") + \n  \n  labs(\n    title= \"Frequency of clinical symptoms in Mpox cases\",\n    y = \"\",\n    x = \"Number of cases\"\n  ) +\n  \n  theme_bw() +\n  \n  theme(axis.text = element_text(size=9))       #define the font size of the axis\n\nbar_clinical  \n\n\n# Table with number and percentage of cases by outcome\n\ntab_outcome <- cb_data %>% \n  \n  select(outcome) %>% \n  \n  tbl_summary(label = list(outcome = \"Reported outcome\")) # with the argument \"label\" we can change how the column name is displayed\n\ntab_outcome\n\n\n```\n\n</br>\n\n</details>\n\n## **Step 6: Reviewing data quality**\n\nIt is important to understand how timely, complete, and valid your data is, if it will be the basis of understanding an outbreak and making decisions. For example - you will need to be mindful of reporting delays when interpreting epicurves, and be aware of how complete different sources of data are compared to each other. \n\n### 6.1: Delay between date of onset, diagnosis and notification\n\n**Tasks**\n\n-   Calculate median time from symptom onset to diagnosis and from diagnosis to notification, both overall and by country\n\n-   Assess visually the number of cases by calendar period and type of date (onset, diagnosis and notification)\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo plot together the different dates you may need to transform your data from \"wide\" to \"long\" form. What we call \"pivoting\" in R. The objective is to have a column with the different date categories (onset, diagnosis and notification) and another column with their date value. If you are unsure on how to do this, have a look at the [Pivoting data](https://epirhandbook.com/en/new_pages/pivoting.html) chapter of the EpiRhandbook. Then, try to plot with the daily values, but if that's not easy to interpret you may want to aggregate cases by week.\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Yes\",\n  answer = \"No\"\n)\n\n\ncat(\"Is there a difference in the delay from diagnosis to notification by country?\", longmcq(opts))\n\n```\n:::\n:::\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Estimate delay between onset and diagnosis, and between diagnosis and notification\n\ndelay_db <- cb_data %>% \n  \n  mutate(delay_diag = as.numeric(date_of_diagnosis - date_of_onset)) %>%   #we create variables with difference between dates, we transform them in numeric to be able to then calculate measures of central tendency\n  \n  mutate(delay_not = as.numeric(date_of_notification - date_of_diagnosis))\n\nsummary(delay_db$delay_diag) #the summary will give us measures of central tendency and dispersion\nsummary(delay_db$delay_not)\n\n\ndelay_country <- delay_db %>% #here, we group by country and summarise the median to compare across countries\n  \n  group_by(country) %>% \n  \n  summarise(median_delay_diag = median(delay_diag, na.rm = T),\n            median_delay_not = median(delay_not, na.rm = T))\n\ndelay_country\n\n# Line graph with the different dates \n\ndates_longer <- cb_data %>% # use the variables of the dates and make a longer dataset. In the pivot_longer() command we select the columns which we want to expand in long format and transform the dataset\n   \n  pivot_longer(\n    \n    cols=starts_with(\"date_\"),         # all columns starting with \"date_\" will be taken \n\n    names_to = \"indicator\",            #the names of the columns will be placed in a single column called \"indicator\"\n\n    values_to = \"date\")                # the values (which are dates in this case) will be placed in a column called \"date\"\n  \n\ndates_longer_week <- dates_longer  %>% \n\n  mutate(week_date = floor_date(date, unit = \"week\", week_start = \"Monday\")) %>%  # we create a week column\n    \n  group_by(indicator, week_date) %>% \n    \n  summarise(n=n(), .groups=\"drop\") %>%   # we group and summarise to have the number of cases by date type and week\n    \n  drop_na(week_date)                     # we drop the cases with no data on dates\n\n\n\n\nplot_date_delay <-   ggplot(data = dates_longer_week,\n                            aes(x = week_date, \n                                y = n, \n                                color=indicator)) +\n  \n  geom_line(linewidth = 1.5) +\n  \n  scale_x_date(breaks = \"2 weeks\")+\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\", \n        axis.text = element_text(size=9),\n        axis.title = element_blank(),\n        axis.text.x = element_text(angle=90),\n        legend.title = element_blank()) +\n  labs(title=\"Mpox cases reported in 2022, by date of onset, diagnosis and notification.\")\n\nplot_date_delay\n```\n\n</br>\n\n</details>\n\n### 6.2: Compare case-based and aggregated data\n\n**Task**: Create a plot comparing the number of cases reported to through the case-based flow and through the aggregated flow in each\ncountry.\n\nNOTE: Take into consideration that the column on cases in the aggregated\ndata frame reports the *cumulative* number of cases.\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"A\",\n  \"B\",\n  answer = \"C\",\n  \"D\",\n  \"E\"\n)\n\n\ncat(\"Which country is not reporting aggregated data?\", longmcq(opts))\n\n```\n:::\n:::\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Create a data frame with the overall number of cases reported through the aggregated flux\n\nagg_data_country <- agg_data %>% \n  \n  group_by(country) %>% \n  \n  filter(date_rep == max(date_rep)) %>% # as we have cumulative data, we keep only the last week (after grouping by country)\n  \n  select(-date_rep, -week_date) %>%     # remove unnecessary columns\n\n  mutate(source = \"aggregated\")         # we create this column to distinguish the numbers from the case-based flux\n\n\n# Create a data frame with the overall number of cases reported through the case-based flux\n\ncb_data_country <- cb_data %>%\n  \n  group_by(country) %>% \n  \n  summarise(cases = n(), .groups = \"drop\") %>% \n  \n  mutate(source = \"case_based\")       # we create this column to distinguish the numbers from the\n  \n\n# We append both data frames. Remember this is different from merging\n\ntotal_data <- bind_rows(cb_data_country, agg_data_country)\n\n\n# We create a graph to compare the cases reported in both sources\n\ngraph_comp <- ggplot(data = total_data,\n                     aes(x = source, \n                         y = cases, \n                         fill = source)) +\n  \n  geom_col(position = \"dodge\") +            #position dodge puts bars one next to each other, instead of \"stacked\"\n  \n  facet_wrap(~ country, scales = \"free_y\") +  # this command gives us one graph per country. The argument scales is used to allow each y axis scales to adjust to the data\n\n  scale_fill_viridis_d(\n    labels = c(\"Aggregated\", \"Case-based\")  # this function changes the colours, but with the argument \"labels\" we can change the text of each fill.\n     ) +\n  \n  \n  labs(\n    title = \"Number of cases of Mpox reported in 2022 according to source of data\",\n    fill = \"Source\",\n    x = \"\",\n    y = \"Total number of cases\"\n  ) + \n  \n  theme_bw() +\n  \n  theme(axis.text.x = element_blank(),      # we remove the text of the x axis because it is already present in the legend\n        axis.ticks.x = element_blank())     # we also remove the ticks for aesthetic purposes\n\ngraph_comp\n```\n\n</br>\n\n</details>\n\n## Final thoughts\n\nWell done! Through your analysis you now understand the magnitude of the outbreak so far, where and when it spread, which demographic groups are most affected, and how the disease actually manifests in terms of symptoms and severity. ECDC is very happy with your work. \n\nBy coding this up in R, this analysis should be reproducible, meaning you can quickly update it with new data and keep monitoring the outbreak. To further practise reproducible reports, [link to RMarkdown]. \n\n## Case study information \n\n**Authorship**\n\nOriginal authors: Xanthi Andrianou, Gianfranco Spiteri (ECDC EI Group)\\\nData source: Fictional data provided by ECDC EI Group for training\npurposes\\\n\n| Date         | Changes made       | Version          | Author          |\n|--------------|:-------------------|-----------------:|------------------|\n| October 2021 |First draft         |     1            |  Xanthi Andrianou |\n| June 2024    | Adapted to case study template  | 1.1 | Alberto Mateo Urdiales |\n\n\n**Terms of Use**\n\n<!-- Describe the licencing and other appropriate information about Terms of use or any other disclaimer -->\n","srcMarkdownNoYaml":"\n\n# Descriptive analysis of the 2022 Mpox outbreak in Europe {#sec-rpractical}\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n**Tool**: R \\| **Technical complexity**: Basic \\| **Methodological\ncomplexity**: Basic\\\n**Source:** ECDC EI Group (simulated data)\\\n**Prior knowledge required:** [R\nbasics](https://epirhandbook.com/en/new_pages/basics.html) (Using\nRstudio; R packages, functions and arguments)\n:::\n\nFor instructions on how to use our case studies, [see here.] We welcome feedback and suggestions via [contact\\@appliedepi.org](mailto:contact@appliedepi.org). Discuss the case study at [community].\n\n\\pagebreak\n\n## Objectives\n\n1.  Explore different types of files and how they can be imported in R.\n2.  Perform basic data cleaning, e.g., changing the variable type, recode variables, aggregate and filter.\n3.  Perform a basic descriptive analysis using tables and graphs\n\n## Scenario\n\nIt is May 2022 and Mpox has just been reported for the first time across 5 countries in Europe. You have been requested to provide a basic descriptive analysis to the European Centre for Disease Prevention and Control (ECDC).\n\nYou are given access to:\n\n-   Linelists with cases collated by the five countries\n-   Datasets with aggregate cases from open sources\n\nLet's go!\n\n## Step 1. Set up\n\n### 1.1 Get started in R Studio\n\nYou want to create a reproducible workflow, so you need a place to save your code so you can run it again if you need to. You want all your files easily organised so you don't get lost later on. \n\n**Tasks:**\n\n-   Ensure your working language in RStudio is English\n-   Set up a R Studio project\n-   Create an R script, or an Rmarkdown file if you prefer. Make sure\n    the script purpose, date, and author are written as comments at the\n    top.\n-   Make sure your folders/subfolders are well-organised\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\n- Download folder named r_practical and extract contents in the local laptop\n\n- Create an Rstudio project in the folder r_practical. If you are unsure on how to do that, read the EpiRhandbook on R projects\n\n- Inside \"r_practical\": Subfolder \"data\" contains the raw data you will use in this case study. You should see six different files, three called E_pox_aggregated_data and three E_pox_case_based_data. Each has a specific file type.\n\n- Inside \"r_practical\": Subfolder \"scripts\" should be used to save any scripts related to the analysis. Inside scripts there is another subfolder called \"backup\" where you can find a solution R script for each step in case you are stuck at any point or if you want to compare your own script with the solution one.\n\n- Inside \"r_practical\": Subfolder \"outputs\" can be used to store any outputs (tables, graphs, documents) that are the result of the analysis.\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r, include=FALSE}\n# To see your language locale \nSys.getlocale() \n\n# To change it into English \nSys.setlocale(\"LC_ALL\", \"English\")  \n```\n\n</details>\n\n### 1.2 Install/load packages\n\nThe first part of your code is to install and load packages. You've heard that a great way to do this is with the {pacman} package, so that's where you start.\n\nYou know that you will need to use rio (for importing data), janitor (for cleaning data), lubridate (for cleaning dates), skimr (for reviewing data), epikit, gtsummary, apyramid, and tidyverse.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\nThe function p_load() from {pacman} will check each listed package. If not already installed it will install install them. Then, it will load it for use in your R session.\n\nNote you may end up using a long list of packages. Unfortunately different\npackages have functions with the same name. For example, the package {dplyr} (already installed with {tidyverse}) has a function called select() which we frequently use to subset columns of a data frame. But\nother packages such as {MASS} do also have a function called select(). This could create headaches if you want to subset columns using dplyr's select() but R thinks you're calling MASS's select() (we call this masking - dplyr's select() is masked by MASS's select()). Given that you\nare more likely to use functions from {tidyverse}, ensure that this is\nthe last package in your p_load() list so that functions from {tidyverse} (including {dplyr} functions) will always \"prevail\".\n\n```{r, echo=TRUE, eval=TRUE}\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)\n\n```\n\n## Step 2: Import the data\n\nECDC provides you with six files for your analysis: Three case-based linelists with case information from X, X, X, and the three aggregate datasets summarising total case counts. They are available as three different types of files: csv, json and excel, and are located inside “data/raw”.\n\n**Task:** Import the three case-based data frames and the three aggregated data frames into your R environment \n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nThis function will recognise the file type and import it accordingly. It replaces the use of file-type specific functions, such as read.csv() from {base} for .csv files, JSON() function from {jsonlite} to import .json files, and read_excel() from {readxl} to import .xlsx files.\n\nIf you feel you need to know more about importing functions, read the Import and export chapter of the EpiRhandbook.\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n```{r , echo=TRUE, eval=FALSE}\n# Importing ------------------------------------------------------\n# Case-based data\ncb_data_raw_csv <- import(\"data/E_pox_case_based_data.csv\")\ncb_data_raw_json <- import(\"data/E_pox_case_based_data.json\")\ncb_data_raw_xlsx <- import(\"data/E_pox_case_based_data.xlsx\")\n\n# Aggregated data\nagg_data_raw_csv <- import(\"data/E_pox_aggregated_data.csv\")\nagg_data_raw_json <- import(\"data/E_pox_aggregated_data.json\")\nagg_data_raw_xlsx <- import(\"data/E_pox_aggregated_data.xlsx\")\n\n```\n\n```{r , include = FALSE}\ncb_data_raw_csv <- import(\"../case_studies_to_translate/ENG/r_practical/data/E_pox_case_based_data.csv\")\ncb_data_raw_json <- import(\"../case_studies_to_translate/ENG/r_practical/data/E_pox_case_based_data.json\")\ncb_data_raw_xlsx <- import(\"../case_studies_to_translate/ENG/r_practical/data/E_pox_case_based_data.xlsx\")\n\nagg_data_raw_csv <- import(\"../case_studies_to_translate/ENG/r_practical/data/E_pox_aggregated_data.csv\")\nagg_data_raw_json <- import(\"../case_studies_to_translate/ENG/r_practical/data/E_pox_aggregated_data.json\")\nagg_data_raw_xlsx <- import(\"../case_studies_to_translate/ENG/r_practical/data/E_pox_aggregated_data.xlsx\")\n```\n</details>\n\n## Step 3: Explore the data\n\nYou need to understand what the data looks like as a first step, to inform your analysis. \n\nTasks: Take a look at the different data frames and try to find out:\n\n-   The number of columns and observations\n\n-   The class of their columns and whether it matches its nature (e.g., are \"dates\" considered \"dates\" by R?)\n\n-   Look at the different categories of the columns about gender, clinical symptoms, outcome, hiv status and sexual orientation existing in the case-based data. Do you need to recode any of them?\n\n-   How is unknown or missing data being categorised in these columns? Should you standardise this category?\n\n-   If case-based and aggregated data from file types (.csv, .json and .xlsx) are exactly the same, remove the .json and .xlsx data frames from your environment.\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nAn efficient way to explore data is to use the function skim() from the {skimr} package, as it gives you all the information needed with only\none command. Of course, there are several alternatives. To know the different categories in a column, you can use the function tabyl() from {janitor}, which will give you counts and percentages of every category in the data column.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE, results = 'hide'}\n# Explore the different case-based data frames\n\nskim(cb_data_raw_csv)\nskim(cb_data_raw_json)\nskim(cb_data_raw_xlsx)\n\n# Explore the different categories of gender and clinical columns in one of the cb data frames\ntabyl(cb_data_raw_csv, Gender)\n\ntabyl(cb_data_raw_csv, ClinicalSymptoms)\n\ntabyl(cb_data_raw_csv, Outcome)\n\ntabyl(cb_data_raw_csv, HIVStatus)\n\ntabyl(cb_data_raw_csv, SexualOrientation)\n\n# Explore the different aggregated data frames\n\nskim(agg_data_raw_csv)\nskim(agg_data_raw_json)\nskim(agg_data_raw_xlsx)\n\n# Remove json and xlsx files as they are exactly the same as the csv ones. Within rm() we ask for the objects containing the pattern \"json\" or \"xlsx\" to be removed from the environment\nrm(list = ls(pattern = \"json|xlsx\"))\n\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"2000\",\n  \"13\",\n  answer = \"3\",\n  \"101\"\n)\n\n\ncat(\"How many columns does the aggregated data frame have?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Date\",\n  answer = \"Character\",\n  \"Numeric\",\n  \"Factor\"\n)\n\n\ncat(\"What is the class of the column DateOfNotification in the case-based data?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"1168\",\n  \"722\",\n  \"900\",\n  \"446\"\n)\n\n\ncat(\"For how many cases is the HIV status Unknown or missing?\", longmcq(opts))\n\n```\n:::\n:::\n\n## Step 4: Clean the data\n\n### 4.1: Clean the case-based data\n\nWhen exploring the case-based data, you may have noticed that there are\na few things that we need to take care of before we can start doing further analysis. Firstly, names contain a mixture of upper and lower case letters. Whilst this isn't in itself a problem, R is case-sensitive, so having all names in lower case may make our life easier. Also, date columns are not consider \"Dates\" by R, but instead they are being consider as \"Character\", which means they are being considered as nominal data. This would give us problems when plotting by Dates. Another issue is that some columns have categories that may not be intuitive for all. For example, Gender is categorised with \"F\", \"M\", \"O\" and \"UNK\". The column Outcome as \"A\" and \"UNK\". We should give them more appropriate categories. Finally, it is important that missing data is considered as \"missing\" in R. That means that R treats it as \"NA\". In\nthe column clinical symptoms, for example, missing data is an empty cell, not \"NA\". R is considering this as another nominal category instead of missing, and will consider it this way in any analysis or\noutput you produce.\n\n**Tasks**:\n\n-   Create a clean version of your case-based data making all cleaning changes in a single piping command\n-   Change all column names to lower case.\n-   Convert all date columns to class \"Date\".\n-   Use the column \"DateOfNotification\" to create a column called \"week_date\" which has the week of notification, starting on Mondays.\n-   Transform all empty cells into \"NA\"\n-   Recode \"Gender\" categories into: \"Female\", \"Male\", \"Other\" and \"Unknown\"\n-   Recode \"Outcome\" categories into: \"Alive\" and \"Unknown\"\n-   Recode HIV status into: \"Positive\", \"Negative\" and \"Unknown/Missing\"\n-   Recode Sexual orientation into: \"Bisexual\", \"Heterosexual\", \"MSM/homo or bisexual male\" and \"Unknown/missing\".\n-   Create a column called \"age_group\" with ten year age groups and the oldest group being 70+\n-   Check that all changes have been made correctly\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo convert all names to lower case, rather than renaming each column you may use the function clean_names() from the {janitor} package, which will do it automatically for all columns. Use lubridate functions to\ntransform date columns into \"Date\" class, you can do this one by one, or you could do all at the same time using the across() function from {dplyr}. If you feel you need to know more about transforming dates read\nthe chapter [Working with\nDates](https://epirhandbook.com/en/new_pages/dates.html) from the EpiRhandbook. If you are not sure how to use the across() function, you can also read the section on [Transform multiple columns](https://epirhandbook.com/en/new_pages/cleaning.html#clean_across).\n\nOne simple way to create the \"week_date\" column would be to use the function floor_date() from {lubridate}. Take a look at the documentation to understand how it works and how to make Monday the starting day of the week.\n\nThere are different functions that we can use to recode. We propose three: The function recode() from {dplyr}, the function ifelse() from {base} and the function case_when() from {dplyr}. If you want to know more about these functions, look that the section on [Re-code\nvalues](https://epirhandbook.com/en/new_pages/cleaning.html#re-code-values)\nfrom the EpiRhandbook.\n\nTo create the age groups, explore the function called age_categories()\nfrom the {epikit} package.\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE, results = 'hide'}\n# Create a new object called cb_data which is the clean version of the raw data, applying the cleaning functions\n\n\ncb_data <- cb_data_raw_csv %>% \n  \n  clean_names() %>% # standardises names and puts all into lower case \n  \n  #(Note: after this point all column names have changed)\n  \n  mutate(date_of_notification = ymd(date_of_notification)) %>%  #transform ONE column into date\n\n  mutate(across(starts_with(\"date\"), \n                .fns = ~ ymd(.x))) %>%  #transforms ALL columns starting with \"date\" into dates\n  \n  mutate(week_date = floor_date(date_of_notification, # create week column with Monday start\n                              unit = \"week\",\n                              week_start = \"Monday\")) %>% \n  \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x == \"\", NA, .x)))  %>% #transforms empty cells into NA across all character columns\n  \n  mutate(gender = recode(gender,\n                         \"F\" = \"Female\",\n                         \"M\" = \"Male\",\n                         \"O\" = \"Other\",\n                         \"UNK\" = \"Unknown\")) %>%\n  \n    \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x == \"UNK\", \"Unknown\", .x)))  %>% #transforms UNK to Unknown across all character columns\n  \n  mutate(outcome = ifelse(outcome == \"A\", \"Alive\", outcome)) %>%   #we can recode as well with ifelse if we want to change only one or two categories\n  \n  mutate(hiv_status = case_when(hiv_status == \"NEG\" ~ \"Negative\",    #for more complex recoding better case_when\n                                hiv_status == \"POS\" ~ \"Positive\",\n                                TRUE                ~ \"Unknown/missing\")) %>% \n  \n  mutate(sexual_orientation = case_when(sexual_orientation == \"BISEXUAL\" ~ \"Bisexual\",\n                                        sexual_orientation == \"HETERO\" ~ \"Heterosexual\",\n                                        sexual_orientation == \"MSM\" ~ \"MSM/homo or bisexual male\",\n                                        TRUE                        ~  \"Unknown/missing\")) %>% \n  \n  mutate(age_group = age_categories(age, \n                                    lower = 0,      #set up the lower age\n                                    upper = 70,     #set up the upper age\n                                    by = 10))       #set up the age breaks\n\n\n\n\n# Check that all changes have been made correctly\n\nskim(cb_data)\n\ntabyl(cb_data, gender)\n\ntabyl(cb_data, clinical_symptoms)\n\ntabyl(cb_data, outcome)\n\ntabyl(cb_data, hiv_status)\n\ntabyl(cb_data, sexual_orientation)\n\ntabyl(cb_data, week_date)\n\ntabyl(cb_data, age_group)\n\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"36\",\n  answer = \"1960\",\n  \"65\",\n  \"1523\"\n)\n\n\ncat(\"How many male cases we have in the data frame?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  answer = \"2022-04-11\",\n  \"2022-07-25\",\n  \"2022-02-28\",\n  \"2022-05-09\"\n)\n\n\ncat(\"Which week has the largest number of cases?\", longmcq(opts))\n\n```\n:::\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"1\",\n  answer = \"3\",\n  \"None\",\n  \"396\"\n)\n\ncat(\"How many cases with missing age are present?\", longmcq(opts))\n\n```\n:::\n\n::: \n\n### 4.2: Clean the aggregated data\n\nIn a similar way, clean the aggregated data by:\n\n-   Standardising names to lower case\n-   Ensure that date of reporting is of class \"Date\"\n-   Create a column called \"week_date\" with the week of reporting starting on Monday\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE, results = 'hide'}\n# Check class of date of reporting column\n\nclass(agg_data_raw_csv$DateRep) #It is a date, so we do not need to change its class\n\n# Create a new object called agg_data which is the clean version of the raw data, applying the cleaning functions\n\nagg_data <- agg_data_raw_csv %>% \n  \n  clean_names() %>% # standardises names and puts all into lower case \n  \n  #(Note: after this point all column names have changed)\n  \n  mutate(week_date = floor_date(date_rep, # create week column with Monday start\n                              unit = \"week\",\n                              week_start = \"Monday\")) \n\n```\n\n</br>\n\n</details>\n\n## Step 5: Describe outbreak by person, place, and time\n\nYou’re now aware that you have information on region of residence, dates of notification, age, and sex of cases. You can use this to build a picture of how the outbreak is progressing in Europe.\n\n### 5.1: Describe geographic distribution of cases\n\n**Task**: Using the case-based data, create a table with the number of cases by country\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nAn easy way to produce tables is using the function tbl_summary() from\n{gtsummary} package\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"C\",\n  \"D\",\n  \"B\",\n  answer = \"A\"\n)\n\n\ncat(\"What's the country with the largest percentage of cases?\", longmcq(opts))\n\n```\n:::\n:::\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Create an object with the table\ncb_country_table <- cb_data %>%\n\n  select(country) %>% #select the column that we want to use in the table\n  \n  gtsummary::tbl_summary() # create the table\n\n# Ask R to print the table\ncb_country_table\n\n```\n\n</br>\n\n</details>\n\n### 5.2: Describe cases over time\n\n**Tasks**: \n\n- Using the case-based data, create an epicurve by week of notification\n- Using the case-based data, create an epicurve by week of notification in which the colour of the bins represents the number of cases by country\n- Using the case-based data, create a heat plot with the number of cases by country and week of notification.\n\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo do the epicurve, you can use ggplot() and geom_histogram(), which will automatically aggregate your data. If you are unsure on how ggplot() works, read the EpiRhandbook chapter on [Epidemic\ncurves](https://epirhandbook.com/en/new_pages/epicurves.html).\n\nAn alternative approach is to first aggregate the number of cases by week of notification. You can do this using the functions group_by() and summarise() from {dplyr}. If you are unsure on how to do this, review the [Grouping data](https://epirhandbook.com/en/new_pages/grouping.html) chapter of the EpiRhandbook.\n\nOnce you have an object with aggregated cases by week of notification, create the epicurve using ggplot().\nIf want a dynamic colour inside the bins, you need to assign the fill to the column you want to use (country) and place it inside the aesthetics\n\nHeat plots can be useful to understand how the epidemic evolved in different countries. You will need to aggregate your data by country and week of notification. You can do this using the functions group_by() and summarise() from {dplyr}. If you are unsure on how to do this, review the Grouping data chapter of the EpiRhandbook. Then, use the geom geom_tile() to create a heat plot. If you’re unsure on how to do this, read the EpiRhanbook section on [Heat Plots](https://epirhandbook.com/en/new_pages/heatmaps.html)\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Epicurve by notification\n\nepicurve_epox <- ggplot(data = cb_data,          #data to be used\n                        aes(x = week_date)) +    #with geom_histogram() you only need to assign the x axis\n  \n  geom_histogram(binwidth = 7,                   #binwidth 7 ensures that the width represents 7 days\n                 fill=\"darkgreen\",               #colour inside the bins\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  \n  labs(title=\"Mpox cases reported in 2022\") +  #add a title\n  \n  theme_bw() +                                  #assign a predefined theme\n  \n  theme(axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n           \n  \nepicurve_epox\n\n# Epicurve by notification and country \n\nepicurve_epox_country <- ggplot(data = cb_data,  #data to be used\n                        aes(x = week_date,       \n                            fill = country)) +   #now the fill needs to be inside aes()  \n  \n  geom_histogram(binwidth = 7,                   #binwidth 7 ensures that the width represents 7 days\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_fill_viridis_d() +                       #we change the predefined colours\n\n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  \n  labs(title=\"Mpox cases reported by country in 2022\") +  #add a title\n  \n  theme_bw() +                                  #assign a predefined theme\n  \n  theme(legend.position = \"bottom\",             #legend position to the bottom\n        axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90),   #rotate the x axis text\n        legend.title = element_blank())         #remove title of legend\n           \n  \nepicurve_epox_country\n\n# Heatmap of cases by country over time\n\nhp_epox <- cb_data %>% #we first group the data by country and week of notification\n  \n  group_by(country, week_date) %>% \n  \n  summarise(n_cases = n(), .groups = \"drop\") %>% \n\n  #now we can use the pipe to directly plot the resulting data from the grouping\n  \n  ggplot(aes(x = week_date,\n           y = country,           #we want the countries to be in the y axis\n           fill = n_cases)) +     #the colour of the tiles should depend on the number of cases\n  \n  geom_tile(colour = \"black\") +   #this is the outline colour of each tile\n  \n  scale_fill_gradient(            #here we define the colours we want to use in the gradient\n    low = \"lightgreen\",\n    high = \"red\") +\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n  \n  labs(\n    title= \"Mpox cases by country and week of notification\",\n    fill = \"Number of cases\"                               \n  ) +\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\",             #legend position to the bottom\n        axis.text = element_text(size=9),       #define the font size of the axis\n        axis.title = element_blank(),           #remove the titles of the x and y \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n    \nhp_epox \n\n```\n\n</br>\n\n</details>\n\n### 5.3: Describe demographic characteristics\n\nNow that we have created some outputs by time and place, we should focus on the \"person\" element. The two most important demographic characteristics are usually age and gender. In the case we are seeing,\nwe may also want to explore the sexual orientation of cases.\n\n**Task**:\n\n-   Explore the number of cases by age group and gender.\n-   Create a table with number and percentages of cases by sexual orientation\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nThe easiest way to explore both columns (age_group and gender) would be to use the tabyl() function from {janitor}. Then, to create the age\npyramid explore the function age_pyramid() from the {apyramid} package. You can find more about this function in the EpiRhandbook chapter [Demographic pyramids and Likert-scales](https://epirhandbook.com/en/new_pages/age_pyramid.html)\n\nTo create the table by sexual orientation, consider using the function tbl_summary() from {gtsummary}\n\n</br>\n\n</details>\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Explore gender and age group columns\ntabyl(cb_data, gender)\ntabyl(cb_data, age_group)\n\n# Table with sexual orientation \n\ntab_sor <- cb_data %>% \n  \n  select(sexual_orientation) %>% \n  \n  tbl_summary(label = list(sexual_orientation ~ \"Sexual Orientation\")) \n\ntab_sor\n```\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Females 60-69\",\n  \"Males 40-49\",\n  \"Females 10-19\",\n  answer = \"Males 30-39\"\n)\n\n\ncat(\"Which demographic group is more affected by Mpox?\", longmcq(opts))\n\n```\n:::\n:::\n\n\n### 5.4: Describe clinical characteristics\n\nNow, let's summarise the main clinical information that we have in our case-based data frame.\n\n**Tasks**:\n\n-   Create a bar plot with the proportion of each type clinical symptoms\n\n-   Create a table with the number and percentage of cases by outcome\n\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo create bar plots we can use geom_bar() or geom_col() depending on the nature of our data. If we aggregate first, we can use geom_col(), otherwise we should use geom_bar(). There is a function of the {gtsummary} package called add_p() which enables you to easy calculate a statistical test across groups. If you want to know more read the section on [gtsummary package](https://epirhandbook.com/en/new_pages/stat_tests.html#stats_gt) of the EpiRhandbook.\n\n</br>\n\n</details>\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Bar plot with clinical symptoms\n\nbar_clinical <- cb_data %>% \n  \n  drop_na(clinical_symptoms) %>%   # we remove those with missing clinical symptoms\n  \n  group_by(clinical_symptoms) %>% \n  \n  summarise(n_cases = n(), .groups = \"drop\") %>%\n  \n  mutate(prop=(n_cases/sum(n_cases))*100) %>%  # we create a column with proportions\n  \n  ggplot(aes(y = reorder(clinical_symptoms, prop), x = prop)) +  # the reorder function ensures that categories are ordered by proportion in the graph\n  \n  geom_col(fill = \"darkgreen\") + \n  \n  labs(\n    title= \"Frequency of clinical symptoms in Mpox cases\",\n    y = \"\",\n    x = \"Number of cases\"\n  ) +\n  \n  theme_bw() +\n  \n  theme(axis.text = element_text(size=9))       #define the font size of the axis\n\nbar_clinical  \n\n\n# Table with number and percentage of cases by outcome\n\ntab_outcome <- cb_data %>% \n  \n  select(outcome) %>% \n  \n  tbl_summary(label = list(outcome = \"Reported outcome\")) # with the argument \"label\" we can change how the column name is displayed\n\ntab_outcome\n\n\n```\n\n</br>\n\n</details>\n\n## **Step 6: Reviewing data quality**\n\nIt is important to understand how timely, complete, and valid your data is, if it will be the basis of understanding an outbreak and making decisions. For example - you will need to be mindful of reporting delays when interpreting epicurves, and be aware of how complete different sources of data are compared to each other. \n\n### 6.1: Delay between date of onset, diagnosis and notification\n\n**Tasks**\n\n-   Calculate median time from symptom onset to diagnosis and from diagnosis to notification, both overall and by country\n\n-   Assess visually the number of cases by calendar period and type of date (onset, diagnosis and notification)\n\n<details>\n\n<summary style=\"text-decoration: underline; color: darkgreen;\">\n\n`r fontawesome::fa(\"lightbulb\", fill = \"gold\")` Click to read a hint\n\n</summary>\n\n</br>\n\nTo plot together the different dates you may need to transform your data from \"wide\" to \"long\" form. What we call \"pivoting\" in R. The objective is to have a column with the different date categories (onset, diagnosis and notification) and another column with their date value. If you are unsure on how to do this, have a look at the [Pivoting data](https://epirhandbook.com/en/new_pages/pivoting.html) chapter of the EpiRhandbook. Then, try to plot with the daily values, but if that's not easy to interpret you may want to aggregate cases by week.\n\n</br>\n\n</details>\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"Yes\",\n  answer = \"No\"\n)\n\n\ncat(\"Is there a difference in the delay from diagnosis to notification by country?\", longmcq(opts))\n\n```\n:::\n:::\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Estimate delay between onset and diagnosis, and between diagnosis and notification\n\ndelay_db <- cb_data %>% \n  \n  mutate(delay_diag = as.numeric(date_of_diagnosis - date_of_onset)) %>%   #we create variables with difference between dates, we transform them in numeric to be able to then calculate measures of central tendency\n  \n  mutate(delay_not = as.numeric(date_of_notification - date_of_diagnosis))\n\nsummary(delay_db$delay_diag) #the summary will give us measures of central tendency and dispersion\nsummary(delay_db$delay_not)\n\n\ndelay_country <- delay_db %>% #here, we group by country and summarise the median to compare across countries\n  \n  group_by(country) %>% \n  \n  summarise(median_delay_diag = median(delay_diag, na.rm = T),\n            median_delay_not = median(delay_not, na.rm = T))\n\ndelay_country\n\n# Line graph with the different dates \n\ndates_longer <- cb_data %>% # use the variables of the dates and make a longer dataset. In the pivot_longer() command we select the columns which we want to expand in long format and transform the dataset\n   \n  pivot_longer(\n    \n    cols=starts_with(\"date_\"),         # all columns starting with \"date_\" will be taken \n\n    names_to = \"indicator\",            #the names of the columns will be placed in a single column called \"indicator\"\n\n    values_to = \"date\")                # the values (which are dates in this case) will be placed in a column called \"date\"\n  \n\ndates_longer_week <- dates_longer  %>% \n\n  mutate(week_date = floor_date(date, unit = \"week\", week_start = \"Monday\")) %>%  # we create a week column\n    \n  group_by(indicator, week_date) %>% \n    \n  summarise(n=n(), .groups=\"drop\") %>%   # we group and summarise to have the number of cases by date type and week\n    \n  drop_na(week_date)                     # we drop the cases with no data on dates\n\n\n\n\nplot_date_delay <-   ggplot(data = dates_longer_week,\n                            aes(x = week_date, \n                                y = n, \n                                color=indicator)) +\n  \n  geom_line(linewidth = 1.5) +\n  \n  scale_x_date(breaks = \"2 weeks\")+\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\", \n        axis.text = element_text(size=9),\n        axis.title = element_blank(),\n        axis.text.x = element_text(angle=90),\n        legend.title = element_blank()) +\n  labs(title=\"Mpox cases reported in 2022, by date of onset, diagnosis and notification.\")\n\nplot_date_delay\n```\n\n</br>\n\n</details>\n\n### 6.2: Compare case-based and aggregated data\n\n**Task**: Create a plot comparing the number of cases reported to through the case-based flow and through the aggregated flow in each\ncountry.\n\nNOTE: Take into consideration that the column on cases in the aggregated\ndata frame reports the *cumulative* number of cases.\n\n::: {.callout-note appearance=\"minimal\" icon=\"false\"}\n\n**Test yourself!**\n\n::: webex-check\n```{r, results=\"asis\", echo=FALSE}\npacman::p_load(webexercises)\n\nopts <- c(\n  \"A\",\n  \"B\",\n  answer = \"C\",\n  \"D\",\n  \"E\"\n)\n\n\ncat(\"Which country is not reporting aggregated data?\", longmcq(opts))\n\n```\n:::\n:::\n\n<details>\n\n<summary style=\"text-decoration: underline; color: red;\">\n\n`r fontawesome::fa(\"check\", fill = \"red\")`Click to see a solution (try\nit yourself first!)\n\n</summary>\n\n</br>\n\n```{r , echo=TRUE}\n# Create a data frame with the overall number of cases reported through the aggregated flux\n\nagg_data_country <- agg_data %>% \n  \n  group_by(country) %>% \n  \n  filter(date_rep == max(date_rep)) %>% # as we have cumulative data, we keep only the last week (after grouping by country)\n  \n  select(-date_rep, -week_date) %>%     # remove unnecessary columns\n\n  mutate(source = \"aggregated\")         # we create this column to distinguish the numbers from the case-based flux\n\n\n# Create a data frame with the overall number of cases reported through the case-based flux\n\ncb_data_country <- cb_data %>%\n  \n  group_by(country) %>% \n  \n  summarise(cases = n(), .groups = \"drop\") %>% \n  \n  mutate(source = \"case_based\")       # we create this column to distinguish the numbers from the\n  \n\n# We append both data frames. Remember this is different from merging\n\ntotal_data <- bind_rows(cb_data_country, agg_data_country)\n\n\n# We create a graph to compare the cases reported in both sources\n\ngraph_comp <- ggplot(data = total_data,\n                     aes(x = source, \n                         y = cases, \n                         fill = source)) +\n  \n  geom_col(position = \"dodge\") +            #position dodge puts bars one next to each other, instead of \"stacked\"\n  \n  facet_wrap(~ country, scales = \"free_y\") +  # this command gives us one graph per country. The argument scales is used to allow each y axis scales to adjust to the data\n\n  scale_fill_viridis_d(\n    labels = c(\"Aggregated\", \"Case-based\")  # this function changes the colours, but with the argument \"labels\" we can change the text of each fill.\n     ) +\n  \n  \n  labs(\n    title = \"Number of cases of Mpox reported in 2022 according to source of data\",\n    fill = \"Source\",\n    x = \"\",\n    y = \"Total number of cases\"\n  ) + \n  \n  theme_bw() +\n  \n  theme(axis.text.x = element_blank(),      # we remove the text of the x axis because it is already present in the legend\n        axis.ticks.x = element_blank())     # we also remove the ticks for aesthetic purposes\n\ngraph_comp\n```\n\n</br>\n\n</details>\n\n## Final thoughts\n\nWell done! Through your analysis you now understand the magnitude of the outbreak so far, where and when it spread, which demographic groups are most affected, and how the disease actually manifests in terms of symptoms and severity. ECDC is very happy with your work. \n\nBy coding this up in R, this analysis should be reproducible, meaning you can quickly update it with new data and keep monitoring the outbreak. To further practise reproducible reports, [link to RMarkdown]. \n\n## Case study information \n\n**Authorship**\n\nOriginal authors: Xanthi Andrianou, Gianfranco Spiteri (ECDC EI Group)\\\nData source: Fictional data provided by ECDC EI Group for training\npurposes\\\n\n| Date         | Changes made       | Version          | Author          |\n|--------------|:-------------------|-----------------:|------------------|\n| October 2021 |First draft         |     1            |  Xanthi Andrianou |\n| June 2024    | Adapted to case study template  | 1.1 | Alberto Mateo Urdiales |\n\n\n**Terms of Use**\n\n<!-- Describe the licencing and other appropriate information about Terms of use or any other disclaimer -->\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":"html_document","warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":false,"css":["../webex.css","webex.css"],"include-after-body":["../webex.js","webex.js"],"output-file":"r_practical.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","published-title":"Last updated","lightbox":true,"babelquarto":{"languagecodes":[{"name":"es","text":"Español"},{"name":"en","text":"English"}],"mainlanguage":"en","languages":["es"]},"title-es":"Estudios de casos de AppliedEpi","bibliography":["../references.bib"],"theme":{"light":"cosmo","dark":["darkly","../theme-dark.scss"]},"number-depth":0,"editor_options":{"chunk_output_type":"console"},"editor":{"markdown":{"wrap":72}}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}