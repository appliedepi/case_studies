[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AppliedEpi cases studies",
    "section": "",
    "text": "Case-studies Open Repository\nInstallazione pacchetto in 'C:/Users/mateourdiales_albert/AppData/Local/R/win-library/4.4'\n(perché 'lib' non è specificato)\n\n\nsi installano anche le dipendenze 'lazyeval', 'crosstalk'\n\n\nWarning: non è possibile accedere all'indice per il repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4:\n  non è possibile aprire URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4/PACKAGES'\n\n\npacchetto 'lazyeval' aperto con successo con controllo somme MD5\npacchetto 'crosstalk' aperto con successo con controllo somme MD5\npacchetto 'DT' aperto con successo con controllo somme MD5\n\nI pacchetti binari scaricati sono in\n    C:\\Users\\mateourdiales_albert\\AppData\\Local\\Temp\\RtmpMznIRa\\downloaded_packages\n\n\n\nDT installed\nObjective : In this repository can help you to develop your epidemiological through case studies covering common epidemiological situations and methods.\nWritten by epidemiologists, for epidemiologists\nApplied Epi is a nonprofit organisation and grassroots movement of frontline epis from around the world. We write in our spare time to offer this resource to the community. Your encouragement and feedback is most welcome:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Case-studies Open Repository</span>"
    ]
  },
  {
    "objectID": "index.html#authors",
    "href": "index.html#authors",
    "title": "AppliedEpi cases studies",
    "section": "Authors",
    "text": "Authors",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Case-studies Open Repository</span>"
    ]
  },
  {
    "objectID": "pages/fulton.html",
    "href": "pages/fulton.html",
    "title": "Fulton (EN)",
    "section": "",
    "text": "Overview\nAuthorship\nOriginal authors: Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer\nData source: Anonymised and jittered data provided by Fulton County for training purposes\nAdapted by: Alberto Mateo Urdiales to the case study template",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fulton (EN)</span>"
    ]
  },
  {
    "objectID": "pages/fulton.html#overview",
    "href": "pages/fulton.html#overview",
    "title": "Fulton (EN)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\nName\nFulton County\n\n\nLanguage\nEnglish\n\n\nTool\nR\n\n\nLocation\nUnited States\n\n\nScale\nLocal\n\n\nDiseases\nCOVID-19\n\n\nKeywords\nCOVID-19; SARS-COV-2; Outbreak\n\n\nTechnical complexity\nIntermediate\n\n\nMethodological complexity\nBasic",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fulton (EN)</span>"
    ]
  },
  {
    "objectID": "pages/fulton.html#instructions",
    "href": "pages/fulton.html#instructions",
    "title": "Fulton (EN)",
    "section": "Instructions",
    "text": "Instructions\n\nGetting Help\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\nHints and Solutions\nHere is what the “helpers” look like:\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\nPosting a question in the Community Forum\n… description here about posting in Community…\n\n\nTerms of Use\nXXXXXXXXXXXXXXXXXXXXX\n\n\n\nFeedback & suggestions\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\nVersion and revisions\nThe first version was written by Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer in August 2021.\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nMar 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuidance\n\nBackground and Objectives of this case study\nThis is a an example R-markdown script which demonstrates how to create an automated outbreak situation report for COVID-19 in Fulton county, USA. The data used comes from an anonymised and fake (scrambled) linelist of COVID-19 cases in Fulton county from the beginning of the pandemic (early 2020) until July 2021.\nThe overall objective is to create an automatic and dynamic report that shows the COVID-19 epidemiological situation in Fulton County.\nIn this case study you will learn:\n\nHow to import, clean and analyse your data.\n\nCarry out descrptive analysis by time, place and person.\n\nUse the above to create an automatic and dynamic report in word using Rmarkdown.\n\n\nFor the purpose of the case study we separate this by descriptive analysis and visualisation (normally this would be mixed together of course). The visualisation section is organised in to place, time and person. This is to simplify flow for didactic delivery.\nAnalysis is loosely based off the monthly epidemiology reports for Fulton county\n\n\n\nPrevious level of expertise assumed\nUsers should have some prior experience with R, including:\n\nR basics: Several packages are required for different aspects of analysis with R. You will need to install these before starting. We install and load packages using the {pacman} package. Its p_load() command will install packages if necessary and load them for use in the current session. This might prove difficult if you have limited administrative rights for your computer. Making sure your IT-department gives you the correct access can save a lot of headache. See this handbook pages on the basics of installing packages and running R from network drives (company computers) for more detail. https://epirhandbook.com/r-basics.html#installation https://epirhandbook.com/r-on-network-drives.html#r-on-network-drives\nR projects: See Chapter 6 R Projects from the EpiRhandbook\nImport and export of data: See Chapter7 Import and export\n\n\n\nPreparation for the case study\n\nDownload folder fulton_en and extract contents in the local laptop\nOpen the Rstudio project inside the folder called fulton_en.Rproj\nInside the folder you can find the Rmd and the word output (weekly report). You can also find a word template that will be used as the template for the report. The Rmd and the output are there to help you if you struggle, but you should try to recreate these yourself following this case study.\nSubfolder data contains fulton COVID-19 data needed for the analysis\nSubfolder solution_materials has a copy of the Rmd document with the solution and a copy Word document with the output requested\nOpen a new Rmarkdown file in RStudio and save it in the root folder fulton_en. If you have any doubts about how to create an Rmarkdown follow the EpiRhandbook instructors here\nThis Rmarkdown file will be the file used throughout the case study and, rendering it will produce the weekly report in word format",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fulton (EN)</span>"
    ]
  },
  {
    "objectID": "pages/fulton.html#step-1-rmarkdown-set-up",
    "href": "pages/fulton.html#step-1-rmarkdown-set-up",
    "title": "Fulton (EN)",
    "section": "Step 1: Rmarkdown set up",
    "text": "Step 1: Rmarkdown set up\nRemember that this case study is created in Rmarkdown and that code goes within “chunks”, which is different from a standard R script. The first steps will be to define the language in which you want the report, the default chunk options and to install/load the necessary packages.\n\nStep 1.1: Define R language\nDepending on where you are and how to carried out R installation, your language “locale” might be different from the language of the report that you want to produce. For example, a french person might have a french “locale”. If that is the case, when creating a graph by day of the week, Monday will be displayed as “lundi”. If that french person wants to create an English report, as for this case study, the language “locale” should be changed.\nTask: Ensure your “locale” is in English and change it into English if it is not.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# To see your language locale\nSys.getlocale()\n\n# To change it into English\nSys.setlocale(\"LC_ALL\", \"English\")\n\n\n\n\n\nStep 1.2: Default chunk options\nChange the default chunk options of your Rmarkdown script to:\n\nhide all code chunks in the report\ndo not show messages or warnings\nshow errors if they appear, but to not stop the rendering\nset up the default figure width to 7 and the figure height to 6\nto show the figure titles on top of the plots by default\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# hide all code chunks in the output, but show errors \nknitr::opts_chunk$set(echo = FALSE,  # hide all code chunks in output\n                      error = TRUE,  # show errors if they appear, but don't stop (produce the word doc)\n                      warning = FALSE, # do not show warnings in the output word doc \n                      message = FALSE, # do not show  messages in the output word doc\n                      fig.width = 7,         # Figure width\n                      fig.height = 6,        # Figure height\n                      fig.topcaption = TRUE  # show figure titles on top of plot\n                     )\n\n\n\n\n\nStep 1.3: Install/load packages\nInstall the following packages that will be needed to carry out the analysis: officedown, officer, rio, here, skimr, janitor, lubridate, epikit, tidyverse, flextable, sf, scales, gtsummary, labelled, ggspatial, patchwork, apyramid and incidence2.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  officedown, # format MS word document output\n  officer,    # add table of contents to output\n  rio,        # importing data  \n  here,       # relative file pathways \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # age_categories() function\n  flextable,  # converting tables to pretty images\n  sf,         # manage spatial data using a Simple Feature format\n  scales,     # define colour schemes for flextables \n  gtsummary,  # summary statistics, tests and regressions \n  labelled,   # create variable labels to be displayed in table outputs\n  ggspatial,  # basemaps and scalebars \n  patchwork,  # combining multiple ggplots \n  apyramid,   # plotting age pyramids \n  webexercises,# for web exericses\n  tidyverse   # data management and visualization\n\n)",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fulton (EN)</span>"
    ]
  },
  {
    "objectID": "pages/fulton.html#step-2-data-import-and-exploration",
    "href": "pages/fulton.html#step-2-data-import-and-exploration",
    "title": "Fulton (EN)",
    "section": "Step 2: Data import and exploration",
    "text": "Step 2: Data import and exploration\n\nStep 2.1: Data import\n\nImport the COVID-19 linelist called covid_example_data.xlsx that can be found in the following path: data/covid_example_data/.\nImport also the csv files named fulton_population.csv found in data/covid_example_data needed to retrieve the population in Fulton County.\n\n\n\nClick to see a solution code (try it yourself first!)\n\n\n\nlinelist_raw &lt;- rio::import(\n  file = here::here(\"data\", \"covid_example_data\", \"covid_example_data.xlsx\"),\n  which = \"in\"\n)\n\n# import population data by zipcode to calculate incidence\npop &lt;- import(\n     here(\"data\", \"covid_example_data\", \"fulton_population.csv\")\n)\n\n\n\n\n\nStep 2.2: Data exploration\nExplore the linelist to understand better the data.\n\nQuestion 2.1: How many rows are present in linelist_raw?\n\n 48 31 82101 5\n\nQuestion 2.2: How many columns are of class numeric?\n\n 8 4 19 31\n\n\n\n\nClick to see a solution code (try it yourself first!)\n\n\n\n# view your whole dataset interactively (in an excel style format)\nView(linelist_raw)\n\n# get mean, median and max values of numeric variables; counts for categorical variables and NAs with summary\nsummary(linelist_raw)\n\n# get information about each variable in a dataset \nskim(linelist_raw)\n\n# view unique values contained in variables - useful for categorical variables\nunique(linelist_raw$case_gender)",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fulton (EN)</span>"
    ]
  },
  {
    "objectID": "pages/fulton.html#step-3-data-cleaning",
    "href": "pages/fulton.html#step-3-data-cleaning",
    "title": "Fulton (EN)",
    "section": "Step 3: Data cleaning",
    "text": "Step 3: Data cleaning\n\nStep 3.1: Create date objects\nCreate an object called surveillance_date defined as 7 days prior to the reporting date (30 June 2021). Then, create another object rounding it to the closest Wednesday. Create two daily sequences of dates, one as the 14 days prior to the surveillance_date and another as 14-28 days prior to the same date. We will use these throughout the case study\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# create a date object for the surveillance\n# Minus 7 days from the date of report (see YAML) to account for lag in reporting lab results\nsurveillance_date &lt;- as.Date(\"2021-06-30\") - 7\n\n# create an epiweek object from the date \n# floor_date() rounds down to the closest week here\nsurveillance_week &lt;- floor_date(surveillance_date,\n                          # round by weeks\n                          unit = \"week\", \n                          # define week to start on Wednesday\n                          week_start = 3)\n\n# define recent (past 14 days) and previous (28 to 14 days prior)\nrecent_period   &lt;- seq(surveillance_week  - 13, surveillance_week, by = 1)\nprevious_period &lt;- seq(surveillance_week  - 27, surveillance_week - 14, by = 1)\n\n# define a text label of date range for the recent period (for table headers)\nrecent_period_labels &lt;- str_glue(\n  format(min(recent_period), format = \"%m/%d\"), \n  \"-\", \n  format(max(recent_period), format = \"%m/%d\")\n)\n\n# define text label of date range for previous period (for table headers) \nprevious_period_labels &lt;- str_glue(\n  format(min(previous_period), format = \"%m/%d\"), \n  \"-\", \n  format(max(previous_period), format = \"%m/%d\")\n)\n\n\n# define a label for past 28 days (for table captions)\nfull_period_labels &lt;- str_glue(\n  format(min(previous_period), format = \"%B %d\"), \n  \"-\", \n  format(surveillance_week, format = \"%B %d, %Y\")\n)\n\n\n\n\n\nStep 3.2: Clean column names\nClean the column names ensuring that names do not contain special characters. Rename the following columns from the raw data:\n\nDate of report (reprt_creationdt_FALSE) to date_report\nDate of birth (case_dob_FALSE) to date_dob\nDate of symptom onset (sym_startdt_FALSE) to date_onset\nDate of positive testing (pos_sampledt_FALSE) to date_positive\nDate of recovery (sym_resolveddt_FALSE) to date_recovery\nDate of hospitalisation (hosp_admidt_FALSE) to date_hospitalized\nDate of discharge (hosp_dischdt_FALSE) to date_discharge\nDate of death (died_dt_FALSE) to date_died\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist_raw %&gt;% \n     clean_names() %&gt;% \n     # NEW name = OLD name\n  rename( \n    date_report         = reprt_creationdt_false,      \n    date_dob            = case_dob_false,              \n    date_onset          = sym_startdt_false,\n    date_recovery       = sym_resolveddt_false, \n    date_hospitalized   = hosp_admidt_false,\n    date_discharge      = hosp_dischdt_false,\n    date_died           = died_dt_false,\n    date_positive       = pos_sampledt_false\n    )\n\n\n\n\n\nStep 3.3: Remove duplicated rows\nRemove rows that have duplicated information on: patient id, gender and date of birth. Keep duplicates in a separate dataframe.\n\n\n Click to read a hint\n\n\nTo store duplicates in a new dataframe you can use the function get_dupes() from the {janitor} package\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# get a data frame of all the duplicates. This is mostly to inspect manually, but can be used for analysing those dropped\nduplicates &lt;- linelist %&gt;% \n     get_dupes(pid, case_gender, date_dob)\n\n# find duplicates based on unique ID, gender and date of birth. Only keep the first occurrence \nlinelist &lt;- linelist %&gt;% \n  distinct(pid, case_gender, date_dob, .keep_all = TRUE)\n\n\n\n\nQuestion 3.2: How many duplicated rows were present in the raw data?\n\n 28 31 38 124\n\n\n\n\nStep 3.4: Change column class and remove data inconsistencies\nUsing the across() function from {dplyr} make the following:\n\nEnsure that dates are considered dates by R\nClean date columns dealing with values that are not compatible with the period under analysis (early 2020 to July 2021)\nMake the column age of numeric class\nSet us NA those with negative ages and missing Date of birth\nMake the zip code column a factor class column\n\n\n\n Click to read a hint\n\n\nThe across() allows to apply the same modification to multiple columns in an easy way. So, these two options are equivalent:\n\n# Without across()\n\nlinelist &lt;- linelist %&gt;% \n  mutate(date_report = as.Date(date_report)) %&gt;% \n  mutate(date_dob = as.Date(date_dob)) %&gt;% \n  mutate(date_onset = as.Date(date_onset)) %&gt;% \n  mutate(date_hospitalized = as.Date(date_hospitalized)) %&gt;% \n  mutate(date_discharge = as.Date(date_discharge)) %&gt;% \n  mutate(date_died = as.Date(date_died)) %&gt;% \n  mutate(date_positive = as.Date(date_positive))\n\n\n# With across()\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = contains(\"date\"), .fns = ~as.Date(.x)))\n\nYou can read more about across() in the EpiRhandbook section\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(\n    .cols = contains(\"date\"),\n    .fns = ~as.Date(.x)\n  )) %&gt;%\n  \n  # mark as missing onset dates prior to 2020\n  mutate(across(\n    .cols = c(date_report, date_onset, date_hospitalized, date_discharge, date_died),\n    .fns  = ~replace(.x, .x &lt; as.Date(\"2020-01-01\"), NA)\n    )) %&gt;% \n\n  # mark as missing dates after the surveillance_date (for this report) from all date columns\n  mutate(across(\n    .cols = contains(\"date\"),\n    .fns  =  ~replace(.x, .x &gt; surveillance_date, NA)\n    )) %&gt;%\n     \n  # transform age into numeric class\n  mutate(\n    # ensure that age is a numeric variable\n    case_age = as.numeric(case_age),\n    # set those with negative ages and missing DOB to missing \n    # otherwise just leave the age value as is\n          # nb. NA_real_ just ensures the variable class is not changed\n    case_age = if_else(case_age &lt; 0 & is.na(date_dob), NA_real_, case_age)\n  ) %&gt;% \n     \n  # create a factor from a default numeric class\n  mutate(case_zip = as_factor(case_zip)) \n\n\n\n\nQuestion 3.3: Which one of the following could NOT be used to transform the column sym_startdt_FALSE from the raw data frame into a date object?\n\n base::as.Date() lubridate::as_date() lubridate::ymd() lubridate::dmy()\n\n\n\n\nStep 3.5: Create a column for weeks\nCreate a column named “epiweek” using the function floor_date() from the {lubridate} package rounding the report date to the nearest week, taking “Wednesday” as the start of the week.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n  # create an \"epiweek\" column from the report date. Use floor_date() to round down to the closest week\n  mutate(epiweek = floor_date(date_report,\n                          # round by weeks\n                          unit = \"week\", \n                          # define week to start on Wednesday\n                          week_start = 3)\n  )\n\n\n\n\n\nStep 3.6: Create time difference columns\nIn this step we ask you to create columns with various time differences that will be used later on in the case study. Please, try to create:\n\nA column with the number (numeric) of days from date of symptom onset to the date of hospitalization\nIn this new column, set as missing those cases where the difference is longer than 30 days (interval is too long for the hospitalization to be due to the infection), and those less than 0 (cannot be hospitalized before the symptom onset)\nUsing the function coalesce() from {dplyr} create a new column for the date of outcome among hospitalized cases, using date of death or date of discharge, depending on whether cases died or not\nCreate a new column with the length of hospitalization in days, calculated as the time difference between date of hospitalization and the recently created date of outcome.\nIn this newly created column mark as missing cases in which the difference between the date of hospitalization and the date of death/discharge was longer than 60 days or lower than 0 days\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;%\n     \n  # delay from onset to hospitalization\n  mutate(\n    # calculate time differences\n    days_onset_hosp = as.numeric(date_hospitalized - date_onset),\n    # set those under 0 or over 30 to missing\n    days_onset_hosp = replace(days_onset_hosp, days_onset_hosp &lt; 0, NA),\n    days_onset_hosp = replace(days_onset_hosp, days_onset_hosp &gt; 30, NA)\n  ) %&gt;%\n     \n  # length of hospitalization\n  mutate(\n    # create outcome date based on whether died or was discharged\n    date_outcome = coalesce(date_died, date_discharge),\n    # calculate time difference\n    days_hosp = as.numeric(date_outcome - date_hospitalized),\n    # set those under 0 or over 60 to missing\n    days_hosp = replace(days_hosp, days_hosp &lt; 0, NA),\n    days_hosp = replace(days_hosp, days_hosp &gt; 60, NA)\n  )\n\n\n\n\n\nStep 3.7: Create age groups\nCreate a column with 10 year age groups up until 70 (and 70+ afterwards) using the age_group() function from the package {epikit}. You can also use any other alternative\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;%\n     # create age group variable\n     mutate(\n       age_group = age_categories(case_age,\n        # define break points\n        c(0, 10, 20, 30, 40, 50, 60, 70),\n        # whether last break should be highest category\n        ceiling = FALSE\n     ))\n\n\n\n\n\nStep 3.8: Recode character/categorical columns\nRecode the following columns:\n\nIn the column named died_covid recode the category “Under Review” to “Unknown”\nIn the column named confirmed_case recode the category “Pending” to “Unknown”\nForce categorical columns to use consistent cases\nAcross character/factor columns recode the category “Unk” to “Unknown”\nAcross the different character/factor columns recode NA to “Unknown”\nIn the column named sym_resolved recode categories into “Yes”, “No” or “Unknown”\nTransform the gender column into a factor with these levels: “Female”, “Male” and “Unknown”\nTransform all columns that have the categories: “Yes”, “No” and “Unknown” into factors with the order of the levels as “Yes”, “No” and “Unknown”\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n     \n     # recode one value and leave the rest as they are \n     mutate(\n       died_covid = if_else(died_covid == \"Under Review\",\n                            \"Unknown\", died_covid), \n       confirmed_case = if_else(confirmed_case == \"Pending\", \n                                \"Unknown\", confirmed_case), \n     \n        # force categorical variables to use consistent cases (this can be done for others) \n        sym_myalgia = str_to_title(sym_myalgia),\n      ) %&gt;% \n     \n     #replace one value and leave the rest, across multiple variables\n      mutate(across(\n       .cols = c(contact_household, contains(\"sym_\")),\n       .fns  = ~if_else(.x == \"Unk\", \"Unknown\", .x)\n     )) %&gt;% \n     \n        # replace missing with \"Unknown\" where relevant \n     mutate(across(\n       .cols = c(case_gender, case_race, case_eth, case_zip,\n                 contact_id, contact_household, \n                 hospitalized, died, died_covid, confirmed_case,\n                 contains(\"sym_\"), age_group),\n       .fns  = ~fct_na_value_to_level(.x, level = \"Unknown\")\n     )) %&gt;% \n     \n          # recode with searching for string patterns \n     mutate(sym_resolved = case_when(\n          str_detect(sym_resolved, \"Yes\")     ~ \"Yes\", \n          str_detect(sym_resolved, \"No\")      ~ \"No\", \n          str_detect(sym_resolved, \"Unknown\") ~ \"Unknown\", \n          TRUE                                ~ \"Unknown\"\n     )) %&gt;% \n     \n      # set levels of a factor (define order)\n     mutate(case_gender      = fct_relevel(case_gender, \"Female\", \"Male\", \"Unknown\")) %&gt;% \n     \n          # set levels of all factors that are yes/no/unknown \n     mutate(across(\n          .cols = c(contact_household, hospitalized, died, died_covid,\n                    confirmed_case, contains(\"sym_\")), \n          .fns = ~fct_relevel(.x, \"Yes\", \"No\", \"Unknown\")\n     )) \n\n\n\n\n\nStep 3.9: Merge ethnicity and race\nThe linelist contains a column for ethnicity (case_eth) and a column for race (case_race). Create a new column merging information from these two existing columns. The new column should:\n\nContain a category “Hispanic, all races” when case_eth is “HISPANIC/LATINO”. For those cases where this condition is not met:\n\nShould have a category for those whose race is “Asian”, another for those whose race is “Black” and another for those whose race is “White”.\nCreate an “Other” category for the rest of races and an “Unknown” category for those with missing race\nEnsure all categories have consistent cases\n\nTransform the newly formed column into a factor with the “Unknown” category as the last level\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nlinelist &lt;- linelist %&gt;% \n          # create a composite category from race and ethnicitiy  \n     mutate(eth_race = case_when(\n          eth  == \"HISPANIC/LATINO\"                           ~ \"Hispanic, all races\", \n          race == \"ASIAN\"                                     ~ \"Asian, NH\", \n          race == \"BLACK\"                                     ~ \"Black, NH\",\n          race == \"WHITE\"                                     ~ \"White, NH\",\n      # find all instances of NATIVE (covers AMERICAN INDIAN/ALASKA NATIVE **AND** NATIVE HAWAIIAN/PACIFIC ISLANDER)\n          str_detect(race, \"NATIVE\")                          ~ \"Other, NH\",\n          race == \"OTHER\"                                     ~ \"Other, NH\", \n          TRUE                                                ~ \"Unknown\"\n     )) %&gt;% \n     mutate(eth_race = factor(eth_race, levels=c(\n          \"Black, NH\", \"White, NH\", \"Hispanic, all races\",\n          \"Asian, NH\", \"Other, NH\", \"Unknown\"\n     )))\n\n\n\n\nQuestion 3.4: A column that has ordinal data, what class should it have?\n\n logical character factor integer\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n\n\nStep 3.10: Filter data frame\nFilter the data to keep only confirmed cases whose date of report is not above the date of the report (June 30, 2021). Consider also keeping records with missing date of report.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n##############       FILTER     ##############        \n\n# store those which do not meet our filter criteria \ndropped &lt;- linelist %&gt;% \n     filter(confirmed_case != \"Yes\" |\n              date_report &gt; surveillance_date & \n                !is.na(date_report))\n\n\n# drop the cases that dont meet the criteria \nlinelist &lt;- linelist %&gt;% \n     filter(confirmed_case == \"Yes\" & \n              date_report &lt;= surveillance_date & \n                 !is.na(date_report))",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fulton (EN)</span>"
    ]
  },
  {
    "objectID": "pages/fulton.html#step-4-start-the-report-with-a-summary-of-the-findings",
    "href": "pages/fulton.html#step-4-start-the-report-with-a-summary-of-the-findings",
    "title": "Fulton (EN)",
    "section": "Step 4: Start the report with a summary of the findings",
    "text": "Step 4: Start the report with a summary of the findings\n\nWrite in rmarkdown three bullet points summarising the data we imported, showing the number of cases by the date of analysis, the number of hospitalisations and the number of deaths.\nWrite it in a dynamic way, so that the dates and numbers are updated automatically if you get a new updated dataset\n\n\n\nClick to see a solution (try it yourself first!)\n\n This is an example of how the code should look like in your rmarkdown file:",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fulton (EN)</span>"
    ]
  },
  {
    "objectID": "pages/fulton.html#step-5.-analysis-by-time",
    "href": "pages/fulton.html#step-5.-analysis-by-time",
    "title": "Fulton (EN)",
    "section": "Step 5. Analysis by time",
    "text": "Step 5. Analysis by time\n\nStep 5.1: Table weekly number of cases\nCreate a table with the number of cases per reporting week to see how the epidemic evolved by time in Fulton County\n\nQuestion 5.1: During which week do we observe the peak in cases by date of reporting?\n\n The week starting on March 02, 2021 The week starting on December 16, 2020 The week starting on January 13, 2021 The week starting on December 30, 2020\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# save a quick descriptive table of number of cases reported by week\nepiweek_table &lt;- linelist %&gt;% \n  # get counts and percentages \n  tabyl(epiweek) %&gt;% \n  # add the overall counts as a row\n  adorn_totals() %&gt;%  \n  # change from proportions to percentages (do not add a % sign)\n  adorn_pct_formatting(affix_sign = FALSE) \n\n# transform it into flextable for better visualisation\nepiweek_flextable &lt;- epiweek_table %&gt;% \n     qflextable()\n\n\n\n\n\nStep 5.2: Epicurve\nCreate an epicurve by reporting week, with the colour of the bins based on whether the cases were hospitalised or not\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n     # we first define the dataset to be used, the x axis which will be reporting week and the colour (fill) of the bins which will depend on hospitalisation outcome\nggplot(\n     data = linelist,\n     mapping = aes(\n          x = epiweek,\n          fill = hospitalized\n     )) + \n     \n     geom_histogram() + \n     \n     # we define that we want breaks by month and formated with scales::label_date_short()\n     scale_x_date(\n          date_breaks = \"month\",\n          labels = label_date_short()\n     ) +\n     \n     # we change the name of the different elements of the graph\n     labs(\n          x = \"\",\n          y = \"Weekly number of cases\",\n          fill = \"Hospitalised\",\n          caption = paste0(\"Data as of \", format(surveillance_date, \"%d %b %Y\"))\n          \n     ) + \n     \n     # we apply one of the predefined themes\n     theme_bw()",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fulton (EN)</span>"
    ]
  },
  {
    "objectID": "pages/fulton.html#step-6.-analysis-by-person",
    "href": "pages/fulton.html#step-6.-analysis-by-person",
    "title": "Fulton (EN)",
    "section": "Step 6. Analysis by person",
    "text": "Step 6. Analysis by person\n\nStep 6.1: Table with demographic information\nCreate a table summarising, with counts and percentages, the total cumulative number of cases and deaths, as well the cases and deaths notified in the last 28 days by demographic characteristics: sex, age and race.\n\nQuestion 6.1: In which age group do we observe the largest proportion of cumulative cases?\n\n 0-9 30-39 20-29 70+\n\nQuestion 6.2: In which race do we observe the largest proportion of deaths in the last 28 days?\n\n Black White Asian Hispanic\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# get counts tables for measures of interest \n############################################\n\n# we generate 3 summary tables and bind them together\n# summary demographic table for gender\ndem_gender &lt;- linelist %&gt;% \n  tabyl(gender) %&gt;% \n  select(Characteristic = gender, n, percent)\n\n# summary demographic table for age\ndem_age &lt;- linelist %&gt;% \n  tabyl(age_group) %&gt;% \n  select(Characteristic = age_group, n, percent)\n\n# summary demographic table for ethnicity and race\ndem_eth_race &lt;- linelist %&gt;% \n  tabyl(eth_race) %&gt;% \n  select(Characteristic = eth_race, n, percent)\n\n# bind all tables together\ntotal_cases &lt;- bind_rows(list(dem_gender, dem_age, dem_eth_race))\n\n# counts of new cases (last 28 days) \nrecent_cases &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter the linelist for dates on or after 28 days ago\n  .f = ~filter(linelist, \n          date_report &gt;= (surveillance_date - 28)) %&gt;% \n        # get counts based on filtered data\n        tabyl(.x) %&gt;% \n        # nb we dont keep the characteristic column because it would be duplicated\n        select(n_cases_recent = n,\n               perc_cases_recent = percent)\n  ) %&gt;%\n  bind_rows()\n\n# counts of total deaths \ntotal_deaths &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter for those who died \n  .f = ~filter(linelist, \n          died_covid == \"Yes\") %&gt;% \n        # get counts based on filtered data \n        tabyl(.x, show_na = TRUE) %&gt;%\n        select(n_deaths_total = n, perc_deaths_total = percent)\n  ) %&gt;% \n  bind_rows()\n\n# counts of new deaths (last 28 days)\nrecent_deaths &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter to those who died in the last 28 days\n  .f = ~filter(linelist, \n          died_covid == \"Yes\" & \n          date_died &gt;= (surveillance_date - 28)) %&gt;% \n        # get counts based on filtered data\n        tabyl(.x) %&gt;% \n        select(n_deaths_recent = n, perc_deaths_recent = percent) %&gt;% \n        # add in a variable column (used for colouring later) \n        mutate(variable = .x)\n  ) %&gt;% \n  bind_rows()\n\n\n# total counts for all of the above measures (not by demographic)\noverall &lt;- linelist %&gt;% \n  summarise(\n    # add in row label \n    Characteristic = \"Total\",\n    # counts of total cases \n    n_cases_total = n(),\n    # leave all percentages empty (would just be 100)\n    perc_cases_total  = NA, \n    # counts of new cases (last 28 days) \n    n_cases_recent = sum(date_report &gt;= (surveillance_date - 28)), \n    perc_cases_recent  = NA, \n    # counts of total deaths \n    n_deaths_total = sum(died_covid == \"Yes\"), \n    perc_deaths_total = NA, \n    # counts of new deaths (last 28 days)\n    n_deaths_recent = sum(died_covid == \"Yes\" & \n                          date_died &gt;= (surveillance_date - 28)),\n    perc_deaths_recent = NA, \n    # add in a variable column (used for colouring later) \n    variable = \"Overall\"\n  )\n\n\n# merge tables together \n#######################\n\n# combine all the demographic tables - side by side\ndemographics_counts &lt;- bind_cols(total_cases, recent_cases, total_deaths, recent_deaths) %&gt;% \n  # mutate each of the proportion columns to be percentages\n  mutate(across(\n    .cols = contains(\"perc\"),\n    .fns = ~round(.x * 100, digits = 1)\n    )) \n# add in the totals row at the top of the merged demographics table\ndemographics_counts &lt;- bind_rows(overall, demographics_counts)\n\n\n# define colour scheme \n######################\n\n# get the column numbers that are percentages (based on the name) \npercentage_cols &lt;- names(demographics_counts) %&gt;% \n  str_detect(\"perc\") %&gt;% \n  which()\n\n# define colour cut-offs for gender column \ngender_colours &lt;- scales::col_bin(\n  # choose colours \n  palette = c(\"#91CF60\", \"#FC8D59\"), \n  # choose min and max (range)\n  domain  = c(0, 100),\n  # choose how to split (in this case above and below 50)\n  bins    = 2\n)\n\n# define colour cut-offs for age column \nage_colours &lt;- scales::col_bin(\n  # choose colours\n  palette = c(\"#91CF60\",\"#FFFFBF\", \"#FC8D59\"),\n  # choose min and max (range)\n  domain  = c(0, 100), \n  # choose cut-off categories \n  bins    = c(0, 5, 20, 100)\n)\n\n# define colour cut-offs for ethnicity column \neth_colours &lt;- scales::col_bin(\n  palette = c(\"#91CF60\",\"#FFFFBF\", \"#FC8D59\"),\n  domain  = c(0, 100), \n  bins    = c(0, 10, 40, 100)\n)\n\n\n# create styled table  \n######################\n\ndemographics_counts %&gt;%\n  # initiate flextable to produce styled output table\n  flextable(\n    # retain variable column for formatting but do not display it\n    col_keys = names(demographics_counts)[-10]\n  ) %&gt;%\n  # redefine column names based on original names\n  set_header_labels(\n    \"n_cases_total\"       = \"Total Confirmed Cases\",\n    \"perc_cases_total\" = \"% of Total Cases\",\n    \"n_cases_recent\"       = \"Confirmed Cases past 28 days\",\n    \"perc_cases_recent\" = \"% of Confirmed Cases past 28 days\",\n    \"n_deaths_total\"       = \"Total Confirmed Deaths\",\n    \"perc_deaths_total\" = \"% of Total Deaths\",\n    \"n_deaths_recent\"       = \"Confirmed Deaths past 28 days\",\n    \"perc_deaths_recent\" = \"% of Confirmed Deaths past 28 days\"\n  ) %&gt;%\n  # move the header text to the centre\n  align(align = \"center\", part = \"header\") %&gt;%\n  # make header text bold\n  bold(part = \"header\") %&gt;%\n  # make the totals row bold (i.e. first row)\n  bold(i = 1, part = \"body\") %&gt;%\n  # fill in the cells\n  # choose the rows with gender counts\n  bg(i = ~variable == \"gender\",\n     # choose the columns with percentages in them\n     j = percentage_cols,\n     # fill in based on previous defined cut-offs\n     bg = gender_colours) %&gt;%\n  bg(i = ~variable == \"age_group\",\n     j = percentage_cols, bg = age_colours) %&gt;%\n  bg(i = ~variable == \"eth_race\",\n     j = percentage_cols, bg = eth_colours) %&gt;%\n  # add horizontal lines after the cells with totals and unknowns\n    # (short-cut to find row ending of each demographic variable)\n  hline(i = ~Characteristic %in% c(\"Total\", \"Unknown\")) %&gt;%\n  # add in footnotes for rows counting unknowns (reference in first column)\n  footnote(i = ~Characteristic == \"Unknown\", j = 1, part = \"body\", ref_symbols = c(\"a\"),\n           value = as_paragraph(\"Unknown includes cases not yet interviewed\")) %&gt;%\n  # add in footnote for deaths counts (ref in the header)\n  footnote(i = 1, j = c(6, 8), part = \"header\", ref_symbols = c(\"b\"),\n           value = as_paragraph(\"Deaths refer to all persons who had a positive PCR test result\n                                for Covid-19 and there is evidence that COVID-19 was the cause of\n                                death or a significant contributor to their death.\")) %&gt;%\n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\") %&gt;% \n  # decrease the fontsize in the header and body for aesthetic purposes in the document\n  fontsize(part = \"all\", size = 8)\n\n\n\n\n\nStep 6.2: Age pyramid\nCreate an age pyramid with the percentage of cases by age group and sex.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# prepare dataset\n\n# start a new dataframe (as dont want to overwrite the original)\nlinelist_2g &lt;- linelist %&gt;% \n  # update the gender and age_group columns\n  mutate(across(.cols = c(gender, age_group), \n                .fns = ~{\n                  # replace \"Unknown\" with NA\n                  .x = na_if(.x, \"Unknown\") \n                  # drop \"Unknown\" from the factor levels \n                  .x = fct_drop(.x)\n                }))\n\n# plot age pyramid \nage_pyramid(\n  data = linelist_2g,\n  age_group = \"age_group\",\n  split_by = \"gender\",\n  # Show as percentages of total cases\n  proportional = TRUE,\n  # remove guide line for mid-point\n  show_midpoint = FALSE) +\n  # set theme to basic \n  theme_minimal() +\n  # add labels \n  labs(\n    title = \"\",\n    subtitle = ,\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = \"Gender\",\n    # use str_glue to set dynamic captions \n    # {missing} is defined in the second argument below\n    caption = str_glue(\n      \"{missing} cases missing either age or gender are not shown. \\n Fictional COVID-19 data\",\n      missing = linelist_2g %&gt;%\n        filter(is.na(gender) | is.na(age_group)) %&gt;%\n        nrow()\n      )\n    )\n\n\n\n\n\nStep 6.3: Scatter plot\nCreate a scatter plot showing the relation between age and duration of hospital stay. Colour the points based on whether cases died or not.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n#################### C) SCATTER PLOT ####################\n# open a plot with the linelist data\nggplot(data = linelist) +\n  # add points \n  geom_point(\n    mapping = aes(\n      # plot age on the x and days hospitalised on the y axis \n      x = age,\n      y = days_hosp,\n      # color points by outcome\n      color = died),  \n    # all points 3x size\n    size = 3, \n    # opacity of 30% (i.e. relatively see-through)\n    alpha = 0.3) +      \n  # make the x and y axes start at the origin \n  scale_y_continuous(expand = c(0, 0)) + \n  scale_x_continuous(expand = c(0, 0)) + \n  # add in labels \n  labs(\n    x = \"Age (years)\",\n    y = \"Duration (days)\",\n    caption = \"Fulton COVID-19 data\",\n    color = \"Deceased\"\n    ) + \n     theme_bw()\n\n\n\n\n\nStep 6.4: Bar plot\nCreate a bar stacked bar plot showing the absolute number of cases by race and vital status\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# open a plot with the linelist data\nggplot(linelist) +\n  # add bars \n  geom_bar(\n    mapping = aes(\n      # plot the number of cases by ethnicity (ordered in reverse frequency)\n      x = fct_rev(fct_infreq(eth_race)),\n      # stack bars and colour by died (ordered in reverse frequency)\n      fill = fct_rev(fct_infreq(died))\n    )\n  ) +\n  # flip the x and y axes \n  coord_flip() +\n  # make the x axes start at the origin (nb axes flipped)\n  scale_y_continuous(expand = c(0, 0), \n                     # define where to label xaxis (nb axes flipped )\n                     breaks = seq(from = 0,\n                                  to = 35000,\n                                  by = 5000)) + \n  # add in labels \n  labs(\n    # set the axes titles (nb axes flipped)\n    x = \"Race and Ethnicity\",\n    y = \"Cases (n)\",\n    caption = \"Fictional COVID-19 data\",\n    fill = \"Deceased\"\n    ) + \n  # apply a defined theme\n     theme_bw()",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fulton (EN)</span>"
    ]
  },
  {
    "objectID": "pages/fulton.html#step-7.-analysis-by-place",
    "href": "pages/fulton.html#step-7.-analysis-by-place",
    "title": "Fulton (EN)",
    "section": "Step 7. Analysis by place",
    "text": "Step 7. Analysis by place\nCreate a table by zip code in which you show the incidence in the most recent 14 days period, the incidence in the previous 14 days period and the percentage change in incidence between these periods.\n\nQuestion 7.1: What is the change in incidence observed between periods in the zip code number 30337?\n\n +20% +36% -62.5% -25%\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n################### TABLE BY ZIP CODE\n\nzip_counts &lt;- linelist %&gt;% \n  group_by(zip) %&gt;% \n  # count cases in the appropriate period \n  summarise(\n    recent   = sum(date_report %in% recent_period),\n    previous = sum(date_report %in% previous_period)\n  ) %&gt;% \n  adorn_totals() %&gt;% \n  # a percentage change column and round the digits\n  mutate(\n    perc_change = round((recent - previous) / previous * 100, digits = 1)\n    )\n\n# extract population counts for each zip from the shapefile\nzip_pop &lt;- shapefile %&gt;% \n  # change to tibble (otherwise geo-data gets pulled with)\n  as_tibble() %&gt;% \n  # only keep zip code and population counts\n  select(ZipCode, Population) %&gt;% \n  # add a row with overall counts\n  adorn_totals()\n  \n# merge case counts and population counts\n# zip (or ZipCode in the shapefile) variable is the unique identifier\nzip_counts &lt;- left_join(zip_counts, \n                        zip_pop, \n                        by = c(\"zip\" = \"ZipCode\")\n                        ) %&gt;% \n  # calculate the incidence \n  mutate(across(\n      # for each period (recent and previous)\n      .cols = c(recent, previous), \n      # divide each variable by population (and round the outcome)\n      .fns = ~round(.x / Population * 10000, digits = 1), \n      # for each period create a new variable with _inc on the end\n      .names = \"{.col}_inc\"), \n    \n    # replace NAs in incidence with 0\n    across(\n      .cols = contains(\"inc\"),\n      .fns = ~replace_na(.x, 0)),\n    \n    perc_change = case_when(\n      # fix the outliers: set missing to 0 and infinity (divided by 0) to 100\n      is.na(perc_change)       ~ 0,\n      is.infinite(perc_change) ~ 100, \n      TRUE                     ~ perc_change\n    ))\n\n\n# choose colours to fill in cells  \nrow_colour &lt;- case_when(\n  # those less than zero will be green (decreasing cases)\n  zip_counts$perc_change &lt; 0 ~ \"#91CF60\", \n  # over zero red (increasing)\n  zip_counts$perc_change &gt; 0 ~ \"#FC8D59\", \n  # missing or zero orange\n  TRUE                       ~ \"#FFFFBF\")\n\n\nzip_counts %&gt;% \n  # keep the columns of interest and define order\n  select(zip, recent, recent_inc, previous, previous_inc, perc_change) %&gt;% \n  # initiate {flextable} to produce styled output table\n  flextable() %&gt;% \n  # fill in cells - choose the column and then pass our colour-scheme defined above\n  bg(j = \"perc_change\", \n     bg = row_colour\n     ) %&gt;% \n  # add in a header for labeling counts and incidence by period \n    # note the empty columns (\"\") to fit to the original table headers\n  add_header_row(\n    values = c(\"\", \n               str_c(\"Recent 14-day reporting period\\n\", recent_period_labels), \n               \"\", \n               str_c(\"Previous 14-day reporting period\\n\", previous_period_labels), \n               \"\", \n               \"Change between reporting periods\"\n               )) %&gt;% \n  # redefine column names based on original names\n    # note the different syntax to dplyr::select, here it is old_name = new_name\n  set_header_labels(\n    zip          = \"Zip Code\", \n    recent       = \"n\", \n    recent_inc   = \"Incidence\", \n    previous     = \"n\", \n    previous_inc = \"Incidence\", \n    perc_change  = \"%\"\n  ) %&gt;% \n  # combine the headers cells for the appropriate periods \n  # (i defines rows, j defines columns)\n  merge_at(i = 1, j = 2:3, part = \"header\") %&gt;% \n  merge_at(i = 1, j = 4:5, part = \"header\") %&gt;% \n  # move the header text to the centre\n  align(align = \"center\", part = \"header\") %&gt;% \n  # make header text bold \n  bold(part = \"header\") %&gt;% \n  # make the row with totals in it bold (i.e. the last row in the dataframe)\n  bold(i = nrow(zip_counts), part = \"body\") %&gt;% \n  # add in footnotes for variables (referencing the header cells)\n  footnote(j = c(3, 5), part = \"header\", ref_symbols = c(\"a\"),\n           value = as_paragraph(\"Incidence calculated as cases per 10,000 population by zip code\")) %&gt;% \n  footnote(j = 6, part = \"header\", ref_symbols = c(\"b\"),\n           value = as_paragraph(\"These reflect the percentage increase or decrease of new diagnoses \n                                between the 14 days preceding the past 7 days and the 14 days\n                                preceding that.\")) %&gt;% \n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\")",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fulton (EN)</span>"
    ]
  },
  {
    "objectID": "pages/fulton.html#step-8.-analysis-of-risk-factors-for-mortality",
    "href": "pages/fulton.html#step-8.-analysis-of-risk-factors-for-mortality",
    "title": "Fulton (EN)",
    "section": "Step 8. Analysis of risk factors for mortality",
    "text": "Step 8. Analysis of risk factors for mortality\n\nCreate a table in which you assess, with the appropriate statistical tests, whether the demographic characteristics of those dying from Covid-19 are significantly different from cases who did not die from it.\nFor each of the variables used in the table that you just created, carry out univariate regression using each demographic variable as the independent variable and the outcome (dead, not dead) as the dependent variables. Create a table with the estimates -alongside 95% CI - of the estimates.\n\n\nQuestion 8.1: According to the results of the univariate analysis, how was having a sore throat associated with mortality from Covid-19\n\n It was a risk factor for mortality It was a protective factor for mortality It was not associated with mortality Impossible to know\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# define a list of variables for looping over later\nsymptom_vars &lt;- linelist %&gt;% \n     # choose all columns that contain \"sym_\" in the name but exclude \"sym_resolved\"\n     select(c(contains(\"sym_\"), -sym_resolved)) %&gt;% \n     # pull the names out \n     names()\n\n# define variables of interest (save typing them out later) \ndescriptive_vars &lt;- c(\"gender\", \n                      \"age_group\",\n                      \"eth_race\",\n                      symptom_vars,\n                      \"hospitalized\",\n                      \"days_hosp\")\n\n# filter dataset  \nrf_data &lt;- linelist %&gt;% \n  # only keep variables of interest\n  select(died_covid, age, all_of(descriptive_vars)) %&gt;% \n  # set unknown back to NA for all factor variables\n  mutate(across(\n    .cols = where(is.factor),\n    .fns = ~fct_recode(.x, NULL = \"Unknown\"))) %&gt;% \n  # flip factor levels (so that the reference values are correct)\n  mutate(eth_race = fct_infreq(eth_race)) %&gt;% \n  mutate(gender = fct_relevel(gender, \"Female\", \"Male\")) %&gt;% \n  mutate(across(all_of(c(\"died_covid\", symptom_vars, \"hospitalized\")), \n                ~fct_relevel(.x, \"No\", \"Yes\")\n                )) %&gt;% \n  # only keep rows with complete data for all variables of interest\n  # note that this will drop rows where **ANY** of the listed variables are NA\n  drop_na(any_of(c(\"died_covid\", \"age\", descriptive_vars)))\n\n\n# define variable labels to show in output tables \nrf_data &lt;- rf_data %&gt;%\n  set_variable_labels(\n    died_covid = \"Died\",\n    age = \"Age (years)\",\n    gender = \"Gender\",\n    age_group = \"Age group (years)\",\n    eth_race = \"Ethnicity\",\n    sym_fever = \"Fever\",\n    sym_subjfever = \"Subjective fever\",\n    sym_myalgia = \"Myalgia\",\n    sym_losstastesmell = \"Loss taste/smell\",\n    sym_sorethroat = \"Sore throat\",\n    sym_cough = \"Cough\",\n    sym_headache = \"Headache\",\n    hospitalized = \"Hospitalized\",\n    days_hosp = \"Days in hospital\"\n  )\n\n\n\nrf_data %&gt;%\n  # keep variables of interest\n  select(died_covid, gender, eth_race, age, days_hosp) %&gt;%\n  # produce summary table and specify grouping variable\n  tbl_summary(\n    by = died_covid\n  ) %&gt;%\n  # specify what test to perform\n  add_p(\n    list(\n      all_continuous() ~ \"kruskal.test\",\n      eth_race ~ \"kruskal.test\",\n      all_dichotomous() ~ \"chisq.test\"\n    )\n  ) %&gt;%\n  # edit what the column headers say (using {gtsummary})\n  # nb. {n} automatically shows the number in that group and \\n is a linebreak\n  modify_header(update = list(\n    stat_1 ~ \"**Dead**\\n (N={n})\",\n    stat_2 ~ \"**Alive**\\n (N={n})\"\n  )) %&gt;%\n  # edit what it says in the footnote (using {gtsummary})\n  modify_footnote(update = list(\n    all_stat_cols() ~ \"n (%) for categorical;\\n median (IQR) for continuous\",\n    p.value ~ \"Pearson's Chi-squared test for dichotomous;\\n Kruskal-Wallis rank sum test for continuous and categorical\"\n  )) %&gt;%\n  # change to flextable format\n  as_flex_table() %&gt;%\n  # make header text bold (using {flextable})\n  bold(part = \"header\")\n\n###################### B) UNIVARIATE REGRESSION ANALYSIS ####################################\n\n\n# produce table with regression estimates\nregress_tab &lt;- rf_data %&gt;%\n  # drop variables not interested in \n  select(-age_group) %&gt;%\n  # produce univariate table\n  tbl_uvregression(\n    # define outcome variable\n    y = died_covid, \n    # define regression want to run (generalised linear model)\n    method = glm, \n    # define what type of glm want to run (logistic)\n    method.args = list(family = binomial), \n    # exponentiate to produce odds ratios (rather than log odds)\n    exponentiate = TRUE, \n    # do not show the overall counts (this is done in cross_tab below)\n    hide_n = TRUE,\n    ## uncomment this line if you want to not show reference rows\n    # show_single_row = c(symptom_vars, gender, hospitalized),\n    ## note: NULL at the end allows you to have a comma before a commented out row\n    NULL\n  )\n\n# produce table with counts by outcome (using the data fed to the regression above)\ncross_tab &lt;- regress_tab$inputs$data %&gt;%\n  tbl_summary(\n    # group by outcome \n    by = died_covid,\n    ## uncomment this line if you only want to show the \"Male\" row for gender\n    ## this would be run if you also uncommented the single_row in regression above\n    # value = list(gender ~\"Male\"),\n    ## show all levels (otherwise only shows the \"Yes\" level)\n    type = list(all_dichotomous() ~ \"categorical\"),\n    ## note: NULL at the end allows you to have a comma before a commented out row\n    NULL\n  )\n\n# combine tables \ntbl_merge(list(cross_tab, regress_tab)) %&gt;%\n  # edit what it says in the grouping headers \n  modify_spanning_header(update = list(\n    c(\"stat_1_1\",\"stat_2_1\") ~ \"Died\",\n    c(\"estimate_2\", \"ci_2\", \"p.value_2\") ~ \"Univariate regression\")\n    ) %&gt;% \n  # edit what it says in the footnote (using {gtsummary})\n  modify_footnote(update = list(\n    all_stat_cols() ~ \"n (%) for categorical;\\n median (IQR) for continuous\")\n    ) %&gt;% \n  # change to flextable format\n  as_flex_table() %&gt;%\n  # make header text bold (using {flextable})\n  bold(part = \"header\") %&gt;% \n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\")",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fulton (EN)</span>"
    ]
  },
  {
    "objectID": "pages/r_practical_epiet.html",
    "href": "pages/r_practical_epiet.html",
    "title": "",
    "section": "",
    "text": "Introductory Course: R basics practical\nAuthorship\nOriginal authors: Xanthi Andrianou, Gianfranco Spiteri (ECDC EI Group)\nData source: Fictional data provided by ECDC EI Group for training purposes\nAdapted by: Alberto Mateo Urdiales to the case study template",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>![](../images/ecdc/logo_epiet_rki.png){width=12in}</span>"
    ]
  },
  {
    "objectID": "pages/r_practical_epiet.html#overview",
    "href": "pages/r_practical_epiet.html#overview",
    "title": "R basics practical (ENG)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\nName\nR practical\n\n\nLanguage\nEnglish\n\n\nTool\nR\n\n\nLocation\nEU\n\n\nScale\nInternational\n\n\nDiseases\nMpox\n\n\nKeywords\nMpox; Cleaning; Descriptives\n\n\nTechnical complexity\nBasic\n\n\nMethodological complexity\nBasic\n\n\n\n\n\nInstructions\n\nGetting Help\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\nHints and Solutions\nHere is what the “helpers” look like:\n\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see the solution\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\n\nPosting a question in the Community Forum\n… description here about posting in Community… TO BE COMPLETED BY APPLIED EPI\n\n\nTerms of Use\n\n\n\n\nFeedback & suggestions\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\nVersion and revisions\nThe first version was written by Xanthi Andrianou in October 2021.\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nJune 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R basics practical (ENG)</span>"
    ]
  },
  {
    "objectID": "pages/r_practical_epiet.html#guidance",
    "href": "pages/r_practical_epiet.html#guidance",
    "title": "",
    "section": "Guidance",
    "text": "Guidance\n\nBackground\nThe practical is based on a scenario that requires the analysis of surveillance data coming from two sources: case-based information reported by countries and aggregated case data collected from open sources. The datasets have been created to resemble the data collected during monitoring of mpox in Europe in 2022.\n\n\nScenario and objectives\nMpox has been reported in 5 countries for the first time in 2022. We have collected aggregated case numbers from open sources, and we have also reported case-based data. The objectives of the practical are the following: 1. Explore different types of files and how they can be imported in R 2. Perform basic data cleaning, e.g., changing the variable type, recode variables, aggregate and filter 3. Perform a basic descriptive analysis using tables and graphs\n\n\nPrevious level of expertise assumed\nTo follow this case study you should be already familiar with the layout of Rstudio and on basic R concepts, such as packages, functions and arguments.\nIf you feel you need to familiarise a bit further with these aspects, read the EpiRhandbook chapter on R basics\n\n\nPreparation for the case study\n\nDownload folder named r_practical and extract contents in the local laptop\nCreate an Rstudio project in the folder r_practical. If you are unsure on how to do that, read the EpiRhandbook on R projects\nInside “r_practical”: Subfolder “data” contains the raw data you will use in this case study. You should see six different files, three called E_pox_aggregated_data and three E_pox_case_based_data. Each has a specific file type.\nInside “r_practical”: Subfolder “scripts” should be used to save any scripts related to the analysis. Inside scripts there is another subfolder called “backup” where you can find a solution R script for each step in case you are stuck at any point or if you want to compare your own script with the solution one.\nInside “r_practical”: Subfolder “outputs” can be used to store any outputs (tables, graphs, documents) that are the result of the analysis.",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>![](../images/ecdc/logo_epiet_rki.png){width=12in}</span>"
    ]
  },
  {
    "objectID": "pages/r_practical_epiet.html#step-1-getting-ready-for-importing-the-data",
    "href": "pages/r_practical_epiet.html#step-1-getting-ready-for-importing-the-data",
    "title": "",
    "section": "Step 1: Getting ready for importing the data",
    "text": "Step 1: Getting ready for importing the data\n\nStep 1.1: Create a new R script\nOnce you have created an Rproject inside the “r_practical” folder (as specified in the second point of the section Preparation for the case study). Create a new script with the name mpox_rpractical and save it in the subfolder “scripts”. If you are familiar with Rmarkdown, you may decide to use this type of file instead of a standard R script.\n\n\nStep 1.2: Define R language\nDepending on where you are and how to carried out R installation, your language “locale” might be different from the language of the graphs that you want to produce. For example, a french person might have a french “locale”. If that is the case, when creating a graph by day of the week, Monday will be displayed as “lundi”. If that french person wants to create an English report, as for this case study, the language “locale” should be changed.\nTask: Ensure your “locale” is in English and change it into English if it is not. If you don’t know how to do this try finding it online (searching for online help is an important skill for R users!). Otherwise, see the solution below\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# To see your language locale\nSys.getlocale()\n\n# To change it into English\nSys.setlocale(\"LC_ALL\", \"English\")\n\n\n\n\n\nStep 1.3: Install/load packages\nAs you probably know, the first part of our script (besides including -commented- some information about the aim, author, date last updated and contact details) is to install and load packages. Fortunatelly there is a package that does this task very effectively: {pacman}. The function p_load() from this package will install any packages listed not already installed and will load them. If a listed package had already been installed, it will just load it. You can find more about installing/loading packages in the Packages section of the EpiRhandbook.\nUsing this approach, try to install and load the following packages: rio, janitor, lubridate, skimr, epikit, gtsummary, apyramid and tidyverse.\n\n\n Click to read a hint\n\n\nYou may end up using a long list of packages. Unfortunately different packages have functions with the same name. For example, the package {dplyr} (already installed with {tidyverse}) has a function called select() which we frequently use to subset columns of a data frame. But other packages such as {MASS} do also have a function called select(). This could create headaches if you want to subset columns using dplyr’s select() but R thinks you’re calling MASS’s select() (we call this masking - dplyr’s select() is masked by MASS’s select()). Given that you are more likely to use functions from {tidyverse}, ensure that this is the last package in your p_load() list so that functions from {tidyverse} (including {dplyr} functions) will always “prevail”.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # to create age categories\n  gtsummary,  # summary statistics, tests and regressions \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n)",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>![](../images/ecdc/logo_epiet_rki.png){width=12in}</span>"
    ]
  },
  {
    "objectID": "pages/r_practical_epiet.html#step-2-import-and-explore-the-data",
    "href": "pages/r_practical_epiet.html#step-2-import-and-explore-the-data",
    "title": "",
    "section": "Step 2: Import and explore the data",
    "text": "Step 2: Import and explore the data\n\nStep 2.1: Import the different data frames\nThere are several ways in which you can import the different data frames. Inside “data/raw” you have three different types of files: csv, json and excel. One way would be to use a specific R function to import each file. For example, read.csv() from {base} can be used to import .csv files, fromJSON() function from {jsonlite} to import .json files and read_excel() from {readxl} to import .xlsx files. Fortunately, there is a more efficient approach which is to use the import() function from {rio} to open any file. This function will recognise the type of file and choose the appropriate function to import it. If you feel you need to know more about importing functions, read the Import and export chapter of the EpiRhandbook.\nTask: Import the three case-based data frames and the three aggregated data frames using import() from {rio}.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Importing ------------------------------------------------------\n# Case-based data\ncb_data_raw_csv &lt;- import(\"data/E_pox_case_based_data.csv\")\ncb_data_raw_json &lt;- import(\"data/E_pox_case_based_data.json\")\ncb_data_raw_xlsx &lt;- import(\"data/E_pox_case_based_data.xlsx\")\n\n# Aggregated data\nagg_data_raw_csv &lt;- import(\"data/E_pox_aggregated_data.csv\")\nagg_data_raw_json &lt;- import(\"data/E_pox_aggregated_data.json\")\nagg_data_raw_xlsx &lt;- import(\"data/E_pox_aggregated_data.xlsx\")\n\n\n\n\n\nStep 2.2: Explore the different data frames\nTake a look at the different data frames and try to find out:\n\nThe number of columns and observations\nThe class of their columns and whether it matches its nature (e.g., are “dates” considered “dates” by R?)\nLook at the different categories of the columns about gender, clinical symptoms, outcome, hiv status and sexual orientation existing in the case-based data. Do you need to recode any of them?\nHow is unknown or missing data being categorised in these columns? Should you standardise this category?\nIf case-based and aggregated data from file types (.csv, .json and .xlsx) are exactly the same, remove the .json and .xlsx data frames from your environment.\n\n\n\n Click to read a hint\n\n\nAn efficient way to explore data is to use the function skim() from the {skimr} package, as it gives you all the information needed with only one command. Of course, there are several alternatives. To know the different categories in a column, you can use the function tabyl() from {janitor}, which will give you counts and percentages of every category in the data column.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Explore the different case-based data frames\n\nskim(cb_data_raw_csv)\nskim(cb_data_raw_json)\nskim(cb_data_raw_xlsx)\n\n# Explore the different categories of gender and clinical columns in one of the cb data frames\ntabyl(cb_data_raw_csv, Gender)\n\ntabyl(cb_data_raw_csv, ClinicalSymptoms)\n\ntabyl(cb_data_raw_csv, Outcome)\n\ntabyl(cb_data_raw_csv, HIVStatus)\n\ntabyl(cb_data_raw_csv, SexualOrientation)\n\n# Explore the different aggregated data frames\n\nskim(agg_data_raw_csv)\nskim(agg_data_raw_json)\nskim(agg_data_raw_xlsx)\n\n# Remove json and xlsx files as they are exactly the same as the csv ones. Within rm() we ask for the objects containing the pattern \"json\" or \"xlsx\" to be removed from the environment\nrm(list = ls(pattern = \"json|xlsx\"))\n\n\n\n\nHow many columns does the aggregated data frame have?\n\n 2000 13 3 101\n\n\n\nWhat is the class of the column DateOfNotification in the case-based data?\n\n Date Character Numeric Factor\n\n\n\nFor how many cases is the HIV status Unknown or missing?\n\n 1168 722 900 446",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>![](../images/ecdc/logo_epiet_rki.png){width=12in}</span>"
    ]
  },
  {
    "objectID": "pages/r_practical_epiet.html#step-3-cleaning-the-data",
    "href": "pages/r_practical_epiet.html#step-3-cleaning-the-data",
    "title": "",
    "section": "Step 3: Cleaning the data",
    "text": "Step 3: Cleaning the data\n\nStep 3.1: Clean the case-based data\nWhen exploring the case-based data, you may have noticed that there are a few things that we need to take care of before we can start doing further analysis. Firstly, names contain a mixture of upper and lower case letters. Whilst this isn’t in itself a problem, R is case-sensitive, so having all names in lower case may make our life easier. Also, date columns are not consider “Dates” by R, but instead they are being consider as “Character”, which means they are being considered as nominal data. This would give us problems when plotting by Dates. Another issue is that some columns have categories that may not be intuitive for all. For example, Gender is categorised with “F”, “M”, “O” and “UNK”. The column Outcome as “A” and “UNK”. We should give them more appropriate categories. Finally, it is important that missing data is considered as “missing” in R. That means that R treats it as “NA”. In the column clinical symptoms, for example, missing data is an empty cell, not “NA”. R is considering this as another nominal category instead of missing, and will consider it this way in any analysis or output you produce.\nTasks:\n\nCreate a clean version of your case-based data making all cleaning changes in a single piping command\nChange all column names to lower case.\nConvert all date columns to class “Date”.\nUse the column “DateOfNotification” to create a column called “week_date” which has the week of notification, starting on Mondays.\nTransform all empty cells into “NA”\nRecode “Gender” categories into : “Female”, “Male”, “Other” and “Unknown”\nRecode “Outcome” categories into: “Alive” and “Unknown”\nRecode HIV status into: “Positive”, “Negative” and “Unknown/Missing”\nRecode Sexual orientation into: “Bisexual”, “Heterosexual”, “MSM/homo or bisexual male” and “Unknown/missing”.\nCreate a column called “age_group” with ten year age groups and the oldest group being 70+\nCheck that all changes have been made correctly\n\n\n\n Click to read a hint\n\n\nTo convert all names to lower case, rather than renaming each column you may use the function clean_names() from the {janitor} package, which will do it automatically for all columns. Use lubridate functions to transform date columns into “Date” class, you can do one by one, or you could do all at the same time using the across() function from {dplyr}. If you feel you need to know more about transforming dates read the chapter Working with Dates from the EpiRhandbook.If you are not sure how to use the across() function, you can also read the section on Transform multiple columns.\nOne simple way to create the “week_date” column would be to use the function floor_date() from {lubridate}. Take a look at the documentation to understand how it works and how to make Monday the starting day of the week.\nThere are different functions that we can use to recode. We propose three: The function recode() from {dplyr}, the function ifelse() from {base} and the function case_when() from {dplyr}. If you want to know more about these functions, look that the section on Re-code values from the EpiRhandbook.\nTo create the age groups, explore the function called age_categories() from the {epikit} package.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Create a new object called cb_data which is the clean version of the raw data, applying the cleaning functions\n\n\ncb_data &lt;- cb_data_raw_csv %&gt;% \n  \n  clean_names() %&gt;% # standardises names and puts all into lower case \n  \n  #(Note: after this point all column names have changed)\n  \n  mutate(date_of_notification = ymd(date_of_notification)) %&gt;%  #transform ONE column into date\n\n  mutate(across(starts_with(\"date\"), \n                .fns = ~ ymd(.x))) %&gt;%  #transforms ALL columns starting with \"date\" into dates\n  \n  mutate(week_date = floor_date(date_of_notification, # create week column with Monday start\n                              unit = \"week\",\n                              week_start = \"Monday\")) %&gt;% \n  \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x == \"\", NA, .x)))  %&gt;% #transforms empty cells into NA across all character columns\n  \n  mutate(gender = recode(gender,\n                         \"F\" = \"Female\",\n                         \"M\" = \"Male\",\n                         \"O\" = \"Other\",\n                         \"UNK\" = \"Unknown\")) %&gt;%\n  \n    \n  mutate(across(where(is.character), \n                .fns = ~ ifelse(.x == \"UNK\", \"Unknown\", .x)))  %&gt;% #transforms UNK to Unknown across all character columns\n  \n  mutate(outcome = ifelse(outcome == \"A\", \"Alive\", outcome)) %&gt;%   #we can recode as well with ifelse if we want to change only one or two categories\n  \n  mutate(hiv_status = case_when(hiv_status == \"NEG\" ~ \"Negative\",    #for more complex recoding better case_when\n                                hiv_status == \"POS\" ~ \"Positive\",\n                                TRUE                ~ \"Unknown/missing\")) %&gt;% \n  \n  mutate(sexual_orientation = case_when(sexual_orientation == \"BISEXUAL\" ~ \"Bisexual\",\n                                        sexual_orientation == \"HETERO\" ~ \"Heterosexual\",\n                                        sexual_orientation == \"MSM\" ~ \"MSM/homo or bisexual male\",\n                                        TRUE                        ~  \"Unknown/missing\")) %&gt;% \n  \n  mutate(age_group = age_categories(age, \n                                    lower = 0,      #set up the lower age\n                                    upper = 70,     #set up the upper age\n                                    by = 10))       #set up the age breaks\n\n\n\n\n# Check that all changes have been made correctly\n\nskim(cb_data)\n\ntabyl(cb_data, gender)\n\ntabyl(cb_data, clinical_symptoms)\n\ntabyl(cb_data, outcome)\n\ntabyl(cb_data, hiv_status)\n\ntabyl(cb_data, sexual_orientation)\n\ntabyl(cb_data, week_date)\n\ntabyl(cb_data, age_group)\n\n\n\n\nHow many male cases we have in the data frame?\n\n 36 1960 65 1523\n\n\n\nWhich week has the largest number of cases?\n\n 2022-04-11 2022-07-25 2022-02-28 2022-05-09\n\n\n\nHow many cases with missing age are present?\n\n 1 3 None 396\n\n\n\n\nStep 3.2: Clean the aggregated data\nIn a similar way, clean the aggregated data by:\n\nStandardising names to lower case\nEnsure that date of reporting is of class “Date”\nCreate a column called “week_date” with the week of reporting starting on Monday\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Check class of date of reporting column\n\nclass(agg_data_raw_csv$DateRep) #It is a date, so we do not need to change its class\n\n# Create a new object called agg_data which is the clean version of the raw data, applying the cleaning functions\n\nagg_data &lt;- agg_data_raw_csv %&gt;% \n  \n  clean_names() %&gt;% # standardises names and puts all into lower case \n  \n  #(Note: after this point all column names have changed)\n  \n  mutate(week_date = floor_date(date_rep, # create week column with Monday start\n                              unit = \"week\",\n                              week_start = \"Monday\"))",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>![](../images/ecdc/logo_epiet_rki.png){width=12in}</span>"
    ]
  },
  {
    "objectID": "pages/r_practical_epiet.html#step-4-basic-descriptives",
    "href": "pages/r_practical_epiet.html#step-4-basic-descriptives",
    "title": "",
    "section": "Step 4: Basic descriptives",
    "text": "Step 4: Basic descriptives\n\nStep 4.1: Table my place (country)\nTask: Using the case-based data, create a table with the number of cases by country\n\n\n Click to read a hint\n\n\nAn easy way to produce tables is using the function tbl_summary() from {gtsummary} package\n\n\n\nWhat’s the country with the largest percentage of cases?\n\n C D B A\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Create an object with the table\ncb_country_table &lt;- cb_data %&gt;%\n\n  select(country) %&gt;% #select the column that we want to use in the table\n  \n  gtsummary::tbl_summary() # create the table\n\n# Ask R to print the table\ncb_country_table\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 2,000\n1\n\n\n\n\ncountry\n\n\n\n\n    CountryA\n816 (41%)\n\n\n    CountryB\n391 (20%)\n\n\n    CountryC\n474 (24%)\n\n\n    CountryD\n217 (11%)\n\n\n    CountryE\n102 (5.1%)\n\n\n\n1\nn (%)\n\n\n\n\n\n\n\n\n\n\n\n\nStep 4.2: Epicurve by week of notification (overall)\nTask: Using the case-based data, create an epicurve by week of notification\n\n\n Click to read a hint\n\n\nTo do the epicurve, you can use ggplot() and geom_histogram(), which will automatically aggregate your data. If you are unsure on how ggplot() works, read the EpiRhandbook chapter on Epidemic curves\nAn alternative approach is to first aggregate the number of cases by week of notification. You can do this using the functions group_by() and summarise() from {dplyr}. If you are unsure on how to do this, review the Grouping data chapter of the EpiRhandbook.\nOnce you have an object with aggregated cases by week of notification, create the epicurve using ggplot() \n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nepicurve_epox &lt;- ggplot(data = cb_data,          #data to be used\n                        aes(x = week_date)) +    #with geom_histogram() you only need to assign the x axis\n  \n  geom_histogram(binwidth = 7,                   #binwidth 7 ensures that the width represents 7 days\n                 fill=\"darkgreen\",               #colour inside the bins\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  \n  labs(title=\"Mpox cases reported in 2022\") +  #add a title\n  \n  theme_bw() +                                  #assign a predefined theme\n  \n  theme(axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n           \n  \nepicurve_epox\n\n\n\n\n\n\n\n\n\n\n\n\nStep 4.3: Epicurve by week of notification (by country)\nTask: Using the case-based data, create an epicurve by week of notification in which the colour of the bins represents the number of cases by country\n\n\n Click to read a hint\n\n\nThe code will be very similar to the previous one, but remember that if want a dynamic colour inside the bins, you need to assign the fill to the column you want to use (country) and place it inside the aesthetics \n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nepicurve_epox_country &lt;- ggplot(data = cb_data,  #data to be used\n                        aes(x = week_date,       \n                            fill = country)) +   #now the fill needs to be inside aes()  \n  \n  geom_histogram(binwidth = 7,                   #binwidth 7 ensures that the width represents 7 days\n                 color=\"white\",                  #outline colour of the bins\n                 alpha=0.8) +                    #transparency of the bins\n  \n  scale_fill_viridis_d() +                       #we change the predefined colours\n\n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n\n  \n  labs(title=\"Mpox cases reported by country in 2022\") +  #add a title\n  \n  theme_bw() +                                  #assign a predefined theme\n  \n  theme(legend.position = \"bottom\",             #legend position to the bottom\n        axis.text = element_text(size=9),       #define the font size of the axis text\n        axis.title = element_blank(),           #remove the titles of the x and y axis \n        axis.text.x = element_text(angle=90),   #rotate the x axis text\n        legend.title = element_blank())         #remove title of legend\n           \n  \nepicurve_epox_country\n\n\n\n\n\n\n\n\n\n\n\n\nStep 4.4: Demographic characteristics\nNow that we have created some outputs by time and place, we should focus on the “person” element. The two most important demographic characteristics are usually age and gender. In the case we are seeing, we may also want to explore the sexual orientation of cases.\nTask:\n\nExplore the number of cases by age group and gender.\nCreate a table with number and percentages of cases by sexual orientation\n\n\n\n Click to read a hint\n\n\nThe easiest way to explore both columns (age_group and gender) would be to use the tabyl() function from {janitor}. Then, to create the age pyramid explore the function age_pyramid() from the {apyramid} package. You can find more about this function in the EpiRhandbook chapter Demographic pyramids and Likert-scales To create the table by sexual orientation, consider using the function tbl_summary() from {gtsummary}\n\n\n\nWhich demographic group is more affected by Mpox?\n\n Females 60-69 Males 40-49 Females 10-19 Males 30-39\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Explore gender and age group columns\ntabyl(cb_data, gender)\n\n  gender    n percent\n  Female   36  0.0180\n    Male 1960  0.9800\n   Other    1  0.0005\n Unknown    3  0.0015\n\ntabyl(cb_data, age_group)\n\n age_group   n percent valid_percent\n       0-9   1  0.0005  0.0005007511\n     10-19  33  0.0165  0.0165247872\n     20-29 396  0.1980  0.1982974462\n     30-39 766  0.3830  0.3835753630\n     40-49 524  0.2620  0.2623935904\n     50-59 204  0.1020  0.1021532298\n     60-69  64  0.0320  0.0320480721\n       70+   9  0.0045  0.0045067601\n      &lt;NA&gt;   3  0.0015            NA\n\n# Table with sexual orientation \n\ntab_sor &lt;- cb_data %&gt;% \n  \n  select(sexual_orientation) %&gt;% \n  \n  tbl_summary(label = list(sexual_orientation ~ \"Sexual Orientation\")) \n\ntab_sor\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 2,000\n1\n\n\n\n\nSexual Orientation\n\n\n\n\n    Bisexual\n7 (0.4%)\n\n\n    Heterosexual\n46 (2.3%)\n\n\n    MSM/homo or bisexual male\n833 (42%)\n\n\n    Unknown/missing\n1,114 (56%)\n\n\n\n1\nn (%)\n\n\n\n\n\n\n\n\n\n\n\n\nStep 4.5: Clinical characteristics\nNow, let’s summarise the main clinical information that we have in our case-based data frame.\nTasks:\n\nCreate a bar plot with the proportion of each type clinical symptoms\nCreate a table with the number and percentage of cases by outcome\nCreate a table with sexual orientation by HIV status. You may add a statistical test to ascertain if there are significant differences between groups.\n\n\n\n Click to read a hint\n\n\nTo create bar plots we can use geom_bar() or geom_col() depending on the nature of our data. If we aggregate first, we can use geom_col(), otherwise we should use geom_bar(). There is a function of the {gtsummary} package called add_p() which enables you to easy calculate a statistical test across groups. If you want to know more read the section on gtsummary package of the EpiRhandbook.\n\n\n\nAre there significant differences in HIV status across cases according to their sexual orientation ?\n\n Yes No\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Bar plot with clinical symptoms\n\nbar_clinical &lt;- cb_data %&gt;% \n  \n  drop_na(clinical_symptoms) %&gt;%   # we remove those with missing clinical symptoms\n  \n  group_by(clinical_symptoms) %&gt;% \n  \n  summarise(n_cases = n(), .groups = \"drop\") %&gt;%\n  \n  mutate(prop=(n_cases/sum(n_cases))*100) %&gt;%  # we create a column with proportions\n  \n  ggplot(aes(y = reorder(clinical_symptoms, prop), x = prop)) +  # the reorder function ensures that categories are ordered by proportion in the graph\n  \n  geom_col(fill = \"darkgreen\") + \n  \n  labs(\n    title= \"Frequency of clinical symptoms in Mpox cases\",\n    y = \"\",\n    x = \"Number of cases\"\n  ) +\n  \n  theme_bw() +\n  \n  theme(axis.text = element_text(size=9))       #define the font size of the axis\n\nbar_clinical  \n\n\n\n\n\n\n\n# Table with number and percentage of cases by outcome\n\ntab_outcome &lt;- cb_data %&gt;% \n  \n  select(outcome) %&gt;% \n  \n  tbl_summary(label = list(outcome = \"Reported outcome\")) # with the argument \"label\" we can change how the column name is displayed\n\ntab_outcome\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 2,000\n1\n\n\n\n\nReported outcome\n\n\n\n\n    Alive\n1,405 (70%)\n\n\n    Unknown\n595 (30%)\n\n\n\n1\nn (%)\n\n\n\n\n\n\n\n# Table with sexual orientation by HIV outcome\n\ntab_hiv_sor &lt;- cb_data %&gt;% \n  \n  select(hiv_status, sexual_orientation) %&gt;% \n  \n  filter(hiv_status != \"Unknown/missing\") %&gt;% # we remove the Unknown\n  \n  tbl_summary(by = hiv_status, label = list(sexual_orientation ~ \"Sexual Orientation\")) %&gt;% \n  \n  add_p()                                     # this function will estimate a p value with the appropriate statistical test based on the class of the columns and the number of observations\n\ntab_hiv_sor\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nNegative, N = 525\n1\nPositive, N = 307\n1\np-value\n2\n\n\n\n\nSexual Orientation\n\n\n\n\n0.4\n\n\n    Bisexual\n3 (0.6%)\n1 (0.3%)\n\n\n\n\n    Heterosexual\n14 (2.7%)\n3 (1.0%)\n\n\n\n\n    MSM/homo or bisexual male\n219 (42%)\n131 (43%)\n\n\n\n\n    Unknown/missing\n289 (55%)\n172 (56%)\n\n\n\n\n\n1\nn (%)\n\n\n2\nFisher’s exact test",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>![](../images/ecdc/logo_epiet_rki.png){width=12in}</span>"
    ]
  },
  {
    "objectID": "pages/r_practical_epiet.html#step-5-optional-analysis",
    "href": "pages/r_practical_epiet.html#step-5-optional-analysis",
    "title": "",
    "section": "Step 5: Optional analysis",
    "text": "Step 5: Optional analysis\nIf you have time, let’s now undertake some further analysis. First we will look at data quality. We will check two things:\n\nIn the case-based data, what’s the delay between symptom onset, diagnosis and notification?\nAre numbers from case-based data consistent with the aggregated data?\n\nThen, we will test your skills in data visualisation creating a heat plot.\n\nStep 5.1: Delay between date of onset, diagnosis and notification\nTasks\n\nCalculate median time from symptom onset to diagnosis and from diagnosis to notification, both overall and by country\nAssess visually the number of cases by calendar period and type of date (onset, diagnosis and notification)\n\n\n\n Click to read a hint\n\n\nTo plot together the different dates you may need to transform your data from “wide” to “long” form. What we call “pivoting” in R. The objective is to have a column with the different date categories (onset, diagnosis and notification) and another column with their date value. If you are unsure on how to do this, have a look at the PivoTing data chapter of the EpiRhandbook. Then, try to plot with the daily values, but if that’s not easy to interpret you may want to aggregate cases by week.\n\n\n\nIs there a difference in the delay from diagnosis to notification by country?\n\n Yes No\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Estimate delay between onset and diagnosis, and between diagnosis and notification\n\ndelay_db &lt;- cb_data %&gt;% \n  \n  mutate(delay_diag = as.numeric(date_of_diagnosis - date_of_onset)) %&gt;%   #we create variables with difference between dates, we transform them in numeric to be able to then calculate measures of central tendency\n  \n  mutate(delay_not = as.numeric(date_of_notification - date_of_diagnosis))\n\nsummary(delay_db$delay_diag) #the summary will give us measures of central tendency and dispersion\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n -2.000   4.000   7.000   7.758  10.000  66.000     897 \n\nsummary(delay_db$delay_not)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-46.0000  -2.0000   0.0000  -0.6078   1.0000  23.0000      715 \n\ndelay_country &lt;- delay_db %&gt;% #here, we group by country and summarise the median to compare across countries\n  \n  group_by(country) %&gt;% \n  \n  summarise(median_delay_diag = median(delay_diag, na.rm = T),\n            median_delay_not = median(delay_not, na.rm = T))\n\ndelay_country\n\n# A tibble: 5 x 3\n  country  median_delay_diag median_delay_not\n  &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt;\n1 CountryA                 7                0\n2 CountryB                 7                0\n3 CountryC                 6                0\n4 CountryD                 7                0\n5 CountryE                 6                0\n\n# Line graph with the different dates \n\ndates_longer &lt;- cb_data %&gt;% # use the variables of the dates and make a longer dataset. In the pivot_longer() command we select the columns which we want to expand in long format and transform the dataset\n   \n  pivot_longer(\n    \n    cols=starts_with(\"date_\"),         # all columns starting with \"date_\" will be taken \n\n    names_to = \"indicator\",            #the names of the columns will be placed in a single column called \"indicator\"\n\n    values_to = \"date\")                # the values (which are dates in this case) will be placed in a column called \"date\"\n  \n\ndates_longer_week &lt;- dates_longer  %&gt;% \n\n  mutate(week_date = floor_date(date, unit = \"week\", week_start = \"Monday\")) %&gt;%  # we create a week column\n    \n  group_by(indicator, week_date) %&gt;% \n    \n  summarise(n=n(), .groups=\"drop\") %&gt;%   # we group and summarise to have the number of cases by date type and week\n    \n  drop_na(week_date)                     # we drop the cases with no data on dates\n\n\n\n\nplot_date_delay &lt;-   ggplot(data = dates_longer_week,\n                            aes(x = week_date, \n                                y = n, \n                                color=indicator)) +\n  \n  geom_line(linewidth = 1.5) +\n  \n  scale_x_date(breaks = \"2 weeks\")+\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\", \n        axis.text = element_text(size=9),\n        axis.title = element_blank(),\n        axis.text.x = element_text(angle=90),\n        legend.title = element_blank()) +\n  labs(title=\"Mpox cases reported in 2022, by date of onset, diagnosis and notification.\")\n\nplot_date_delay\n\n\n\n\n\n\n\n\n\n\n\n\nStep 5.2: Compare case-based and aggregated data\nTask: Create a plot comparing the number of cases reported to through the case-based flow and through the aggregated flow in each country.\nNOTE: Take into consideration that the column on cases in the aggregated data frame reports the cumulative number of cases.\n\nWhich country is not reporting aggregated data?\n\n A B C D E\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Create a data frame with the overall number of cases reported through the aggregated flux\n\nagg_data_country &lt;- agg_data %&gt;% \n  \n  group_by(country) %&gt;% \n  \n  filter(date_rep == max(date_rep)) %&gt;% # as we have cumulative data, we keep only the last week (after grouping by country)\n  \n  select(-date_rep, -week_date) %&gt;%     # remove unnecessary columns\n\n  mutate(source = \"aggregated\")         # we create this column to distinguish the numbers from the case-based flux\n\n\n# Create a data frame with the overall number of cases reported through the case-based flux\n\ncb_data_country &lt;- cb_data %&gt;%\n  \n  group_by(country) %&gt;% \n  \n  summarise(cases = n(), .groups = \"drop\") %&gt;% \n  \n  mutate(source = \"case_based\")       # we create this column to distinguish the numbers from the\n  \n\n# We append both data frames. Remember this is different from merging\n\ntotal_data &lt;- bind_rows(cb_data_country, agg_data_country)\n\n\n# We create a graph to compare the cases reported in both sources\n\ngraph_comp &lt;- ggplot(data = total_data,\n                     aes(x = source, \n                         y = cases, \n                         fill = source)) +\n  \n  geom_col(position = \"dodge\") +            #position dodge puts bars one next to each other, instead of \"stacked\"\n  \n  facet_wrap(~ country, scales = \"free_y\") +  # this command gives us one graph per country. The argument scales is used to allow each y axis scales to adjust to the data\n\n  scale_fill_viridis_d(\n    labels = c(\"Aggregated\", \"Case-based\")  # this function changes the colours, but with the argument \"labels\" we can change the text of each fill.\n     ) +\n  \n  \n  labs(\n    title = \"Number of cases of Mpox reported in 2022 according to source of data\",\n    fill = \"Source\",\n    x = \"\",\n    y = \"Total number of cases\"\n  ) + \n  \n  theme_bw() +\n  \n  theme(axis.text.x = element_blank(),      # we remove the text of the x axis because it is already present in the legend\n        axis.ticks.x = element_blank())     # we also remove the ticks for aesthetic purposes\n\ngraph_comp\n\n\n\n\n\n\n\n\n\n\n\n\nStep 5.3: Heat plot with number of cases by country and week of notification\nHeat plots are a type of plots that are gaining popularity in epidemiology. In our case, they can be useful to understand how the epidemic evolved in different countries.\nTask: Using the case-based data, create a heat plot with the number of cases by country and week of notification.\n\n\n Click to read a hint\n\n\nIn this case you will need to aggregate your data by country and week of notification. You can do this using the functions group_by() and summarise() from {dplyr}. If you are unsure on how to do this, review the Grouping data chapter of the EpiRhandbook. Then, use the geom geom_tile() to create a heat plot. If you’re unsure on how to do this, read the EpiRhanbook section on [Heat Plots]https://epirhandbook.com/en/new_pages/heatmaps.html)\n\n\n\nWhich country had the latest date of notification?\n\n A D E B\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nhp_epox &lt;- cb_data %&gt;% #we first group the data by country and week of notification\n  \n  group_by(country, week_date) %&gt;% \n  \n  summarise(n_cases = n(), .groups = \"drop\") %&gt;% \n\n  #now we can use the pipe to directly plot the resulting data from the grouping\n  \n  ggplot(aes(x = week_date,\n           y = country,           #we want the countries to be in the y axis\n           fill = n_cases)) +     #the colour of the tiles should depend on the number of cases\n  \n  geom_tile(colour = \"black\") +   #this is the outline colour of each tile\n  \n  scale_fill_gradient(            #here we define the colours we want to use in the gradient\n    low = \"lightgreen\",\n    high = \"red\") +\n  \n  scale_x_date(breaks = \"2 weeks\") +             #set the x axis labels to two week intervals\n  \n  labs(\n    title= \"Mpox cases by country and week of notification\",\n    fill = \"Number of cases\"                               \n  ) +\n  \n  theme_bw() +\n  \n  theme(legend.position = \"bottom\",             #legend position to the bottom\n        axis.text = element_text(size=9),       #define the font size of the axis\n        axis.title = element_blank(),           #remove the titles of the x and y \n        axis.text.x = element_text(angle=90))   #rotate the x axis text\n    \nhp_epox",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>![](../images/ecdc/logo_epiet_rki.png){width=12in}</span>"
    ]
  },
  {
    "objectID": "pages/tbe.html",
    "href": "pages/tbe.html",
    "title": "TBE - Linear regression (ENG)",
    "section": "",
    "text": "Overview\nAuthorship\nOriginal authors: Teresa Nygren (RKI), Alicia Barrasa Blanco (UK FETP), Jan Walter (RKI) and Achim Dörre (RKI)\nData source: Data is fictional and was inspired by Nygren et al. Tick-borne encephalitis: acute clinical manifestations and severity in 581 cases from Germany, 2018-2020. Journal of Infection. 2023 Apr 1;86(4):369-75\nAdapted by: Liese Van Gompel (MediPIET), Joana Gomes Dias (ECDC), Chiara Entradi (ECDC) and Alberto Mateo Urdiales (ISS)",
    "crumbs": [
      "Case studies",
      "TBE - Linear regression (ENG)"
    ]
  },
  {
    "objectID": "pages/tbe.html#overview",
    "href": "pages/tbe.html#overview",
    "title": "TBE - Linear regression (ENG)",
    "section": "",
    "text": "Case study characteristics\n\n\n\n\n\nName:\nTBE - linear regression\n\n\nLanguage:\nEnglish\n\n\nTool:\nR; DAGitty\n\n\nLocation:\nGermany\n\n\nScale:\nNational\n\n\nDiseases:\nTBE\n\n\nKeywords:\nTBE; Linear Regression; R\n\n\nTechnical complexity:\nIntermediate\n\n\nMethodological complexity:\nIntermediate",
    "crumbs": [
      "Case studies",
      "TBE - Linear regression (ENG)"
    ]
  },
  {
    "objectID": "pages/tbe.html#instructions",
    "href": "pages/tbe.html#instructions",
    "title": "TBE - Linear regression (ENG)",
    "section": "Instructions",
    "text": "Instructions\n\nGetting Help\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n\nHints and Solutions\nHere is what the “helpers” look like:\n\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see the solution\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\nPosting a question in the Community Forum\n… description here about posting in Community… TO BE COMPLETED BY APPLIED EPI\n\n\nTerms of Use\nDisclaimer: The information presented in this exercise and the associated data files have been deliberately changed so as to facilitate the acquisition of the learning objectives for fellows of EPIET, EUPHEM and EPIET-associated programmes. This case study was first introduced in 2022 (see Copyright and Licence agreement for more information).\nYou are free:\n\nto Share: to copy and distribute the work\nto Remix: to adapt and build upon the material\n\nUnder the following conditions:\n\nAttribution: You must attribute the work in the manner specified by the author or licensor (but not in any way that suggests that they endorse you or your use of the work). The best way to do this is to keep as it is the list of contributors: sources, authors and reviewers.\nShare Alike: If you alter, transform, or build upon this work, you may distribute the resulting work only under the same or similar license to this one. Your changes must be documented. Under that condition, you are allowed to add your name to the list of contributors.\nNotification: If you use the work in the manner specified by the author or licensor, Walter@rki.de\nYou cannot sell this work alone but you can use it as part of a teaching.\n\nWith the understanding that:\n\nWaiver: Any of the above conditions can be waived if you get permission from the copyright holder.\nPublic Domain: Where the work or any of its elements is in the public domain under applicable law, that status is in no way affected by the license.\nOther Rights: In no way are any of the following rights affected by the license:\n\nYour fair dealing or fair use rights, or other applicable copyright exceptions and limitations;\nThe author’s moral rights;\nRights other persons may have either in the work itself or in how the work is used, such as publicity or privacy rights.\n\nNotice: For any reuse or distribution, you must make clear to others the license terms of this work by keeping together this work and the current license.\n\nThis licence is based on http://creativecommons.org/licenses/by-sa/3.0/\n\n\n\nFeedback & suggestions\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\nVersion and revisions\nWrite date of first version\nWrite any revisions made to the case study\n\n\n\n\n\n\n\n\nDate\nChanges made\nAuthor\n\n\n\n\n2023\nRevision R code\nLiese Van Gompel (MediPIET)\n\n\n2024\nRevision R code\nJoana Gomes Dias and Chiara Entradi (ECDC)\n\n\n2024\nRevision of structure, format and R code\nAlberto Mateo Urdiales (ISS)",
    "crumbs": [
      "Case studies",
      "TBE - Linear regression (ENG)"
    ]
  },
  {
    "objectID": "pages/tbe.html#guidance",
    "href": "pages/tbe.html#guidance",
    "title": "TBE - Linear regression (ENG)",
    "section": "Guidance",
    "text": "Guidance\n\nObjectives of this case study\nAt the end of the case study, participants should be able to:\n\nUse directed acyclic graphs (DAG) to identify variables suitable to control for confounding;\nTo perform linear regression in R;\nTo write down the associated models and interpret them.\n\n\n\nPrevious level of expertise assumed\nParticipants are expected to be familiar with directed acyclic graphs (DAGs) and the use of DAGitty (a browser-based environment for creating DAGS) for the first part; and with data management as well as descriptive and stratified analysis in R for the second part.\n\n\nPreparation for the case study\nInclude the steps needed to start replicating the analysis of the case study\nFor example:\n\nDownload folder named tbe_en and extract contents in the local laptop\nCreate an Rstudio project in the folder tbe_en. If you are unsure on how to do that, read the EpiRhandbook on R projects\nInside “tbe_en”: Subfolder “data” contains the raw data you will use in this case study called tbe.RDS\nSubfolder scripts should be used to save any scripts related to the analysis\nSubfolder outputs will be used to store all outputs (tables, graphs, documents) that are the result of the analysis\nYou will also find inside “tbe_en” a word document called starter_guide_DAGitty.docx in case you need help using this website",
    "crumbs": [
      "Case studies",
      "TBE - Linear regression (ENG)"
    ]
  },
  {
    "objectID": "pages/tbe.html#goal-1-draw-a-directed-acyclic-graph-dag",
    "href": "pages/tbe.html#goal-1-draw-a-directed-acyclic-graph-dag",
    "title": "TBE - Linear regression (ENG)",
    "section": "Goal 1: Draw a Directed Acyclic Graph (DAG)",
    "text": "Goal 1: Draw a Directed Acyclic Graph (DAG)\nSince you are interested in a causal question, please draw a DAG. If you want to use a computer, you may try http://www.dagitty.net/ Which variables would you need to adjust for? If you are new to DAGitty you can find a few helpful information in the document called starter_guide_DAGitty.docx present in the “tbe_en” folder you have downloaded in your laptop.\n\n\nClick to see the solution\n\n\nWhen planning the study, the epidemiologist considered this DAG:\n\n\n\n\nAccording to this DAG you should adjust for TBE diagnosis, TBE vaccination, age, large tick (=large viral load), monophasic course, other comorbidities and sex.\nTBE Diagnosis is controlled by design (only cases are included).\nProbably your DAG will look differently. This is absolutely fine, since there is not only one possible DAG. But you should be able to justify your DAG based on the existing evidence.",
    "crumbs": [
      "Case studies",
      "TBE - Linear regression (ENG)"
    ]
  },
  {
    "objectID": "pages/tbe.html#goal-2-perform-linear-regression-in-r",
    "href": "pages/tbe.html#goal-2-perform-linear-regression-in-r",
    "title": "TBE - Linear regression (ENG)",
    "section": "Goal 2: Perform linear regression in R",
    "text": "Goal 2: Perform linear regression in R\nNow we will work on the data frame provided which includes data for 523 patients who have been hospitalized with TBE in the years 2018 to 2020 in Germany and for whom data were collected.\nThe following variables are provided:\nTable 1: Data dictionary for the dataframe “tbe.RDS”:\n\n\n\nVariable\nDescription\nValues\n\n\n\n\nage\nage in years\ncontinuous\n\n\nhyper\nhypertension\n1= yes, 0=no\n\n\nvac\nvaccinated against TBE\n1= yes, 0=no\n\n\nmono\nmonophasic disease course\n1= yes, 0=no\n\n\nother\nother comorbidities\n1= yes, 0=no\n\n\ntick\nlarge tick at removal\n1= yes, 0=no\n\n\nsex\nsex\n1= female, 0= male\n\n\nhospd\nlength of hospitalization in days\ncontinuous\n\n\n\n\nStep 1: Set up\n\nStep 1.1: Create a new R script\nOnce you have created an Rproject inside the “tbe_en” folder (as specified in the second point of the section Preparation for the case study). Create a new script with the name tbe_lr and save it in the subfolder “scripts”. If you are familiar with Rmarkdown, you may decide to use this type of file instead of a standard R script.\n\n\nStep 1.2: Define R language\nDepending on where you are and how to carried out R installation, your language “locale” might be different from the language of the graphs that you want to produce. For example, a french person might have a french “locale”. If that is the case, when creating a graph by day of the week, Monday will be displayed as “lundi”. If that french person wants to create an English report, as for this case study, the language “locale” should be changed.\nTask: Ensure your “locale” is in English and change it into English if it is not. If you don’t know how to do this try finding it online (searching for online help is an important skill for R users!). Otherwise, see the solution below\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# To see your language locale\nSys.getlocale()\n\n# To change it into English\nSys.setlocale(\"LC_ALL\", \"English\")\n\n\n\n\n\nStep 1.3: Install/load packages\nInstall and load the following packages: rio, skimr, janitor, gtsummary, broom, ggfortify, ggh4x and tidyverse.\nYou can find more about installing/loading packages in the Packages section of the EpiRhandbook.\n\n\n Click to read a hint\n\n\nYou may end up using a long list of packages. Unfortunately different packages have functions with the same name. For example, the package {dplyr} (already installed with {tidyverse}) has a function called select() which we frequently use to subset columns of a data frame. But other packages such as {MASS} do also have a function called select(). This could create headaches if you want to subset columns using dplyr’s select() but R thinks you’re calling MASS’s select() (we call this masking - dplyr’s select() is masked by MASS’s select()). Given that you are more likely to use functions from {tidyverse}, ensure that this is the last package in your p_load() list so that functions from {tidyverse} (including {dplyr} functions) will always “prevail”.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  rio,        # importing data  \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  gtsummary,  # summary statistics, tests and regressions \n  broom,      # to generate tidy tibbles of regression analysis\n  ggfortify,  # data visualisation for statistical analysis results\n  ggh4x,      # a ggplot extension package used for advanced plotting\n  tidyverse  # data management and visualization\n)\n\n\n\n\n\n\nStep 2: Import and explore data\n\nStep 2.1: Import the data and brief exploration\nImport the data frame called “tbe.RDS” inside the “data” subfolder. If you are working within a project, finding the path to the dataframe should be relatively straightfoward. A “.RDS” file is a R object file. You can import this dataframe using the readRDS() function from {base}. However, we recommend that you use the import() function from {rio} because, as you may remember, this function will recognise the file type and import it whether the file is from R, Stata, excel or many others. If you have any doubts about importing review the Import and export chapter of the EpiRhandbook.\nThen, explore the data trying to answer the following questions:\n\nHow many columns and rows are present?\nWhat class are the columns?\nWhat is the completeness rate of the columns?\nHow many categories are present in the nominal columns?\nWhat is the range in the numeric columns? Do they make sense?\n\n\n\n Click to read a hint\n\n\nAn efficient way to explore data is to use the function skim() from the {skimr} package, as it gives you all the information needed with only one command. Of course, there are several alternatives.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Import the data\n\ntbe &lt;- import(\"data/tbe.RDS\")\n\n\n# Explore the dataframe\nskim(tbe)\n\n\nData summary\n\n\nName\ntbe\n\n\nNumber of rows\n523\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n6\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nhyper\n0\n1.00\nFALSE\n2\nno: 404, yes: 119\n\n\nvac\n0\n1.00\nFALSE\n2\nno: 503, yes: 20\n\n\nmono\n0\n1.00\nFALSE\n2\nno: 285, yes: 238\n\n\nother\n22\n0.96\nFALSE\n2\nyes: 317, no: 184\n\n\ntick\n0\n1.00\nFALSE\n2\nno: 345, yes: 178\n\n\nsex\n0\n1.00\nFALSE\n2\nmal: 332, fem: 191\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n18\n0.97\n47.30\n18.97\n1\n34\n47.0\n61\n90\n▂▅▇▆▂\n\n\nhospd\n39\n0.93\n42.23\n13.59\n3\n33\n41.5\n52\n86\n▁▆▇▃▁\n\n\n\n\n\n\n\n\nHow many columns does the dataframe have?\n\n 523 2 8 6\n\n\n\nHow many rows have missing the column ‘Other comorbidities’?\n\n 958 22 18 39\n\n\n\nHow many cases have hypertension?\n\n 119 191 332 285\n\n\n\nHow many character columns does the dataframe have?\n\n 0 6 2 8\n\n\n\nWhat is the difference between a column of class ‘character’ and a column of class ‘factor’?\n\n There is no difference between these classes, those are synonims Character columns contain text, whereas factors contain numbers Factors are used when we have more than 5 categories of data Both classes contain text, but factors are used when there are a limited number of unique character strings and they often represent categorical data\n\n\nNormally, at this point we would start cleaning our data. Fortunately for you, the tbe_en has already been cleaned, so you can jump directly to the fun part. However, feel free to rename/recode or change any aspect of the dataframe to accomodate it to your personal preferences.\n\n\nStep 2.3: Histogram with length of hospitalisation\nCreate an histogram with the distribution of the length of hospitalisation in days (column hosp). Try adding the normal curve to this histogram.\n\n\n Click to read a hint\n\n\nThere are many ways to create an histogram in R, but try using the package {ggplot2}. You can have a look at the ggplot basics chapter of the EpiRhandbook if you struggle.\nAdding the normal curve to the histogram may prove quite challenging. Do not worry if you don’t manage. One hint is that, in the histogram, you will need to display the density and not the frequency count. Also, ask a seach engine or any AI platform if they can help you. Most of us use these tools on a daily basis to ask for help.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Create the histogram with the length of hospitalisation adding a  normal curve\n\ntbe %&gt;%                                  #we call the data first and we pass it into ggplot with the pipe operator\n  \n  ggplot(mapping = aes(x = hospd)) +     #when drawing an histogram we only need to specify the x axis   \n  \n  geom_histogram(aes(y = ..density..)) + #here we are telling ggplot2 to display the density and not the freq count\n  \n  #the function below will add the normal curve. \n  stat_function(fun = dnorm,  #The fun = argument we are specifying that we want the normal curve         \n                args = list(mean = mean(tbe$hospd, na.rm = T), #to draw a normal curve we need to give the mean and standard deviation of our column\n                            sd   = sd(tbe$hospd, na.rm = T)),  \n                \n                col = \"darkblue\", lwd = 1) # Identify the colour and line width of the normal curve\n\n\n\n\n\n\n\n\n\n\nNow, that was tough! But we’re here to push you out of your comfort zone. Let’s go into more detail about what we have done.\nBy now, you should feel comfortable creating a basic histogram using ggplot, so let’s focus on the new things. We have added another aesthetic to the geom_histogram() in which we specify that we want plotted the density and not the frequency count. Why is that? Displaying the density is more appropriate when we want to focus on the shape of the data, as we can see the underlying probability distribution more clearly.\nBut, what is actually the density? The density represents the relative frequency, what we do is scale the y-axis so that the area under the histogram equals 1, normalising the histogram to represent probabilities (density) rather than raw counts. In fact, look at how the y-axis changes when you represent the density and when you represent the counts.\nFinally, why are we putting two dots before and after density in the aes()? The double dots before and after ..density.. are a special syntax used within ggplot2. They indicate an internal variable that ggplot2 calculates during the plotting process. So, ggplot2 normally calculates the density for histograms, but it does not display it unless you specify it (with this syntax).\n\n\nStep 2.4: Inspect factor columns\nAs we saw before, we have 6 factor columns representing categorical variables in our dataframe. Although we looked at them with the skim() function, explore them further with the tabyl() function from the {janitor} package.\n\n\n Click to read a hint\n\n\nTo save time, try to always use functions that allow you to apply the same function to many different objects (e.g., multiple columns) simultaneously. You can achieve this using several approaches, for example loops, lapply or purrr. Here we give the solution with purrr, so if you want to explore further purrr have a look at the dedicated section in the EpiRhandbook.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Inspect all factor columns at once\n\n### One by one\n\ntabyl(tbe, hyper)\n\n hyper   n   percent\n    no 404 0.7724665\n   yes 119 0.2275335\n\ntabyl(tbe, vac)\n\n vac   n    percent\n  no 503 0.96175908\n yes  20 0.03824092\n\n#### All at once\n\ntbe %&gt;% \n  \n  select(where(is.factor)) %&gt;% #we first select only the columns that are of class 'factor'\n  \n  map(.f = tabyl)              #inside map() from {purrr} we specify the function we want to apply to the entire dataframe\n\n$hyper\n .x[[i]]   n   percent\n      no 404 0.7724665\n     yes 119 0.2275335\n\n$vac\n .x[[i]]   n    percent\n      no 503 0.96175908\n     yes  20 0.03824092\n\n$mono\n .x[[i]]   n   percent\n      no 285 0.5449331\n     yes 238 0.4550669\n\n$other\n .x[[i]]   n    percent valid_percent\n      no 184 0.35181644     0.3672655\n     yes 317 0.60611855     0.6327345\n    &lt;NA&gt;  22 0.04206501            NA\n\n$tick\n .x[[i]]   n   percent\n      no 345 0.6596558\n     yes 178 0.3403442\n\n$sex\n .x[[i]]   n   percent\n    male 332 0.6347992\n  female 191 0.3652008\n\n\n\n\n\n\nStep 2.4: Create a cross-table and calculate a statistical test\nLet’s say that we now want to explore whether sex is associated with hypertension. To find out this, create a cross-table displaying these two variables and calculate the appropriate statistical test to know if there is a statistical association between them.\n\n\n Click to read a hint\n\n\nThere are several ways in which you can do this. You could, for example, create the cross-table with tabyl() and then separately calculate the statistical test. The easiest way would be to use the tbl_summary() function from the {gtsummary} package, which allows you to do both, the cross tabulation and the statistical tests, in the same command. You should be familiar with this package by now, but if you need a little refresher have a look at the dedicated chapter of the EpiRhandbook.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Cross-table -------------------------------------------------------------\n\ntbe %&gt;% \n  select(hyper, sex) %&gt;%   #we select the columns we are interested in\n  tbl_summary(by = hyper) %&gt;% #we specify that we want by hypertension status\n  add_p()                     # adding this command will calculate the most appropriate statistical test\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nno, N = 404\n1\nyes, N = 119\n1\np-value\n2\n\n\n\n\nsex\n\n\n\n\n0.5\n\n\n    male\n253 (63%)\n79 (66%)\n\n\n\n\n    female\n151 (37%)\n40 (34%)\n\n\n\n\n\n1\nn (%)\n\n\n2\nPearson’s Chi-squared test\n\n\n\n\n\n\n\n\n\n\nAs you can see, there isn’t a significant association between sex and hypertension.\n\n\n\nStep 3: Check if there a linear association between length of hospitalisation and age\nAge is a potential confounder for a more severe course of TBE involving a longer stay in hospital, for which we would like to adjust. Since age is a continuous variable, we could include it in the regression model in various ways (e.g. as a continuous variable, in categories, by transforming it, etc.). In order to decide this, we need to analyze the association of age with the length of hospitalisation.\n\nStep 3.1: Inspect a potential linear association\nPlease first have a look at the relationship between age and length of hospitalization using a scatterplot.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Scatterplot for linear association ------------------------------------------------------\n\ntbe %&gt;%    \n  \n  ggplot(mapping = aes(x = age,        # we put length of hospitalisation on the y-axis because this axis usually contains the dependent variable; and here we want to know if hospd depends on age\n                       y = hospd)) +    \n  \n  geom_point() +                       # this geometry will create a scatterplot\n    \n  scale_x_continuous(name = \"Age\" , limits = c(0,100)) +          # Format the x-axis to a range between 0 and 100 \n  \n  scale_y_continuous(limits = c(0,70)) +                          # Format the y axis to a range between 0 and 70\n  \n  labs(\n    x = \"Age\",\n    y = \"Length of hospitalization in days\"\n  ) + \n  \n  \n  theme_bw()                            # Add a pre-defined theme for formatting\n\n\n\n\n\n\n\n\n\n\nWhat do you think? Is there an association? How can you be sure? Add a linear model trend line to help you with the interpretation.\n\n\n Click to read a hint\n\n\nFor the trend line, you can add a geom_smooth() geometry. Look up the documentation for geom_smooth (you can type ?geom_smooth in the console and press “Enter”) and search for the methods option.For a linear trend line you can assign the methods argument to “lm” (linear model). \n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Scatterplot for linear association with trend line ------------------------------------------------------\n\ntbe %&gt;%    \n  \n  ggplot(mapping = aes(x = age,        # we put length of hospitalisation on the y-axis because this axis usually contains the dependent variable; and here we want to know if hospd depends on age\n                       y = hospd)) +    \n  \n  geom_point() +                       # this geometry will create a scatterplot\n  \n  geom_smooth(method = lm) +           # this geometry will add a trend line. \"lm\" is for \"linear model\"\n  \n  scale_x_continuous(name = \"Age\" , limits = c(0,100)) +          # Format the x-axis to a range between 0 and 100 \n  \n  scale_y_continuous(limits = c(0,70)) +                          # Format the y axis to a range between 0 and 70\n  \n  labs(\n    x = \"Age\",\n    y = \"Length of hospitalization in days\"\n  ) + \n  \n  \n  theme_bw()                            # Add a pre-defined theme for formatting\n\n\n\n\n\n\n\n\n\n\nYou have visual evidence of a linear association of age with the duration of hospitalization. Therefore, it seems reasonable to include age as a continuous variable in the analysis.\nNow, we will see how to perform linear regression with R.\n\n\nStep 3.2: Univariate linear regression between length of hospitalisation and age\nNow, try running a linear regression model using the tbe data, with length of hospitalisation (hospd) as the dependent variable and age as the independent variable. Assign this model to an object named: age_hospd_lm If this is the first time doing regression in R, have a look at the Univariate regression chapter of the EpiRhandbook.\n\n\n Click to read a hint\n\n\nYou could use the lm() function from {base} to analyze the linear association between age and length of hospitalization. The syntax is: lm(outcome/dependent variable ~ exposure/independent variable, data = dataframe) You can print the model output in a subsequent command using the summary() function. However, the tidy() function from {broom} provides an overview which can be more easily compiled and used in down-stream analyses if needed.\nThe approach described above is the {base} R approach. You can also perform univariate regression analysis using the function tbl_uvregression() from the {gtsummary} package. If you want to explore this alternative approach further read the dedicated EpiRhandbook chapter \n\n\nBased on the results of this model, is there a significant association between age and hospd?\n\n Yes No\n\n\n\nHow much does an additional year of age increase length of hospitalisation (in days)?\n\n 0.372 24.5 0.271 1.42\n\n\n\nWhat % of the variability in length of hospitalisation can be explained by age?\n\n 65% 15% 27% 99%\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# Univariate regression analysis between hospd and age ------------------------------------------\n\n# Run the linear regression and assign the output to age_hospd_lm\nage_hospd_lm &lt;- lm(hospd ~ age, data = tbe)\n\n# Print the results using the summary() function\nsummary(age_hospd_lm)\n\n\nCall:\nlm(formula = hospd ~ age, data = tbe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-35.676  -7.893   0.521   6.844  32.279 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  24.5314     1.4233   17.24   &lt;2e-16 ***\nage           0.3722     0.0278   13.39   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.61 on 482 degrees of freedom\n  (39 osservazioni eliminate a causa di valori mancanti)\nMultiple R-squared:  0.2711,    Adjusted R-squared:  0.2696 \nF-statistic: 179.2 on 1 and 482 DF,  p-value: &lt; 2.2e-16\n\n# Get the results of the regression analysis with the tidy() function as a data.frame\nresults_age_hospd_lm &lt;- tidy(age_hospd_lm)\n\nresults_age_hospd_lm\n\n# A tibble: 2 x 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   24.5      1.42        17.2 3.24e-52\n2 age            0.372    0.0278      13.4 5.60e-35\n\n\n\n\nNow let’s go through the outputs of the model. We will first review the outputs of the tidy() function. As explained before, the advantage of using tidy() is that we can save the output as an object for further manipulation. Also, tidy() keeps what we would normally need in epidemiology for the interpretation of the model:\nWe have four columns and two rows. The rows refer to the intercept (baseline value for hospd when age is zero: 24.5) and our only exposure/predictor (age). In most cases, you will be mostly interested in the row for age (your predictor) and in the columns estimate and p.value. The estimate of age tells us the estimated change in hospd for a one-unit increase in age. Here, it’s approximately 0.37. The column p.value tells us whether this estimate is statistically significant.\nIf you want to know what the other columns are, keep reading.\nThe column std.error provides an estimate of the variability or uncertainty associated with the estimate. In this case it means that the estimated effect of age on hospitalisation duration (hospd) is expected to vary by about 0.0278 days (on average) due to sampling variability. Finally, the statistic column gives us a value of the statistical test (t-test in this case) used to ascertain if the estimate is significantly different from 0 (normally you can ignore this column).\nYou may have noticed that the summary() output has more information than the tidy() output. Here we leave a brief explanation on what each part of the output means:\nCall: This line shows the formula used for the regression model.\nResiduals: These are the differences between the actual hospd values and the predicted values from the regression model. The summary provides statistics like minimum, median, and maximum residuals.\nCoefficients: This is the bit that interests us the most:\n\nIntercept: The estimated intercept (baseline value) for hospd when age is zero. In this case, it’s approximately 24.53.\nAge: The estimated change in hospd for a one-unit increase in age. Here, it’s approximately 0.37. The t-value and p-value indicate whether this coefficient is statistically significant.\n\nSignificance Codes: Indicate whether the p-value is highly significant (*** p &lt; 0.001) or only marginally significant (* p&lt;0.05)\nResidual Standard Error: This measures the average deviation of the observed hospd values from the regression line. In this case, it’s approximately 11.61.\nMultiple and Adjusted R-squared: These values (0.2711 and 0.269) represent the proportion of variance in hospd explained by the linear relationship with age. Higher values indicate better fit. The adjusted one is adjusted for the number of predictors.\nF-statistic and p-value: The F-statistic tests whether the overall model (including all predictors) is significant. A low p-value (like yours, &lt; 2.2e-16) indicates that the model is significant.\n\n\n(Optional) Step 3.3: Check if the association between age and length of hospitalisation varies by sex\nCheck visually whether the association between age and hospd differs by sex\n\n\n Click to read a hint\n\n\nYou may choose to create separate graphs adding a facet_grid() to your ggplot() (try looking up the syntax yourself). You may also decide to use colour coding to differentiate between factor levels of sex. For the latter, where do you think you should specify the colour, inside or outside the aes()? Read this section of the EpiRhandbook if you have doubts.\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n# As separate graphs ------------------------------------------\n\ntbe %&gt;%    \n  \n  ggplot(mapping = aes(x = age,        # we put length of hospitalisation on the y-axis because this axis usually contains the dependent variable; and here we want to know if hospd depends on age\n                       y = hospd)) +    \n  \n  geom_point() +                       # this geometry will create a scatterplot\n  \n  geom_smooth(method = lm) +           # this geometry will add a trend line. \"lm\" is for \"linear model\"\n  \n  facet_grid(~sex)  +                   # adding this function will generate a separate graph for each category of sex\n\n  \n  scale_x_continuous(name = \"Age\" , limits = c(0,100)) +          # Format the x-axis to a range between 0 and 100 \n  \n  scale_y_continuous(limits = c(0,70)) +                          # Format the y axis to a range between 0 and 70\n  \n  labs(\n    x = \"Age\",\n    y = \"Length of hospitalization in days\"\n  ) + \n  \n  \n  theme_bw()                            # Add a pre-defined theme for formatting\n\n\n\n\n\n\n\n# Same graphs with different colours ------------------------------------------\n\ntbe %&gt;%    \n  \n  ggplot(mapping = aes(x = age,        # we put length of hospitalisation on the y-axis because this axis usually contains the dependent variable; and here we want to know if hospd depends on age\n                       y = hospd,\n                       colour = sex )) + #we add the colour in the aes so that it varies according to the categories of sex   \n  \n  geom_point() +                       # this geometry will create a scatterplot\n  \n  geom_smooth(method = lm) +           # this geometry will add a trend line. \"lm\" is for \"linear model\"\n  \n  scale_x_continuous(name = \"Age\" , limits = c(0,100)) +          # Format the x-axis to a range between 0 and 100 \n  \n  scale_y_continuous(limits = c(0,70)) +                          # Format the y axis to a range between 0 and 70\n  \n  labs(\n    x = \"Age\",\n    y = \"Length of hospitalization in days\"\n  ) + \n  \n  \n  theme_bw()                            # Add a pre-defined theme for formatting\n\n\n\n\n\n\n\n\n\n\n\nWhat do you observe? The lines for female and male patients have different slopes, indicating that the association between age and hospitalization days is modified by age.\nWhy does this matter? Since there are different effects of age on the length of the hospitalization by sex, you may want to control for this.",
    "crumbs": [
      "Case studies",
      "TBE - Linear regression (ENG)"
    ]
  },
  {
    "objectID": "pages/r_practical_epiet.html#instructions",
    "href": "pages/r_practical_epiet.html#instructions",
    "title": "",
    "section": "Instructions",
    "text": "Instructions\n\nGetting Help\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nAsk one of the module facilitators\nPost a question in Applied Epi Community with reference to this case study\n\n\n\nHints and Solutions\nHere is what the “helpers” look like:\n\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see the solution\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\nTerms of Use\nDisclaimer: The information presented in this exercise and the associated data files have been deliberately changed so as to facilitate the acquisition of the learning objectives for fellows of EPIET, EUPHEM and EPIET-associated programmes. This case study was first introduced in 2022 (see Copyright and Licence agreement for more information).\nYou are free:\n\nto Share: to copy and distribute the work\nto Remix: to adapt and build upon the material\n\nUnder the following conditions:\n\nAttribution: You must attribute the work in the manner specified by the author or licensor (but not in any way that suggests that they endorse you or your use of the work). The best way to do this is to keep as it is the list of contributors: sources, authors and reviewers.\nShare Alike: If you alter, transform, or build upon this work, you may distribute the resulting work only under the same or similar license to this one. Your changes must be documented. Under that condition, you are allowed to add your name to the list of contributors.\nNotification: If you use the work in the manner specified by the author or licensor, Walter@rki.de\nYou cannot sell this work alone but you can use it as part of a teaching.\n\nWith the understanding that:\n\nWaiver: Any of the above conditions can be waived if you get permission from the copyright holder.\nPublic Domain: Where the work or any of its elements is in the public domain under applicable law, that status is in no way affected by the license.\nOther Rights: In no way are any of the following rights affected by the license:\n\nYour fair dealing or fair use rights, or other applicable copyright exceptions and limitations;\nThe author’s moral rights;\nRights other persons may have either in the work itself or in how the work is used, such as publicity or privacy rights.\n\nNotice: For any reuse or distribution, you must make clear to others the license terms of this work by keeping together this work and the current license.\n\nThis licence is based on http://creativecommons.org/licenses/by-sa/3.0/\n\n\nFeedback & suggestions\n\nYou can write feedback and suggestions on this case study at the ECDC GITHUB\nAlternatively email us at: [ECDC CONTACT MAIL]\n\n\n\n\nVersion and revisions\nThe first version was written by Xanthi Andrianou in October 2021.\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nJune 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>![](../images/ecdc/logo_epiet_rki.png){width=12in}</span>"
    ]
  },
  {
    "objectID": "pages/oswego.es.html",
    "href": "pages/oswego.es.html",
    "title": "Oswego (ES)",
    "section": "",
    "text": "Overview\nCase study characteristics\nAuthorship\nOriginal authors: Centre for Disease Prevention and Control (CDC)\nData source: Epi Info, version 3.5.4 (CDC)\nAdapted to R by: Leonel Lerebours Nadal y Alberto Mateo Urdiales",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Oswego (ES)</span>"
    ]
  },
  {
    "objectID": "pages/oswego.es.html#overview",
    "href": "pages/oswego.es.html#overview",
    "title": "Oswego (ES)",
    "section": "",
    "text": "Name\nOswego\n\n\nTool\nR\n\n\nLanguage\nSpanish/Español\n\n\nLocation\nUnited States\n\n\nScale\nLocal\n\n\nDiseases\nGastrointestinal\n\n\nKeywords\nGastrointestinal;Outbreak investigation\n\n\nTechnical complexity\nIntermidiate\n\n\nMethodolocial complexity\nIntermidiate",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Oswego (ES)</span>"
    ]
  },
  {
    "objectID": "pages/oswego.es.html#instructions",
    "href": "pages/oswego.es.html#instructions",
    "title": "Oswego (ES)",
    "section": "Instructions",
    "text": "Instructions\n\nGetting Help\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\nHints and Solutions\nHere is what the “helpers” look like:\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\nPosting a question in the Community Forum\n… description here about posting in Community… TO BE COMPLETED BY APPLIED EPI\n\n\nIcons\nYou will see these icons throughout the exercises:\n\n\n\n\n\n\n\nIcon\nMeaning\n\n\n\n\n\nObserve\n\n\n\nAlert!\n\n\n\nAn informative note\n\n\n\nTime for you to code!\n\n\n\nChange to another window\n\n\n\nRemember this for later\n\n\n\n\n\n\nTerms of use\nThis case study has been adapted from an existing tutorial on Epi Info created by the Centre for Disease Prevention and Control (CDC). Epi Info™ is a trademark of CDC. Epi Info™ programs are provided in the public domain to promote public health. Programs might be freely translated, copied, or distributed. No warranty is made or implied for use of the software for any particular purpose.\n Applied Epi Incorporated, 2022 This work is licensed by Applied Epi Incorporated under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\nPlease email contact@appliedepi.org with questions about the use of these materials for academic courses and epidemiologist training programs.",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Oswego (ES)</span>"
    ]
  },
  {
    "objectID": "pages/oswego.es.html#feedback-suggestions",
    "href": "pages/oswego.es.html#feedback-suggestions",
    "title": "Oswego (ES)",
    "section": "Feedback & suggestions",
    "text": "Feedback & suggestions\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Oswego (ES)</span>"
    ]
  },
  {
    "objectID": "pages/oswego.es.html#version-1",
    "href": "pages/oswego.es.html#version-1",
    "title": "Oswego (ES)",
    "section": "Version 1",
    "text": "Version 1\n16 November 2023",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Oswego (ES)</span>"
    ]
  },
  {
    "objectID": "pages/oswego.es.html#disclaimer",
    "href": "pages/oswego.es.html#disclaimer",
    "title": "Oswego (ES)",
    "section": "Disclaimer",
    "text": "Disclaimer\nEsto es un estudio de caso diseñado por el Centre for Disease Prevention and Control (CDC) como tutorial de Epi Info. Puede consultar más detalles en este Enlace",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Oswego (ES)</span>"
    ]
  },
  {
    "objectID": "pages/oswego.es.html#revisions",
    "href": "pages/oswego.es.html#revisions",
    "title": "Oswego (ES)",
    "section": "Revisions",
    "text": "Revisions\n\n\n\nDate\nChanges made\nVersion\n\n\n\n\n16 November\nAdapted to template\n1",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Oswego (ES)</span>"
    ]
  },
  {
    "objectID": "pages/oswego.es.html#guía",
    "href": "pages/oswego.es.html#guía",
    "title": "Oswego (ES)",
    "section": "Guía",
    "text": "Guía",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Oswego (ES)</span>"
    ]
  },
  {
    "objectID": "pages/oswego.es.html#objetivos-de-este-estudio-de-caso",
    "href": "pages/oswego.es.html#objetivos-de-este-estudio-de-caso",
    "title": "Oswego (ES)",
    "section": "Objetivos de este estudio de caso",
    "text": "Objetivos de este estudio de caso\nLos objetivos de este estudio de caso son:\n\nEntender los diferentes pasos en la investigación de un brote de casos de enfermedad gastrointestinal\nAdquirir confianza en el manejo de datos de un listado nominal con el software estadístico R\nAdquirir experience en el análisis descriptivo en R, particularmente curvas epidémicas\nAdquirir experience construyendo tablas 2x2 con exposición y desenlace que nos permitan calcular medidas de asociación\nAplicar los conocimientos adquiridos a posibles actividades de control y prevención de brotes infecciosos de origen alimentario\n\n\nConocimientos previos asumidos\nEn este estudio de caso se asume un conocimiento básico de los principios fundamental de la investigación epidemiológica de brotes gastrointestinales. Se asume también un conocimiento básico de R.\n\n\nPreparation for the case study\nAntes de iniciar este estudio de caso, le aconsejamos que:\n\nDescargue en su computadora la carpeta “oswego_cs_es” y que extraiga todos sus componentes, preferibilmente en su escritorio o en un lugar de fácil acceso. Evite extraerlo en servicios de nube o “drives”\n\nDentro de la carpeta, encontrará un proyecto de R llamado “oswego_cs”. Es un archivo de tipo “R project” y debe siempre asegurarse que está trabajando en RStudio desde el proyecto. La forma más fácil es que habra RStudio cada vez a través de abrir este archivo.\nDentro de la carpeta “oswego_cs_es” encontrará una subcarpeta llamada data en el que encontrará todos los datos necesarios para realizar el análisis en un file llamado “oswego.xlsx”.\nDeberá crear un script dentro de la carpeta scripts en el que usted escribe el código para el análisis. Puede utilizar el script que ya está presente llamado “01_oswego_sol” que contiene el código de análisis si se encuentra atascado o si quiere comparar el código que usted realiza con la solución.\nEn la subcarpeta outputs encontrará todos los gráficos y tablas generadas en el anlálisis.\n\n\nPrimera parte - AntecedentesSegunda parte - El EventoTercera parte - AnálisisCuarta Parte - Conclusión\n\n\n\n\n\n\n\n\n\n\n\nEl 19 de abril de 1940, el oficial de salud local en el pueblo de Lycoming, condado de Oswego, Nueva York, informó de la ocurrencia de un brote de enfermedad gastrointestinal al Distrito de Salud Oficial en Siracusa. Dr. A. M. Rubin, epidemiólogo en formación, fue asignado para investigar lo ocurrido.\nCuando el Dr. Rubin llegó al campo, determinó a través del oficial de salud que todas las personas que enfermaron había asistido a una cena en la iglesia celebrada la noche anterior, 18 de abril. Otra información importante fue que los familiares que no asistieron a la cena, no enfermaron.\nEn consecuencia, el Dr. Rubin centró la investigación sobre lo ocurrido en la cena. Pudo completar 75 entrevistas de las 80 personas conocidas que asistieron a la cena, recopilando información sobre los ocurrencia y tiempo de aparición de los síntomas, y alimentos consumidos. de las 75 personas entrevistados, 46 personas presentaron síntomas de enfermedad gastrointestinal.\n\nPregunta 1\n\n¿Ante que tipo de situación está presente el Dr Rubin?\n\n Una epidemia Una serie de casos Un brote No se puede establecer\n\n\n\n\n\n Click para leer una pista\n\n\nPuede utilizar este glosario preparado por el Gobierno de México para encontrar la definición que se ajusta más a la situación descrita Enlace \n\n\n\nClick para ver la explicación (¡Inténtelo usted primero!)\n\n\nNumero 1 - No es la respuesta correcta; revisa el concepto de epidemia, tiene que ver con la cantidad de personas afectadas.\nNumero 2 - Es posible, pero también debes tomar en cuenta otros factores, como el hecho de que los casos tienen una relación epidemiológica entre ellos.\nNumero 4 - No te preocupes, en este tutorial vas a poder aprender los pasos del trabajo de campo.\n\n\n\n\nPregunta 2\n\nLos pasos de una investigación de brote son:\n\n Determinar la existencia del brote, análisis descriptivo, generar hipótesis, confirmar hipótesis, controlar brote, conclusiones y recomendaciones, informe final Una serie de casos Determinar la existencia del brote, confirmar diagnóstico, contar casos, análisis descriptivo, determinar quién está a riesgo de enfermar, desarrollar hipótesis, confirmar hipótesis, controlar brote, conclusiones y recomendaciones, informe final Determinar la existencia del brote, confirmar el diagnóstico, controlar brote, comunicar brote, generar hipótesis, confirmar hipótesis, controlar brote, conclusiones y recomendaciones, informe final\n\n\n\n\nClick para ver la explicación (¡Inténtelo usted primero!)\n\n\nPuede utilizar el sitio de la OPS para profundizar sobre el tema Enlace\n\n\n\n\nDescripción clínicade los casos\nEl inicio de la enfermedad en todos los casos fue agudo, caracterizada principalmente por náuseas, vómitos, diarrea y dolor abdominal. Ninguno de los enfermos personas reportaron tener un nivel elevado temperatura; todos se recuperaron dentro de las 24 a 30 horas.\nAproximadamente el 20% de los enfermos que visitaron al médico no se les realizó examen de muestras fecales para el examen bacteriológico.\n\nPregunta 3\nEnumere una de las grandes categorías de agentes causales de enfermedades que se deben considerar en el diagnóstico diferencial de un brote de enfermedad gastrointestinal como el de Oswego:\n\n\n\n\nClick para ver la explicación de la solución (¡Inténtelo usted primero!)\n\n\n\nBacterias\nVirus\nParásitos\nToxinas\n\nPuede utilizar el sitio de la OPS para profundizar sobre el tema Enlace\n\n\n\nLos investigadores en Oswego, desconocen el agente causal, pero sospechan de que la génesis de este brote fue través de los alimentos como vehiculo de transmisión entre los afectados.\n\n\nPregunta 4\nEn lenguaje epidemiológico, ¿Qué es un vehículo? ¿Qué es un vector? ¿Cuáles son otros modos?\nPiense en estos conceptos y cuando esté listo, vea la solución propuesta\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEn la jerga epidemiológica, un ‘vehículo’ es un objeto o sustancia inanimada que puede transportar un patógeno y transmitirlo a un huésped susceptible. Ejemplos de vehículos incluyen alimentos o agua contaminados, fómites (objetos inanimados como pomos de puertas o ropa) o partículas transportadas por el aire. En este contexto, un vehículo no es un modo de transporte, sino más bien un medio de transmisión de un agente infeccioso. Por otro lado, un ‘vector’ es un objeto animado, generalmente un artrópodo como un mosquito, una garrapata o una pulga, que puede transportar un agente infeccioso desde un huésped infectado a un huésped susceptible. El vector puede transmitir el patógeno directamente a través de su picadura o indirectamente al depositar el patógeno en una superficie o en una fuente de alimentos o agua. Los otros modos de transmisión de agentes infecciosos incluyen el contacto persona a persona, ya sea directamente a través del contacto físico, como el tacto o el beso, o indirectamente a través de gotas generadas durante la tos o el estornudo, o mediante transmisión aérea en espacios cerrados. Además, algunos agentes infecciosos pueden ser transmitidos a través del contacto sexual, la transmisión perinatal de la madre al hijo o mediante la exposición a fluidos corporales, como la sangre o el semen. Los factores ambientales, como la mala higiene, el hacinamiento o la exposición a animales, también pueden desempeñar un papel en la transmisión de ciertos agentes infecciosos.\n\n\n\nEl Dr. Rubin decidió administrar un cuestionario a los participantes de la cena de la iglesia para averiguar qué alimento podía estar asociado al desarrollo de los síntomas\n\n\nPregunta 5\nSi fuese usted el que administra el cuestionario, ¿qué información recopilaría? Agrupa la información en categorías. Una vez que haya escrito sus categorías, puede ver abajo la solución.\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstos son algunos de los campos que normalmente se includirían en un cuestionario en un brote similar:\n\nInformación demográfica\nInformaión clínica\nDatos de laboratorio si disponibles\nFactores de riesgo (exposición): Alimentos y bebidas ingeridas durante la cena\n\n\n\n\nAdemás de decidir la información que quería recolectar, el Dr. Rubin decidió recolectó los datos entrevistados a través de un listado nominal.\n\n\nPregunta 6\n\n¿En que NO nos ayuda un listado nominal?\n\n Organizar los datos y describirlos por tiempo, lugar y persona Clasificar a los individuos como casos, no casos y sospechosos A diagnosticar a los pacientes A manejar un documento dinámico que se puede actualizar constantemente\n\n\nPor favor, continue el caso entrando en la pestaña “Segunda parte - El Evento” en la parte superior\n\n\n\n\n\nDescripción de la Cena\nLa investigación del Dr. Rubin también implicó averiguar más detalles sobre la cena. Después de hablar con los organizadores, descubrió que la cena se celebró en el sótano del iglesia del pueblo. Los alimentos fueron aportados por numerosos miembros de la congregación. La cena comenzaba a las 6:00 p.m. y continuó hasta 11.00 pm.\nLa comida estaba esparcida sobre una mesa y fue consumida durante un período de varias horas. Los datos sobre el inicio de la enfermedad y los alimentos consumidos por cada una de las 75 personas entrevistados se proporcionan en la listado adjunto.\nLa hora aproximada de participación en el evento solo se recolectó aproximadamente la mitad de las personas que tuvo una enfermedad gastrointestinal.\n\nPregunta 7\n¿Cuál es el valor de una curva epidémica en la investigación de un brote?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstas son algunos de los usos de las curvas epidémicas cuando se investigan brotes:\n\nNos permite ver la evolución en el tiempo de un evento forma rápida\nAporta información para tomar decisiones para medidas de control\nAyuda a revelar patrones y tendencias sobre un evento\n\n\n\n\n\n\nPregunta 8\n¿Qué nos dice el siguiente gráfico?\n\n\n\n\n\n\n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nLa curva epidémica nos dice que:\n\nTodos los casos ocurrieron antes de las 10am del día siguiente (19 de abril)\nDesde la 11pm del 18 a las 3am del 19 de abril ocurrieron la mayoría de los casos\nNos muestra la magnitud del evento y como se propaga, así como ver valores extremos\n\n\n\n\n\n\nPregunta 9\n¿Hay algún caso en el que los tiempos de inicio no coincidan con los generales? ¿experiencia? ¿Cómo podrían explicarse?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nConsidere que: - Hay casos que la hora de inicio de signos y sintomas fueron antes de la cena, pudo ser que se contaminara antes durante los preparativos - Un caso ocurrió 17 horas después de la cena, posiblemente es alguien que comió más tarde o que la infomación es incorrecta (otra enfermedad parecida) o un caso secundario\n\n\n\n\n\n\nListado nominal de individuos del brote de gastroenteritis, Oswego, Nueva York, 1940\n\n\n\n\n\n\n\nPregunta 10\n¿Cómo podrían presentarse mejor los datos en el listado nominal de participantes?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nDos ideas, aunque puede haber más son:\n\nLos datos pudieron ser separados de acuerdo al estatus de enfermedad y tiempo de inicio de sintomas\nSi se hubiese usado el formato del en tiempo militar, (ej. 00:00 o 14:00)\n\n\n\n\n\n\nVersión digital\n\n\n\n\n\nApoyo en análisis de los datos\n\n\n\nAhora vamos a comenzar con uno de los pasos más importantes en la investigación de brote, el análisis de los datos donde a través de este vamos a determinar cual o cuales son las posibles causas del brote, medidas a tomar entre otros pasos. ¡También vamos a usar un poco de R para ayudar con este proceso de análisis!.\n\nSiempre que sea posible, utilizando el listado nominal actualizado, calcule los períodos de incubación e ilustre su distribución con un gráfico apropiado.\n \nPara contestar esta pregunta, vamos hacer los siguientes pasos usando R:\n \n\nen Rstudio, crea un nuevo script para cargar los datos (cargar el archivo “oswego.xlsx”, que está en la carpeta data) y explore las dos columnas que contienen la información necesaria para calcular los períodos de incubación: TimeSupper (hora de la cena) y DateOnset (Fecha inizio síntomas)\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#Cargar los paquetes necesarios\npacman::p_load(rio,\n               here,\n               tidyverse, \n               epitools, \n               lubridate,\n               DT)\n\n#Importar los datos\nlistado &lt;- import(\"../cs/ESP/oswego_cs_es/data/oswego.xlsx\")\n\n#Explorar las variables de la fecha y hora del almuerzo\nhead(oswego_db$TimeSupper)\n\n[1] NA                        NA                       \n[3] NA                        \"1940-04-18 22:00:00 UTC\"\n[5] \"1940-04-18 19:30:00 UTC\" \"1940-04-18 19:30:00 UTC\"\n\nhead(oswego_db$DateOnset)\n\n[1] \"1940-04-18 23:00:00 UTC\" NA                       \n[3] \"1940-04-18 22:30:00 UTC\" \"1940-04-19 01:00:00 UTC\"\n[5] \"1940-04-19 02:30:00 UTC\" \"1940-04-18 23:30:00 UTC\"\n\n\n\n\n\nPara referencia sobre como importar archivos, ver el capítulo 7 del libro de R para epidemiologos\n \n\nEl listado cargado ya tiene el formato correcto de la fecha y hora de almuerzo y la fecha y hora de inicio de síntomas ahora intente crear un código para crear una nueva variable con los periodos de incubación para cada caso. (recuerda que con las variables de tiempo en R se pueden hacer operaciones matemáticas)\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n# Crear la variable del período de incubación\n# puedes copiar este código en rstudio en tu editor de códigos\n#las funciones \"interval\" y \"dhours()\" son las que usaremos para calcular la diferencia en hora\n\nlistado_incubacion &lt;- listado %&gt;%\n  \n  mutate(incubacion=interval(TimeSupper, DateOnset) / dhours(1)) \n\n\n\n\nPara más detalles de como trabajar con fechas, ver el capítulo 9 del libro de R para epidemiologos\n \n\nAhora intente hacer un gráfico de barras con el período de incubación usando ggplot para visualizar la distribución. Puede encontrar pistas sobre como hacer un gráfico de barras en la sección dedicada del EpiRhandbook\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n# Hacer un gráfico de barra de los periodos de incubación calculados\n# puedes copiar este código en rstudio en tu editor de códigos\n\nlistado_incubacion %&gt;% \n  \n  ggplot(aes(x=incubacion))+\n  \n  geom_bar()+\n  \n  labs(title=\"Casos de enfermedad gastrointestinal por período de incubación en horas\",\n       subtitle = \"Oswego, NY, 18-19 de abril, 1940\",\n       x=\"Período de incubación (Horas)\",\n       y=\"n de casos\")+\n  \n  theme_minimal()\n\nWarning: Removed 53 rows containing non-finite outside the scale range\n(`stat_count()`).\n\n\n\n\n\n\n\n\n#Si quieres asignar este gráfico a un objeto, solo tienes que en la primera línea del código \n#usar un nombre (como grafico1) y escribir el signo de asignación (&lt;-)\n\n\n\n\nPara más detalles de como trabajar con gráficos en general, ver el capítulo 30 del libro de R para epidemiologos\n \n\n\nPregunta 10: ¿Cuantos casos tenian el dato de incubación?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n22\nPara saberlo, puedes verificar viendo el listado directamente o con el siguiente código\n\n\n\n\n\nPregunta 11: Determine el rango y la mediana del período de incubación\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n Para ejecutar esto en R hay varias formas, usando ya sea las funciones base o de otros paquetes. Aquí tiene un ejemplo usando el paquete {dplyr} que viene integrado en el paquete {tidyverse}\n\n# Calcular el rango, la mediana y el periodo de incubacion\n# puedes copiar este código en rstudio en tu editor de códigos\n\nresumen_estadistico &lt;- listado_incubacion %&gt;% \n  filter(!is.na(incubacion)) %&gt;% \n  reframe(mediana=median(incubacion),\n          min=min(incubacion),\n          max=max(incubacion),\n          rango=max-min)\n\nresumen_estadistico\n\n  mediana min max rango\n1       4   3   7     4\n\n\nLa mediana del periodo de incubación fue 4 horas, así como el rango del periodo del periodo de incubación también fue de 4 horas\n\n\n\n\n\nPregunta 12: ¿Cómo ayuda la información sobre el período de incubación y los datos sobre síntomas a establecer diagnósticos diferenciales de la enfermedad? (Si es necesario, consulte adjunto Compendio de enfermedades gastrointestinales agudas transmitidas por los alimentos)\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nNos ayuda porque:\n\nCada enfermedad transmitida por los alimentos tiene un período de incubación característico, síntomas específicos y alimentos con los que es más probable que esté asociada\nEl período de incubación observado es demasiado largo para los metales pesados y demasiado corto para los agentes virales y el botulismo\nLa intoxicación alimentaria estafilocócica tiene un período de incubación promedio de 2 a 4 horas\nEstos datos son insuficientes para saber cual puede ser el agente causal \n\n\n\n\n\nPregunta 13: Usando los datos del listado, complete la tabla a continuación. ¿Cúal o cuales alimentos pudieron ser el vehículo más probable de infección?\n \nPara contestar esta pregunta, intente hacer los siguientes pasos usando R con el mismo script que creaste anteriormente:\n\nCree un objeto “data.frame” con el resumen de los alimentos ingeridos por los que enfermaron y otro con el resumen de los alimentos ingeridos por los que no enfermaron. Recodifique las variables para asignar el valor de 1 si fue consumido y 0 para no consumido.\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#Ve copiando el codigo a rstudio (este ejercicio es un poco largo)\n\npacman::p_load(janitor, gtsummary)\n\n\n#Comieron\n#hacer un dataframe con un resumen de los alimentos por los que enfermaron\ntotal_por_alimentos_casos_a &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no enfermo\")) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"enfermo\") %&gt;% \nslice_tail()\n\n#hacer un dataframe con un resumen de los alimentos por los que no enfermaron\ntotal_por_alimentos_no_casos_a &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no_enfermo\")) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"no_enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"no_enfermo\") %&gt;% \nslice_tail()\n\n\n\n\nUna los dos objectos “data.frame” y calcule la proporción de personas enfermas y no enfermas que consumieron cada alimento\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#Combinar ambos dataframes, transformarlo a formato extendido y calcular la proporción de los que consumieron\ntabla_maestra_a &lt;- bind_rows(total_por_alimentos_casos_a,\n                           total_por_alimentos_no_casos_a) %&gt;% \n  pivot_longer(2:ncol(.), names_to = \"alimentos\", values_to = \"n\") %&gt;% \n  pivot_wider(names_from = tipo_caso, values_from = n) %&gt;% \n  mutate(total=enfermo+no_enfermo,\n         ptc_enfermo=enfermo/total,\n         ptc_no_enfermo=no_enfermo/total)\n\n\n\n#Combinar ambos dataframes, transformarlo a formato extendido y calcular la proporción de los que no consumieron \ntabla_maestra_b &lt;- bind_rows(total_por_alimentos_casos_b,\n                           total_por_alimentos_no_casos_b) %&gt;% \n  pivot_longer(2:ncol(.), names_to = \"alimentos\", values_to = \"n\") %&gt;% \n  pivot_wider(names_from = tipo_caso, values_from = n) %&gt;% \n  mutate(total=enfermo+no_enfermo,\n         ptc_enfermo=enfermo/total,\n         ptc_no_enfermo=no_enfermo/total)\n\ntabla_final &lt;- tabla_maestra_a %&gt;% \n  left_join(tabla_maestra_b,suffix = c(\"_consumieron\", \"_no_consumieron\"), by=\"alimentos\") %&gt;% \n  mutate(tasa_ataque=ptc_enfermo_consumieron/ptc_enfermo_no_consumieron)\n\nView(tabla_final)\n\n\n\n\nCalcule una medida de asociación para estimar qué alimento se asoció en mayor medida a enfermar\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#otra forma.. para obtener los OR de cada alimento\n\n#crear un modelo de regresión logistica\nmodel &lt;- glm(data=listado, enfermo~m_jamon_horneado+\n            m_espinaca+m_pure_papa+m_ensa_repollo+\n            m_gelatina+m_rollos+m_pan+m_lehe+m_cafe+m_agua+\n            m_bizcocho+m_hel_vainilla+m_hel_chocolate+m_ens_fruta,\n            family=binomial())\n#Luego una tabla\ntbl_regression(model, exponentiate = TRUE)\n\ntest &lt;- listado %&gt;% \n  select(enfermo, starts_with(\"m_\")) %&gt;% \n  tbl_summary(by=enfermo)\n\n\n\n\nPara más detalles de como trabajar con transformación de datos y tablas, ver el capítulo 17 del libro de R para epidemiologos\n\n\nPregunta 15: Resuma las investigaciones adicionales que deben llevarse a cabo.\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstas son las principales investigaciones adicionales que deben llevarse a cabo:\n\nRevisión detallada de la fuente, los ingredientes, la preparación y el almacenamiento de los alimentos incriminados\nIntentar explicar los casos con tiempo de inicio atípico\nSe podría hacer un examen de laboratorio\nDeterminar si se produjo una propagación secundaria en los miembros de la familia\nCálculos adicionales (p. ej., tasas de ataque específicas por edad o género) \n\n\n\n\n\nPregunta 16: ¿Qué medidas de control sugeriría?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstas son las principales medidas de control y prevención en un brote de estas características:\n\nEvite el consumo del helado de vainilla restante\nPrevenga la recurrencia de eventos similares en el futuro educando a los manipuladores de alimentos\nSe podría hacer un examen de laboratorio\nDeterminar si se trata de un producto comercial\nEliminó cualquier fuente contaminada de alimentos\n\n\n\n\n\n\nPregunta 17: ¿Por qué fue importante trabajar en este brote?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nTrabajar en este brote ayudó a:\n\nDescartar la contaminación de un producto comercial. Si se trata de un producto comercial, la intervención inmediata puede prevenir un número considerable de casos adicionales\nPrevenir futuros brotes mediante la identificación de manipuladores de alimentos infectados, lagunas específicas en la educación o técnicas de manipulación de alimentos\nLos funcionarios de salud pública deben responder a tales problemas de manera oportuna para mantener una relación de cooperación con los departamentos de salud locales, los médicos privados y la comunidad\nUna explicación epidemiológica de la causa del brote puede disipar los temores y preocupaciones de la comunidad\nLa investigación del brote puede brindar oportunidades para que los investigadores respondan preguntas sobre el agente, el huésped, el entorno, el período de incubación, etc.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLo siguiente se cita textualmente del informe preparado por el Dr. Rubin:\nEl helado fue preparado por el Petrie hermanas de la siguiente manera: En la tarde del 17 de abril la leche cruda de la La granja Petrie en Lycoming se desbordó al baño maría se le agrega azúcar y huevos y un poco de harina para darle cuerpo a la mezcla. El se prepararon helado de chocolate y vainilla por separado.\nEl chocolate de Hershey era necesariamente añadido a la mezcla de chocolate. A las 6 pm. los dos las mezclas se llevaban en recipientes tapados al sótano de la iglesia y se dejó reposar durante la noche. Presuntamente no fueron tocados por nadie. durante este período.\nEn la mañana del 18 de abril, el Sr. Coe agregó cinco onzas de vainilla y dos latas de leche condensada a la mezcla de vainilla y tres onzas de vainilla y una lata de leche condensada a la mezcla de chocolate. Luego el helado de vainilla se transfirió a un lata de congelación y se coloca en un congelador eléctrico durante 20 minutos, después de lo cual el helado de vainilla se sacó de la lata del congelador y se envasó en otra lata que había sido previamente lavado con agua hirviendo. Entonces el chocolate la mezcla se puso en la lata del congelador que había sido se enjuaga con agua del grifo y se deja congelardurante 20 minutos.”\nAl concluir esto, ambos las latas se taparon y se colocaron en grandes recipientes de madera recipientes llenos de hielo. Como señaló, el helado de chocolate permaneció en el una lata de congelador.\nTodos los manipuladores del helado fueron examinados. Sin lesiones externas ni respiratorias altas se notaron infecciones. Cultivos de nariz y garganta fueron tomados de dos individuos que prepararon el helado.\nLos exámenes bacteriológicos fueron hechos por el División de Laboratorios e Investigación, Albany, en ambos helados. Su informe es el siguiente:\n‘Un gran número de Staphylococcus aureus y albus se encontraron en la muestra de hielo de vainilla crema. Sólo unos pocos estafilococos fueron demostrado en el helado de chocolate.’\nInforme de los cultivos de nariz y garganta de Los Petries que prepararon el helado decía lo siguiente:\nPresencia de Staphylococcus aureus y hemolítica del cultivo nasal y Staphylococcus albus del cultivo faríngeo de Gracia Petrie. Tambien Staphylococcus albus del cultivo de la nariz de Marian Petrie. Los estreptococos hemolíticos no eran del tipo generalmente asociado con infecciones en el hombre.\nDiscusión sobre la fuente: la fuente de contaminación bacteriana del helado de vainilla no está claro. Cualquiera que sea el método de la introducción de los estafilococos, parece razonable suponer que debe haber ocurrido entre la tarde del 17 de abril y la mañana del 18 de abril. Sin motivo de contaminación Se conoce la peculiaridad del helado de vainilla. “Al dispensar los helados, la misma cuchara se utilizó. Por lo tanto, no es improbable suponer que alguna contaminación al helado de chocolate crema ocurrió de esta manera. Esto parecería ser la explicación más plausible para la enfermedad en los tres individuos que no comieron el helado de vainilla.\nMedidas de Control: El 19 de mayo, todo el helado restantes fue condenado. Todos los demás alimentos en el la cena de la iglesia había sido consumida.\nConclusiones: Un brote de gastroenteritis ocurrió después de una cena en la iglesia en Lycoming. La causa del brote fue helado de vainilla por contaminado. El método de contaminación de helado no se entiende claramente.\nSi el estafilococo dio positivo de la nariz y la garganta de los cultivos realizados en la familia Petrie haba todo lo que tenga que ver con la contaminación es un asunto por nexo epidemiológico.\nNota: El paciente #52 era un niño que mientras viendo el procedimiento de congelación se le dio una plato de helado de vainilla a las 11:00 am en abril 18.",
    "crumbs": [
      "Case studies",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Oswego (ES)</span>"
    ]
  }
]