[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Epi Case Studies",
    "section": "",
    "text": "Case-studies Open Repository\nObjective: This open repository of case studies can be used as a guide on how to implement different epidemiological methods in different situations using a variety of tools\nThis is an internal link: See Fulton County English\nThis is another kind of internal link that makes use of a tag: Chapter 2\nThis is a static table to test links:\nFilterable version of table (but will need to insert weblinks, not references as they do not seem to work)"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Acknowledgements",
    "section": "",
    "text": "This is a book created from markdown and executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "fulton.html#sec-fulton-en",
    "href": "fulton.html#sec-fulton-en",
    "title": "2  Fulton County COVID-19",
    "section": "2.1 English",
    "text": "2.1 English\nThis page contains the Fulton County COVID-19 case study (all languages)\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "fulton.html#sec-fulton-es",
    "href": "fulton.html#sec-fulton-es",
    "title": "2  Fulton County COVID-19",
    "section": "2.2 Spanish",
    "text": "2.2 Spanish"
  },
  {
    "objectID": "oswego.html",
    "href": "oswego.html",
    "title": "3  Oswego",
    "section": "",
    "text": "This page contains the Oswego case study (all languages)\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "oswego.html#overview",
    "href": "oswego.html#overview",
    "title": "3  Oswego",
    "section": "3.1 Overview",
    "text": "3.1 Overview\nCase study characteristics Name: Oswego\nLanguage: Spanish\nTool: R\nLocation: United States\nDisease: TBD\nKeywords:\nAcknowledgements Tutorial authors:\nData source:"
  },
  {
    "objectID": "oswego.html#instructions",
    "href": "oswego.html#instructions",
    "title": "3  Oswego",
    "section": "3.2 Instructions",
    "text": "3.2 Instructions\n\n3.2.1 Getting Help\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\n3.2.1.1 Hints and Solutions\nHere is what the “helpers” look like:\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\n3.2.1.2 Posting a question in the Community Forum\n… description here about posting in Community…"
  },
  {
    "objectID": "oswego.html#primera-parte---antecedentes",
    "href": "oswego.html#primera-parte---antecedentes",
    "title": "3  Oswego",
    "section": "3.3 Primera parte - Antecedentes",
    "text": "3.3 Primera parte - Antecedentes\n\n \n\n\nEl 19 de abril de 1940, el oficial de salud local en el pueblo de Lycoming, condado de Oswego, Nueva York, informó de la ocurrencia de un brote de enfermedad gastrointestinal al Distrito de Salud Oficial en Siracusa. Dr. A. M. Rubin, epidemiólogo en formación, fue asignado para investigar lo ocurrido.\nCuando el Dr. Rubin llegó al campo, determinó a través del oficial de salud que todas las personas que enfermaron había asistido a una cena en la iglesia celebrada el noche anterior, 18 de abril. Otra información importante fue que los familiares que no asistieron a la cena, no enfermaron.\nEn consecuencia, el Dr. Rubin centró la investigación sobre lo ocurrido en la cena. Pudo completar 75 entrevistas de las 80 personas conocidas que asistieron a la cena, recopilando información sobre los ocurrencia y tiempo de aparición de los síntomas, y alimentos consumidos. de las 75 personas entrevistados, 46 personas se enfermaron de enfermedad gastrointestinal.\n\n3.3.1 Pregunta 1: ¿Ante que tipo de situación está presente el Dr Rubin?.\n\nUna epidemia\n\nUna serie de casos\n\nUn brote\n\nNo se puede establecer\n\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nLa solucion es numero 3 - Un brote. TODO Here is more explanation.\nNumero 1 - No es la respuesta correcta; revisa el concepto de epidemia, tiene que ver con la cantidad de personas afectadas.\nNumero 2 - Es posible, pero también debes tomar en cuenta otros factores.\nNumero 4 - No te preocupes, en este tutorial vas a poder aprender los pasos del trabajo de campo.\n\n\n\n\n\n\n3.3.2 Pregunta 2: Los pasos de una investigación de brote son:.\n\n\n\n\n\n3.3.3 Descripción clínica\n\n \n\n\nEl inicio de la enfermedad en todos los casos fue agudo, caracterizada principalmente por náuseas, vómitos, diarrea y dolor abdominal. Ninguno de los enfermos personas reportaron tener un nivel elevado temperatura; todos se recuperaron dentro de las 24 a 30 horas.\nAproximadamente el 20% de los enfermos que visitaron al médico no se les realizó examen de muestras fecales para el examen bacteriológico.\n\n\n3.3.4 Pregunta 3: Enumere las grandes categorías de agentes causales de enfermedades que se deben considerar en el diagnóstico diferencial de un brote de enfermedad gastrointestinal.\nLos investigadores sospechan de que la génesis de este brote fue través de los alimentos como vehiculo de transmisión entre los afectados.\n\n\n3.3.5 Pregunta 4: En lenguaje epidemiológico, ¿Qué es un vehículo? ¿Qué es un vector? ¿Cuáles son otros modos?\n\n\n3.3.6 Pregunta 5: Si tuviera que administrar un cuestionario a los participantes de la cena de la iglesia, ¿qué información recopilarías? Agrupa la información en categorías.\nEl Dr. Rubin recolectó los datos de los entrevistados a través de un listado nominal\n\n\n3.3.7 Pregunta 6: ¿En que nos ayuda un listado nominal?."
  },
  {
    "objectID": "oswego.html#segunda-parte---el-evento",
    "href": "oswego.html#segunda-parte---el-evento",
    "title": "3  Oswego",
    "section": "3.4 Segunda parte - El Evento",
    "text": "3.4 Segunda parte - El Evento\n\n3.4.0.1 Descripción de la Cena\n\n  \n\nLa cena se celebró en el sótano del iglesia del pueblo. Los alimentos fueron aportados por numerosos miembros de la congregación. La cena comenzaba a las 6:00 p.m. y continuó hasta 11.00 pm.\nLa comida estaba esparcida sobre una mesa y fue consumida durante un período de varias horas. Los datos sobre el inicio de la enfermedad y los alimentos consumidos por cada una de las 75 personas entrevistados se proporcionan en la listado adjunto.\nLa hora aproximada de participación en el evento solo se recolectó aproximadamente la mitad de las personas que tuvo una enfermedad gastrointestinal.\n\n\n3.4.1 Pregunta 7: ¿Cuál es el valor de una curva epidémica?\n\n\n3.4.2 Pregunta 8: ¿Qué nos dice el siguiente gráfico?\n\n\n3.4.3 Pregunta 9: ¿Hay algún caso en el que los tiempos de inicio no coincidan con los generales? ¿experiencia? ¿Cómo podrían explicarse?\n\n\n3.4.4 Listado nominal de individuos del brote de gastroenteritis, Oswego, Nueva York, 1940\n\n\n\n\n\n\n\n\n3.4.5 ¿Cómo podrían presentarse mejor los datos en el listado nominal de participantes?\n\n3.4.5.1 Versión digital"
  },
  {
    "objectID": "oswego.html#tercera-parte---análisis",
    "href": "oswego.html#tercera-parte---análisis",
    "title": "3  Oswego",
    "section": "3.5 Tercera parte - Análisis",
    "text": "3.5 Tercera parte - Análisis\n\n3.5.1 Apoyo en análisis de los datos\n\n\n\n\nAhora vamos a comenzar con uno de los pasos más importantes en la investigación de brote, el análisis de los datos donde a través de este vamos a determinar cual o cuales son las posibles causas del brote, medidas a tomar entre otros pasos. ¡También vamos a usar un poco de R para ayudar con este proceso de análisis!.\n\n\n3.5.2 Pregunta 11: Siempre que sea posible, utilizando el listado nominal actualizado, calcule los períodos de incubación e ilustre su distribución con un gráfico apropiado.\n \nPara contestar esta pregunta, vamos hacer los siguientes pasos usando R:\n \n\nen Rstudio, crea un nuevo script para cargar los datos (cargar el archivo “listado_oswego_limpio.csv”, que está en la carpeta data)\n\n\n# Importa el listado al espacio de trabajo, \n# puedes copiar este código en rstudio en tu editor de códigos\n\nlibrary(pacman) # para gestionar los paquetes\n\np_load(rio,         # para importar archivos\n       here,        # para gestionar la ruta del archivo\n       tidyverse,   # Para transformar datos\n       lubridate)   # para trabajar con fechas\n\nlibrary(here)\n\nlistado &lt;- import(here(\"casos_estudios\", \"data\", \"listado_oswego_limpio.csv\"))\n\nView(listado)\n\nPara referencia sobre como importar archivos, ver el capítulo 7 del libro de R para epidemiologos\n \n\nEl listado cargado ya tiene el formato correcto de la fecha y hora de almuerzo y la fecha y hora de inicio de síntomas ahora con el siguiente código creas la variable que tendrá el valor del período de incubación. (recuerda que con las variables de tiempo en R se pueden hacer operaciones matemáticas)\n\n\n# Crear la variable del período de incubación\n# puedes copiar este código en rstudio en tu editor de códigos\n#las funciones \"interval\" y \"dhours()\" son las que usaremos para calcular la diferencia en hora\n\nlistado_incubacion &lt;- listado %&gt;% \n  \n  mutate(incubacion=interval(fecha_hora_almuerzo, fecha_hora_ini_sintomas) / dhours(1)) \n\nPara más detalles de como trabajar con fechas, ver el capítulo 9 del libro de R para epidemiologos\n \n\nAhora vamos a graficar el período de incubación con ggplot para visualizar la distribución\n\n\n# Hacer un histograma de los periodos de incubación calculados\n# puedes copiar este código en rstudio en tu editor de códigos\n\nlistado_incubacion %&gt;% \n  \n  ggplot(aes(x=incubacion))+\n  \n  geom_histogram()+\n  \n  labs(title=\"Casos de enfermedad gastrointestinal por período de incubación en horas\",\n       subtitle = \"Oswego, NY, 18-19 de abril, 1940\",\n       x=\"Período de incubación (Horas)\",\n       y=\"n de casos\")+\n  \n  theme_minimal()\n\n#Si quieres asignar este gráfico a un objeto, solo tienes que en la primera línea del código \n#usar un nombre (como grafico1) y escribir el signo de asignación (&lt;-)\n\nPara más detalles de como trabajar con gráficos, ver el capítulo 30 del libro de R para epidemiologos\n \n\n3.5.2.1 ¿Cuantos casos tenian el dato de incubación?\n\n\n\n3.5.3 Pregunta 12: Determine el rango y la mediana del período de incubación.\nPara ejecutar esto en R hay varias formas, usando ya sea las funciones base o de otros paquetes. Vamos a usar directamente el paquete {dplyer} que viene integrado en el paquete {tidyverse}\n\n# Calcular el rango, la mediana y el periodo de incubacion\n# puedes copiar este código en rstudio en tu editor de códigos\n\nresumen_estadistico &lt;- listado_incubacion %&gt;% \n  filter(!is.na(incubacion)) %&gt;% \n  reframe(mediana=median(incubacion),\n          min=min(incubacion),\n          max=max(incubacion),\n          rango=max-min)\n\nresumen_estadistico\n\n\n\n3.5.4 Pregunta 13: ¿Cómo ayuda la información sobre el período de incubación y los datos sobre síntomas a establecer diagnósticos diferenciales de la enfermedad? (Si es necesario, consulte adjunto Compendio de enfermedades gastrointestinales agudas transmitidas por los alimentos).\n\n\n3.5.5 Pregunta 14: Usando los datos del listado, complete la tabla a continuación. ¿Cúal o cuales alimentos pudieron ser el vehículo más probable de infección?\n \nPara contestar esta pregunta, vamos hacer los siguientes pasos usando R:\n \n\nSiguiendo con el mismo script que creaste anteriormente, ahora vamos hacer un resumen para calcular la tasa de ataque de cada variable de exposición (en este caso bebidas y alimentos). El listado que cargamos ya tiene recodificadas las variables para asignar el valor de 1 si fue consumido y 0 para no consumido.\n\n\n#Ve copiando el codigo a rstudio (este ejercicio es un poco largo)\n\np_load(janitor, gtsummary)\n\n\n#Comieron\n#hacer un dataframe con un resumen de los alimentos por los que enfermaron\ntotal_por_alimentos_casos_a &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no enfermo\")) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"enfermo\") %&gt;% \nslice_tail()\n\n#hacer un dataframe con un resumen de los alimentos por los que no enfermaron\ntotal_por_alimentos_no_casos_a &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no_enfermo\")) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"no_enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"no_enfermo\") %&gt;% \nslice_tail()\n\n#No Comieron\n#hacer un dataframe con un resumen de los alimentos por los que enfermaron\ntotal_por_alimentos_casos_b &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no enfermo\"),\n         across(starts_with(\"m_\"),~ifelse(.x==1,0,1))) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"enfermo\") %&gt;% \nslice_tail()\n\n#hacer un dataframe con un resumen de los alimentos por los que no enfermaron\ntotal_por_alimentos_no_casos_b &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no_enfermo\"),\n         across(starts_with(\"m_\"),~ifelse(.x==1,0,1))) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"no_enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"no_enfermo\") %&gt;% \nslice_tail()\n\n\n#Combinar ambos dataframes, transformarlo a formato extendido y calcular la proporción de los que consumieron\ntabla_maestra_a &lt;- bind_rows(total_por_alimentos_casos_a,\n                           total_por_alimentos_no_casos_a) %&gt;% \n  pivot_longer(2:ncol(.), names_to = \"alimentos\", values_to = \"n\") %&gt;% \n  pivot_wider(names_from = tipo_caso, values_from = n) %&gt;% \n  mutate(total=enfermo+no_enfermo,\n         ptc_enfermo=enfermo/total,\n         ptc_no_enfermo=no_enfermo/total)\n\n\n\n#Combinar ambos dataframes, transformarlo a formato extendido y calcular la proporción de los que no consumieron \ntabla_maestra_b &lt;- bind_rows(total_por_alimentos_casos_b,\n                           total_por_alimentos_no_casos_b) %&gt;% \n  pivot_longer(2:ncol(.), names_to = \"alimentos\", values_to = \"n\") %&gt;% \n  pivot_wider(names_from = tipo_caso, values_from = n) %&gt;% \n  mutate(total=enfermo+no_enfermo,\n         ptc_enfermo=enfermo/total,\n         ptc_no_enfermo=no_enfermo/total)\n\ntabla_final &lt;- tabla_maestra_a %&gt;% \n  left_join(tabla_maestra_b,suffix = c(\"_consumieron\", \"_no_consumieron\"), by=\"alimentos\") %&gt;% \n  mutate(tasa_ataque=ptc_enfermo_consumieron/ptc_enfermo_no_consumieron)\n\nView(tabla_final)\n\n#otra forma.. para obtener los OR de cada alimento\n\n#crear un modelo de regresión logistica\nmodel &lt;- glm(data=listado, enfermo~m_jamon_horneado+\n            m_espinaca+m_pure_papa+m_ensa_repollo+\n            m_gelatina+m_rollos+m_pan+m_lehe+m_cafe+m_agua+\n            m_bizcocho+m_hel_vainilla+m_hel_chocolate+m_ens_fruta,\n            family=binomial())\n#Luego una tabla\ntbl_regression(model, exponentiate = TRUE)\n\ntest &lt;- listado %&gt;% \n  select(enfermo, starts_with(\"m_\")) %&gt;% \n  tbl_summary(by=enfermo)\n\nPara más detalles de como trabajar con transformación de datos y tablas, ver el capítulo 17 del libro de R para epidemiologos\n\n\n3.5.6 Pregunta 15: Resuma las investigaciones adicionales que deben llevarse a cabo.\n\n\n3.5.7 Pregunta 16: ¿Qué medidas de control sugeriría?\n\n\n3.5.8 Pregunta 17: ¿Por qué fue importante trabajar en este brote?\n\n\n3.5.9 Pregunta 18: Consulte los pasos de una investigación de brote que enumeró en la Pregunta 2. ¿Cómo funciona esto? investigación se ajusta a ese esquema?"
  },
  {
    "objectID": "oswego.html#cuarta-parte---conclusión",
    "href": "oswego.html#cuarta-parte---conclusión",
    "title": "3  Oswego",
    "section": "3.6 Cuarta Parte - Conclusión",
    "text": "3.6 Cuarta Parte - Conclusión\n\n\n\n\n\nLo siguiente se cita textualmente del informe preparado por el Dr. Rubin:\nEl helado fue preparado por el Petrie hermanas de la siguiente manera: En la tarde del 17 de abril la leche cruda de la La granja Petrie en Lycoming se desbordó al baño maría se le agrega azúcar y huevos y un poco de harina para darle cuerpo a la mezcla. El se prepararon helado de chocolate y vainilla por separado.\nEl chocolate de Hershey era necesariamente añadido a la mezcla de chocolate. A las 6 pm. los dos las mezclas se llevaban en recipientes tapados al sótano de la iglesia y se dejó reposar durante la noche. Presuntamente no fueron tocados por nadie. durante este período.\nEn la mañana del 18 de abril, el Sr. Coe agregó cinco onzas de vainilla y dos latas de leche condensada a la mezcla de vainilla y tres onzas de vainilla y una lata de leche condensada a la mezcla de chocolate. Luego el helado de vainilla se transfirió a un lata de congelación y se coloca en un congelador eléctrico durante 20 minutos, después de lo cual el helado de vainilla se sacó de la lata del congelador y se envasó en otra lata que había sido previamente lavado con agua hirviendo. Entonces el chocolate la mezcla se puso en la lata del congelador que había sido se enjuaga con agua del grifo y se deja congelardurante 20 minutos.”\nAl concluir esto, ambos las latas se taparon y se colocaron en grandes recipientes de madera recipientes llenos de hielo. Como señaló, el helado de chocolate permaneció en el una lata de congelador.\nTodos los manipuladores del helado fueron examinados. Sin lesiones externas ni respiratorias altas se notaron infecciones. Cultivos de nariz y garganta fueron tomados de dos individuos que prepararon el helado.\nLos exámenes bacteriológicos fueron hechos por el División de Laboratorios e Investigación, Albany, en ambos helados. Su informe es el siguiente:\n‘Un gran número de Staphylococcus aureus y albus se encontraron en la muestra de hielo de vainilla crema. Sólo unos pocos estafilococos fueron demostrado en el helado de chocolate.’\nInforme de los cultivos de nariz y garganta de Los Petries que prepararon el helado decía lo siguiente:\nPresencia de Staphylococcus aureus y hemolítica del cultivo nasal y Staphylococcus albus del cultivo faríngeo de Gracia Petrie. Tambien Staphylococcus albus del cultivo de la nariz de Marian Petrie. Los estreptococos hemolíticos no eran del tipo generalmente asociado con infecciones en el hombre.\nDiscusión sobre la fuente: la fuente de contaminación bacteriana del helado de vainilla no está claro. Cualquiera que sea el método de la introducción de los estafilococos, parece razonable suponer que debe haber ocurrido entre la tarde del 17 de abril y la mañana del 18 de abril. Sin motivo de contaminación Se conoce la peculiaridad del helado de vainilla. “Al dispensar los helados, la misma cuchara se utilizó. Por lo tanto, no es improbable suponer que alguna contaminación al helado de chocolate crema ocurrió de esta manera. Esto parecería ser la explicación más plausible para la enfermedad en los tres individuos que no comieron el helado de vainilla.\nMedidas de Control: El 19 de mayo, todo el helado restantes fue condenado. Todos los demás alimentos en el la cena de la iglesia había sido consumida.\nConclusiones: Un brote de gastroenteritis ocurrió después de una cena en la iglesia en Lycoming. La causa del brote fue helado de vainilla por contaminado. El método de contaminación de helado no se entiende claramente.\nSi el estafilococo dio positivo de la nariz y la garganta de los cultivos realizados en la familia Petrie haba todo lo que tenga que ver con la contaminación es un asunto por nexo epidemiológico.\nNota: El paciente #52 era un niño que mientras viendo el procedimiento de congelación se le dio una plato de helado de vainilla a las 11:00 am en abril 18."
  },
  {
    "objectID": "fulton.html",
    "href": "fulton.html",
    "title": "2  Fulton County COVID-19",
    "section": "",
    "text": "3 Descriptive analysis\nThis section will be analysing data by time, place, and person to produce descriptive tables."
  },
  {
    "objectID": "fulton.html#overview",
    "href": "fulton.html#overview",
    "title": "2  Fulton County COVID-19",
    "section": "2.1 Overview",
    "text": "2.1 Overview\nCase study characteristics Name: Fulton\nLanguage: English\nTool: R\nLocation: United States\nDisease: COVID-19\nKeywords:\nAcknowledgements\nTutorial authors: Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer\nData source: Anonymised and jittered data provided by Fulton County for training purposes"
  },
  {
    "objectID": "fulton.html#introduction-to-this-case-study-script",
    "href": "fulton.html#introduction-to-this-case-study-script",
    "title": "2  Fulton County COVID-19",
    "section": "2.2 Introduction to this case study script",
    "text": "2.2 Introduction to this case study script\nThis is a an example R-markdown script which demonstrates how to create an automated outbreak situation report for COVID-19 in Fulton county, USA. The data used are anonymised and fake (scrambled), for example purposes only.\n\nWe demonstrate how to import, clean and analyse your data.\n\nAnalysis is organised by time, place and person.\n\nFor the purpose of the case study we separate this by descriptive analysis and visualisation (normally this would be mixed together of course)\n\nThe visualisation section is organised in to place, time and person. This is to simplify flow for didactic delivery.\n\n\nAnalysis is loosely based off the monthly epidemiology reports for Fulton county\n\n\nText within &lt;! &gt; will not show in your final document.\n\nThe other parts such as slashes (///), dashes (-) and tildes (~) are just aesthetic\nThese comments are used to explain the code chunks.\n\nWe refer to functions in curly brackets, e.g. {dplyr} and functions end in brackets, e.g. count()\n\nThis comment will not show up when you knit the document.\n\nYou can delete them if you want.\n\n\nFeedback & suggestions are welcome at the GitHub issues page\n\nAlternatively email us at: epirhandbook@gmail.com"
  },
  {
    "objectID": "fulton.html#summary",
    "href": "fulton.html#summary",
    "title": "2  Fulton County COVID-19",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\nAs of June 23 2021, Fulton County has recorded 81757 confirmed cases of COVID-19.\n\nAs of June 23 2021, Fulton County has recorded 1701 (2.1%) deaths.\n\nAmong all confirmed cases of COVID-19 in Fulton County, 5277 (6.5%) required hospitalization."
  },
  {
    "objectID": "fulton.html#time",
    "href": "fulton.html#time",
    "title": "2  Fulton County COVID-19",
    "section": "3.2 Time",
    "text": "3.2 Time\n\n\n\n\nError in opts_current_table(): if a label (epiweek_table) is defined, chunk option `tbl-cap` should also be defined.\n\n\n\nAs you can see from above in Table @ref(tab:timetab) we can see clear trends in reporting patterns - cases increase in waves and peak in December 2020."
  },
  {
    "objectID": "fulton.html#place",
    "href": "fulton.html#place",
    "title": "2  Fulton County COVID-19",
    "section": "3.3 Place",
    "text": "3.3 Place\n\n\n\n\n\n\n\n\nError in opts_current_table(): if a label (zip_table) is defined, chunk option `tbl-cap` should also be defined."
  },
  {
    "objectID": "fulton.html#person",
    "href": "fulton.html#person",
    "title": "2  Fulton County COVID-19",
    "section": "3.4 Person",
    "text": "3.4 Person\n\n\n\n\nError in opts_current_table(): if a label (demographics_tab) is defined, chunk option `tbl-cap` should also be defined.\n\n\n\n\n3.4.1 Risk factors for mortality\n\n\n\n\n\n\nError in opts_current_table(): if a label (simple_stats) is defined, chunk option `tbl-cap` should also be defined.\n\n\n\n\n\n\n\nError in opts_current_table(): if a label (regression) is defined, chunk option `tbl-cap` should also be defined.\n\n\nAs seen in Table @ref(tab:regrtab), mortality was associated with being male (OR 2.02; 95% CI 1.44, 2.85), being white (OR 1.61; 95% CI 1.08, 2.36)and longer hospital stays (OR 1.14; 95% CI 1.12, 1.17)."
  },
  {
    "objectID": "fulton.html#person-1",
    "href": "fulton.html#person-1",
    "title": "2  Fulton County COVID-19",
    "section": "4.1 Person",
    "text": "4.1 Person\nAs we see below in Figure @ref(fig:agehospplot) there appears to be an association between older age, length of hospital stay and mortality. We saw this in Table @ref(tab:regrtab) as well for the individual associations, although we did not check for interaction and confounding.\n\n\n\n\n\n\nDuration of admission among hospitalized COVID-19 patients\n\n\n\n\n\n\n\n\n\n\n\nCOVID-19 cases by ethnicity\n\n\n\n\n\n\n\n\n\n\n\nAge and Gender of COVID-19 cases, Fulton County"
  },
  {
    "objectID": "fulton.html#time-1",
    "href": "fulton.html#time-1",
    "title": "2  Fulton County COVID-19",
    "section": "4.2 Time",
    "text": "4.2 Time\n\n\n\nError in `plot()`:\n! Arguments in `...` must be used.\n✖ Problematic argument:\n• n.breaks = 24\nℹ Did you misspell an argument name?"
  },
  {
    "objectID": "fulton.html#place-1",
    "href": "fulton.html#place-1",
    "title": "2  Fulton County COVID-19",
    "section": "4.3 Place",
    "text": "4.3 Place\n\n\n\n\n\n\n\n\nNew COVID-19 cases (06/10-06/23) by ethnicity in Fulton County\n\n\n\n\n\n\n\n\n\n\n\n\nCOVID-19 case incidence (per 100,000) by Zip Code (06/10-06/23) in Fulton County\n\n\n\n\n\n\n\n\n\n\n\nCOVID-19 case incidence (per 100,000) by proportion of ethnic minority cases and Zip Code (06/10-06/23) in Fulton County\n\n\n\n\n\n\n\n\n\n\n\nDensity map - New COVID-19 cases (06/10-06/23) in Fulton County"
  },
  {
    "objectID": "fulton-en.html",
    "href": "fulton-en.html",
    "title": "2  Fulton (EN)",
    "section": "",
    "text": "Import data and cleaning\nIn this section we will see how to create an automatic and dynamic report to present a descriptive analysis of the data previously imported and cleaned.\nIn this section we will show how to include in the report an analysis of the risk factors for Covid-19 mortality."
  },
  {
    "objectID": "fulton-en.html#overview",
    "href": "fulton-en.html#overview",
    "title": "2  Fulton (EN)",
    "section": "2.1 Overview",
    "text": "2.1 Overview\nCase study characteristics Name: Fulton\nLanguage: English\nTool: R\nLocation: United States\nDisease: COVID-19\nKeywords:\nAcknowledgements\nTutorial authors: Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer\nData source: Anonymised and jittered data provided by Fulton County for training purposes"
  },
  {
    "objectID": "fulton-en.html#instructions",
    "href": "fulton-en.html#instructions",
    "title": "2  Fulton (EN)",
    "section": "Instructions",
    "text": "Instructions\n\nGetting Help\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\nHints and Solutions\nHere is what the “helpers” look like:\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\nPosting a question in the Community Forum\n… description here about posting in Community…\n\n\nTerms of Use\nXXXXXXXXXXXXXXXXXXXXX\n\n\n\nFeedback & suggestions\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org\n\n\n\n\n2.0.1 Version and revisions\nThe first version was written by Alex Spina, Neale Batra, Mathilde Musset, Henry Laurenson-Schafer in August 2021.\n\n\n\n\n\n\n\n\n\nDate\nChanges made\nVersion\nAuthor\n\n\n\n\nJan 2024\nAdapted to case study template\n1.1\nAlberto Mateo Urdiales\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuidance\n\nBackground and Objectives of this case study\nThis is a an example R-markdown script which demonstrates how to create an automated outbreak situation report for COVID-19 in Fulton county, USA. The data used comes from an anonymised and fake (scrambled) linelist of COVID-19 cases in Fulton county from the beginning of the pandemic (early 2020) until July 2021.\nThe overall objective is to create an automatic and dynamic report that shows the COVID-19 epidemiological situation in Fulton County.\nIn this case study you will learn:\n\nHow to import, clean and analyse your data.\n\nCarry out descrptive analysis by time, place and person.\n\nUse the above to create an automatic and dynamic report in word using Rmarkdown.\n\n\nFor the purpose of the case study we separate this by descriptive analysis and visualisation (normally this would be mixed together of course). The visualisation section is organised in to place, time and person. This is to simplify flow for didactic delivery.\nAnalysis is loosely based off the monthly epidemiology reports for Fulton county\n\n\n\nPrevious level of expertise assumed\nUsers should have some prior experience with R, including:\n\nR basics: Several packages are required for different aspects of analysis with R. You will need to install these before starting. We install and load packages using the {pacman} package. Its p_load() command will install packages if necessary and load them for use in the current session. This might prove difficult if you have limited administrative rights for your computer. Making sure your IT-department gives you the correct access can save a lot of headache. See this handbook pages on the basics of installing packages and running R from network drives (company computers) for more detail. https://epirhandbook.com/r-basics.html#installation https://epirhandbook.com/r-on-network-drives.html#r-on-network-drives\nR projects: See Chapter 6 R Projects from the EpiRhandbook\nImport and export of data: See Chapter7 Import and export\n\n\n\nPreparation for the case study\n\nDownload folder fulton_en and extract contents in the local laptop\nOpen the Rstudio project inside the folder called fulton_en.Rproj\nInside the folder you can find the Rmd and the word output (weekly report). You can also find a word template that will be used as the template for the report. The Rmd and the output are there to help you if you struggle, but you should try to recreate these yourself following this case study.\nSubfolder data contains fulton COVID-19 data needed for the analysis\nSubfolder solution_materials has a copy of the Rmd document with the solution and a copy Word document with the output requested\nOpen a new Rmarkdown file in RStudio and save it in the root folder fulton_en. If you have any doubts about how to create an Rmarkdown follow the EpiRhandbook instructors here\nThis Rmarkdown file will be the file used throughout the case study and, rendering it will produce the weekly report in word format\n\n\nImport data and cleaningDescriptive analysisAnalysis of mortality\n\n\n\nStep 1: Install/load packages\nInstall the following packages that will be needed to carry out the analysis: officedown, officer, rio, here, skimr, janitor, lubridate, epikit, tidyverse, flextable, sf, scales, gtsummary, labelled, ggspatial, patchwork, apyramid and incidence2.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nSys.setlocale(\"LC_ALL\", \"English\")\n\n# hide all code chunks in the output, but show errors \nknitr::opts_chunk$set(echo = FALSE,  # hide all code chunks in output\n                      error = TRUE,  # show errors if they appear, but don't stop (produce the word doc)\n                      warning = FALSE, # do not show warnings in the output word doc \n                      message = FALSE, # do not show  messages in the output word doc\n                      fig.width = 7,         # Figure width\n                      fig.height = 6,        # Figure height\n                      fig.topcaption = TRUE  # show figure titles on top of plot\n                     )\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  officedown, # format MS word document output\n  officer,    # add table of contents to output\n  rio,        # importing data  \n  here,       # relative file pathways \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # age_categories() function\n  flextable,  # converting tables to pretty images\n  sf,         # manage spatial data using a Simple Feature format\n  scales,     # define colour schemes for flextables \n  gtsummary,  # summary statistics, tests and regressions \n  labelled,   # create variable labels to be displayed in table outputs\n  ggspatial,  # basemaps and scalebars \n  patchwork,  # combining multiple ggplots \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n\n)\n\n\n\n\n\n\nStep 2: Data import\n\nImport the COVID-19 linelist called covid_example_data.xlsx that can be found in the following path: data/covid_example_data/.\nImport also the shapefile named FultonCountyZipCodes.shp found in data/covid_example_data/covid_shapefile/ needed to retrieve the population in Fulton County.\nExplore the linelist to understand better the data.\n\n\nQuestion 2.1: How many rows are present in linelist_raw?\n\n 48 31 82101 5\n\nQuestion 2.2: How many columns are of class numeric?\n\n 8 4 19 31\n\n\n\n\nClick to see a solution code (try it yourself first!)\n\n\n\n##############        IMPORTING DATA     ##############        \n\n# We use the {rio} package for importing our example data - it is very versatile \n# and can read in most file types. \n# \n# We use the {here} package for defining the path to our file. This is important \n# for sharing your script with others (by email or on Sharepoint) - if you used an\n# \"absolute\" path, they would need to update the script to match their computer. \n# \n# This way your whole R-project folder can be zipped up and moved somewhere else. \n# \n# For more details see: \n# https://epirhandbook.com/import-and-export.html\n\n  \n  #import the raw case data set\n  # define the path using {here} then pass that to the {rio} import function\n  # specify the sheet to read using which (default is to read first sheet)\nlinelist_raw &lt;- rio::import(\n  file = here::here(\"data\", \"fulton-en\", \"covid_example_data\", \"covid_example_data.xlsx\"),\n  which = \"in\"\n)\n\n# import shapefile\n  # for extracting population counts for zipcodes and mapping\nshapefile &lt;- read_sf(\n  here::here(\"data\", \"fulton-en\", \"covid_example_data\", \"covid_shapefile\", \"FultonCountyZipCodes.shp\")\n)\n\n##############        EXPLORING THE DATA     ##############        \n\n# Here we take a look at the raw data to get a feel for what needs cleaning. \n# \n# We first use the in-built browser with the {base} function View(). \n# \n# Then we can use the {base} function summary(), but probably the most comprehensive \n# overview is with the {skimr} function. \n# You can also view distinct values for variables using the {base} unique() function. \n# \n# For more details see: \n# https://epirhandbook.com/cleaning-data-and-core-functions.html#review\n# https://epirhandbook.com/descriptive-tables.html#browse-data\n\n# view your whole dataset interactively (in an excel style format)\nView(linelist_raw)\n\n# get summary: \n# mean, median and max values of numeric variables\n# counts for categorical variables\n# also gives number of NAs\nsummary(linelist_raw)\n\n# get information about each variable in a dataset \n# nb. “POSIXct” is a type of raw date class \nskim(linelist_raw)\n\n# view unique values contained in variables - useful for categorical variables\n# you can run this for any column -- just replace the column name\nunique(linelist_raw$case_gender) \n\n\n# we can also loop through all categorical variables to look at all possibilities\n# see later in the script for introductions to using iteration\npurrr::map(\n  # all column names (inputs)\n  .x = linelist_raw %&gt;% \n    select(where(is_character)) %&gt;% \n    names(), \n  # applies select() then unique() to each column\n  .f = ~select(linelist_raw, .x) %&gt;% \n    unique()\n  )\n\n\n\n\n\nStep 3: Data cleaning\n\nCreate an object called surveillance_date defined as 7 days prior to the reporting date (30 June 2021). Then, create another object rounding it to the closest Wednesday. Create two sequences of dates, one as the 14 days prior to the surveillance_date and another as 14-28 days prior to the same date. We will use these throughout the case study\nClean the column names\nEnsure that dates are considered dates by R\nClean date columns dealing with values that are not compatible with the period under analysis (early 2020 to July 2021)\nClean the rest of columns, ensuring that missing values are considered NA by R, ensuring that data values are plausible (e.g., no negative age) and recoding data into new variables as you see appropriate.\nCreate a column named “epiweek” using the report date which rounds the report date to the nearest week, taking “Wednesday” as the start of the week.\nRemove duplicates from the data\nFilter the data to keep only confirmed cases whose date of report is not above the date of the report (June 30, 2021). Consider also keeping recors with missing date of report.\n\n\nQuestion 3.1: How many duplicated rows were present in the raw data?\n\n 28 31 38 124\n\nError in eval(expr, envir, enclos): oggetto 'opts3.2' non trovato\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n##############       DEFINE DATES     ##############        \n\n# Here we create a date object (surveillance date), which is the day of the report minus 7\n# days to take into account delay in reporting. This object can be used throughout \n# the document for filtering datasets, plots/tables, etc. \n# \n# We also create a week object to make grouping data easier. In this scenario we \n# have defined the week to start on Wednesdays as this is when Fulton County \n# releases their reports (but you can choose any other day of the week too). \n# \n# From these we are then able to define periods 14 and 28 days prior to our \n# report date. We can also make the appropriate labels to auto-populate\n# table titles.\n\n# create a date object for the surveillance\n# Minus 7 days from the date of report (see YAML) to account for lag in reporting lab results\nsurveillance_date &lt;- as.Date(\"2021-06-30\") - 7\n\n# create an epiweek object from the date \n# floor_date() rounds down to the closest week here\nsurveillance_week &lt;- floor_date(surveillance_date,\n                          # round by weeks\n                          unit = \"week\", \n                          # define week to start on Wednesday\n                          week_start = 3)\n\n# define recent (past 14 days) and previous (28 to 14 days prior)\nrecent_period   &lt;- seq(surveillance_week  - 13, surveillance_week, by = 1)\nprevious_period &lt;- seq(surveillance_week  - 27, surveillance_week - 14, by = 1)\n\n# define a text label of date range for the recent period (for table headers)\nrecent_period_labels &lt;- str_c(\n  format(min(recent_period), format = \"%m/%d\"), \n  \"-\", \n  format(max(recent_period), format = \"%m/%d\")\n)\n\n# define text label of date range for previous period (for table headers) \nprevious_period_labels &lt;- str_c(\n  format(min(previous_period), format = \"%m/%d\"), \n  \"-\", \n  format(max(previous_period), format = \"%m/%d\")\n)\n\n\n# define a label for past 28 days (for table captions)\nfull_period_labels &lt;- str_c(\n  format(min(previous_period), format = \"%B %d\"), \n  \"-\", \n  format(surveillance_week, format = \"%B %d, %Y\")\n)\n\n\n##############        CLEAN NAMES     ##############        \n\n# Here we are going to clean the column names of our data set - and store as a new\n# dataset called \"linelist\". \n# \n# It is possible to use the {janitor} package for automated cleaning of variable \n# names - but as there are only a few variables that we want to rename, \n# here we will demonstrate using {dplyr} select() function for manually renaming.\n# \n# Select() can be used either to retain specific columns or to rename them by using\n# the syntax New name = Old name. \n# \n# For more details see: \n# https://epirhandbook.com/cleaning-data-and-core-functions.html#column-names\n\n\n# create a new object called linelist and assign linelist_raw with renamed columns\nlinelist &lt;- linelist_raw %&gt;% \n  # use select() to retain columns and rename them \n     # NEW name = OLD name\n     # aligned for readability\n  select( \n    pid                 = PID,\n    date_report         = reprt_creationdt_FALSE,      \n    date_dob            = case_dob_FALSE,              \n    age                 = case_age,                    \n    gender              = case_gender,\n    race                = case_race,\n    eth                 = case_eth,\n    zip                 = case_zip,\n    # county              = case_county,\n    # district            = case_district,\n    # state               = case_state,\n    contact_id          = Contact_id, \n    date_onset          = sym_startdt_FALSE,\n    sym_fever,\n    sym_subjfever,\n    sym_myalgia,\n    sym_losstastesmell,\n    sym_sorethroat,\n    sym_cough,\n    sym_headache,\n    sym_resolved,\n    date_recovery       = sym_resolveddt_FALSE, \n    contact_hh          = contact_household,\n    hospitalized,  \n    date_hospitalized   = hosp_admidt_FALSE,\n    date_discharge      = hosp_dischdt_FALSE,\n    died,  \n    died_covid,  \n    date_died           = died_dt_FALSE,\n    confirmed_case, \n    covid_dx, \n    date_positive       = pos_sampledt_FALSE,\n    lat                 = latitude_JITT,\n    lon                 = longitude_JITT\n    )\n\n\n##############        CLEAN DATES     ##############        \n\n# Here we are going to clean the date variables \n# \n# The {base} way to convert columns to Date class is with as.Date(). If the\n# current format is YYYY-MM-DD or YYYY/MM/DD then no other arguments are needed. \n# If the format is different, specify it to format= (for more detail see: \n# https://epirhandbook.com/working-with-dates.html#convert-to-date )\n# \n# Below we also introduce using across() from {dplyr}, which allows you to apply a\n# function across multiple specified columns. See\n# https://epirhandbook.com/cleaning-data-and-core-functions.html#clean_across\n\n\nlinelist &lt;- linelist %&gt;% \n  # convert all date columns to date type \n  # note that dates must be formatted correctly - in some cases date parsers from lubridate can be used here\n  mutate(\n    date_report =       as.Date(date_report),\n    date_dob =          as.Date(date_dob),\n    date_onset =        as.Date(date_onset)\n    # date_recovery =     as.Date(date_recovery),\n    # date_hospitalized = as.Date(date_hospitalized),\n    # date_discharge =    as.Date(date_discharge),\n    # date_died =         as.Date(date_died),\n    # date_positive =     as.Date(date_positive)\n  ) %&gt;% \n  \n  # we can do this in a much faster way by by using across()\n  # the apply the as.Date() function to every column with \"date\" in the name\n  # contains() is a tidyselect function (see the handbook for details)\n  # the top mutate can be deleted now!\n  mutate(across(\n    .cols = contains(\"date\"),\n    .fns = ~as.Date(.x)\n  )) %&gt;%\n  \n  # remove onset dates prior to 2020\n  mutate(across(\n    .cols = c(date_report, date_onset, date_hospitalized, date_discharge, date_died),\n    .fns  = ~replace(.x, .x &lt; as.Date(\"2020-01-01\"), NA)\n    )) %&gt;% \n\n  # remove dates after the surveillance_date (for this report) from all date columns\n  mutate(across(\n    .cols = contains(\"date\"),\n    .fns  =  ~replace(.x, .x &gt; surveillance_date, NA)\n    )) %&gt;%\n     \n  # create an \"epiweek\" column from the report date \n  # floor_date() rounds down to the closest week\n  mutate(epiweek = floor_date(date_report,\n                          # round by weeks\n                          unit = \"week\", \n                          # define week to start on Wednesday\n                          week_start = 3)\n  )\n\n\n##############        CLEAN NUMERICS     ##############        \n\n# Here we are going to clean all numeric variables, as well as create some new \n# variables based on difference between dates. \n# \n# First we will ensure that age is numeric and then fix those with incorrectly \n# entered dates (notice that one individual was -20 years old). \n# \n# Then we show how to create new numeric variables for the number of days between \n# two dates. \n# \n# For more details see: \n# https://epirhandbook.com/cleaning-data-and-core-functions.html#num_cats\n# https://epirhandbook.com/cleaning-data-and-core-functions.html#clean_case_when\n# \n# Note the use of if_else() from {dplyr}, which is faster than {base}'s ifelse()\n# and handles dates better.  \n\n# Age \n############\n\nlinelist &lt;- linelist %&gt;%\n  mutate(\n    # ensure that age is a numeric variable\n    age = as.numeric(age),\n    # set those with negative ages and missing DOB to missing \n    # otherwise just leave the age value as is\n          # nb. NA_real_ just ensures the variable class is not changed\n    age = if_else(age &lt; 0 & is.na(date_dob), NA_real_, age)\n  )\n\n \n    \n# Calculating time differences \n##############################\n\nlinelist &lt;- linelist %&gt;%\n     \n  # delay from onset to hospitalization\n  mutate(\n    # calculate time differences\n    days_onset_hosp = as.numeric(date_hospitalized - date_onset),\n    # set those under 0 or over 30 to missing\n    days_onset_hosp = replace(days_onset_hosp, days_onset_hosp &lt; 0, NA),\n    days_onset_hosp = replace(days_onset_hosp, days_onset_hosp &gt; 30, NA)\n  ) %&gt;%\n     \n  # length of hospitalization\n  mutate(\n    # create outcome date based on whether died or was discharged\n    date_outcome = coalesce(date_died, date_discharge),\n    # calculate time difference\n    days_hosp = as.numeric(date_outcome - date_hospitalized),\n    # set those under 0 or over 60 to missing\n    days_hosp = replace(days_hosp, days_hosp &lt; 0, NA),\n    days_hosp = replace(days_hosp, days_hosp &gt; 60, NA)\n  )\n\n## it's a good habit to make sure the variables you're generating seem realistic\n# (are you calculating them correctly?)\n# summary(linelist$days_hosp)\n\n\n##############        CLEAN CATEGORIES     ##############        \n\n\n# create age groups based on the age variable using \n# the age_categories() function from {epikit}. It is also possible to create \n# age groups using the {dplyr} case_when() function - but is more involved. \n# \n# For more details see: \n# https://epirhandbook.com/cleaning-data-and-core-functions.html#column-creation-and-transformation\n# https://epirhandbook.com/cleaning-data-and-core-functions.html#re-code-values\n# https://epirhandbook.com/characters-and-strings.html?q=regex#regular-expressions-regex\n\nlinelist &lt;- linelist %&gt;% \n     \n     # create age group variable\n     mutate(\n       age_group = age_categories(age,\n        # define break points\n        c(0, 10, 20, 30, 40, 50, 60, 70),\n        # whether last break should be highest category\n        ceiling = FALSE\n     )) %&gt;% \n     \n     # recode one value and leave the rest as they are \n     mutate(\n       died_covid = if_else(died_covid == \"Under Review\",\n                            \"Unknown\", died_covid), \n       confirmed_case = if_else(confirmed_case == \"Pending\", \n                                \"Unknown\", confirmed_case), \n     \n        # force categorical variables to use consistent cases (this can be done for others) \n        sym_myalgia = str_to_title(sym_myalgia),\n      ) %&gt;% \n     \n     #replace one value and leave the rest, across multiple variables \n     # mutate(across(\n     #   .cols = c(contact_hh, contains(\"sym_\")),\n     #   .funs = ~if_else(.x == \"Unk\", \"Unknown\", .x)\n     # )) %&gt;% \n\n     # create a composite category from race and ethnicitiy  \n          #  (nb. this sets those that are non-specified in eth to non-hispanic)\n     mutate(eth_race = case_when(\n       # we evaluate if ethnicity is HISPANIC/LATINO **FIRST**\n       # case_when() evaluates in order (if, else if, else if, ... else)\n          eth  == \"HISPANIC/LATINO\"                           ~ \"Hispanic, all races\", \n          race == \"ASIAN\"                                     ~ \"Asian, NH\", \n          race == \"BLACK\"                                     ~ \"Black, NH\",\n          race == \"WHITE\"                                     ~ \"White, NH\",\n      # find all instances of NATIVE (covers AMERICAN INDIAN/ALASKA NATIVE **AND** NATIVE HAWAIIAN/PACIFIC ISLANDER)\n          str_detect(race, \"NATIVE\")                          ~ \"Other, NH\",\n          race == \"OTHER\"                                     ~ \"Other, NH\", \n          TRUE                                                ~ \"Unknown\"\n     )) %&gt;% \n     \n     ## change from upper-case to lower case (with leading capital)\n     # mutate(across(\n     #   .cols = c(county, state),\n     #   .fns = str_to_title\n     # )) %&gt;% \n     # \n     \n     # recode with searching for string patterns\n     # (from \"No-Asymptomatic\"/\"Yes-Symptomatic\"/\"Unknown\")\n     mutate(contact_id = case_when(\n       str_detect(contact_id, \"Yes\")     ~ \"Yes\", \n       str_detect(contact_id, \"No\")      ~ \"No\", \n       str_detect(contact_id, \"Unknown\") ~ \"Unknown\", \n       TRUE                              ~ \"Unknown\"\n     )) %&gt;% \n  \n     # # this section does the same as above, but takes advantage of the way the data is formatted\n     # # data is formatted as \"Yes/No-A/Symptomatic\"\n     # # remove text from a string (everything after the dash) - this uses regular expressions (regex)\n     # # see handbook section on regex for understanding how this works\n     # mutate(contact_id = str_remove(linelist$contact_id, \"-.*\")) %&gt;% \n\n     # recode with searching for string patterns \n     mutate(sym_resolved = case_when(\n          str_detect(sym_resolved, \"Yes\")     ~ \"Yes\", \n          str_detect(sym_resolved, \"No\")      ~ \"No\", \n          str_detect(sym_resolved, \"Unknown\") ~ \"Unknown\", \n          TRUE                                ~ \"Unknown\"\n     )) %&gt;% \n     \n     \n     # create a factor from a default numeric class\n     mutate(zip = as_factor(zip)) %&gt;% \n     \n  \n     # replace missing with \"Unknown\" where relevant \n     mutate(across(\n       .cols = c(gender, race, eth, zip,\n                 contact_id, contact_hh, \n                 hospitalized, died, died_covid, confirmed_case,\n                 contains(\"sym_\"), age_group),\n       .fns  = ~fct_explicit_na(.x, na_level = \"Unknown\")\n     )) %&gt;% \n    \n     # set levels of a factor (define order)\n     mutate(gender      = fct_relevel(gender, \"Female\", \"Male\", \"Unknown\"), \n            eth_race    = fct_relevel(eth_race, \n                                   \"Asian, NH\", \"Black, NH\", \"White, NH\", \n                                   \"Hispanic, all races\", \"Other, NH\", \"Unknown\")\n     ) %&gt;% \n     \n     # set levels of all factors that are yes/no/unknown \n     mutate(across(\n          .cols = c(contact_id, contact_hh, hospitalized, died, died_covid,\n                    confirmed_case, contains(\"sym_\")), \n          .fns = ~fct_relevel(.x, \"Yes\", \"No\", \"Unknown\")\n     ))\n\n##############       REMOVE DUPLICATES     ##############        \n\n\n# Here we remove the duplicates based on having the same pid, gender and date of \n# birth. \n# Note that this might exclude those which are legitimately reported twice - i.e. \n# those who recovered and were reinfected. To deal with these you could create a \n# composite variable of the identifiers of interest, flag the duplicates there and \n# then add an additional argument for having a report date within six months. \n# \n# For more details see: \n# https://epirhandbook.com/de-duplication.html \n\n\n# get a data frame of all the duplicates \n     # this is mostly to inspect manually, but can be used for analysing those dropped\nduplicates &lt;- linelist %&gt;% \n     get_dupes(pid, gender, date_dob)\n\nlinelist &lt;- linelist %&gt;% \n  ## find duplicates based on unique ID, gender and date of birth \n  ## only keep the first occurrence \n  distinct(pid, gender, date_dob, .keep_all = TRUE)\n\n\n##############       FILTER     ##############        \n\n\n# Here we are going to filter our data set to only keep relevant cases for analysis. \n# We keep those that are reported before our surveillance cut-off date and those \n# that are entered as a confirmed case. \n# \n# For more details see: \n# https://epirhandbook.com/cleaning-data-and-core-functions.html#filter-rows\n\n# store those which do not meet our filter criteria \ndropped &lt;- linelist %&gt;% \n     filter(confirmed_case != \"Yes\" |\n              date_report &gt; surveillance_date & \n                !is.na(date_report))\n\n\n# drop the cases that dont meet the criteria \nlinelist &lt;- linelist %&gt;% \n     filter(confirmed_case == \"Yes\" & \n              date_report &lt;= surveillance_date & \n                 !is.na(date_report))\n\n\n\nPlease, continue the case study by clicking in the tab above named: “Descriptive analysis”\n\n\n\nIn this section we will see how to create an automatic and dynamic report to present a descriptive analysis of the data previously imported and cleaned.\n\nStep 4: Start the report with a summary of the findings\n\nWrite in rmarkdown three bullet points summarising the data we imported, showing the number of cases by the date of analysis, the number of hospitalisations and the number of deaths.\nWrite it in a dynamic way, so that the dates and numbers are updated automatically if you get a new updated dataset\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nThis is an example of how the code should look like in your rmarkdown file:\n\n\n\n\n\n\n\n\n\n\nStep 5. Analysis by time\n\nCreate a table with the number of cases per reporting week to see how the epidemic evolved by time in Fulton County\nCreate an epicurve by reporting week, with the colour of the bins based on whether the cases were hospitalised or not\n\n\nQuestion 5.1: During which week do we observe the peak in cases by date of reporting?\n\n The week starting on March 02, 2021 The week starting on December 16, 2020 The week starting on January 13, 2021 The week starting on December 30, 2020\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n############ CREATE EPIWEEK TABLE ###################  \n\n# Here we use the {janitor} tabyl() function to get case counts by calendar week \n# (as well as the percentage these contribute to the overall). \n# \n# We then create use {flextable} to produce a clean output table. \n# \n# For more details see: \n# https://epirhandbook.com/descriptive-tables.html\n# https://epirhandbook.com/tables-for-presentation.html\n# https://epirhandbook.com/descriptive-tables.html#tbl_janitor\n\n# save a quick descriptive table of number of cases reported by week\nepiweek_table &lt;- linelist %&gt;% \n  # get counts and percentages \n  tabyl(epiweek) %&gt;% \n  # add the overall counts as a row\n  adorn_totals() %&gt;%  \n  # change from proportions to percentages (do not add a % sign)\n  adorn_pct_formatting(affix_sign = FALSE) \n\n# transform it into flextable for better visualisation\nepiweek_flextable &lt;- epiweek_table %&gt;% \n     qflextable()\n\n############ CREATE EPICURVE ###################  \n# Here we demonstrate how to plot epicurves using the {ggplot2} package.\n# \n# For more details see: \n# https://epirhandbook.com/epidemic-curves.html\n\n     # we first define the dataset to be used, the x axis which will be reporting week and the colour (fill) of the bins which will depend on hospitalisation outcome\nggplot(\n     data = linelist,\n     mapping = aes(\n          x = epiweek,\n          fill = hospitalized\n     )) + \n     \n     geom_histogram() + \n     \n     # we define that we want breaks by month and formated with scales::label_date_short()\n     scale_x_date(\n          date_breaks = \"month\",\n          labels = label_date_short()\n     ) +\n     \n     # we change the name of the different elements of the graph\n     labs(\n          x = \"\",\n          y = \"Weekly number of cases\",\n          fill = \"Hospitalised\",\n          caption = paste0(\"Data as of \", format(surveillance_date, \"%d %b %Y\"))\n          \n     ) + \n     \n     # we apply one of the predefined themes\n     theme_bw()\n\n\n\n\n\n\nStep 6. Analysis by person\n\nCreate a table summarising, with counts and percentages, the total cumulative number of cases and deaths, as well the cases and deaths notified in the last 28 days by demographic characteristics: sex, age and race.\nCreate an age pyramid with the percentage of cases by age group and sex.\nCreate a scatter plot showing the relation between age and duration of hospital stay. Colour the points based on whether cases died or not.\nCreate a bar stacked bar plot showing the absolute number of cases by race and vital status\n\n\nQuestion 6.1: In which age group do we observe the largest proportion of cumulative cases?\n\n 0-9 30-39 20-29 70+\n\nQuestion 6.2: In which race do we observe the largest proportion of deaths in the last 28 days?\n\n Black White Asian Hispanic\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n#################### A) TABLE WITH DEMOGRAPHIC CHARACTERISTICS ####################\n\n# Here we use {purrr} to iterate over demographics variables (defined in the \n# vector_vars code chunk) - to produce tables of counts and percentages for cases\n# and deaths. \n# \n# We use {dplyr} bind_rows() and bind_cols() to combine the various smaller dataframes\n# of counts in to one large table. \n# \n# And then we colour in our {flextable} with different criteria for each of the \n# demographic variables of interest. \n# \n# For more details see: \n# https://epirhandbook.com/tables-for-presentation.html\n# https://epirhandbook.com/iteration-loops-and-lists.html\n\n\n# get counts tables for measures of interest \n############################################\n\n# we generate 3 summary tables and bind them together\n# summary demographic table for gender\ndem_gender &lt;- linelist %&gt;% \n  tabyl(gender) %&gt;% \n  select(Characteristic = gender, n, percent)\n\n# summary demographic table for age\ndem_age &lt;- linelist %&gt;% \n  tabyl(age_group) %&gt;% \n  select(Characteristic = age_group, n, percent)\n\n# summary demographic table for ethnicity and race\ndem_eth_race &lt;- linelist %&gt;% \n  tabyl(eth_race) %&gt;% \n  select(Characteristic = eth_race, n, percent)\n\n# bind all tables together\ntotal_cases &lt;- bind_rows(list(dem_gender, dem_age, dem_eth_race))\n\n# type out the variables of interest\ndemographic_vars &lt;- c(\"gender\", \"age_group\", \"eth_race\")\n\n# the above can also be done iteratively (we are repeating code)\n# this uses the {purrr} package to iterate over each variable\n# counts of total cases \ntotal_cases &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars,\n  # create a table  \n  .f = ~tabyl(linelist, .x) %&gt;%\n        # only keep variables of interest and rename the variable column \n        # this is so that they are all the same for row binding \n        select(\"Characteristic\" = .x,\n               n_cases_total = n,\n               perc_cases_total = percent)\n  ) %&gt;% \n  # combine rows in to one dataframe\n  bind_rows()\n\n\n# counts of new cases (last 28 days) \nrecent_cases &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter the linelist for dates on or after 28 days ago\n  .f = ~filter(linelist, \n          date_report &gt;= (surveillance_date - 28)) %&gt;% \n        # get counts based on filtered data\n        tabyl(.x) %&gt;% \n        # nb we dont keep the characteristic column because it would be duplicated\n        select(n_cases_recent = n,\n               perc_cases_recent = percent)\n  ) %&gt;%\n  bind_rows()\n\n# counts of total deaths \ntotal_deaths &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter for those who died \n  .f = ~filter(linelist, \n          died_covid == \"Yes\") %&gt;% \n        # get counts based on filtered data \n        tabyl(.x, show_na = TRUE) %&gt;%\n        select(n_deaths_total = n, perc_deaths_total = percent)\n  ) %&gt;% \n  bind_rows()\n\n# counts of new deaths (last 28 days)\nrecent_deaths &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter to those who died in the last 28 days\n  .f = ~filter(linelist, \n          died_covid == \"Yes\" & \n          date_died &gt;= (surveillance_date - 28)) %&gt;% \n        # get counts based on filtered data\n        tabyl(.x) %&gt;% \n        select(n_deaths_recent = n, perc_deaths_recent = percent) %&gt;% \n        # add in a variable column (used for colouring later) \n        mutate(variable = .x)\n  ) %&gt;% \n  bind_rows()\n\n\n# total counts for all of the above measures (not by demographic)\noverall &lt;- linelist %&gt;% \n  summarise(\n    # add in row label \n    Characteristic = \"Total\",\n    # counts of total cases \n    n_cases_total = n(),\n    # leave all percentages empty (would just be 100)\n    perc_cases_total  = NA, \n    # counts of new cases (last 28 days) \n    n_cases_recent = sum(date_report &gt;= (surveillance_date - 28)), \n    perc_cases_recent  = NA, \n    # counts of total deaths \n    n_deaths_total = sum(died_covid == \"Yes\"), \n    perc_deaths_total = NA, \n    # counts of new deaths (last 28 days)\n    n_deaths_recent = sum(died_covid == \"Yes\" & \n                          date_died &gt;= (surveillance_date - 28)),\n    perc_deaths_recent = NA, \n    # add in a variable column (used for colouring later) \n    variable = \"Overall\"\n  )\n\n\n\n# merge tables together \n#######################\n\n# combine all the demographic tables - side by side\ndemographics_counts &lt;- bind_cols(total_cases, recent_cases, total_deaths, recent_deaths) %&gt;% \n  # mutate each of the proportion columns to be percentages\n  mutate(across(\n    .cols = contains(\"perc\"),\n    .fns = ~round(.x * 100, digits = 1)\n    )) \n\n# add in the totals row at the top of the merged demographics table\ndemographics_counts &lt;- bind_rows(overall, demographics_counts)\n\n\n\n# define colour scheme \n######################\n\n# get the column numbers that are percentages (based on the name) \npercentage_cols &lt;- names(demographics_counts) %&gt;% \n  str_detect(\"perc\") %&gt;% \n  which()\n\n# define colour cut-offs for gender column \ngender_colours &lt;- scales::col_bin(\n  # choose colours \n  palette = c(\"#91CF60\", \"#FC8D59\"), \n  # choose min and max (range)\n  domain  = c(0, 100),\n  # choose how to split (in this case above and below 50)\n  bins    = 2\n)\n\n# define colour cut-offs for age column \nage_colours &lt;- scales::col_bin(\n  # choose colours\n  palette = c(\"#91CF60\",\"#FFFFBF\", \"#FC8D59\"),\n  # choose min and max (range)\n  domain  = c(0, 100), \n  # choose cut-off categories \n  bins    = c(0, 5, 20, 100)\n)\n\n# define colour cut-offs for ethnicity column \neth_colours &lt;- scales::col_bin(\n  palette = c(\"#91CF60\",\"#FFFFBF\", \"#FC8D59\"),\n  domain  = c(0, 100), \n  bins    = c(0, 10, 40, 100)\n)\n\n\n# create styled table  \n######################\n\ndemographics_counts %&gt;%\n  # initiate flextable to produce styled output table\n  flextable(\n    # retain variable column for formatting but do not display it\n    col_keys = names(demographics_counts)[-10]\n  ) %&gt;%\n  # redefine column names based on original names\n  set_header_labels(\n    \"n_cases_total\"       = \"Total Confirmed Cases\",\n    \"perc_cases_total\" = \"% of Total Cases\",\n    \"n_cases_recent\"       = \"Confirmed Cases past 28 days\",\n    \"perc_cases_recent\" = \"% of Confirmed Cases past 28 days\",\n    \"n_deaths_total\"       = \"Total Confirmed Deaths\",\n    \"perc_deaths_total\" = \"% of Total Deaths\",\n    \"n_deaths_recent\"       = \"Confirmed Deaths past 28 days\",\n    \"perc_deaths_recent\" = \"% of Confirmed Deaths past 28 days\"\n  ) %&gt;%\n  # move the header text to the centre\n  align(align = \"center\", part = \"header\") %&gt;%\n  # make header text bold\n  bold(part = \"header\") %&gt;%\n  # make the totals row bold (i.e. first row)\n  bold(i = 1, part = \"body\") %&gt;%\n  # fill in the cells\n  # choose the rows with gender counts\n  bg(i = ~variable == \"gender\",\n     # choose the columns with percentages in them\n     j = percentage_cols,\n     # fill in based on previous defined cut-offs\n     bg = gender_colours) %&gt;%\n  bg(i = ~variable == \"age_group\",\n     j = percentage_cols, bg = age_colours) %&gt;%\n  bg(i = ~variable == \"eth_race\",\n     j = percentage_cols, bg = eth_colours) %&gt;%\n  # add horizontal lines after the cells with totals and unknowns\n    # (short-cut to find row ending of each demographic variable)\n  hline(i = ~Characteristic %in% c(\"Total\", \"Unknown\")) %&gt;%\n  # add in footnotes for rows counting unknowns (reference in first column)\n  footnote(i = ~Characteristic == \"Unknown\", j = 1, part = \"body\", ref_symbols = c(\"a\"),\n           value = as_paragraph(\"Unknown includes cases not yet interviewed\")) %&gt;%\n  # add in footnote for deaths counts (ref in the header)\n  footnote(i = 1, j = c(6, 8), part = \"header\", ref_symbols = c(\"b\"),\n           value = as_paragraph(\"Deaths refer to all persons who had a positive PCR test result\n                                for Covid-19 and there is evidence that COVID-19 was the cause of\n                                death or a significant contributor to their death.\")) %&gt;%\n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\") %&gt;% \n  # decrease the fontsize in the header and body for aesthetic purposes in the document\n  fontsize(part = \"all\", size = 8)\n\n\n#################### B) AGE PYRAMID ####################\n\n# Here we demonstrate how to plot age pyramids using the {apyramid} package and edit\n# it with {ggplot2]. \n# \n# For more details see: \n# https://epirhandbook.com/demographic-pyramids-and-likert-scales.html\n\n# prepare dataset\n\n# start a new dataframe (as dont want to overwrite the original)\nlinelist_2g &lt;- linelist %&gt;% \n  # update the gender and age_group columns\n  mutate(across(.cols = c(gender, age_group), \n                .fns = ~{\n                  # replace \"Unknown\" with NA\n                  .x = na_if(.x, \"Unknown\") \n                  # drop \"Unknown\" from the factor levels \n                  .x = fct_drop(.x)\n                }))\n\n# plot age pyramid \nage_pyramid(\n  data = linelist_2g,\n  age_group = \"age_group\",\n  split_by = \"gender\",\n  # Show as percentages of total cases\n  proportional = TRUE,\n  # remove guide line for mid-point\n  show_midpoint = FALSE) +\n  # set theme to basic \n  theme_minimal() +\n  # add labels \n  labs(\n    title = \"\",\n    subtitle = ,\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = \"Gender\",\n    # use str_glue to set dynamic captions \n    # {missing} is defined in the second argument below\n    caption = str_glue(\n      \"{missing} cases missing either age or gender are not shown. \\n Fictional COVID-19 data\",\n      missing = linelist_2g %&gt;%\n        filter(is.na(gender) | is.na(age_group)) %&gt;%\n        nrow()\n      )\n    )\n\n#################### C) SCATTER PLOT ####################\n\n# Here we demonstrate how to plot points with {ggplot2}. \n# \n# For more details see: \n# https://epirhandbook.com/ggplot-basics.html#geoms\n\n# open a plot with the linelist data\nggplot(data = linelist) +\n  # add points \n  geom_point(\n    mapping = aes(\n      # plot age on the x and days hospitalised on the y axis \n      x = age,\n      y = days_hosp,\n      # color points by outcome\n      color = died),  \n    # all points 3x size\n    size = 3, \n    # opacity of 30% (i.e. relatively see-through)\n    alpha = 0.3) +      \n  # make the x and y axes start at the origin \n  scale_y_continuous(expand = c(0, 0)) + \n  scale_x_continuous(expand = c(0, 0)) + \n  # add in labels \n  labs(\n    x = \"Age (years)\",\n    y = \"Duration (days)\",\n    caption = \"Fulton COVID-19 data\",\n    color = \"Deceased\"\n    ) + \n     theme_bw()\n\n#################### D) BAR PLOT BY RACE ####################\n\n# Here we demonstrate how to plot bar charts with {ggplot2}. \n# \n# For more details see: \n# https://epirhandbook.com/ggplot-basics.html#geoms\n# https://epirhandbook.com/ggplot-tips.html\n\n# open a plot with the linelist data\nggplot(linelist) +\n  # add bars \n  geom_bar(\n    mapping = aes(\n      # plot the number of cases by ethnicity (ordered in reverse frequency)\n      x = fct_rev(fct_infreq(eth_race)),\n      # stack bars and colour by died (ordered in reverse frequency)\n      fill = fct_rev(fct_infreq(died))\n    )\n  ) +\n  # flip the x and y axes \n  coord_flip() +\n  # make the x axes start at the origin (nb axes flipped)\n  scale_y_continuous(expand = c(0, 0), \n                     # define where to label xaxis (nb axes flipped )\n                     breaks = seq(from = 0,\n                                  to = 35000,\n                                  by = 5000)) + \n  # add in labels \n  labs(\n    # set the axes titles (nb axes flipped)\n    x = \"Race and Ethnicity\",\n    y = \"Cases (n)\",\n    caption = \"Fictional COVID-19 data\",\n    fill = \"Deceased\"\n    ) + \n  # apply a defined theme\n     theme_bw()\n\n\n\n\n\n\nStep 7. Analysis by place\nCreate a table by zip code in which you show the incidence in the most recent 14 days period, the incidence in the previous 14 days period and the percentage change in incidence between these periods.\n\nQuestion 7.1: What is the change in incidence observed between periods in the zip code number 30337?\n\n +20% +36% -62.5% -25%\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n################### TABLE BY ZIP CODE\n\n# /// zip_counts \\\\\\\n# \n# # Here we use {dplyr} functions to get case counts based on ZIP Code and the \n# time periods created in the define_reporting_periods code chunk above. \n# We store as an object called zip_counts so that it can be merged with population\n# in the chunks below. \n# \n# For more details see: \n# https://epirhandbook.com/descriptive-tables.html#dplyr-package\n\nzip_counts &lt;- linelist %&gt;% \n  group_by(zip) %&gt;% \n  # count cases in the appropriate period \n  summarise(\n    recent   = sum(date_report %in% recent_period),\n    previous = sum(date_report %in% previous_period)\n  ) %&gt;% \n  adorn_totals() %&gt;% \n  # a percentage change column and round the digits\n  mutate(\n    perc_change = round((recent - previous) / previous * 100, digits = 1)\n    )\n\n\n# /// zip_join \\\\\\\n# \n# Here, use {dplyr} functions to extract the population counts from our shapefile, \n# and then merge these with our zip_counts from above. \n# N.b. the left_join() functions preserves all the rows from the first dataset \n# provided and only merges the rows from the second that match. \n# We then calculate incidence per 10,000 population. \n# \n# For more details see: \n# https://epirhandbook.com/descriptive-tables.html#dplyr-package\n# https://epirhandbook.com/joining-data.html\n\n# extract population counts for each zip from the shapefile\nzip_pop &lt;- shapefile %&gt;% \n  # change to tibble (otherwise geo-data gets pulled with)\n  as_tibble() %&gt;% \n  # only keep zip code and population counts\n  select(ZipCode, Population) %&gt;% \n  # add a row with overall counts\n  adorn_totals()\n  \n# merge case counts and population counts\n# zip (or ZipCode in the shapefile) variable is the unique identifier\nzip_counts &lt;- left_join(zip_counts, \n                        zip_pop, \n                        by = c(\"zip\" = \"ZipCode\")\n                        ) %&gt;% \n  # calculate the incidence \n  mutate(across(\n      # for each period (recent and previous)\n      .cols = c(recent, previous), \n      # divide each variable by population (and round the outcome)\n      .fns = ~round(.x / Population * 10000, digits = 1), \n      # for each period create a new variable with _inc on the end\n      .names = \"{.col}_inc\"), \n    \n    # replace NAs in incidence with 0\n    across(\n      .cols = contains(\"inc\"),\n      .fns = ~replace_na(.x, 0)),\n    \n    perc_change = case_when(\n      # fix the outliers: set missing to 0 and infinity (divided by 0) to 100\n      is.na(perc_change)       ~ 0,\n      is.infinite(perc_change) ~ 100, \n      TRUE                     ~ perc_change\n    ))\n\n# /// zip_table \\\\\\\n# \n# Here we use {flextable} to produce a publication-ready table. We also demonstrate\n# how to colour cells based on their values, defining the cut-offs in advance using\n# {dplyr} case_when(). Colours are called here using HEX-codes but can also be \n# referred to by name. \n# \n# For more details see: \n# https://epirhandbook.com/tables-for-presentation.html\n# https://colorbrewer2.org/#type=sequential&scheme=Reds&n=3\n\n# pick colours (uncomment next to lines)\n# RColorBrewer::brewer.pal(3, \"RdYlGn\") %&gt;% \n#   scales::show_col()\n\n# choose colours to fill in cells  \nrow_colour &lt;- case_when(\n  # those less than zero will be green (decreasing cases)\n  zip_counts$perc_change &lt; 0 ~ \"#91CF60\", \n  # over zero red (increasing)\n  zip_counts$perc_change &gt; 0 ~ \"#FC8D59\", \n  # missing or zero orange\n  TRUE                       ~ \"#FFFFBF\")\n\n\nzip_counts %&gt;% \n  # keep the columns of interest and define order\n  select(zip, recent, recent_inc, previous, previous_inc, perc_change) %&gt;% \n  # initiate {flextable} to produce styled output table\n  flextable() %&gt;% \n  # fill in cells - choose the column and then pass our colour-scheme defined above\n  bg(j = \"perc_change\", \n     bg = row_colour\n     ) %&gt;% \n  # add in a header for labeling counts and incidence by period \n    # note the empty columns (\"\") to fit to the original table headers\n  add_header_row(\n    values = c(\"\", \n               str_c(\"Recent 14-day reporting period\\n\", recent_period_labels), \n               \"\", \n               str_c(\"Previous 14-day reporting period\\n\", previous_period_labels), \n               \"\", \n               \"Change between reporting periods\"\n               )) %&gt;% \n  # redefine column names based on original names\n    # note the different syntax to dplyr::select, here it is old_name = new_name\n  set_header_labels(\n    zip          = \"Zip Code\", \n    recent       = \"n\", \n    recent_inc   = \"Incidence\", \n    previous     = \"n\", \n    previous_inc = \"Incidence\", \n    perc_change  = \"%\"\n  ) %&gt;% \n  # combine the headers cells for the appropriate periods \n  # (i defines rows, j defines columns)\n  merge_at(i = 1, j = 2:3, part = \"header\") %&gt;% \n  merge_at(i = 1, j = 4:5, part = \"header\") %&gt;% \n  # move the header text to the centre\n  align(align = \"center\", part = \"header\") %&gt;% \n  # make header text bold \n  bold(part = \"header\") %&gt;% \n  # make the row with totals in it bold (i.e. the last row in the dataframe)\n  bold(i = nrow(zip_counts), part = \"body\") %&gt;% \n  # add in footnotes for variables (referencing the header cells)\n  footnote(j = c(3, 5), part = \"header\", ref_symbols = c(\"a\"),\n           value = as_paragraph(\"Incidence calculated as cases per 10,000 population by zip code\")) %&gt;% \n  footnote(j = 6, part = \"header\", ref_symbols = c(\"b\"),\n           value = as_paragraph(\"These reflect the percentage increase or decrease of new diagnoses \n                                between the 14 days preceding the past 7 days and the 14 days\n                                preceding that.\")) %&gt;% \n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\")\n\n\n\nPlease, continue the case study by clicking in the tab above named: “Analysis of mortality”\n\n\n\nIn this section we will show how to include in the report an analysis of the risk factors for Covid-19 mortality.\n\nStep 8. Analysis of risk factors for mortality\n\nCreate a table in which you assess, with the appropriate statistical tests, whether the demographic characteristics of those dying from Covid-19 are significantly different from cases who did not die from it.\nFor each of the variables used in the table that you just created, carry out univariate regression using each demographic variable as the independent variable and the outcome (dead, not dead) as the dependent variables. Create a table with the estimates -alongside 95% CI - of the estimates.\n\n\nQuestion 8.1: According to the results of the univariate analysis, how was having a sore throat associated with mortality from Covid-19\n\n It was a risk factor for mortality It was a protective factor for mortality It was not associated with mortality Impossible to know\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n################### A) TABLE WITH DEMOGRAPHIC DIFFERENCES BY VITAL STATUS #################\n\n# /// rf_unknowns \\\\\\\n# \n# Here we need to define our variables of interest to investigate as risk factors. \n# We then need to swap factor levels so that the appropriate levels are selected \n# as the exposure level in regression. \n# We then need to keep only complete cases (i.e. that don't have any missings\n# for any of the variables of interest). \n# Finally, we  use the {labelled} package to assign text for each variable name to appear \n# in output tables. \n# \n# For more details see: \n# https://epirhandbook.com/univariate-and-multivariable-regression.html#store-explanatory-variables\n# https://epirhandbook.com/cleaning-data-and-core-functions.html#re-code-values\n# http://larmarange.github.io/labelled/\n\n# define a list of variables for looping over later\nsymptom_vars &lt;- linelist %&gt;% \n     # choose all columns that contain \"sym_\" in the name but exclude \"sym_resolved\"\n     select(c(contains(\"sym_\"), -sym_resolved)) %&gt;% \n     # pull the names out \n     names()\n\n# define variables of interest (save typing them out later) \ndescriptive_vars &lt;- c(\"gender\", \n                      \"age_group\",\n                      \"eth_race\",\n                      symptom_vars,\n                      \"hospitalized\",\n                      \"days_hosp\")\n\n# filter dataset  \nrf_data &lt;- linelist %&gt;% \n  # only keep variables of interest\n  select(died_covid, age, all_of(descriptive_vars)) %&gt;% \n  # set unknown back to NA for all factor variables\n  mutate(across(\n    .cols = where(is.factor),\n    .fns = ~fct_recode(.x, NULL = \"Unknown\"))) %&gt;% \n  # flip factor levels (so that the reference values are correct)\n  mutate(eth_race = fct_infreq(eth_race)) %&gt;% \n  mutate(gender = fct_relevel(gender, \"Female\", \"Male\")) %&gt;% \n  mutate(across(all_of(c(\"died_covid\", symptom_vars, \"hospitalized\")), \n                ~fct_relevel(.x, \"No\", \"Yes\")\n                )) %&gt;% \n  # only keep rows with complete data for all variables of interest\n  # note that this will drop rows where **ANY** of the listed variables are NA\n  drop_na(any_of(c(\"died_covid\", \"age\", descriptive_vars)))\n\n\n# define variable labels to show in output tables \nrf_data &lt;- rf_data %&gt;%\n  set_variable_labels(\n    died_covid = \"Died\",\n    age = \"Age (years)\",\n    gender = \"Gender\",\n    age_group = \"Age group (years)\",\n    eth_race = \"Ethnicity\",\n    sym_fever = \"Fever\",\n    sym_subjfever = \"Subjective fever\",\n    sym_myalgia = \"Myalgia\",\n    sym_losstastesmell = \"Loss taste/smell\",\n    sym_sorethroat = \"Sore throat\",\n    sym_cough = \"Cough\",\n    sym_headache = \"Headache\",\n    hospitalized = \"Hospitalized\",\n    days_hosp = \"Days in hospital\"\n  )\n\n\n# &lt;!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# /// simple_stats \\\\\\\n# --------------------------------------------------------------------------------\n# \n# Here we demonstrate how to do simple statistical tests using the {gtsummary} \n# package. We can define which tests to run for which variables and then modify the \n# table format afterwards, also using {gtsummary}. The syntax for formatting is \n# similar to {flextable} and as this needs to be in {flextable} for MS word anyway, \n# you could also do all the formatting using {flextable}.  \n# \n# For more details see: \n# https://epirhandbook.com/simple-statistical-tests.html#stats_gt\n# https://epirhandbook.com/tables-for-presentation.html\n\nrf_data %&gt;%\n  # keep variables of interest\n  select(died_covid, gender, eth_race, age, days_hosp) %&gt;%\n  # produce summary table and specify grouping variable\n  tbl_summary(\n    by = died_covid\n  ) %&gt;%\n  # specify what test to perform\n  add_p(\n    list(\n      all_continuous() ~ \"kruskal.test\",\n      eth_race ~ \"kruskal.test\",\n      all_dichotomous() ~ \"chisq.test\"\n    )\n  ) %&gt;%\n  # edit what the column headers say (using {gtsummary})\n  # nb. {n} automatically shows the number in that group and \\n is a linebreak\n  modify_header(update = list(\n    stat_1 ~ \"**Dead**\\n (N={n})\",\n    stat_2 ~ \"**Alive**\\n (N={n})\"\n  )) %&gt;%\n  # edit what it says in the footnote (using {gtsummary})\n  modify_footnote(update = list(\n    all_stat_cols() ~ \"n (%) for categorical;\\n median (IQR) for continuous\",\n    p.value ~ \"Pearson's Chi-squared test for dichotomous;\\n Kruskal-Wallis rank sum test for continuous and categorical\"\n  )) %&gt;%\n  # change to flextable format\n  as_flex_table() %&gt;%\n  # make header text bold (using {flextable})\n  bold(part = \"header\")\n\n###################### B) UNIVARIATE REGRESSION ANALYSIS ####################################\n\n# /// regression \\\\\\\n# \n# Here we demonstrate how to do univariate regression to produce odds ratios with \n# {gtsummary}. We first create a regression table, then a counts table and then \n# finally merge the two and format the output. \n# Note that a cox regression taking into account observation time might be a \n# more appropriate analysis given the question on mortality - you could do this \n# using {gtsummary} but take a look at the epiRhandbook page on survival analysis.\n# \n# For more details see: \n# https://epirhandbook.com/univariate-and-multivariable-regression.html\n# https://epirhandbook.com/survival-analysis.html\n# https://epirhandbook.com/tables-for-presentation.html\n\n# produce table with regression estimates\nregress_tab &lt;- rf_data %&gt;%\n  # drop variables not interested in \n  select(-age_group) %&gt;%\n  # produce univariate table\n  tbl_uvregression(\n    # define outcome variable\n    y = died_covid, \n    # define regression want to run (generalised linear model)\n    method = glm, \n    # define what type of glm want to run (logistic)\n    method.args = list(family = binomial), \n    # exponentiate to produce odds ratios (rather than log odds)\n    exponentiate = TRUE, \n    # do not show the overall counts (this is done in cross_tab below)\n    hide_n = TRUE,\n    ## uncomment this line if you want to not show reference rows\n    # show_single_row = c(symptom_vars, gender, hospitalized),\n    ## note: NULL at the end allows you to have a comma before a commented out row\n    NULL\n  )\n\n# produce table with counts by outcome (using the data fed to the regression above)\ncross_tab &lt;- regress_tab$inputs$data %&gt;%\n  tbl_summary(\n    # group by outcome \n    by = died_covid,\n    ## uncomment this line if you only want to show the \"Male\" row for gender\n    ## this would be run if you also uncommented the single_row in regression above\n    # value = list(gender ~\"Male\"),\n    ## show all levels (otherwise only shows the \"Yes\" level)\n    type = list(all_dichotomous() ~ \"categorical\"),\n    ## note: NULL at the end allows you to have a comma before a commented out row\n    NULL\n  )\n\n# combine tables \ntbl_merge(list(cross_tab, regress_tab)) %&gt;%\n  # edit what it says in the grouping headers \n  modify_spanning_header(update = list(\n    c(\"stat_1_1\",\"stat_2_1\") ~ \"Died\",\n    c(\"estimate_2\", \"ci_2\", \"p.value_2\") ~ \"Univariate regression\")\n    ) %&gt;% \n  # edit what it says in the footnote (using {gtsummary})\n  modify_footnote(update = list(\n    all_stat_cols() ~ \"n (%) for categorical;\\n median (IQR) for continuous\")\n    ) %&gt;% \n  # change to flextable format\n  as_flex_table() %&gt;%\n  # make header text bold (using {flextable})\n  bold(part = \"header\") %&gt;% \n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\")"
  },
  {
    "objectID": "fulton-en.html#introduction-to-this-case-study-script",
    "href": "fulton-en.html#introduction-to-this-case-study-script",
    "title": "2  Fulton (EN)",
    "section": "2.3 Introduction to this case study script",
    "text": "2.3 Introduction to this case study script\nThis is a an example R-markdown script which demonstrates how to create an automated outbreak situation report for COVID-19 in Fulton county, USA. The data used are anonymised and fake (scrambled), for example purposes only.\n\nWe demonstrate how to import, clean and analyse your data.\n\nAnalysis is organised by time, place and person.\n\nFor the purpose of the case study we separate this by descriptive analysis and visualisation (normally this would be mixed together of course)\n\nThe visualisation section is organised in to place, time and person. This is to simplify flow for didactic delivery.\n\n\nAnalysis is loosely based off the monthly epidemiology reports for Fulton county\n\n\nText within &lt;! &gt; will not show in your final document.\n\nThe other parts such as slashes (///), dashes (-) and tildes (~) are just aesthetic\nThese comments are used to explain the code chunks.\n\nWe refer to functions in curly brackets, e.g. {dplyr} and functions end in brackets, e.g. count()\n\nThis comment will not show up when you knit the document.\n\nYou can delete them if you want.\n\n\nFeedback & suggestions are welcome at the GitHub issues page\n\nAlternatively email us at: epirhandbook@gmail.com"
  },
  {
    "objectID": "fulton-en.html#summary",
    "href": "fulton-en.html#summary",
    "title": "2  Fulton (EN)",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nAs of , Fulton County has recorded confirmed cases of COVID-19.\n\nAs of , Fulton County has recorded deaths.\n\nAmong all confirmed cases of COVID-19 in Fulton County, required hospitalization."
  },
  {
    "objectID": "fulton-en.html#time",
    "href": "fulton-en.html#time",
    "title": "2  Fulton (EN)",
    "section": "3.2 Time",
    "text": "3.2 Time\n\n\n# create an \"incidence\" object (with number of cases by week)\nSunWeeks &lt;- incidence(\n  # define dataset\n  x = linelist,    \n  # date column\n  date_index = date_onset,   \n  # bin interval (day which week starts on)\n  interval = \"Sunday weeks\", \n  # grouping variable\n  groups = eth_race,\n  # wether to include missings as a group (or drop) \n  na_as_group = TRUE)\n\n\n# plot epicurve \nplot(SunWeeks,\n  fill = eth_race,\n  date_format = \"%a %d %b %Y\\n (Week %W)\",\n  # how many axis labels to include \n  n.breaks = 24,\n  # angle of date labels)\n  angle = 30) +\n  scale_y_continuous(\n    # make the y axis start at the origin\n    expand = c(0, 0),\n    # define where to label y axis \n    breaks = seq(0, 2000, 250)) +\n  # update legend label \n  labs(fill = \"Race and\\nEthnicity\") + \n  # move the legend to the bottom \n  theme(legend.position = \"bottom\", \n        # remove the outside box (axes added back in via epicurve_theme)\n        panel.border = element_blank()) +\n  # apply the theme we defined in ggplot_theme code chunk above\n  epicurve_theme"
  },
  {
    "objectID": "fulton-en.html#place",
    "href": "fulton-en.html#place",
    "title": "2  Fulton (EN)",
    "section": "2.1 Place",
    "text": "2.1 Place\n\n\n\nzip_counts &lt;- linelist %&gt;% \n  group_by(zip) %&gt;% \n  # count cases in the appropriate period \n  summarise(\n    recent   = sum(date_report %in% recent_period),\n    previous = sum(date_report %in% previous_period)\n  ) %&gt;% \n  adorn_totals() %&gt;% \n  # a percentage change column and round the digits\n  mutate(\n    perc_change = round((recent - previous) / previous * 100, digits = 1)\n    )\n\n\n\n\n# extract population counts for each zip from the shapefile\nzip_pop &lt;- shapefile %&gt;% \n  # change to tibble (otherwise geo-data gets pulled with)\n  as_tibble() %&gt;% \n  # only keep zip code and population counts\n  select(ZipCode, Population) %&gt;% \n  # add a row with overall counts\n  adorn_totals()\n  \n# merge case counts and population counts\n# zip (or ZipCode in the shapefile) variable is the unique identifier\nzip_counts &lt;- left_join(zip_counts, \n                        zip_pop, \n                        by = c(\"zip\" = \"ZipCode\")\n                        ) %&gt;% \n  # calculate the incidence \n  mutate(across(\n      # for each period (recent and previous)\n      .cols = c(recent, previous), \n      # divide each variable by population (and round the outcome)\n      .fns = ~round(.x / Population * 10000, digits = 1), \n      # for each period create a new variable with _inc on the end\n      .names = \"{.col}_inc\"), \n    \n    # replace NAs in incidence with 0\n    across(\n      .cols = contains(\"inc\"),\n      .fns = ~replace_na(.x, 0)),\n    \n    perc_change = case_when(\n      # fix the outliers: set missing to 0 and infinity (divided by 0) to 100\n      is.na(perc_change)       ~ 0,\n      is.infinite(perc_change) ~ 100, \n      TRUE                     ~ perc_change\n    ))\n\n\n\n\n# pick colours (uncomment next to lines)\n# RColorBrewer::brewer.pal(3, \"RdYlGn\") %&gt;% \n#   scales::show_col()\n\n# choose colours to fill in cells  \nrow_colour &lt;- case_when(\n  # those less than zero will be green (decreasing cases)\n  zip_counts$perc_change &lt; 0 ~ \"#91CF60\", \n  # over zero red (increasing)\n  zip_counts$perc_change &gt; 0 ~ \"#FC8D59\", \n  # missing or zero orange\n  TRUE                       ~ \"#FFFFBF\")\n\n\nzip_counts %&gt;% \n  # keep the columns of interest and define order\n  select(zip, recent, recent_inc, previous, previous_inc, perc_change) %&gt;% \n  # initiate {flextable} to produce styled output table\n  flextable() %&gt;% \n  # fill in cells - choose the column and then pass our colour-scheme defined above\n  bg(j = \"perc_change\", \n     bg = row_colour\n     ) %&gt;% \n  # add in a header for labeling counts and incidence by period \n    # note the empty columns (\"\") to fit to the original table headers\n  add_header_row(\n    values = c(\"\", \n               str_c(\"Recent 14-day reporting period\\n\", recent_period_labels), \n               \"\", \n               str_c(\"Previous 14-day reporting period\\n\", previous_period_labels), \n               \"\", \n               \"Change between reporting periods\"\n               )) %&gt;% \n  # redefine column names based on original names\n    # note the different syntax to dplyr::select, here it is old_name = new_name\n  set_header_labels(\n    zip          = \"Zip Code\", \n    recent       = \"n\", \n    recent_inc   = \"Incidence\", \n    previous     = \"n\", \n    previous_inc = \"Incidence\", \n    perc_change  = \"%\"\n  ) %&gt;% \n  # combine the headers cells for the appropriate periods \n  # (i defines rows, j defines columns)\n  merge_at(i = 1, j = 2:3, part = \"header\") %&gt;% \n  merge_at(i = 1, j = 4:5, part = \"header\") %&gt;% \n  # move the header text to the centre\n  align(align = \"center\", part = \"header\") %&gt;% \n  # make header text bold \n  bold(part = \"header\") %&gt;% \n  # make the row with totals in it bold (i.e. the last row in the dataframe)\n  bold(i = nrow(zip_counts), part = \"body\") %&gt;% \n  # add in footnotes for variables (referencing the header cells)\n  footnote(j = c(3, 5), part = \"header\", ref_symbols = c(\"a\"),\n           value = as_paragraph(\"Incidence calculated as cases per 10,000 population by zip code\")) %&gt;% \n  footnote(j = 6, part = \"header\", ref_symbols = c(\"b\"),\n           value = as_paragraph(\"These reflect the percentage increase or decrease of new diagnoses \n                                between the 14 days preceding the past 7 days and the 14 days\n                                preceding that.\")) %&gt;% \n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\")"
  },
  {
    "objectID": "fulton-en.html#person",
    "href": "fulton-en.html#person",
    "title": "2  Fulton (EN)",
    "section": "2.2 Person",
    "text": "2.2 Person\n\n\n\n# get counts tables for measures of interest \n############################################\n\n# we generate 3 summary tables and bind them together\n# summary demographic table for gender\ndem_gender &lt;- linelist %&gt;% \n  tabyl(gender) %&gt;% \n  select(Characteristic = gender, n, percent)\n\n# summary demographic table for age\ndem_age &lt;- linelist %&gt;% \n  tabyl(age_group) %&gt;% \n  select(Characteristic = age_group, n, percent)\n\n# summary demographic table for ethnicity and race\ndem_eth_race &lt;- linelist %&gt;% \n  tabyl(eth_race) %&gt;% \n  select(Characteristic = eth_race, n, percent)\n\n# bind all tables together\ntotal_cases &lt;- bind_rows(list(dem_gender, dem_age, dem_eth_race))\n\n\n# the above can also be done iteratively (we are repeating code)\n# this uses the {purrr} package to iterate over each variable\n# counts of total cases \ntotal_cases &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars,\n  # create a table  \n  .f = ~tabyl(linelist, .x) %&gt;%\n        # only keep variables of interest and rename the variable column \n        # this is so that they are all the same for row binding \n        select(\"Characteristic\" = .x,\n               n_cases_total = n,\n               perc_cases_total = percent)\n  ) %&gt;% \n  # combine rows in to one dataframe\n  bind_rows()\n\n\n# counts of new cases (last 28 days) \nrecent_cases &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter the linelist for dates on or after 28 days ago\n  .f = ~filter(linelist, \n          date_report &gt;= (surveillance_date - 28)) %&gt;% \n        # get counts based on filtered data\n        tabyl(.x) %&gt;% \n        # nb we dont keep the characteristic column because it would be duplicated\n        select(n_cases_recent = n,\n               perc_cases_recent = percent)\n  ) %&gt;%\n  bind_rows()\n\n# counts of total deaths \ntotal_deaths &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter for those who died \n  .f = ~filter(linelist, \n          died_covid == \"Yes\") %&gt;% \n        # get counts based on filtered data \n        tabyl(.x, show_na = TRUE) %&gt;%\n        select(n_deaths_total = n, perc_deaths_total = percent)\n  ) %&gt;% \n  bind_rows()\n\n# counts of new deaths (last 28 days)\nrecent_deaths &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter to those who died in the last 28 days\n  .f = ~filter(linelist, \n          died_covid == \"Yes\" & \n          date_died &gt;= (surveillance_date - 28)) %&gt;% \n        # get counts based on filtered data\n        tabyl(.x) %&gt;% \n        select(n_deaths_recent = n, perc_deaths_recent = percent) %&gt;% \n        # add in a variable column (used for colouring later) \n        mutate(variable = .x)\n  ) %&gt;% \n  bind_rows()\n\n\n# total counts for all of the above measures (not by demographic)\noverall &lt;- linelist %&gt;% \n  summarise(\n    # add in row label \n    Characteristic = \"Total\",\n    # counts of total cases \n    n_cases_total = n(),\n    # leave all percentages empty (would just be 100)\n    perc_cases_total  = NA, \n    # counts of new cases (last 28 days) \n    n_cases_recent = sum(date_report &gt;= (surveillance_date - 28)), \n    perc_cases_recent  = NA, \n    # counts of total deaths \n    n_deaths_total = sum(died_covid == \"Yes\"), \n    perc_deaths_total = NA, \n    # counts of new deaths (last 28 days)\n    n_deaths_recent = sum(died_covid == \"Yes\" & \n                          date_died &gt;= (surveillance_date - 28)),\n    perc_deaths_recent = NA, \n    # add in a variable column (used for colouring later) \n    variable = \"Overall\"\n  )\n\n\n\n# merge tables together \n#######################\n\n# combine all the demographic tables - side by side\ndemographics_counts &lt;- bind_cols(total_cases, recent_cases, total_deaths, recent_deaths) %&gt;% \n  # mutate each of the proportion columns to be percentages\n  mutate(across(\n    .cols = contains(\"perc\"),\n    .fns = ~round(.x * 100, digits = 1)\n    )) \n\n# add in the totals row at the top of the merged demographics table\ndemographics_counts &lt;- bind_rows(overall, demographics_counts)\n\n\n\n# define colour scheme \n######################\n\n# get the column numbers that are percentages (based on the name) \npercentage_cols &lt;- names(demographics_counts) %&gt;% \n  str_detect(\"perc\") %&gt;% \n  which()\n\n# define colour cut-offs for gender column \ngender_colours &lt;- scales::col_bin(\n  # choose colours \n  palette = c(\"#91CF60\", \"#FC8D59\"), \n  # choose min and max (range)\n  domain  = c(0, 100),\n  # choose how to split (in this case above and below 50)\n  bins    = 2\n)\n\n# define colour cut-offs for age column \nage_colours &lt;- scales::col_bin(\n  # choose colours\n  palette = c(\"#91CF60\",\"#FFFFBF\", \"#FC8D59\"),\n  # choose min and max (range)\n  domain  = c(0, 100), \n  # choose cut-off categories \n  bins    = c(0, 5, 20, 100)\n)\n\n# define colour cut-offs for ethnicity column \neth_colours &lt;- scales::col_bin(\n  palette = c(\"#91CF60\",\"#FFFFBF\", \"#FC8D59\"),\n  domain  = c(0, 100), \n  bins    = c(0, 10, 40, 100)\n)\n\n\n# create styled table  \n######################\n\ndemographics_counts %&gt;%\n  # initiate flextable to produce styled output table\n  flextable(\n    # retain variable column for formatting but do not display it\n    col_keys = names(demographics_counts)[-10]\n  ) %&gt;%\n  # redefine column names based on original names\n  set_header_labels(\n    \"n_cases_total\"       = \"Total Confirmed Cases\",\n    \"perc_cases_total\" = \"% of Total Cases\",\n    \"n_cases_recent\"       = \"Confirmed Cases past 28 days\",\n    \"perc_cases_recent\" = \"% of Confirmed Cases past 28 days\",\n    \"n_deaths_total\"       = \"Total Confirmed Deaths\",\n    \"perc_deaths_total\" = \"% of Total Deaths\",\n    \"n_deaths_recent\"       = \"Confirmed Deaths past 28 days\",\n    \"perc_deaths_recent\" = \"% of Confirmed Deaths past 28 days\"\n  ) %&gt;%\n  # move the header text to the centre\n  align(align = \"center\", part = \"header\") %&gt;%\n  # make header text bold\n  bold(part = \"header\") %&gt;%\n  # make the totals row bold (i.e. first row)\n  bold(i = 1, part = \"body\") %&gt;%\n  # fill in the cells\n  # choose the rows with gender counts\n  bg(i = ~variable == \"gender\",\n     # choose the columns with percentages in them\n     j = percentage_cols,\n     # fill in based on previous defined cut-offs\n     bg = gender_colours) %&gt;%\n  bg(i = ~variable == \"age_group\",\n     j = percentage_cols, bg = age_colours) %&gt;%\n  bg(i = ~variable == \"eth_race\",\n     j = percentage_cols, bg = eth_colours) %&gt;%\n  # add horizontal lines after the cells with totals and unknowns\n    # (short-cut to find row ending of each demographic variable)\n  hline(i = ~Characteristic %in% c(\"Total\", \"Unknown\")) %&gt;%\n  # add in footnotes for rows counting unknowns (reference in first column)\n  footnote(i = ~Characteristic == \"Unknown\", j = 1, part = \"body\", ref_symbols = c(\"a\"),\n           value = as_paragraph(\"Unknown includes cases not yet interviewed\")) %&gt;%\n  # add in footnote for deaths counts (ref in the header)\n  footnote(i = 1, j = c(6, 8), part = \"header\", ref_symbols = c(\"b\"),\n           value = as_paragraph(\"Deaths refer to all persons who had a positive PCR test result\n                                for Covid-19 and there is evidence that COVID-19 was the cause of\n                                death or a significant contributor to their death.\")) %&gt;%\n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\")\n\n\n\n2.2.1 Risk factors for mortality\n\n\n\n# define variables of interest (save typing them out later) \ndescriptive_vars &lt;- c(\"gender\", \n                      \"age_group\",\n                      \"eth_race\",\n                      symptom_vars,\n                      \"hospitalized\",\n                      \"days_hosp\")\n\n# filter dataset  \nrf_data &lt;- linelist %&gt;% \n  # only keep variables of interest\n  select(died_covid, age, all_of(descriptive_vars)) %&gt;% \n  # set unknown back to NA for all factor variables\n  mutate(across(\n    .cols = where(is.factor),\n    .fns = ~fct_recode(.x, NULL = \"Unknown\"))) %&gt;% \n  # flip factor levels (so that the reference values are correct)\n  mutate(eth_race = fct_infreq(eth_race)) %&gt;% \n  mutate(gender = fct_relevel(gender, \"Female\", \"Male\")) %&gt;% \n  mutate(across(all_of(c(\"died_covid\", symptom_vars, \"hospitalized\")), \n                ~fct_relevel(.x, \"No\", \"Yes\")\n                )) %&gt;% \n  # only keep rows with complete data for all variables of interest\n  # note that this will drop rows where **ANY** of the listed variables are NA\n  drop_na(any_of(c(\"died_covid\", \"age\", descriptive_vars)))\n\n\n# define variable labels to show in output tables \nrf_data &lt;- rf_data %&gt;%\n  set_variable_labels(\n    died_covid = \"Died\",\n    age = \"Age (years)\",\n    gender = \"Gender\",\n    age_group = \"Age group (years)\",\n    eth_race = \"Ethnicity\",\n    sym_fever = \"Fever\",\n    sym_subjfever = \"Subjective fever\",\n    sym_myalgia = \"Myalgia\",\n    sym_losstastesmell = \"Loss taste/smell\",\n    sym_sorethroat = \"Sore throat\",\n    sym_cough = \"Cough\",\n    sym_headache = \"Headache\",\n    hospitalized = \"Hospitalized\",\n    days_hosp = \"Days in hospital\"\n  )\n\n\n\n\nrf_data %&gt;%\n  # keep variables of interest\n  select(died_covid, gender, eth_race, age, days_hosp) %&gt;%\n  # produce summary table and specify grouping variable\n  tbl_summary(\n    by = died_covid\n  ) %&gt;%\n  # specify what test to perform\n  add_p(\n    list(\n      all_continuous() ~ \"kruskal.test\",\n      eth_race ~ \"kruskal.test\",\n      all_dichotomous() ~ \"chisq.test\"\n    )\n  ) %&gt;%\n  # edit what the column headers say (using {gtsummary})\n  # nb. {n} automatically shows the number in that group and \\n is a linebreak\n  modify_header(update = list(\n    stat_1 ~ \"**Dead**\\n (N={n})\",\n    stat_2 ~ \"**Alive**\\n (N={n})\"\n  )) %&gt;%\n  # edit what it says in the footnote (using {gtsummary})\n  modify_footnote(update = list(\n    all_stat_cols() ~ \"n (%) for categorical;\\n median (IQR) for continuous\",\n    p.value ~ \"Pearson's Chi-squared test for dichotomous;\\n Kruskal-Wallis rank sum test for continuous and categorical\"\n  )) %&gt;%\n  # change to flextable format\n  as_flex_table() %&gt;%\n  # make header text bold (using {flextable})\n  bold(part = \"header\")\n\n\n\n\n\n# produce table with regression estimates\nregress_tab &lt;- rf_data %&gt;%\n  # drop variables not interested in \n  select(-age_group) %&gt;%\n  # produce univariate table\n  tbl_uvregression(\n    # define outcome variable\n    y = died_covid, \n    # define regression want to run (generalised linear model)\n    method = glm, \n    # define what type of glm want to run (logistic)\n    method.args = list(family = binomial), \n    # exponentiate to produce odds ratios (rather than log odds)\n    exponentiate = TRUE, \n    # do not show the overall counts (this is done in cross_tab below)\n    hide_n = TRUE,\n    ## uncomment this line if you want to not show reference rows\n    # show_single_row = c(symptom_vars, gender, hospitalized),\n    ## note: NULL at the end allows you to have a comma before a commented out row\n    NULL\n  )\n\n# produce table with counts by outcome (using the data fed to the regression above)\ncross_tab &lt;- regress_tab$inputs$data %&gt;%\n  tbl_summary(\n    # group by outcome \n    by = died_covid,\n    ## uncomment this line if you only want to show the \"Male\" row for gender\n    ## this would be run if you also uncommented the single_row in regression above\n    # value = list(gender ~\"Male\"),\n    ## show all levels (otherwise only shows the \"Yes\" level)\n    type = list(all_dichotomous() ~ \"categorical\"),\n    ## note: NULL at the end allows you to have a comma before a commented out row\n    NULL\n  )\n\n# combine tables \ntbl_merge(list(cross_tab, regress_tab)) %&gt;%\n  # edit what it says in the grouping headers \n  modify_spanning_header(update = list(\n    c(\"stat_1_1\",\"stat_2_1\") ~ \"Died\",\n    c(\"estimate_2\", \"ci_2\", \"p.value_2\") ~ \"Univariate regression\")\n    ) %&gt;% \n  # edit what it says in the footnote (using {gtsummary})\n  modify_footnote(update = list(\n    all_stat_cols() ~ \"n (%) for categorical;\\n median (IQR) for continuous\")\n    ) %&gt;% \n  # change to flextable format\n  as_flex_table() %&gt;%\n  # make header text bold (using {flextable})\n  bold(part = \"header\") %&gt;% \n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\")"
  },
  {
    "objectID": "fulton-en.html#person-1",
    "href": "fulton-en.html#person-1",
    "title": "2  Fulton (EN)",
    "section": "3.1 Person",
    "text": "3.1 Person\nAs we see below in Figure @ref(fig:agehospplot) there appears to be an association between older age, length of hospital stay and mortality. We saw this in Table @ref(tab:regrtab) as well for the individual associations, although we did not check for interaction and confounding.\n\n\n# open a plot with the linelist data\nggplot(data = linelist) +\n  # add points \n  geom_point(\n    mapping = aes(\n      # plot age on the x and days hospitalised on the y axis \n      x = age,\n      y = days_hosp,\n      # color points by outcome\n      color = died),  \n    # all points 3x size\n    size = 3, \n    # opacity of 30% (i.e. relatively see-through)\n    alpha = 0.3) +      \n  # make the x and y axes start at the origin \n  scale_y_continuous(expand = c(0, 0)) + \n  scale_x_continuous(expand = c(0, 0)) + \n  # add in labels \n  labs(\n    x = \"Age (years)\",\n    y = \"Duration (days)\",\n    caption = \"Fictional COVID-19 data\",\n    color = \"Deceased\"\n    ) + \n  # apply the theme we defined in ggplot_theme code chunk above \n  epicurve_theme\n\n\n\n\n# open a plot with the linelist data\nggplot(linelist) +\n  # add bars \n  geom_bar(\n    mapping = aes(\n      # plot the number of cases by ethnicity (ordered in reverse frequency)\n      x = fct_rev(fct_infreq(eth_race)),\n      # stack bars and colour by died (ordered in reverse frequency)\n      fill = fct_rev(fct_infreq(died))\n    )\n  ) +\n  # flip the x and y axes \n  coord_flip() +\n  # make the x axes start at the origin (nb axes flipped)\n  scale_y_continuous(expand = c(0, 0), \n                     # define where to label xaxis (nb axes flipped )\n                     breaks = seq(from = 0,\n                                  to = 35000,\n                                  by = 5000)) + \n  # add in labels \n  labs(\n    # set the axes titles (nb axes flipped)\n    x = \"Race and Ethnicity\",\n    y = \"Cases (n)\",\n    caption = \"Fictional COVID-19 data\",\n    fill = \"Deceased\"\n    ) + \n  # apply the theme we defined in ggplot_theme code chunk above \n  epicurve_theme\n\n\n\n\n# prepare dataset\n\n# start a new dataframe (as dont want to overwrite the original)\nlinelist_2g &lt;- linelist %&gt;% \n  # update the gender and age_group columns\n  mutate(across(.cols = c(gender, age_group), \n                .fns = ~{\n                  # replace \"Unknown\" with NA\n                  .x = na_if(.x, \"Unknown\") \n                  # drop \"Unknown\" from the factor levels \n                  .x = fct_drop(.x)\n                }))\n\n# plot age pyramid \nage_pyramid(\n  data = linelist_2g,\n  age_group = \"age_group\",\n  split_by = \"gender\",\n  # Show as percentages of total cases\n  proportional = TRUE,\n  # remove guide line for mid-point\n  show_midpoint = FALSE) +\n  # set theme to basic \n  theme_minimal() +\n  # add labels \n  labs(\n    title = \"\",\n    subtitle = ,\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = \"Gender\",\n    # use str_glue to set dynamic captions \n    # {missing} is defined in the second argument below\n    caption = str_glue(\n      \"{missing} cases missing either age or gender are not shown. \\n Fictional COVID-19 data\",\n      missing = linelist_2g %&gt;%\n        filter(is.na(gender) | is.na(age_group)) %&gt;%\n        nrow()\n      )\n    )"
  },
  {
    "objectID": "fulton-en.html#time-1",
    "href": "fulton-en.html#time-1",
    "title": "2  Fulton (EN)",
    "section": "3.2 Time",
    "text": "3.2 Time\n\n\n# create an \"incidence\" object (with number of cases by week)\nSunWeeks &lt;- incidence(\n  # define dataset\n  x = linelist,    \n  # date column\n  date_index = date_onset,   \n  # bin interval (day which week starts on)\n  interval = \"Sunday weeks\", \n  # grouping variable\n  groups = eth_race,\n  # wether to include missings as a group (or drop) \n  na_as_group = TRUE)\n\n\n# plot epicurve \nplot(SunWeeks,\n  fill = eth_race,\n  date_format = \"%a %d %b %Y\\n (Week %W)\",\n  # how many axis labels to include \n  n.breaks = 24,\n  # angle of date labels)\n  angle = 30) +\n  scale_y_continuous(\n    # make the y axis start at the origin\n    expand = c(0, 0),\n    # define where to label y axis \n    breaks = seq(0, 2000, 250)) +\n  # update legend label \n  labs(fill = \"Race and\\nEthnicity\") + \n  # move the legend to the bottom \n  theme(legend.position = \"bottom\", \n        # remove the outside box (axes added back in via epicurve_theme)\n        panel.border = element_blank()) +\n  # apply the theme we defined in ggplot_theme code chunk above\n  epicurve_theme"
  },
  {
    "objectID": "fulton-en.html#place-1",
    "href": "fulton-en.html#place-1",
    "title": "2  Fulton (EN)",
    "section": "3.3 Place",
    "text": "3.3 Place\n\n\n# change shapefile coordinate reference system to WGS84\nshapefile &lt;- st_transform(shapefile, crs = 4326)\n\n\n# convert linelist data frame into sf object (with georeference points)\nlinelist_sf &lt;- linelist %&gt;%\n  # remove rows missing gps coordinates\n  drop_na(lat, lon) %&gt;%\n  filter(\n    # drop those with wrong GPS points\n    lat &gt;= 33 & lat &lt;= 35,\n    lon &gt;= -85 & lon &lt;= -84,\n    # drop those outside the last 2 weeks \n    date_report %in% recent_period\n  ) %&gt;%\n  # create an sf object\n  st_as_sf(\n    # define the coordinates based on lat/long variables\n    coords = c(\"lon\", \"lat\"),\n    # set the coordinate reference system to WGS84\n    crs = 4326,\n    # do not change string variables to factors \n    stringsAsFactors = FALSE\n  )\n\n\n\n# get the bounding box for the shapefile \nbounding_box &lt;- shapefile %&gt;% \n  st_bbox()\n\n# plot a base map including scale bar \nbasemap &lt;- ggplot() +\n  # change the bounding box to an sf object\n  # this defines the area to download map tiles for\n  geom_sf(data = st_as_sfc(bounding_box)) +\n  # download map tiles and add to the plot\n  annotation_map_tile(\n    # define what map tiles to use\n    type =  \"cartolight\",\n    # define folder to store tile images \n    cachedir = here::here(\"data\", \"fulton-en\", \"map_tiles\"),\n    # define if should download tiles each time\n    forcedownload = FALSE,\n    # hide messages about download status and zoom\n    progress = \"none\" ) +\n  # add a scalebar in miles\n  annotation_scale(unit_category = \"imperial\") +\n  # remove all axes, labels and legends \n  theme_void() +\n  # define where to put the legend \n  theme(\n    # define position (percentages of the axes)\n    legend.position = c(0.2, 0.85),\n    # define the colour of the legend background\n    legend.box.background = element_rect(\n      fill = \"white\",\n      colour = NA)\n    ) + \n  # add in a note at the bottom of plots to show it is fake data\n  labs(\n    caption = \"Fictional COVID-19 data\",\n  )\n\n\n\n# plot the basemap \nbasemap + \n  # add the shapefile on top with no fill and black borders\n  geom_sf(data = shapefile, fill = NA, colour = \"black\") +\n  # plot points from linelist coloured by ethnicity\n  # (order the factor so that the most frequent group is plotted first)\n  geom_sf(data = linelist_sf, \n          mapping = aes(colour = fct_infreq(eth_race))) + \n  # choose colour combination \n  scale_colour_brewer(palette = \"Set1\") +\n  # change the legend label\n  labs(colour = \"Ethnicity\")\n\n\n## Note: if you didnt have your gps points in an sf object you could use geom_point()\n  # geom_point(data = linelist %&gt;% \n  #              filter(lat &gt;= 33 & lat &lt;= 35, \n  #                     lon &gt;= -85 & lon &lt;= -84 & \n  #                     date_report %in% recent_period),\n  #            aes(x = lon, y = lat, colour = eth_race),\n  #            alpha = 0.5)\n\n\n\n\n# combine counts data with shapefile \nshapefile &lt;- left_join(shapefile, \n                       # drop the population variable (otherwise duplicated)\n                       select(zip_counts, -Population), \n                       # zip (or ZipCode in the shapefile) variable is the unique identifier\n                       by = c(\"ZipCode\" = \"zip\")) %&gt;% \n  # change the name ofthe recent_inc column to incidence\n  rename(incidence = recent_inc)\n\n\n\n# prepare counts for plotting \n#############################\n\n# get counts of points within polygons\nshapefile &lt;- shapefile %&gt;%\n  # add a column to the shapefile with counts\n  mutate(\n    # see which points are in which zip code polygon\n    cases = st_intersects(., linelist_sf) %&gt;% \n            # count how many are in each\n            lengths()\n    )\n\n\n# calculate incidence in shapefiledata\nshapefile &lt;- shapefile %&gt;% \n  mutate(\n    # divide cases by population \n    incidence = round(cases / Population * 100000, digits = 1), \n    # clean up calculations \n    incidence = case_when(\n           # fix the outliers: set infinity to NA and cases less than 10 to NA\n           cases &lt; 10             ~ NA_real_,\n           is.infinite(incidence) ~ NA_real_,  ## nb. infinite due to zero denominator\n           TRUE                   ~ incidence)\n    )\n\n\n# define breaks (for plotting groups)\nbreakers &lt;- shapefile %&gt;% \n  # change shapefile to a tibble (otherwise geometry pulled with)\n  as_tibble() %&gt;% \n  # only keep zips with more than ten cases\n  filter(cases &gt; 10) %&gt;% \n  # pull the incidence column\n  select(incidence) %&gt;% \n  # define grouping cut-offs based on quartiles of observations \n  quantile(probs = seq(0, 1, 0.25), na.rm = TRUE) \n\n# create a factor variable for incidence\nshapefile &lt;- shapefile %&gt;% \n  mutate(\n    # define groups using the cut function \n    incidence_cats = cut(incidence,\n                         # cut-offs as defined above (including zero)\n                         breaks = c(0, breakers), \n                         # add labels by using the cut-offs\n                         labels = str_glue(\"&lt;={breakers}\"))\n    )\n\n# plot choropleth map \n#####################\n\n# plot basemap \nbasemap + \n  # add in shapefile (with black borders) colour by incidence categories\n  geom_sf(data = shapefile, \n          aes(fill = incidence_cats),\n          colour = \"black\") + \n  # define colour scheme \n  scale_fill_brewer(palette = \"YlGn\", \n                    # edit legend labels to the categories defined\n                    # rename the missing group to be fewer than 10 cases\n                    labels = c(\n                      levels(shapefile$incidence_cats),\n                      \"Fewer than 10 cases\")) + \n  # add in text labels for each zip code \n  geom_sf_text(data = shapefile, \n               aes(label = ZipCode), \n               check_overlap = TRUE) + \n  # change the legend title \n  labs(fill = \"Confirmed cases per \\n 100,000 by Zip code\")\n\n\n\n\n# prepare data for plotting \n#############################\n\n\nshapefile &lt;- shapefile %&gt;%\n  mutate(\n    # get counts of the number of non-white cases in each polygon\n    case_eth = st_intersects(.,\n                           filter(\n                             linelist_sf,\n                             eth_race != \"White, NH\"\n                             )) %&gt;%\n                            lengths(),\n    case_eth_perc = case_eth / cases * 100, \n    case_eth_perc = if_else(case_eth == 0, 0, case_eth_perc),\n    case_eth_cats = cut(case_eth_perc, \n                        breaks = c(0, 1, 25, 50, 75, 100), \n                        include.lowest = TRUE,\n                        labels = c(\"0%\", \"25%\", \"50%\", \"75%\", \"100%\")), \n    incidence_cats = fct_explicit_na(incidence_cats, \n                                     na_level = \"Under 10 cases\"), \n    incidence_cats = fct_relevel(incidence_cats, \n                                 \"Under 10 cases\", \n                                 after = 0)\n    )\n\n\n# define your colour palette  \ncol_grps &lt;- make_colours(\n  og_pal1 = \"PinkYl\", \n  og_pal2 = \"YlGnBu\",\n  num1 = 6,\n  num2 = 5)\n\n# create a unique identifier by combining the row and columnn labels\ncol_grps &lt;- col_grps %&gt;% \n  mutate(merger = str_glue(\"{rws}-{cls}\")) \n\n# create a unique identifier by combining category levels in shapefile\nshapefile &lt;- shapefile %&gt;% \n  mutate(merger = str_glue(\"{as.numeric(incidence_cats)}-{as.numeric(case_eth_cats)}\"))\n\n\n# join colours to shapefile \nshapefile &lt;- left_join(shapefile, col_grps, by = \"merger\")\n\n\n# plot bivariate choropleth map \n###############################\n\nbivar_map &lt;- basemap + \n  # fill shape with the colours column \n  geom_sf(data = shapefile, \n          aes(fill = clrs), \n          color = \"black\", \n          size = 0.1) + \n  # fill polygons by the colours as they are named clrs column\n  scale_fill_identity(drop = FALSE, \n          na.value = \"grey90\")\n\n\n\n\n# plot the legend separately \n# use the col_grps dataset (colour scheme generated by make_colours function)\n# use the counts for rows and columns and fill by the clrs columns\nlegend &lt;- ggplot(\n    data = col_grps,\n    mapping = aes(\n      x = cls,\n      y = rws,\n      fill = clrs)) +\n  # create a tile plot (boxes)\n  geom_tile() +\n  # fill tiles by the colour names in clr \n  scale_fill_identity() + \n  # label the axis ticks from 0 to the number of levels\n  scale_x_continuous(\n    breaks = c(1:5),\n    labels = levels(shapefile$case_eth_cats), \n    ) +\n  scale_y_continuous(\n    breaks = c(1:6),\n    labels = levels(shapefile$incidence_cats)\n    ) +\n  # make tiles boxes\n  coord_fixed() + \n  # label axes \n  labs(x = \"Ethnic minorities (%)\", y = \"Incidence (per 100k)\") + \n  # make simple theme and set text size \n  theme_minimal(base_size = 18) + \n  # rotate the xaxis labels \n  theme(axis.text.x = element_text(angle = 45))\n\n\n\n\n# using {patchwork} - set the plot layout area \n# The map goes from top left at 1,1 to bottom right at 10,10\n# the legend sits within that as a smaller box \n# (think of this as upside-down cartesian coordinates)\nlayout &lt;- c(\n  area(t = 1, l = 1, b = 10, r = 10),\n  area(t = 1, l = 2, b = 4, r = 4)\n  )\n\n\n# combine the map and the legend with the above layout\nbivar_map + legend + plot_layout(design = layout)\n\n\n\n\n# calculate coordinate units per distance\n#########################################\n\n# define x and y minimum/maximum coordinates based on bounding box of base map\nxmin &lt;- st_point(c(bounding_box$xmin, bounding_box$ymin))\nxmax &lt;- st_point(c(bounding_box$xmax, bounding_box$ymin))\nymin &lt;- xmin\nymax &lt;- st_point(c(bounding_box$xmin, bounding_box$ymax))\n                 \n\n# create sf points (with coordinate reference system WGS84) for the x and y axis\nxaxis &lt;- st_sfc(xmin, xmax, crs = 4326)\nyaxis &lt;- st_sfc(ymin, ymax, crs = 4326)\n                 \n# calculate the distance in metres on the axes of your based on longitude and latitude\n# i.e. how many metres on your x axis and how many on your y\nxdist &lt;- st_distance(xaxis)[2] %&gt;% units::set_units(\"miles\")\nydist &lt;- st_distance(yaxis)[2] %&gt;% units::set_units(\"miles\")\n\n# calculate how many lat/long units there are on each axis \nxunits &lt;- st_distance(xmin, xmax)\nyunits &lt;- st_distance(ymin, ymax)\n\n\n# divide the difference in latitude or longitude by the corresponding distance\n# returns the number of units per distance of interest (i.e. coord units per mile)\nxfact &lt;- as.numeric(xunits / xdist)\nyfact &lt;- as.numeric(yunits / ydist)\n\n\n# plot heat map\n###############\n\nbasemap + \n  # add in shapefile not filled with black border\n  geom_sf(data = shapefile, fill = NA, colour = \"black\") +\n  # add in a density layer \n  stat_density_2d(\n        # using the sf formatted linelist\n        data = linelist_sf,\n        aes(\n          # extract the lat lon from geometry (list column)\n          x = purrr::map_dbl(geometry, ~.[1]),\n          y = purrr::map_dbl(geometry, ~.[2]), \n          # fill based on the calculated density\n          fill = after_stat(level)\n          ),\n        # define the shape to use for smoothing\n        geom = \"polygon\",\n        # define whether to show legend (removed as uninformative)\n        show.legend = FALSE,\n        # bandwith (distance squared) \n        h = c(xfact, yfact)\n        ) + \n  # define fill palette (viridis continuous) \n  scale_fill_viridis_c(option = \"C\")"
  },
  {
    "objectID": "oswego-es.html#overview",
    "href": "oswego-es.html#overview",
    "title": "3  Oswego (ES)",
    "section": "Overview",
    "text": "Overview\nCase study characteristics\n\n\n\n\n\n\n\n\nName\nOswego\n\n\nTool\nR\n\n\nLanguage\nSpanish/Español\n\n\nLocation\nUnited States\n\n\nScale\nLocal\n\n\nDiseases\nGastrointestinal\n\n\nKeywords\nGastrointestinal;Outbreak investigation\n\n\nTechnical complexity\nIntermidiate\n\n\nMethodolocial complexity\nIntermidiate\n\n\n\nAuthorship\nOriginal authors: Centre for Disease Prevention and Control (CDC)\nData source: Epi Info, version 3.5.4 (CDC)\nAdapted to R by: Leonel Lerebours Nadal y Alberto Mateo Urdiales"
  },
  {
    "objectID": "oswego-es.html#instructions",
    "href": "oswego-es.html#instructions",
    "title": "3  Oswego (ES)",
    "section": "Instructions",
    "text": "Instructions\n\nGetting Help\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\nHints and Solutions\nHere is what the “helpers” look like:\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\nPosting a question in the Community Forum\n… description here about posting in Community… TO BE COMPLETED BY APPLIED EPI\n\n\nIcons\nYou will see these icons throughout the exercises:\n\n\n\n\n\n\n\nIcon\nMeaning\n\n\n\n\n\nObserve\n\n\n\nAlert!\n\n\n\nAn informative note\n\n\n\nTime for you to code!\n\n\n\nChange to another window\n\n\n\nRemember this for later\n\n\n\n\n\n\nTerms of use\nThis case study has been adapted from an existing tutorial on Epi Info created by the Centre for Disease Prevention and Control (CDC). Epi Info™ is a trademark of CDC. Epi Info™ programs are provided in the public domain to promote public health. Programs might be freely translated, copied, or distributed. No warranty is made or implied for use of the software for any particular purpose.\n Applied Epi Incorporated, 2022 This work is licensed by Applied Epi Incorporated under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\nPlease email contact@appliedepi.org with questions about the use of these materials for academic courses and epidemiologist training programs."
  },
  {
    "objectID": "oswego-es.html#primera-parte---antecedentes",
    "href": "oswego-es.html#primera-parte---antecedentes",
    "title": "3  Oswego (ES)",
    "section": "3.3 Primera parte - Antecedentes",
    "text": "3.3 Primera parte - Antecedentes\n\n \n\n\nEl 19 de abril de 1940, el oficial de salud local en el pueblo de Lycoming, condado de Oswego, Nueva York, informó de la ocurrencia de un brote de enfermedad gastrointestinal al Distrito de Salud Oficial en Siracusa. Dr. A. M. Rubin, epidemiólogo en formación, fue asignado para investigar lo ocurrido.\nCuando el Dr. Rubin llegó al campo, determinó a través del oficial de salud que todas las personas que enfermaron había asistido a una cena en la iglesia celebrada el noche anterior, 18 de abril. Otra información importante fue que los familiares que no asistieron a la cena, no enfermaron.\nEn consecuencia, el Dr. Rubin centró la investigación sobre lo ocurrido en la cena. Pudo completar 75 entrevistas de las 80 personas conocidas que asistieron a la cena, recopilando información sobre los ocurrencia y tiempo de aparición de los síntomas, y alimentos consumidos. de las 75 personas entrevistados, 46 personas se enfermaron de enfermedad gastrointestinal.\n\n3.3.1 Pregunta 1: ¿Ante que tipo de situación está presente el Dr Rubin?.\n\nUna epidemia\n\nUna serie de casos\n\nUn brote\n\nNo se puede establecer\n\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nLa solucion es numero 3 - Un brote. TODO Here is more explanation.\nNumero 1 - No es la respuesta correcta; revisa el concepto de epidemia, tiene que ver con la cantidad de personas afectadas.\nNumero 2 - Es posible, pero también debes tomar en cuenta otros factores.\nNumero 4 - No te preocupes, en este tutorial vas a poder aprender los pasos del trabajo de campo.\n\n\n\n\n\n\n3.3.2 Pregunta 2: Los pasos de una investigación de brote son:.\n\n\n\n\n\n3.3.3 Descripción clínica\n\n \n\n\nEl inicio de la enfermedad en todos los casos fue agudo, caracterizada principalmente por náuseas, vómitos, diarrea y dolor abdominal. Ninguno de los enfermos personas reportaron tener un nivel elevado temperatura; todos se recuperaron dentro de las 24 a 30 horas.\nAproximadamente el 20% de los enfermos que visitaron al médico no se les realizó examen de muestras fecales para el examen bacteriológico.\n\n\n3.3.4 Pregunta 3: Enumere las grandes categorías de agentes causales de enfermedades que se deben considerar en el diagnóstico diferencial de un brote de enfermedad gastrointestinal.\nLos investigadores sospechan de que la génesis de este brote fue través de los alimentos como vehiculo de transmisión entre los afectados.\n\n\n3.3.5 Pregunta 4: En lenguaje epidemiológico, ¿Qué es un vehículo? ¿Qué es un vector? ¿Cuáles son otros modos?\n\n\n3.3.6 Pregunta 5: Si tuviera que administrar un cuestionario a los participantes de la cena de la iglesia, ¿qué información recopilarías? Agrupa la información en categorías.\nEl Dr. Rubin recolectó los datos de los entrevistados a través de un listado nominal\n\n\n3.3.7 Pregunta 6: ¿En que nos ayuda un listado nominal?."
  },
  {
    "objectID": "oswego-es.html#segunda-parte---el-evento",
    "href": "oswego-es.html#segunda-parte---el-evento",
    "title": "3  Oswego (ES)",
    "section": "3.4 Segunda parte - El Evento",
    "text": "3.4 Segunda parte - El Evento\n\n3.4.0.1 Descripción de la Cena\n\n  \n\nLa cena se celebró en el sótano del iglesia del pueblo. Los alimentos fueron aportados por numerosos miembros de la congregación. La cena comenzaba a las 6:00 p.m. y continuó hasta 11.00 pm.\nLa comida estaba esparcida sobre una mesa y fue consumida durante un período de varias horas. Los datos sobre el inicio de la enfermedad y los alimentos consumidos por cada una de las 75 personas entrevistados se proporcionan en la listado adjunto.\nLa hora aproximada de participación en el evento solo se recolectó aproximadamente la mitad de las personas que tuvo una enfermedad gastrointestinal.\n\n\n3.4.1 Pregunta 7: ¿Cuál es el valor de una curva epidémica?\n\n\n3.4.2 Pregunta 8: ¿Qué nos dice el siguiente gráfico?\n\n\n3.4.3 Pregunta 9: ¿Hay algún caso en el que los tiempos de inicio no coincidan con los generales? ¿experiencia? ¿Cómo podrían explicarse?\n\n\n3.4.4 Listado nominal de individuos del brote de gastroenteritis, Oswego, Nueva York, 1940\n\n\n\n\n\n\n\n\n3.4.5 ¿Cómo podrían presentarse mejor los datos en el listado nominal de participantes?\n\n3.4.5.1 Versión digital"
  },
  {
    "objectID": "oswego-es.html#tercera-parte---análisis",
    "href": "oswego-es.html#tercera-parte---análisis",
    "title": "3  Oswego (ES)",
    "section": "3.5 Tercera parte - Análisis",
    "text": "3.5 Tercera parte - Análisis\n\n3.5.1 Apoyo en análisis de los datos\n\n\n\n\nAhora vamos a comenzar con uno de los pasos más importantes en la investigación de brote, el análisis de los datos donde a través de este vamos a determinar cual o cuales son las posibles causas del brote, medidas a tomar entre otros pasos. ¡También vamos a usar un poco de R para ayudar con este proceso de análisis!.\n\n\n3.5.2 Pregunta 11: Siempre que sea posible, utilizando el listado nominal actualizado, calcule los períodos de incubación e ilustre su distribución con un gráfico apropiado.\n \nPara contestar esta pregunta, vamos hacer los siguientes pasos usando R:\n \n\nen Rstudio, crea un nuevo script para cargar los datos (cargar el archivo “listado_oswego_limpio.csv”, que está en la carpeta data)\n\n\n# Importa el listado al espacio de trabajo, \n# puedes copiar este código en rstudio en tu editor de códigos\n\nlibrary(pacman) # para gestionar los paquetes\n\np_load(rio,         # para importar archivos\n       here,        # para gestionar la ruta del archivo\n       tidyverse,   # Para transformar datos\n       lubridate)   # para trabajar con fechas\n\nlibrary(here)\n\nlistado &lt;- import(here(\"casos_estudios\", \"data\", \"listado_oswego_limpio.csv\"))\n\nView(listado)\n\nPara referencia sobre como importar archivos, ver el capítulo 7 del libro de R para epidemiologos\n \n\nEl listado cargado ya tiene el formato correcto de la fecha y hora de almuerzo y la fecha y hora de inicio de síntomas ahora con el siguiente código creas la variable que tendrá el valor del período de incubación. (recuerda que con las variables de tiempo en R se pueden hacer operaciones matemáticas)\n\n\n# Crear la variable del período de incubación\n# puedes copiar este código en rstudio en tu editor de códigos\n#las funciones \"interval\" y \"dhours()\" son las que usaremos para calcular la diferencia en hora\n\nlistado_incubacion &lt;- listado %&gt;% \n  \n  mutate(incubacion=interval(fecha_hora_almuerzo, fecha_hora_ini_sintomas) / dhours(1)) \n\nPara más detalles de como trabajar con fechas, ver el capítulo 9 del libro de R para epidemiologos\n \n\nAhora vamos a graficar el período de incubación con ggplot para visualizar la distribución\n\n\n# Hacer un histograma de los periodos de incubación calculados\n# puedes copiar este código en rstudio en tu editor de códigos\n\nlistado_incubacion %&gt;% \n  \n  ggplot(aes(x=incubacion))+\n  \n  geom_histogram()+\n  \n  labs(title=\"Casos de enfermedad gastrointestinal por período de incubación en horas\",\n       subtitle = \"Oswego, NY, 18-19 de abril, 1940\",\n       x=\"Período de incubación (Horas)\",\n       y=\"n de casos\")+\n  \n  theme_minimal()\n\n#Si quieres asignar este gráfico a un objeto, solo tienes que en la primera línea del código \n#usar un nombre (como grafico1) y escribir el signo de asignación (&lt;-)\n\nPara más detalles de como trabajar con gráficos, ver el capítulo 30 del libro de R para epidemiologos\n \n\n3.5.2.1 ¿Cuantos casos tenian el dato de incubación?\n\n\n\n3.5.3 Pregunta 12: Determine el rango y la mediana del período de incubación.\nPara ejecutar esto en R hay varias formas, usando ya sea las funciones base o de otros paquetes. Vamos a usar directamente el paquete {dplyer} que viene integrado en el paquete {tidyverse}\n\n# Calcular el rango, la mediana y el periodo de incubacion\n# puedes copiar este código en rstudio en tu editor de códigos\n\nresumen_estadistico &lt;- listado_incubacion %&gt;% \n  filter(!is.na(incubacion)) %&gt;% \n  reframe(mediana=median(incubacion),\n          min=min(incubacion),\n          max=max(incubacion),\n          rango=max-min)\n\nresumen_estadistico\n\n\n\n3.5.4 Pregunta 13: ¿Cómo ayuda la información sobre el período de incubación y los datos sobre síntomas a establecer diagnósticos diferenciales de la enfermedad? (Si es necesario, consulte adjunto Compendio de enfermedades gastrointestinales agudas transmitidas por los alimentos).\n\n\n3.5.5 Pregunta 14: Usando los datos del listado, complete la tabla a continuación. ¿Cúal o cuales alimentos pudieron ser el vehículo más probable de infección?\n \nPara contestar esta pregunta, vamos hacer los siguientes pasos usando R:\n \n\nSiguiendo con el mismo script que creaste anteriormente, ahora vamos hacer un resumen para calcular la tasa de ataque de cada variable de exposición (en este caso bebidas y alimentos). El listado que cargamos ya tiene recodificadas las variables para asignar el valor de 1 si fue consumido y 0 para no consumido.\n\n\n#Ve copiando el codigo a rstudio (este ejercicio es un poco largo)\n\np_load(janitor, gtsummary)\n\n\n#Comieron\n#hacer un dataframe con un resumen de los alimentos por los que enfermaron\ntotal_por_alimentos_casos_a &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no enfermo\")) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"enfermo\") %&gt;% \nslice_tail()\n\n#hacer un dataframe con un resumen de los alimentos por los que no enfermaron\ntotal_por_alimentos_no_casos_a &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no_enfermo\")) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"no_enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"no_enfermo\") %&gt;% \nslice_tail()\n\n#No Comieron\n#hacer un dataframe con un resumen de los alimentos por los que enfermaron\ntotal_por_alimentos_casos_b &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no enfermo\"),\n         across(starts_with(\"m_\"),~ifelse(.x==1,0,1))) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"enfermo\") %&gt;% \nslice_tail()\n\n#hacer un dataframe con un resumen de los alimentos por los que no enfermaron\ntotal_por_alimentos_no_casos_b &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no_enfermo\"),\n         across(starts_with(\"m_\"),~ifelse(.x==1,0,1))) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"no_enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"no_enfermo\") %&gt;% \nslice_tail()\n\n\n#Combinar ambos dataframes, transformarlo a formato extendido y calcular la proporción de los que consumieron\ntabla_maestra_a &lt;- bind_rows(total_por_alimentos_casos_a,\n                           total_por_alimentos_no_casos_a) %&gt;% \n  pivot_longer(2:ncol(.), names_to = \"alimentos\", values_to = \"n\") %&gt;% \n  pivot_wider(names_from = tipo_caso, values_from = n) %&gt;% \n  mutate(total=enfermo+no_enfermo,\n         ptc_enfermo=enfermo/total,\n         ptc_no_enfermo=no_enfermo/total)\n\n\n\n#Combinar ambos dataframes, transformarlo a formato extendido y calcular la proporción de los que no consumieron \ntabla_maestra_b &lt;- bind_rows(total_por_alimentos_casos_b,\n                           total_por_alimentos_no_casos_b) %&gt;% \n  pivot_longer(2:ncol(.), names_to = \"alimentos\", values_to = \"n\") %&gt;% \n  pivot_wider(names_from = tipo_caso, values_from = n) %&gt;% \n  mutate(total=enfermo+no_enfermo,\n         ptc_enfermo=enfermo/total,\n         ptc_no_enfermo=no_enfermo/total)\n\ntabla_final &lt;- tabla_maestra_a %&gt;% \n  left_join(tabla_maestra_b,suffix = c(\"_consumieron\", \"_no_consumieron\"), by=\"alimentos\") %&gt;% \n  mutate(tasa_ataque=ptc_enfermo_consumieron/ptc_enfermo_no_consumieron)\n\nView(tabla_final)\n\n#otra forma.. para obtener los OR de cada alimento\n\n#crear un modelo de regresión logistica\nmodel &lt;- glm(data=listado, enfermo~m_jamon_horneado+\n            m_espinaca+m_pure_papa+m_ensa_repollo+\n            m_gelatina+m_rollos+m_pan+m_lehe+m_cafe+m_agua+\n            m_bizcocho+m_hel_vainilla+m_hel_chocolate+m_ens_fruta,\n            family=binomial())\n#Luego una tabla\ntbl_regression(model, exponentiate = TRUE)\n\ntest &lt;- listado %&gt;% \n  select(enfermo, starts_with(\"m_\")) %&gt;% \n  tbl_summary(by=enfermo)\n\nPara más detalles de como trabajar con transformación de datos y tablas, ver el capítulo 17 del libro de R para epidemiologos\n\n\n3.5.6 Pregunta 15: Resuma las investigaciones adicionales que deben llevarse a cabo.\n\n\n3.5.7 Pregunta 16: ¿Qué medidas de control sugeriría?\n\n\n3.5.8 Pregunta 17: ¿Por qué fue importante trabajar en este brote?\n\n\n3.5.9 Pregunta 18: Consulte los pasos de una investigación de brote que enumeró en la Pregunta 2. ¿Cómo funciona esto? investigación se ajusta a ese esquema?"
  },
  {
    "objectID": "oswego-es.html#cuarta-parte---conclusión",
    "href": "oswego-es.html#cuarta-parte---conclusión",
    "title": "3  Oswego (ES)",
    "section": "3.6 Cuarta Parte - Conclusión",
    "text": "3.6 Cuarta Parte - Conclusión\n\n\n\n\n\nLo siguiente se cita textualmente del informe preparado por el Dr. Rubin:\nEl helado fue preparado por el Petrie hermanas de la siguiente manera: En la tarde del 17 de abril la leche cruda de la La granja Petrie en Lycoming se desbordó al baño maría se le agrega azúcar y huevos y un poco de harina para darle cuerpo a la mezcla. El se prepararon helado de chocolate y vainilla por separado.\nEl chocolate de Hershey era necesariamente añadido a la mezcla de chocolate. A las 6 pm. los dos las mezclas se llevaban en recipientes tapados al sótano de la iglesia y se dejó reposar durante la noche. Presuntamente no fueron tocados por nadie. durante este período.\nEn la mañana del 18 de abril, el Sr. Coe agregó cinco onzas de vainilla y dos latas de leche condensada a la mezcla de vainilla y tres onzas de vainilla y una lata de leche condensada a la mezcla de chocolate. Luego el helado de vainilla se transfirió a un lata de congelación y se coloca en un congelador eléctrico durante 20 minutos, después de lo cual el helado de vainilla se sacó de la lata del congelador y se envasó en otra lata que había sido previamente lavado con agua hirviendo. Entonces el chocolate la mezcla se puso en la lata del congelador que había sido se enjuaga con agua del grifo y se deja congelardurante 20 minutos.”\nAl concluir esto, ambos las latas se taparon y se colocaron en grandes recipientes de madera recipientes llenos de hielo. Como señaló, el helado de chocolate permaneció en el una lata de congelador.\nTodos los manipuladores del helado fueron examinados. Sin lesiones externas ni respiratorias altas se notaron infecciones. Cultivos de nariz y garganta fueron tomados de dos individuos que prepararon el helado.\nLos exámenes bacteriológicos fueron hechos por el División de Laboratorios e Investigación, Albany, en ambos helados. Su informe es el siguiente:\n‘Un gran número de Staphylococcus aureus y albus se encontraron en la muestra de hielo de vainilla crema. Sólo unos pocos estafilococos fueron demostrado en el helado de chocolate.’\nInforme de los cultivos de nariz y garganta de Los Petries que prepararon el helado decía lo siguiente:\nPresencia de Staphylococcus aureus y hemolítica del cultivo nasal y Staphylococcus albus del cultivo faríngeo de Gracia Petrie. Tambien Staphylococcus albus del cultivo de la nariz de Marian Petrie. Los estreptococos hemolíticos no eran del tipo generalmente asociado con infecciones en el hombre.\nDiscusión sobre la fuente: la fuente de contaminación bacteriana del helado de vainilla no está claro. Cualquiera que sea el método de la introducción de los estafilococos, parece razonable suponer que debe haber ocurrido entre la tarde del 17 de abril y la mañana del 18 de abril. Sin motivo de contaminación Se conoce la peculiaridad del helado de vainilla. “Al dispensar los helados, la misma cuchara se utilizó. Por lo tanto, no es improbable suponer que alguna contaminación al helado de chocolate crema ocurrió de esta manera. Esto parecería ser la explicación más plausible para la enfermedad en los tres individuos que no comieron el helado de vainilla.\nMedidas de Control: El 19 de mayo, todo el helado restantes fue condenado. Todos los demás alimentos en el la cena de la iglesia había sido consumida.\nConclusiones: Un brote de gastroenteritis ocurrió después de una cena en la iglesia en Lycoming. La causa del brote fue helado de vainilla por contaminado. El método de contaminación de helado no se entiende claramente.\nSi el estafilococo dio positivo de la nariz y la garganta de los cultivos realizados en la familia Petrie haba todo lo que tenga que ver con la contaminación es un asunto por nexo epidemiológico.\nNota: El paciente #52 era un niño que mientras viendo el procedimiento de congelación se le dio una plato de helado de vainilla a las 11:00 am en abril 18."
  },
  {
    "objectID": "index.html#authors",
    "href": "index.html#authors",
    "title": "Applied Epi Case Studies",
    "section": "Authors",
    "text": "Authors"
  },
  {
    "objectID": "oswego-es_template.html#overview",
    "href": "oswego-es_template.html#overview",
    "title": "3  Oswego (ES)",
    "section": "Overview",
    "text": "Overview\nCase study characteristics\n\n\n\n\n\n\n\n\nName\nOswego\n\n\nTool\nR\n\n\nLanguage\nSpanish/Español\n\n\nLocation\nUnited States\n\n\nScale\nLocal\n\n\nDiseases\nGastrointestinal\n\n\nKeywords\nGastrointestinal;Outbreak investigation\n\n\nTechnical complexity\nIntermidiate\n\n\nMethodolocial complexity\nIntermidiate\n\n\n\nAuthorship\nOriginal authors: Centre for Disease Prevention and Control (CDC)\nData source: Epi Info, version 3.5.4 (CDC)\nAdapted to R by: Leonel Lerebours Nadal y Alberto Mateo Urdiales"
  },
  {
    "objectID": "oswego-es_template.html#instructions",
    "href": "oswego-es_template.html#instructions",
    "title": "3  Oswego (ES)",
    "section": "Instructions",
    "text": "Instructions\n\nGetting Help\nThere are several ways to get help:\n\nLook for the “hints” and solutions (see below)\nPost a question in Applied Epi Community with reference to this case study\n\n\nHints and Solutions\nHere is what the “helpers” look like:\n\n\n\n Click to read a hint\n\n\nHere you will see a helpful hint!\n\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nebola_linelist %&gt;% \n  filter(\n    age &gt; 25,\n    district == \"Bolo\"\n  )\n\nHere is more explanation about why the solution works.\n\n\n\n\n\nPosting a question in the Community Forum\n… description here about posting in Community… TO BE COMPLETED BY APPLIED EPI\n\n\nIcons\nYou will see these icons throughout the exercises:\n\n\n\n\n\n\n\nIcon\nMeaning\n\n\n\n\n\nObserve\n\n\n\nAlert!\n\n\n\nAn informative note\n\n\n\nTime for you to code!\n\n\n\nChange to another window\n\n\n\nRemember this for later\n\n\n\n\n\n\nTerms of use\nThis case study has been adapted from an existing tutorial on Epi Info created by the Centre for Disease Prevention and Control (CDC). Epi Info™ is a trademark of CDC. Epi Info™ programs are provided in the public domain to promote public health. Programs might be freely translated, copied, or distributed. No warranty is made or implied for use of the software for any particular purpose.\n Applied Epi Incorporated, 2022 This work is licensed by Applied Epi Incorporated under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\nPlease email contact@appliedepi.org with questions about the use of these materials for academic courses and epidemiologist training programs."
  },
  {
    "objectID": "oswego-es_template.html#feedback-suggestions",
    "href": "oswego-es_template.html#feedback-suggestions",
    "title": "3  Oswego (ES)",
    "section": "Feedback & suggestions",
    "text": "Feedback & suggestions\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org"
  },
  {
    "objectID": "oswego-es_template.html#version-1",
    "href": "oswego-es_template.html#version-1",
    "title": "3  Oswego (ES)",
    "section": "Version 1",
    "text": "Version 1\n16 November 2023"
  },
  {
    "objectID": "oswego-es_template.html#disclaimer",
    "href": "oswego-es_template.html#disclaimer",
    "title": "3  Oswego (ES)",
    "section": "Disclaimer",
    "text": "Disclaimer\nEsto es un estudio de caso diseñado por el Centre for Disease Prevention and Control (CDC) como tutorial de Epi Info. Puede consultar más detalles en este Enlace"
  },
  {
    "objectID": "oswego-es_template.html#revisions",
    "href": "oswego-es_template.html#revisions",
    "title": "3  Oswego (ES)",
    "section": "Revisions",
    "text": "Revisions\n\n\n\nDate\nChanges made\nVersion\n\n\n\n\n16 November\nAdapted to template\n1"
  },
  {
    "objectID": "oswego-es_template.html#guía",
    "href": "oswego-es_template.html#guía",
    "title": "3  Oswego (ES)",
    "section": "Guía",
    "text": "Guía"
  },
  {
    "objectID": "oswego-es_template.html#objetivos-de-este-estudio-de-caso",
    "href": "oswego-es_template.html#objetivos-de-este-estudio-de-caso",
    "title": "3  Oswego (ES)",
    "section": "Objetivos de este estudio de caso",
    "text": "Objetivos de este estudio de caso\nLos objetivos de este estudio de caso son:\n\nEntender los diferentes pasos en la investigación de un brote de casos de enfermedad gastrointestinal\nAdquirir confianza en el manejo de datos de un listado nominal con el software estadístico R\nAdquirir experience en el análisis descriptivo en R, particularmente curvas epidémicas\nAdquirir experience construyendo tablas 2x2 con exposición y desenlace que nos permitan calcular medidas de asociación\nAplicar los conocimientos adquiridos a posibles actividades de control y prevención de brotes infecciosos de origen alimentario\n\n\nConocimientos previos asumidos\nEn este estudio de caso se asume un conocimiento básico de los principios fundamental de la investigación epidemiológica de brotes gastrointestinales. Se asume también un conocimiento básico de R.\n\n\nPreparation for the case study\nAntes de iniciar este estudio de caso, le aconsejamos que:\n\nDescargue en su computadora la carpeta “oswego_cs_es” y que extraiga todos sus componentes, preferibilmente en su escritorio o en un lugar de fácil acceso. Evite extraerlo en servicios de nube o “drives”\n\nDentro de la carpeta, encontrará un proyecto de R llamado “oswego_cs”. Es un archivo de tipo “R project” y debe siempre asegurarse que está trabajando en RStudio desde el proyecto. La forma más fácil es que habra RStudio cada vez a través de abrir este archivo.\nDentro de la carpeta “oswego_cs_es” encontrará una subcarpeta llamada data en el que encontrará todos los datos necesarios para realizar el análisis en un file llamado “oswego.xlsx”.\nDeberá crear un script dentro de la carpeta scripts en el que usted escribe el código para el análisis. Puede utilizar el script que ya está presente llamado “01_oswego_sol” que contiene el código de análisis si se encuentra atascado o si quiere comparar el código que usted realiza con la solución.\nEn la subcarpeta outputs encontrará todos los gráficos y tablas generadas en el anlálisis.\n\n\nPrimera parte - Antecedentes**Segunda parte - El Evento {.unnumbered}Tercera parte - AnálisisCuarta Parte - Conclusión\n\n\n\n\n\n\n\nEl 19 de abril de 1940, el oficial de salud local en el pueblo de Lycoming, condado de Oswego, Nueva York, informó de la ocurrencia de un brote de enfermedad gastrointestinal al Distrito de Salud Oficial en Siracusa. Dr. A. M. Rubin, epidemiólogo en formación, fue asignado para investigar lo ocurrido.\nCuando el Dr. Rubin llegó al campo, determinó a través del oficial de salud que todas las personas que enfermaron había asistido a una cena en la iglesia celebrada la noche anterior, 18 de abril. Otra información importante fue que los familiares que no asistieron a la cena, no enfermaron.\nEn consecuencia, el Dr. Rubin centró la investigación sobre lo ocurrido en la cena. Pudo completar 75 entrevistas de las 80 personas conocidas que asistieron a la cena, recopilando información sobre los ocurrencia y tiempo de aparición de los síntomas, y alimentos consumidos. de las 75 personas entrevistados, 46 personas presentaron síntomas de enfermedad gastrointestinal.\n\nPregunta 1\n\n¿Ante que tipo de situación está presente el Dr Rubin?\n\n Una epidemia Una serie de casos Un brote No se puede establecer\n\n\n\n\n\n Click para leer una pista\n\n\nPuede utilizar este glosario preparado por el Gobierno de México para encontrar la definición que se ajusta más a la situación descrita Enlace \n\n\n\nClick para ver la explicación (¡Inténtelo usted primero!)\n\n\nNumero 1 - No es la respuesta correcta; revisa el concepto de epidemia, tiene que ver con la cantidad de personas afectadas.\nNumero 2 - Es posible, pero también debes tomar en cuenta otros factores, como el hecho de que los casos tienen una relación epidemiológica entre ellos.\nNumero 4 - No te preocupes, en este tutorial vas a poder aprender los pasos del trabajo de campo.\n\n\n\n\nPregunta 2\n\nLos pasos de una investigación de brote son:\n\n Determinar la existencia del brote, análisis descriptivo, generar hipótesis, confirmar hipótesis, controlar brote, conclusiones y recomendaciones, informe final Una serie de casos Determinar la existencia del brote, confirmar diagnóstico, contar casos, análisis descriptivo, determinar quién está a riesgo de enfermar, desarrollar hipótesis, confirmar hipótesis, controlar brote, conclusiones y recomendaciones, informe final Determinar la existencia del brote, confirmar el diagnóstico, controlar brote, comunicar brote, generar hipótesis, confirmar hipótesis, controlar brote, conclusiones y recomendaciones, informe final\n\n\n\n\nClick para ver la explicación (¡Inténtelo usted primero!)\n\n\nPuede utilizar el sitio de la OPS para profundizar sobre el tema Enlace\n\n\n\n\nDescripción clínicade los casos\nEl inicio de la enfermedad en todos los casos fue agudo, caracterizada principalmente por náuseas, vómitos, diarrea y dolor abdominal. Ninguno de los enfermos personas reportaron tener un nivel elevado temperatura; todos se recuperaron dentro de las 24 a 30 horas.\nAproximadamente el 20% de los enfermos que visitaron al médico no se les realizó examen de muestras fecales para el examen bacteriológico.\n\nPregunta 3\nEnumere una de las grandes categorías de agentes causales de enfermedades que se deben considerar en el diagnóstico diferencial de un brote de enfermedad gastrointestinal como el de Oswego:\n\n\n\n\nClick para ver la explicación de la solución (¡Inténtelo usted primero!)\n\n\n\nBacterias\nVirus\nParásitos\nToxinas\n\nPuede utilizar el sitio de la OPS para profundizar sobre el tema Enlace\n\n\n\nLos investigadores en Oswego, desconocen el agente causal, pero sospechan de que la génesis de este brote fue través de los alimentos como vehiculo de transmisión entre los afectados.\n\n\nPregunta 4\nEn lenguaje epidemiológico, ¿Qué es un vehículo? ¿Qué es un vector? ¿Cuáles son otros modos?\nPiense en estos conceptos y cuando esté listo, vea la solución propuesta\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEn la jerga epidemiológica, un ‘vehículo’ es un objeto o sustancia inanimada que puede transportar un patógeno y transmitirlo a un huésped susceptible. Ejemplos de vehículos incluyen alimentos o agua contaminados, fómites (objetos inanimados como pomos de puertas o ropa) o partículas transportadas por el aire. En este contexto, un vehículo no es un modo de transporte, sino más bien un medio de transmisión de un agente infeccioso. Por otro lado, un ‘vector’ es un objeto animado, generalmente un artrópodo como un mosquito, una garrapata o una pulga, que puede transportar un agente infeccioso desde un huésped infectado a un huésped susceptible. El vector puede transmitir el patógeno directamente a través de su picadura o indirectamente al depositar el patógeno en una superficie o en una fuente de alimentos o agua. Los otros modos de transmisión de agentes infecciosos incluyen el contacto persona a persona, ya sea directamente a través del contacto físico, como el tacto o el beso, o indirectamente a través de gotas generadas durante la tos o el estornudo, o mediante transmisión aérea en espacios cerrados. Además, algunos agentes infecciosos pueden ser transmitidos a través del contacto sexual, la transmisión perinatal de la madre al hijo o mediante la exposición a fluidos corporales, como la sangre o el semen. Los factores ambientales, como la mala higiene, el hacinamiento o la exposición a animales, también pueden desempeñar un papel en la transmisión de ciertos agentes infecciosos.\n\n\n\nEl Dr. Rubin decidió administrar un cuestionario a los participantes de la cena de la iglesia para averiguar qué alimento podía estar asociado al desarrollo de los síntomas\n\n\nPregunta 5\nSi fuese usted el que administra el cuestionario, ¿qué información recopilaría? Agrupa la información en categorías. Una vez que haya escrito sus categorías, puede ver abajo la solución.\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstos son algunos de los campos que normalmente se includirían en un cuestionario en un brote similar:\n\nInformación demográfica\nInformaión clínica\nDatos de laboratorio si disponibles\nFactores de riesgo (exposición): Alimentos y bebidas ingeridas durante la cena\n\n\n\n\nAdemás de decidir la información que quería recolectar, el Dr. Rubin decidió recolectó los datos entrevistados a través de un listado nominal.\n\n\nPregunta 6\n\n¿En que NO nos ayuda un listado nominal?\n\n Organizar los datos y describirlos por tiempo, lugar y persona Clasificar a los individuos como casos, no casos y sospechosos A diagnosticar a los pacientes A manejar un documento dinámico que se puede actualizar constantemente\n\n\nPor favor, continue el caso entrando en la pestaña “Segunda parte - El Evento” en la parte superior\n\n\n\n\n\nDescripción de la Cena\nLa investigación del Dr. Rubin también implicó averiguar más detalles sobre la cena. Después de hablar con los organizadores, descubrió que la cena se celebró en el sótano del iglesia del pueblo. Los alimentos fueron aportados por numerosos miembros de la congregación. La cena comenzaba a las 6:00 p.m. y continuó hasta 11.00 pm.\nLa comida estaba esparcida sobre una mesa y fue consumida durante un período de varias horas. Los datos sobre el inicio de la enfermedad y los alimentos consumidos por cada una de las 75 personas entrevistados se proporcionan en la listado adjunto.\nLa hora aproximada de participación en el evento solo se recolectó aproximadamente la mitad de las personas que tuvo una enfermedad gastrointestinal.\n\nPregunta 7\n¿Cuál es el valor de una curva epidémica en la investigación de un brote?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstas son algunos de los usos de las curvas epidémicas cuando se investigan brotes:\n\nNos permite ver la evolución en el tiempo de un evento forma rápida\nAporta información para tomar decisiones para medidas de control\nAyuda a revelar patrones y tendencias sobre un evento\n\n\n\n\n\n\nPregunta 8\n¿Qué nos dice el siguiente gráfico?\n\n\n\n\n\n\n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nLa curva epidémica nos dice que:\n\nTodos los casos ocurrieron antes de las 10am del día siguiente (19 de abril)\nDesde la 11pm del 18 a las 3am del 19 de abril ocurrieron la mayoría de los casos\nNos muestra la magnitud del evento y como se propaga, así como ver valores extremos\n\n\n\n\n\n\nPregunta 9\n¿Hay algún caso en el que los tiempos de inicio no coincidan con los generales? ¿experiencia? ¿Cómo podrían explicarse?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nConsidere que: - Hay casos que la hora de inicio de signos y sintomas fueron antes de la cena, pudo ser que se contaminara antes durante los preparativos - Un caso ocurrió 17 horas después de la cena, posiblemente es alguien que comió más tarde o que la infomación es incorrecta (otra enfermedad parecida) o un caso secundario\n\n\n\n\n\n\n3.0.1 Listado nominal de individuos del brote de gastroenteritis, Oswego, Nueva York, 1940\n\n\n\n\n\n\n\nPregunta 10\n¿Cómo podrían presentarse mejor los datos en el listado nominal de participantes?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nDos ideas, aunque puede haber más son:\n\nLos datos pudieron ser separados de acuerdo al estatus de enfermedad y tiempo de inicio de sintomas\nSi se hubiese usado el formato del en tiempo militar, (ej. 00:00 o 14:00)\n\n\n\n\n\n\n3.0.1.1 Versión digital\n\n\n\n\n\n3.0.2 Apoyo en análisis de los datos\n\n\n\nAhora vamos a comenzar con uno de los pasos más importantes en la investigación de brote, el análisis de los datos donde a través de este vamos a determinar cual o cuales son las posibles causas del brote, medidas a tomar entre otros pasos. ¡También vamos a usar un poco de R para ayudar con este proceso de análisis!.\n\n3.0.2.1 Siempre que sea posible, utilizando el listado nominal actualizado, calcule los períodos de incubación e ilustre su distribución con un gráfico apropiado.\n \nPara contestar esta pregunta, vamos hacer los siguientes pasos usando R:\n \n\nen Rstudio, crea un nuevo script para cargar los datos (cargar el archivo “oswego.xlsx”, que está en la carpeta data) y explore las dos columnas que contienen la información necesaria para calcular los períodos de incubación: TimeSupper (hora de la cena) y DateOnset (Fecha inizio síntomas)\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#Cargar los paquetes necesarios\npacman::p_load(rio,\n               here,\n               tidyverse, \n               epitools, \n               lubridate,\n               DT)\n\n#Importar los datos\nlistado &lt;- import(here(\"case_studies\", \"ESP\", \"oswego_cs_es\", \"data\", \"oswego.xlsx\"))\n\n#Explorar las variables de la fecha y hora del almuerzo\nhead(oswego_db$TimeSupper)\n\n[1] NA                        NA                       \n[3] NA                        \"1940-04-18 22:00:00 UTC\"\n[5] \"1940-04-18 19:30:00 UTC\" \"1940-04-18 19:30:00 UTC\"\n\nhead(oswego_db$DateOnset)\n\n[1] \"1940-04-18 23:00:00 UTC\" NA                       \n[3] \"1940-04-18 22:30:00 UTC\" \"1940-04-19 01:00:00 UTC\"\n[5] \"1940-04-19 02:30:00 UTC\" \"1940-04-18 23:30:00 UTC\"\n\n\n\n\n\nPara referencia sobre como importar archivos, ver el capítulo 7 del libro de R para epidemiologos\n \n\nEl listado cargado ya tiene el formato correcto de la fecha y hora de almuerzo y la fecha y hora de inicio de síntomas ahora intente crear un código para crear una nueva variable con los periodos de incubación para cada caso. (recuerda que con las variables de tiempo en R se pueden hacer operaciones matemáticas)\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n# Crear la variable del período de incubación\n# puedes copiar este código en rstudio en tu editor de códigos\n#las funciones \"interval\" y \"dhours()\" son las que usaremos para calcular la diferencia en hora\n\nlistado_incubacion &lt;- listado %&gt;%\n  \n  mutate(incubacion=interval(TimeSupper, DateOnset) / dhours(1)) \n\n\n\n\nPara más detalles de como trabajar con fechas, ver el capítulo 9 del libro de R para epidemiologos\n \n\nAhora intente hacer un gráfico de barras con el período de incubación usando ggplot para visualizar la distribución. Puede encontrar pistas sobre como hacer un gráfico de barras en la sección dedicada del EpiRhandbook\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n# Hacer un gráfico de barra de los periodos de incubación calculados\n# puedes copiar este código en rstudio en tu editor de códigos\n\nlistado_incubacion %&gt;% \n  \n  ggplot(aes(x=incubacion))+\n  \n  geom_bar()+\n  \n  labs(title=\"Casos de enfermedad gastrointestinal por período de incubación en horas\",\n       subtitle = \"Oswego, NY, 18-19 de abril, 1940\",\n       x=\"Período de incubación (Horas)\",\n       y=\"n de casos\")+\n  \n  theme_minimal()\n\nWarning: Removed 53 rows containing non-finite values (`stat_count()`).\n\n\n\n\n#Si quieres asignar este gráfico a un objeto, solo tienes que en la primera línea del código \n#usar un nombre (como grafico1) y escribir el signo de asignación (&lt;-)\n\n\n\n\nPara más detalles de como trabajar con gráficos en general, ver el capítulo 30 del libro de R para epidemiologos\n \n\n\nPregunta 10: ¿Cuantos casos tenian el dato de incubación?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n22\nPara saberlo, puedes verificar viendo el listado directamente o con el siguiente código\n\n\n\n\n\n3.0.2.2 Pregunta 11: Determine el rango y la mediana del período de incubación\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n Para ejecutar esto en R hay varias formas, usando ya sea las funciones base o de otros paquetes. Aquí tiene un ejemplo usando el paquete {dplyr} que viene integrado en el paquete {tidyverse}\n\n# Calcular el rango, la mediana y el periodo de incubacion\n# puedes copiar este código en rstudio en tu editor de códigos\n\nresumen_estadistico &lt;- listado_incubacion %&gt;% \n  filter(!is.na(incubacion)) %&gt;% \n  reframe(mediana=median(incubacion),\n          min=min(incubacion),\n          max=max(incubacion),\n          rango=max-min)\n\nresumen_estadistico\n\n  mediana min max rango\n1       4   3   7     4\n\n\nLa mediana del periodo de incubación fue 4 horas, así como el rango del periodo del periodo de incubación también fue de 4 horas\n\n\n\n\n\n3.0.2.3 Pregunta 12: ¿Cómo ayuda la información sobre el período de incubación y los datos sobre síntomas a establecer diagnósticos diferenciales de la enfermedad? (Si es necesario, consulte adjunto Compendio de enfermedades gastrointestinales agudas transmitidas por los alimentos)\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nNos ayuda porque:\n\nCada enfermedad transmitida por los alimentos tiene un período de incubación característico, síntomas específicos y alimentos con los que es más probable que esté asociada\nEl período de incubación observado es demasiado largo para los metales pesados y demasiado corto para los agentes virales y el botulismo\nLa intoxicación alimentaria estafilocócica tiene un período de incubación promedio de 2 a 4 horas\nEstos datos son insuficientes para saber cual puede ser el agente causal \n\n\n\n\n\n3.0.2.4 Pregunta 13: Usando los datos del listado, complete la tabla a continuación. ¿Cúal o cuales alimentos pudieron ser el vehículo más probable de infección?\n \nPara contestar esta pregunta, intente hacer los siguientes pasos usando R con el mismo script que creaste anteriormente:\n\nCree un objeto “data.frame” con el resumen de los alimentos ingeridos por los que enfermaron y otro con el resumen de los alimentos ingeridos por los que no enfermaron. Recodifique las variables para asignar el valor de 1 si fue consumido y 0 para no consumido.\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#Ve copiando el codigo a rstudio (este ejercicio es un poco largo)\n\npacman::p_load(janitor, gtsummary)\n\n\n#Comieron\n#hacer un dataframe con un resumen de los alimentos por los que enfermaron\ntotal_por_alimentos_casos_a &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no enfermo\")) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"enfermo\") %&gt;% \nslice_tail()\n\n#hacer un dataframe con un resumen de los alimentos por los que no enfermaron\ntotal_por_alimentos_no_casos_a &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no_enfermo\")) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"no_enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"no_enfermo\") %&gt;% \nslice_tail()\n\n\n\n\nUna los dos objectos “data.frame” y calcule la proporción de personas enfermas y no enfermas que consumieron cada alimento\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#Combinar ambos dataframes, transformarlo a formato extendido y calcular la proporción de los que consumieron\ntabla_maestra_a &lt;- bind_rows(total_por_alimentos_casos_a,\n                           total_por_alimentos_no_casos_a) %&gt;% \n  pivot_longer(2:ncol(.), names_to = \"alimentos\", values_to = \"n\") %&gt;% \n  pivot_wider(names_from = tipo_caso, values_from = n) %&gt;% \n  mutate(total=enfermo+no_enfermo,\n         ptc_enfermo=enfermo/total,\n         ptc_no_enfermo=no_enfermo/total)\n\n\n\n#Combinar ambos dataframes, transformarlo a formato extendido y calcular la proporción de los que no consumieron \ntabla_maestra_b &lt;- bind_rows(total_por_alimentos_casos_b,\n                           total_por_alimentos_no_casos_b) %&gt;% \n  pivot_longer(2:ncol(.), names_to = \"alimentos\", values_to = \"n\") %&gt;% \n  pivot_wider(names_from = tipo_caso, values_from = n) %&gt;% \n  mutate(total=enfermo+no_enfermo,\n         ptc_enfermo=enfermo/total,\n         ptc_no_enfermo=no_enfermo/total)\n\ntabla_final &lt;- tabla_maestra_a %&gt;% \n  left_join(tabla_maestra_b,suffix = c(\"_consumieron\", \"_no_consumieron\"), by=\"alimentos\") %&gt;% \n  mutate(tasa_ataque=ptc_enfermo_consumieron/ptc_enfermo_no_consumieron)\n\nView(tabla_final)\n\n\n\n\nCalcule una medida de asociación para estimar qué alimento se asoció en mayor medida a enfermar\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#otra forma.. para obtener los OR de cada alimento\n\n#crear un modelo de regresión logistica\nmodel &lt;- glm(data=listado, enfermo~m_jamon_horneado+\n            m_espinaca+m_pure_papa+m_ensa_repollo+\n            m_gelatina+m_rollos+m_pan+m_lehe+m_cafe+m_agua+\n            m_bizcocho+m_hel_vainilla+m_hel_chocolate+m_ens_fruta,\n            family=binomial())\n#Luego una tabla\ntbl_regression(model, exponentiate = TRUE)\n\ntest &lt;- listado %&gt;% \n  select(enfermo, starts_with(\"m_\")) %&gt;% \n  tbl_summary(by=enfermo)\n\n\n\n\nPara más detalles de como trabajar con transformación de datos y tablas, ver el capítulo 17 del libro de R para epidemiologos\n\n\n3.0.2.5 Pregunta 15: Resuma las investigaciones adicionales que deben llevarse a cabo.\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstas son las principales investigaciones adicionales que deben llevarse a cabo:\n\nRevisión detallada de la fuente, los ingredientes, la preparación y el almacenamiento de los alimentos incriminados\nIntentar explicar los casos con tiempo de inicio atípico\nSe podría hacer un examen de laboratorio\nDeterminar si se produjo una propagación secundaria en los miembros de la familia\nCálculos adicionales (p. ej., tasas de ataque específicas por edad o género) \n\n\n\n\n\n3.0.2.6 Pregunta 16: ¿Qué medidas de control sugeriría?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstas son las principales medidas de control y prevención en un brote de estas características:\n\nEvite el consumo del helado de vainilla restante\nPrevenga la recurrencia de eventos similares en el futuro educando a los manipuladores de alimentos\nSe podría hacer un examen de laboratorio\nDeterminar si se trata de un producto comercial\nEliminó cualquier fuente contaminada de alimentos\n\n\n\n\n\n\n3.0.2.7 Pregunta 17: ¿Por qué fue importante trabajar en este brote?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nTrabajar en este brote ayudó a:\n\nDescartar la contaminación de un producto comercial. Si se trata de un producto comercial, la intervención inmediata puede prevenir un número considerable de casos adicionales\nPrevenir futuros brotes mediante la identificación de manipuladores de alimentos infectados, lagunas específicas en la educación o técnicas de manipulación de alimentos\nLos funcionarios de salud pública deben responder a tales problemas de manera oportuna para mantener una relación de cooperación con los departamentos de salud locales, los médicos privados y la comunidad\nUna explicación epidemiológica de la causa del brote puede disipar los temores y preocupaciones de la comunidad\nLa investigación del brote puede brindar oportunidades para que los investigadores respondan preguntas sobre el agente, el huésped, el entorno, el período de incubación, etc.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLo siguiente se cita textualmente del informe preparado por el Dr. Rubin:\nEl helado fue preparado por el Petrie hermanas de la siguiente manera: En la tarde del 17 de abril la leche cruda de la La granja Petrie en Lycoming se desbordó al baño maría se le agrega azúcar y huevos y un poco de harina para darle cuerpo a la mezcla. El se prepararon helado de chocolate y vainilla por separado.\nEl chocolate de Hershey era necesariamente añadido a la mezcla de chocolate. A las 6 pm. los dos las mezclas se llevaban en recipientes tapados al sótano de la iglesia y se dejó reposar durante la noche. Presuntamente no fueron tocados por nadie. durante este período.\nEn la mañana del 18 de abril, el Sr. Coe agregó cinco onzas de vainilla y dos latas de leche condensada a la mezcla de vainilla y tres onzas de vainilla y una lata de leche condensada a la mezcla de chocolate. Luego el helado de vainilla se transfirió a un lata de congelación y se coloca en un congelador eléctrico durante 20 minutos, después de lo cual el helado de vainilla se sacó de la lata del congelador y se envasó en otra lata que había sido previamente lavado con agua hirviendo. Entonces el chocolate la mezcla se puso en la lata del congelador que había sido se enjuaga con agua del grifo y se deja congelardurante 20 minutos.”\nAl concluir esto, ambos las latas se taparon y se colocaron en grandes recipientes de madera recipientes llenos de hielo. Como señaló, el helado de chocolate permaneció en el una lata de congelador.\nTodos los manipuladores del helado fueron examinados. Sin lesiones externas ni respiratorias altas se notaron infecciones. Cultivos de nariz y garganta fueron tomados de dos individuos que prepararon el helado.\nLos exámenes bacteriológicos fueron hechos por el División de Laboratorios e Investigación, Albany, en ambos helados. Su informe es el siguiente:\n‘Un gran número de Staphylococcus aureus y albus se encontraron en la muestra de hielo de vainilla crema. Sólo unos pocos estafilococos fueron demostrado en el helado de chocolate.’\nInforme de los cultivos de nariz y garganta de Los Petries que prepararon el helado decía lo siguiente:\nPresencia de Staphylococcus aureus y hemolítica del cultivo nasal y Staphylococcus albus del cultivo faríngeo de Gracia Petrie. Tambien Staphylococcus albus del cultivo de la nariz de Marian Petrie. Los estreptococos hemolíticos no eran del tipo generalmente asociado con infecciones en el hombre.\nDiscusión sobre la fuente: la fuente de contaminación bacteriana del helado de vainilla no está claro. Cualquiera que sea el método de la introducción de los estafilococos, parece razonable suponer que debe haber ocurrido entre la tarde del 17 de abril y la mañana del 18 de abril. Sin motivo de contaminación Se conoce la peculiaridad del helado de vainilla. “Al dispensar los helados, la misma cuchara se utilizó. Por lo tanto, no es improbable suponer que alguna contaminación al helado de chocolate crema ocurrió de esta manera. Esto parecería ser la explicación más plausible para la enfermedad en los tres individuos que no comieron el helado de vainilla.\nMedidas de Control: El 19 de mayo, todo el helado restantes fue condenado. Todos los demás alimentos en el la cena de la iglesia había sido consumida.\nConclusiones: Un brote de gastroenteritis ocurrió después de una cena en la iglesia en Lycoming. La causa del brote fue helado de vainilla por contaminado. El método de contaminación de helado no se entiende claramente.\nSi el estafilococo dio positivo de la nariz y la garganta de los cultivos realizados en la familia Petrie haba todo lo que tenga que ver con la contaminación es un asunto por nexo epidemiológico.\nNota: El paciente #52 era un niño que mientras viendo el procedimiento de congelación se le dio una plato de helado de vainilla a las 11:00 am en abril 18."
  },
  {
    "objectID": "webexercises.html#example-questions",
    "href": "webexercises.html#example-questions",
    "title": "4  Webexercises",
    "section": "4.1 Example Questions",
    "text": "4.1 Example Questions\n\n4.1.1 Fill-In-The-Blanks (fitb())\nCreate fill-in-the-blank questions using fitb(), providing the answer as the first argument.\n\n2 + 2 is \n\nYou can also create these questions dynamically, using variables from your R session.\n\nThe square root of 9 is: \n\nThe blanks are case-sensitive; if you don’t care about case, use the argument ignore_case = TRUE.\n\nWhat is the letter after D? \n\nIf you want to ignore differences in whitespace use, use the argument ignore_ws = TRUE (which is the default) and include spaces in your answer anywhere they could be acceptable.\n\nHow do you load the tidyverse package? \n\nYou can set more than one possible correct answer by setting the answers as a vector.\n\nType a vowel: \n\nYou can use regular expressions to test answers against more complex rules.\n\nType any 3 letters: \n\n\n\n4.1.2 Multiple Choice (mcq())\n\n“Never gonna give you up, never gonna: let you goturn you downrun awaylet you down”\n“I bless the rainsguess it rainssense the rain down in Africa” -Toto\n\n\n\n4.1.3 True or False (torf())\n\nTrue or False? You can permute values in a vector using sample(). TRUEFALSE\n\n\n\n4.1.4 Longer MCQs (longmcq())\nWhen your answers are very long, sometimes a drop-down select box gets formatted oddly. You can use longmcq() to deal with this. Since the answers are long, It’s probably best to set up the options inside an R chunk with echo=FALSE.\nWhat is a p-value?\n\n the probability that the null hypothesis is true the probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is true the probability of making an error in your conclusion\n\nWhat is true about a 95% confidence interval of the mean?\n\n 95% of the data fall within this range if you repeated the process many times, 95% of intervals calculated in this way contain the true mean there is a 95% probability that the true mean lies within this range"
  },
  {
    "objectID": "webexercises.html#checked-sections",
    "href": "webexercises.html#checked-sections",
    "title": "4  Webexercises",
    "section": "4.2 Checked sections",
    "text": "4.2 Checked sections\nCreate sections with the class webex-check to add a button that hides feedback until it is pressed. Add the class webex-box to draw a box around the section (or use your own styles).\n\nI am going to learn a lot: TRUEFALSE\nWhat is a p-value?\n\n the probability that the null hypothesis is true the probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is true the probability of making an error in your conclusion"
  },
  {
    "objectID": "webexercises.html#hidden-solutions-and-hints",
    "href": "webexercises.html#hidden-solutions-and-hints",
    "title": "4  Webexercises",
    "section": "4.3 Hidden solutions and hints",
    "text": "4.3 Hidden solutions and hints\nYou can fence off a solution area that will be hidden behind a button using hide() before the solution and unhide() after, each as inline R code. Pass the text you want to appear on the button to the hide() function.\nIf the solution is a code chunk, instead of using hide() and unhide(), simply set the webex.hide chunk option to TRUE, or set it to the string you wish to display on the button.\nRecreate the scatterplot below, using the built-in cars dataset.\n\n\n\n\n\n\n\nI need a hint\n\nSee the documentation for plot() (?plot)\n\n\n\n\n\nClick here to see the solution\n\nplot(cars$speed, cars$dist)"
  },
  {
    "objectID": "oswego-es.html#feedback-suggestions",
    "href": "oswego-es.html#feedback-suggestions",
    "title": "3  Oswego (ES)",
    "section": "Feedback & suggestions",
    "text": "Feedback & suggestions\n\nYou can write feedback and suggestions on this case study at the GitHub issues page\nAlternatively email us at: contact@appliedepi.org"
  },
  {
    "objectID": "oswego-es.html#version-1",
    "href": "oswego-es.html#version-1",
    "title": "3  Oswego (ES)",
    "section": "Version 1",
    "text": "Version 1\n16 November 2023"
  },
  {
    "objectID": "oswego-es.html#disclaimer",
    "href": "oswego-es.html#disclaimer",
    "title": "3  Oswego (ES)",
    "section": "Disclaimer",
    "text": "Disclaimer\nEsto es un estudio de caso diseñado por el Centre for Disease Prevention and Control (CDC) como tutorial de Epi Info. Puede consultar más detalles en este Enlace"
  },
  {
    "objectID": "oswego-es.html#revisions",
    "href": "oswego-es.html#revisions",
    "title": "3  Oswego (ES)",
    "section": "Revisions",
    "text": "Revisions\n\n\n\nDate\nChanges made\nVersion\n\n\n\n\n16 November\nAdapted to template\n1"
  },
  {
    "objectID": "oswego-es.html#guía",
    "href": "oswego-es.html#guía",
    "title": "3  Oswego (ES)",
    "section": "Guía",
    "text": "Guía"
  },
  {
    "objectID": "oswego-es.html#objetivos-de-este-estudio-de-caso",
    "href": "oswego-es.html#objetivos-de-este-estudio-de-caso",
    "title": "3  Oswego (ES)",
    "section": "Objetivos de este estudio de caso",
    "text": "Objetivos de este estudio de caso\nLos objetivos de este estudio de caso son:\n\nEntender los diferentes pasos en la investigación de un brote de casos de enfermedad gastrointestinal\nAdquirir confianza en el manejo de datos de un listado nominal con el software estadístico R\nAdquirir experience en el análisis descriptivo en R, particularmente curvas epidémicas\nAdquirir experience construyendo tablas 2x2 con exposición y desenlace que nos permitan calcular medidas de asociación\nAplicar los conocimientos adquiridos a posibles actividades de control y prevención de brotes infecciosos de origen alimentario\n\n\nConocimientos previos asumidos\nEn este estudio de caso se asume un conocimiento básico de los principios fundamental de la investigación epidemiológica de brotes gastrointestinales. Se asume también un conocimiento básico de R.\n\n\nPreparation for the case study\nAntes de iniciar este estudio de caso, le aconsejamos que:\n\nDescargue en su computadora la carpeta “oswego_cs_es” y que extraiga todos sus componentes, preferibilmente en su escritorio o en un lugar de fácil acceso. Evite extraerlo en servicios de nube o “drives”\n\nDentro de la carpeta, encontrará un proyecto de R llamado “oswego_cs”. Es un archivo de tipo “R project” y debe siempre asegurarse que está trabajando en RStudio desde el proyecto. La forma más fácil es que habra RStudio cada vez a través de abrir este archivo.\nDentro de la carpeta “oswego_cs_es” encontrará una subcarpeta llamada data en el que encontrará todos los datos necesarios para realizar el análisis en un file llamado “oswego.xlsx”.\nDeberá crear un script dentro de la carpeta scripts en el que usted escribe el código para el análisis. Puede utilizar el script que ya está presente llamado “01_oswego_sol” que contiene el código de análisis si se encuentra atascado o si quiere comparar el código que usted realiza con la solución.\nEn la subcarpeta outputs encontrará todos los gráficos y tablas generadas en el anlálisis.\n\n\nPrimera parte - AntecedentesSegunda parte - El EventoTercera parte - AnálisisCuarta Parte - Conclusión\n\n\n\n\n\n\n\nEl 19 de abril de 1940, el oficial de salud local en el pueblo de Lycoming, condado de Oswego, Nueva York, informó de la ocurrencia de un brote de enfermedad gastrointestinal al Distrito de Salud Oficial en Siracusa. Dr. A. M. Rubin, epidemiólogo en formación, fue asignado para investigar lo ocurrido.\nCuando el Dr. Rubin llegó al campo, determinó a través del oficial de salud que todas las personas que enfermaron había asistido a una cena en la iglesia celebrada la noche anterior, 18 de abril. Otra información importante fue que los familiares que no asistieron a la cena, no enfermaron.\nEn consecuencia, el Dr. Rubin centró la investigación sobre lo ocurrido en la cena. Pudo completar 75 entrevistas de las 80 personas conocidas que asistieron a la cena, recopilando información sobre los ocurrencia y tiempo de aparición de los síntomas, y alimentos consumidos. de las 75 personas entrevistados, 46 personas presentaron síntomas de enfermedad gastrointestinal.\n\nPregunta 1\n\n¿Ante que tipo de situación está presente el Dr Rubin?\n\n Una epidemia Una serie de casos Un brote No se puede establecer\n\n\n\n\n\n Click para leer una pista\n\n\nPuede utilizar este glosario preparado por el Gobierno de México para encontrar la definición que se ajusta más a la situación descrita Enlace \n\n\n\nClick para ver la explicación (¡Inténtelo usted primero!)\n\n\nNumero 1 - No es la respuesta correcta; revisa el concepto de epidemia, tiene que ver con la cantidad de personas afectadas.\nNumero 2 - Es posible, pero también debes tomar en cuenta otros factores, como el hecho de que los casos tienen una relación epidemiológica entre ellos.\nNumero 4 - No te preocupes, en este tutorial vas a poder aprender los pasos del trabajo de campo.\n\n\n\n\nPregunta 2\n\nLos pasos de una investigación de brote son:\n\n Determinar la existencia del brote, análisis descriptivo, generar hipótesis, confirmar hipótesis, controlar brote, conclusiones y recomendaciones, informe final Una serie de casos Determinar la existencia del brote, confirmar diagnóstico, contar casos, análisis descriptivo, determinar quién está a riesgo de enfermar, desarrollar hipótesis, confirmar hipótesis, controlar brote, conclusiones y recomendaciones, informe final Determinar la existencia del brote, confirmar el diagnóstico, controlar brote, comunicar brote, generar hipótesis, confirmar hipótesis, controlar brote, conclusiones y recomendaciones, informe final\n\n\n\n\nClick para ver la explicación (¡Inténtelo usted primero!)\n\n\nPuede utilizar el sitio de la OPS para profundizar sobre el tema Enlace\n\n\n\n\nDescripción clínicade los casos\nEl inicio de la enfermedad en todos los casos fue agudo, caracterizada principalmente por náuseas, vómitos, diarrea y dolor abdominal. Ninguno de los enfermos personas reportaron tener un nivel elevado temperatura; todos se recuperaron dentro de las 24 a 30 horas.\nAproximadamente el 20% de los enfermos que visitaron al médico no se les realizó examen de muestras fecales para el examen bacteriológico.\n\nPregunta 3\nEnumere una de las grandes categorías de agentes causales de enfermedades que se deben considerar en el diagnóstico diferencial de un brote de enfermedad gastrointestinal como el de Oswego:\n\n\n\n\nClick para ver la explicación de la solución (¡Inténtelo usted primero!)\n\n\n\nBacterias\nVirus\nParásitos\nToxinas\n\nPuede utilizar el sitio de la OPS para profundizar sobre el tema Enlace\n\n\n\nLos investigadores en Oswego, desconocen el agente causal, pero sospechan de que la génesis de este brote fue través de los alimentos como vehiculo de transmisión entre los afectados.\n\n\nPregunta 4\nEn lenguaje epidemiológico, ¿Qué es un vehículo? ¿Qué es un vector? ¿Cuáles son otros modos?\nPiense en estos conceptos y cuando esté listo, vea la solución propuesta\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEn la jerga epidemiológica, un ‘vehículo’ es un objeto o sustancia inanimada que puede transportar un patógeno y transmitirlo a un huésped susceptible. Ejemplos de vehículos incluyen alimentos o agua contaminados, fómites (objetos inanimados como pomos de puertas o ropa) o partículas transportadas por el aire. En este contexto, un vehículo no es un modo de transporte, sino más bien un medio de transmisión de un agente infeccioso. Por otro lado, un ‘vector’ es un objeto animado, generalmente un artrópodo como un mosquito, una garrapata o una pulga, que puede transportar un agente infeccioso desde un huésped infectado a un huésped susceptible. El vector puede transmitir el patógeno directamente a través de su picadura o indirectamente al depositar el patógeno en una superficie o en una fuente de alimentos o agua. Los otros modos de transmisión de agentes infecciosos incluyen el contacto persona a persona, ya sea directamente a través del contacto físico, como el tacto o el beso, o indirectamente a través de gotas generadas durante la tos o el estornudo, o mediante transmisión aérea en espacios cerrados. Además, algunos agentes infecciosos pueden ser transmitidos a través del contacto sexual, la transmisión perinatal de la madre al hijo o mediante la exposición a fluidos corporales, como la sangre o el semen. Los factores ambientales, como la mala higiene, el hacinamiento o la exposición a animales, también pueden desempeñar un papel en la transmisión de ciertos agentes infecciosos.\n\n\n\nEl Dr. Rubin decidió administrar un cuestionario a los participantes de la cena de la iglesia para averiguar qué alimento podía estar asociado al desarrollo de los síntomas\n\n\nPregunta 5\nSi fuese usted el que administra el cuestionario, ¿qué información recopilaría? Agrupa la información en categorías. Una vez que haya escrito sus categorías, puede ver abajo la solución.\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstos son algunos de los campos que normalmente se includirían en un cuestionario en un brote similar:\n\nInformación demográfica\nInformaión clínica\nDatos de laboratorio si disponibles\nFactores de riesgo (exposición): Alimentos y bebidas ingeridas durante la cena\n\n\n\n\nAdemás de decidir la información que quería recolectar, el Dr. Rubin decidió recolectó los datos entrevistados a través de un listado nominal.\n\n\nPregunta 6\n\n¿En que NO nos ayuda un listado nominal?\n\n Organizar los datos y describirlos por tiempo, lugar y persona Clasificar a los individuos como casos, no casos y sospechosos A diagnosticar a los pacientes A manejar un documento dinámico que se puede actualizar constantemente\n\n\nPor favor, continue el caso entrando en la pestaña “Segunda parte - El Evento” en la parte superior\n\n\n\n\n\nDescripción de la Cena\nLa investigación del Dr. Rubin también implicó averiguar más detalles sobre la cena. Después de hablar con los organizadores, descubrió que la cena se celebró en el sótano del iglesia del pueblo. Los alimentos fueron aportados por numerosos miembros de la congregación. La cena comenzaba a las 6:00 p.m. y continuó hasta 11.00 pm.\nLa comida estaba esparcida sobre una mesa y fue consumida durante un período de varias horas. Los datos sobre el inicio de la enfermedad y los alimentos consumidos por cada una de las 75 personas entrevistados se proporcionan en la listado adjunto.\nLa hora aproximada de participación en el evento solo se recolectó aproximadamente la mitad de las personas que tuvo una enfermedad gastrointestinal.\n\nPregunta 7\n¿Cuál es el valor de una curva epidémica en la investigación de un brote?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstas son algunos de los usos de las curvas epidémicas cuando se investigan brotes:\n\nNos permite ver la evolución en el tiempo de un evento forma rápida\nAporta información para tomar decisiones para medidas de control\nAyuda a revelar patrones y tendencias sobre un evento\n\n\n\n\n\n\nPregunta 8\n¿Qué nos dice el siguiente gráfico?\n\n\n\n\n\n\n\n\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nLa curva epidémica nos dice que:\n\nTodos los casos ocurrieron antes de las 10am del día siguiente (19 de abril)\nDesde la 11pm del 18 a las 3am del 19 de abril ocurrieron la mayoría de los casos\nNos muestra la magnitud del evento y como se propaga, así como ver valores extremos\n\n\n\n\n\n\nPregunta 9\n¿Hay algún caso en el que los tiempos de inicio no coincidan con los generales? ¿experiencia? ¿Cómo podrían explicarse?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nConsidere que: - Hay casos que la hora de inicio de signos y sintomas fueron antes de la cena, pudo ser que se contaminara antes durante los preparativos - Un caso ocurrió 17 horas después de la cena, posiblemente es alguien que comió más tarde o que la infomación es incorrecta (otra enfermedad parecida) o un caso secundario\n\n\n\n\n\n\n3.0.1 Listado nominal de individuos del brote de gastroenteritis, Oswego, Nueva York, 1940\n\n\n\n\n\n\n\nPregunta 10\n¿Cómo podrían presentarse mejor los datos en el listado nominal de participantes?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nDos ideas, aunque puede haber más son:\n\nLos datos pudieron ser separados de acuerdo al estatus de enfermedad y tiempo de inicio de sintomas\nSi se hubiese usado el formato del en tiempo militar, (ej. 00:00 o 14:00)\n\n\n\n\n\n\n3.0.1.1 Versión digital\n\n\n\n\n\n3.0.2 Apoyo en análisis de los datos\n\n\n\nAhora vamos a comenzar con uno de los pasos más importantes en la investigación de brote, el análisis de los datos donde a través de este vamos a determinar cual o cuales son las posibles causas del brote, medidas a tomar entre otros pasos. ¡También vamos a usar un poco de R para ayudar con este proceso de análisis!.\n\n3.0.2.1 Siempre que sea posible, utilizando el listado nominal actualizado, calcule los períodos de incubación e ilustre su distribución con un gráfico apropiado.\n \nPara contestar esta pregunta, vamos hacer los siguientes pasos usando R:\n \n\nen Rstudio, crea un nuevo script para cargar los datos (cargar el archivo “oswego.xlsx”, que está en la carpeta data) y explore las dos columnas que contienen la información necesaria para calcular los períodos de incubación: TimeSupper (hora de la cena) y DateOnset (Fecha inizio síntomas)\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#Cargar los paquetes necesarios\npacman::p_load(rio,\n               here,\n               tidyverse, \n               epitools, \n               lubridate,\n               DT)\n\n#Importar los datos\nlistado &lt;- import(here(\"case_studies\", \"ESP\", \"oswego_cs_es\", \"data\", \"oswego.xlsx\"))\n\n#Explorar las variables de la fecha y hora del almuerzo\nhead(oswego_db$TimeSupper)\n\n[1] NA                        NA                       \n[3] NA                        \"1940-04-18 22:00:00 UTC\"\n[5] \"1940-04-18 19:30:00 UTC\" \"1940-04-18 19:30:00 UTC\"\n\nhead(oswego_db$DateOnset)\n\n[1] \"1940-04-18 23:00:00 UTC\" NA                       \n[3] \"1940-04-18 22:30:00 UTC\" \"1940-04-19 01:00:00 UTC\"\n[5] \"1940-04-19 02:30:00 UTC\" \"1940-04-18 23:30:00 UTC\"\n\n\n\n\n\nPara referencia sobre como importar archivos, ver el capítulo 7 del libro de R para epidemiologos\n \n\nEl listado cargado ya tiene el formato correcto de la fecha y hora de almuerzo y la fecha y hora de inicio de síntomas ahora intente crear un código para crear una nueva variable con los periodos de incubación para cada caso. (recuerda que con las variables de tiempo en R se pueden hacer operaciones matemáticas)\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n# Crear la variable del período de incubación\n# puedes copiar este código en rstudio en tu editor de códigos\n#las funciones \"interval\" y \"dhours()\" son las que usaremos para calcular la diferencia en hora\n\nlistado_incubacion &lt;- listado %&gt;%\n  \n  mutate(incubacion=interval(TimeSupper, DateOnset) / dhours(1)) \n\n\n\n\nPara más detalles de como trabajar con fechas, ver el capítulo 9 del libro de R para epidemiologos\n \n\nAhora intente hacer un gráfico de barras con el período de incubación usando ggplot para visualizar la distribución. Puede encontrar pistas sobre como hacer un gráfico de barras en la sección dedicada del EpiRhandbook\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n# Hacer un gráfico de barra de los periodos de incubación calculados\n# puedes copiar este código en rstudio en tu editor de códigos\n\nlistado_incubacion %&gt;% \n  \n  ggplot(aes(x=incubacion))+\n  \n  geom_bar()+\n  \n  labs(title=\"Casos de enfermedad gastrointestinal por período de incubación en horas\",\n       subtitle = \"Oswego, NY, 18-19 de abril, 1940\",\n       x=\"Período de incubación (Horas)\",\n       y=\"n de casos\")+\n  \n  theme_minimal()\n\nWarning: Removed 53 rows containing non-finite values (`stat_count()`).\n\n\n\n\n#Si quieres asignar este gráfico a un objeto, solo tienes que en la primera línea del código \n#usar un nombre (como grafico1) y escribir el signo de asignación (&lt;-)\n\n\n\n\nPara más detalles de como trabajar con gráficos en general, ver el capítulo 30 del libro de R para epidemiologos\n \n\n\nPregunta 10: ¿Cuantos casos tenian el dato de incubación?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n22\nPara saberlo, puedes verificar viendo el listado directamente o con el siguiente código\n\n\n\n\n\n3.0.2.2 Pregunta 11: Determine el rango y la mediana del período de incubación\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n Para ejecutar esto en R hay varias formas, usando ya sea las funciones base o de otros paquetes. Aquí tiene un ejemplo usando el paquete {dplyr} que viene integrado en el paquete {tidyverse}\n\n# Calcular el rango, la mediana y el periodo de incubacion\n# puedes copiar este código en rstudio en tu editor de códigos\n\nresumen_estadistico &lt;- listado_incubacion %&gt;% \n  filter(!is.na(incubacion)) %&gt;% \n  reframe(mediana=median(incubacion),\n          min=min(incubacion),\n          max=max(incubacion),\n          rango=max-min)\n\nresumen_estadistico\n\n  mediana min max rango\n1       4   3   7     4\n\n\nLa mediana del periodo de incubación fue 4 horas, así como el rango del periodo del periodo de incubación también fue de 4 horas\n\n\n\n\n\n3.0.2.3 Pregunta 12: ¿Cómo ayuda la información sobre el período de incubación y los datos sobre síntomas a establecer diagnósticos diferenciales de la enfermedad? (Si es necesario, consulte adjunto Compendio de enfermedades gastrointestinales agudas transmitidas por los alimentos)\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nNos ayuda porque:\n\nCada enfermedad transmitida por los alimentos tiene un período de incubación característico, síntomas específicos y alimentos con los que es más probable que esté asociada\nEl período de incubación observado es demasiado largo para los metales pesados y demasiado corto para los agentes virales y el botulismo\nLa intoxicación alimentaria estafilocócica tiene un período de incubación promedio de 2 a 4 horas\nEstos datos son insuficientes para saber cual puede ser el agente causal \n\n\n\n\n\n3.0.2.4 Pregunta 13: Usando los datos del listado, complete la tabla a continuación. ¿Cúal o cuales alimentos pudieron ser el vehículo más probable de infección?\n \nPara contestar esta pregunta, intente hacer los siguientes pasos usando R con el mismo script que creaste anteriormente:\n\nCree un objeto “data.frame” con el resumen de los alimentos ingeridos por los que enfermaron y otro con el resumen de los alimentos ingeridos por los que no enfermaron. Recodifique las variables para asignar el valor de 1 si fue consumido y 0 para no consumido.\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#Ve copiando el codigo a rstudio (este ejercicio es un poco largo)\n\npacman::p_load(janitor, gtsummary)\n\n\n#Comieron\n#hacer un dataframe con un resumen de los alimentos por los que enfermaron\ntotal_por_alimentos_casos_a &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no enfermo\")) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"enfermo\") %&gt;% \nslice_tail()\n\n#hacer un dataframe con un resumen de los alimentos por los que no enfermaron\ntotal_por_alimentos_no_casos_a &lt;- listado %&gt;% \n  mutate(tipo_caso=case_when(enfermo==1~\"enfermo\",\n                        TRUE~\"no_enfermo\")) %&gt;% \n  select(tipo_caso, starts_with(\"m_\")) %&gt;% \n  filter(tipo_caso==\"no_enfermo\") %&gt;% \nadorn_totals(\"row\", name = \"no_enfermo\") %&gt;% \nslice_tail()\n\n\n\n\nUna los dos objectos “data.frame” y calcule la proporción de personas enfermas y no enfermas que consumieron cada alimento\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#Combinar ambos dataframes, transformarlo a formato extendido y calcular la proporción de los que consumieron\ntabla_maestra_a &lt;- bind_rows(total_por_alimentos_casos_a,\n                           total_por_alimentos_no_casos_a) %&gt;% \n  pivot_longer(2:ncol(.), names_to = \"alimentos\", values_to = \"n\") %&gt;% \n  pivot_wider(names_from = tipo_caso, values_from = n) %&gt;% \n  mutate(total=enfermo+no_enfermo,\n         ptc_enfermo=enfermo/total,\n         ptc_no_enfermo=no_enfermo/total)\n\n\n\n#Combinar ambos dataframes, transformarlo a formato extendido y calcular la proporción de los que no consumieron \ntabla_maestra_b &lt;- bind_rows(total_por_alimentos_casos_b,\n                           total_por_alimentos_no_casos_b) %&gt;% \n  pivot_longer(2:ncol(.), names_to = \"alimentos\", values_to = \"n\") %&gt;% \n  pivot_wider(names_from = tipo_caso, values_from = n) %&gt;% \n  mutate(total=enfermo+no_enfermo,\n         ptc_enfermo=enfermo/total,\n         ptc_no_enfermo=no_enfermo/total)\n\ntabla_final &lt;- tabla_maestra_a %&gt;% \n  left_join(tabla_maestra_b,suffix = c(\"_consumieron\", \"_no_consumieron\"), by=\"alimentos\") %&gt;% \n  mutate(tasa_ataque=ptc_enfermo_consumieron/ptc_enfermo_no_consumieron)\n\nView(tabla_final)\n\n\n\n\nCalcule una medida de asociación para estimar qué alimento se asoció en mayor medida a enfermar\n\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\n\n#otra forma.. para obtener los OR de cada alimento\n\n#crear un modelo de regresión logistica\nmodel &lt;- glm(data=listado, enfermo~m_jamon_horneado+\n            m_espinaca+m_pure_papa+m_ensa_repollo+\n            m_gelatina+m_rollos+m_pan+m_lehe+m_cafe+m_agua+\n            m_bizcocho+m_hel_vainilla+m_hel_chocolate+m_ens_fruta,\n            family=binomial())\n#Luego una tabla\ntbl_regression(model, exponentiate = TRUE)\n\ntest &lt;- listado %&gt;% \n  select(enfermo, starts_with(\"m_\")) %&gt;% \n  tbl_summary(by=enfermo)\n\n\n\n\nPara más detalles de como trabajar con transformación de datos y tablas, ver el capítulo 17 del libro de R para epidemiologos\n\n\n3.0.2.5 Pregunta 15: Resuma las investigaciones adicionales que deben llevarse a cabo.\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstas son las principales investigaciones adicionales que deben llevarse a cabo:\n\nRevisión detallada de la fuente, los ingredientes, la preparación y el almacenamiento de los alimentos incriminados\nIntentar explicar los casos con tiempo de inicio atípico\nSe podría hacer un examen de laboratorio\nDeterminar si se produjo una propagación secundaria en los miembros de la familia\nCálculos adicionales (p. ej., tasas de ataque específicas por edad o género) \n\n\n\n\n\n3.0.2.6 Pregunta 16: ¿Qué medidas de control sugeriría?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nEstas son las principales medidas de control y prevención en un brote de estas características:\n\nEvite el consumo del helado de vainilla restante\nPrevenga la recurrencia de eventos similares en el futuro educando a los manipuladores de alimentos\nSe podría hacer un examen de laboratorio\nDeterminar si se trata de un producto comercial\nEliminó cualquier fuente contaminada de alimentos\n\n\n\n\n\n\n3.0.2.7 Pregunta 17: ¿Por qué fue importante trabajar en este brote?\n\n\n\nClick para ver la solución (¡Inténtelo usted primero!)\n\n\nTrabajar en este brote ayudó a:\n\nDescartar la contaminación de un producto comercial. Si se trata de un producto comercial, la intervención inmediata puede prevenir un número considerable de casos adicionales\nPrevenir futuros brotes mediante la identificación de manipuladores de alimentos infectados, lagunas específicas en la educación o técnicas de manipulación de alimentos\nLos funcionarios de salud pública deben responder a tales problemas de manera oportuna para mantener una relación de cooperación con los departamentos de salud locales, los médicos privados y la comunidad\nUna explicación epidemiológica de la causa del brote puede disipar los temores y preocupaciones de la comunidad\nLa investigación del brote puede brindar oportunidades para que los investigadores respondan preguntas sobre el agente, el huésped, el entorno, el período de incubación, etc.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLo siguiente se cita textualmente del informe preparado por el Dr. Rubin:\nEl helado fue preparado por el Petrie hermanas de la siguiente manera: En la tarde del 17 de abril la leche cruda de la La granja Petrie en Lycoming se desbordó al baño maría se le agrega azúcar y huevos y un poco de harina para darle cuerpo a la mezcla. El se prepararon helado de chocolate y vainilla por separado.\nEl chocolate de Hershey era necesariamente añadido a la mezcla de chocolate. A las 6 pm. los dos las mezclas se llevaban en recipientes tapados al sótano de la iglesia y se dejó reposar durante la noche. Presuntamente no fueron tocados por nadie. durante este período.\nEn la mañana del 18 de abril, el Sr. Coe agregó cinco onzas de vainilla y dos latas de leche condensada a la mezcla de vainilla y tres onzas de vainilla y una lata de leche condensada a la mezcla de chocolate. Luego el helado de vainilla se transfirió a un lata de congelación y se coloca en un congelador eléctrico durante 20 minutos, después de lo cual el helado de vainilla se sacó de la lata del congelador y se envasó en otra lata que había sido previamente lavado con agua hirviendo. Entonces el chocolate la mezcla se puso en la lata del congelador que había sido se enjuaga con agua del grifo y se deja congelardurante 20 minutos.”\nAl concluir esto, ambos las latas se taparon y se colocaron en grandes recipientes de madera recipientes llenos de hielo. Como señaló, el helado de chocolate permaneció en el una lata de congelador.\nTodos los manipuladores del helado fueron examinados. Sin lesiones externas ni respiratorias altas se notaron infecciones. Cultivos de nariz y garganta fueron tomados de dos individuos que prepararon el helado.\nLos exámenes bacteriológicos fueron hechos por el División de Laboratorios e Investigación, Albany, en ambos helados. Su informe es el siguiente:\n‘Un gran número de Staphylococcus aureus y albus se encontraron en la muestra de hielo de vainilla crema. Sólo unos pocos estafilococos fueron demostrado en el helado de chocolate.’\nInforme de los cultivos de nariz y garganta de Los Petries que prepararon el helado decía lo siguiente:\nPresencia de Staphylococcus aureus y hemolítica del cultivo nasal y Staphylococcus albus del cultivo faríngeo de Gracia Petrie. Tambien Staphylococcus albus del cultivo de la nariz de Marian Petrie. Los estreptococos hemolíticos no eran del tipo generalmente asociado con infecciones en el hombre.\nDiscusión sobre la fuente: la fuente de contaminación bacteriana del helado de vainilla no está claro. Cualquiera que sea el método de la introducción de los estafilococos, parece razonable suponer que debe haber ocurrido entre la tarde del 17 de abril y la mañana del 18 de abril. Sin motivo de contaminación Se conoce la peculiaridad del helado de vainilla. “Al dispensar los helados, la misma cuchara se utilizó. Por lo tanto, no es improbable suponer que alguna contaminación al helado de chocolate crema ocurrió de esta manera. Esto parecería ser la explicación más plausible para la enfermedad en los tres individuos que no comieron el helado de vainilla.\nMedidas de Control: El 19 de mayo, todo el helado restantes fue condenado. Todos los demás alimentos en el la cena de la iglesia había sido consumida.\nConclusiones: Un brote de gastroenteritis ocurrió después de una cena en la iglesia en Lycoming. La causa del brote fue helado de vainilla por contaminado. El método de contaminación de helado no se entiende claramente.\nSi el estafilococo dio positivo de la nariz y la garganta de los cultivos realizados en la familia Petrie haba todo lo que tenga que ver con la contaminación es un asunto por nexo epidemiológico.\nNota: El paciente #52 era un niño que mientras viendo el procedimiento de congelación se le dio una plato de helado de vainilla a las 11:00 am en abril 18."
  },
  {
    "objectID": "fulton-en.html#step-1-installload-packages",
    "href": "fulton-en.html#step-1-installload-packages",
    "title": "2  Fulton (EN)",
    "section": "Step 1: Install/load packages",
    "text": "Step 1: Install/load packages\nInstall the following packages that will be needed to carry out the analysis: officedown, officer, rio, here, skimr, janitor, lubridate, epikit, tidyverse, flextable, sf, scales, gtsummary, labelled, ggspatial, patchwork, apyramid and incidence2.\n\n\nClick to see a solution (try it yourself first!)\n\n\n\nSys.setlocale(\"LC_ALL\", \"English\")\n\n# hide all code chunks in the output, but show errors \nknitr::opts_chunk$set(echo = FALSE,  # hide all code chunks in output\n                      error = TRUE,  # show errors if they appear, but don't stop (produce the word doc)\n                      warning = FALSE, # do not show warnings in the output word doc \n                      message = FALSE, # do not show  messages in the output word doc\n                      fig.width = 7,         # Figure width\n                      fig.height = 6,        # Figure height\n                      fig.topcaption = TRUE  # show figure titles on top of plot\n                     )\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) {\n     install.packages(\"pacman\") }\n\n# install (if necessary) from CRAN and load packages to be used\npacman::p_load(\n  officedown, # format MS word document output\n  officer,    # add table of contents to output\n  rio,        # importing data  \n  here,       # relative file pathways \n  skimr,      # get overview of data\n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # age_categories() function\n  flextable,  # converting tables to pretty images\n  sf,         # manage spatial data using a Simple Feature format\n  scales,     # define colour schemes for flextables \n  gtsummary,  # summary statistics, tests and regressions \n  labelled,   # create variable labels to be displayed in table outputs\n  ggspatial,  # basemaps and scalebars \n  patchwork,  # combining multiple ggplots \n  apyramid,   # plotting age pyramids \n  tidyverse  # data management and visualization\n\n)"
  },
  {
    "objectID": "fulton-en.html#step-2-data-import",
    "href": "fulton-en.html#step-2-data-import",
    "title": "2  Fulton (EN)",
    "section": "Step 2: Data import",
    "text": "Step 2: Data import\n\nImport the COVID-19 linelist called covid_example_data.xlsx that can be found in the following path: data/covid_example_data/.\nImport also the shapefile named FultonCountyZipCodes.shp found in data/covid_example_data/covid_shapefile/ needed to retrieve the population in Fulton County.\nExplore the linelist to understand better the data.\n\n\nQuestion 2.1: How many rows are present in linelist_raw?\n\n 48 31 82101 5\n\nQuestion 2.2: How many columns are of class numeric?\n\n 8 4 19 31\n\n\n\n\nClick to see a solution code (try it yourself first!)\n\n\n\n##############        IMPORTING DATA     ##############        \n\n# We use the {rio} package for importing our example data - it is very versatile \n# and can read in most file types. \n# \n# We use the {here} package for defining the path to our file. This is important \n# for sharing your script with others (by email or on Sharepoint) - if you used an\n# \"absolute\" path, they would need to update the script to match their computer. \n# \n# This way your whole R-project folder can be zipped up and moved somewhere else. \n# \n# For more details see: \n# https://epirhandbook.com/import-and-export.html\n\n  \n  #import the raw case data set\n  # define the path using {here} then pass that to the {rio} import function\n  # specify the sheet to read using which (default is to read first sheet)\nlinelist_raw &lt;- rio::import(\n  file = here::here(\"data\", \"fulton-en\", \"covid_example_data\", \"covid_example_data.xlsx\"),\n  which = \"in\"\n)\n\n# import shapefile\n  # for extracting population counts for zipcodes and mapping\nshapefile &lt;- read_sf(\n  here::here(\"data\", \"fulton-en\", \"covid_example_data\", \"covid_shapefile\", \"FultonCountyZipCodes.shp\")\n)\n\n##############        EXPLORING THE DATA     ##############        \n\n# Here we take a look at the raw data to get a feel for what needs cleaning. \n# \n# We first use the in-built browser with the {base} function View(). \n# \n# Then we can use the {base} function summary(), but probably the most comprehensive \n# overview is with the {skimr} function. \n# You can also view distinct values for variables using the {base} unique() function. \n# \n# For more details see: \n# https://epirhandbook.com/cleaning-data-and-core-functions.html#review\n# https://epirhandbook.com/descriptive-tables.html#browse-data\n\n# view your whole dataset interactively (in an excel style format)\nView(linelist_raw)\n\n# get summary: \n# mean, median and max values of numeric variables\n# counts for categorical variables\n# also gives number of NAs\nsummary(linelist_raw)\n\n# get information about each variable in a dataset \n# nb. “POSIXct” is a type of raw date class \nskim(linelist_raw)\n\n# view unique values contained in variables - useful for categorical variables\n# you can run this for any column -- just replace the column name\nunique(linelist_raw$case_gender) \n\n\n# we can also loop through all categorical variables to look at all possibilities\n# see later in the script for introductions to using iteration\npurrr::map(\n  # all column names (inputs)\n  .x = linelist_raw %&gt;% \n    select(where(is_character)) %&gt;% \n    names(), \n  # applies select() then unique() to each column\n  .f = ~select(linelist_raw, .x) %&gt;% \n    unique()\n  )"
  },
  {
    "objectID": "fulton-en.html#step-3-data-cleaning",
    "href": "fulton-en.html#step-3-data-cleaning",
    "title": "2  Fulton (EN)",
    "section": "Step 3: Data cleaning",
    "text": "Step 3: Data cleaning\n\nCreate an object called surveillance_date defined as 7 days prior to the reporting date (30 June 2021). Then, create another object rounding it to the closest Wednesday. Create two sequences of dates, one as the 14 days prior to the surveillance_date and another as 14-28 days prior to the same date. We will use these throughout the case study\nClean the column names\nEnsure that dates are considered dates by R\nClean date columns dealing with values that are not compatible with the period under analysis (early 2020 to July 2021)\nClean the rest of columns, ensuring that missing values are considered NA by R, ensuring that data values are plausible (e.g., no negative age) and recoding data into new variables as you see appropriate.\nCreate a column named “epiweek” using the report date which rounds the report date to the nearest week, taking “Wednesday” as the start of the week.\nRemove duplicates from the data\nFilter the data to keep only confirmed cases whose date of report is not above the date of the report (June 30, 2021). Consider also keeping recors with missing date of report.\n\n\nQuestion 3.1: How many duplicated rows were present in the raw data?\n\n 28 31 38 124\n\nError in eval(expr, envir, enclos): oggetto 'opts3.2' non trovato\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n##############       DEFINE DATES     ##############        \n\n# Here we create a date object (surveillance date), which is the day of the report minus 7\n# days to take into account delay in reporting. This object can be used throughout \n# the document for filtering datasets, plots/tables, etc. \n# \n# We also create a week object to make grouping data easier. In this scenario we \n# have defined the week to start on Wednesdays as this is when Fulton County \n# releases their reports (but you can choose any other day of the week too). \n# \n# From these we are then able to define periods 14 and 28 days prior to our \n# report date. We can also make the appropriate labels to auto-populate\n# table titles.\n\n# create a date object for the surveillance\n# Minus 7 days from the date of report (see YAML) to account for lag in reporting lab results\nsurveillance_date &lt;- as.Date(\"2021-06-30\") - 7\n\n# create an epiweek object from the date \n# floor_date() rounds down to the closest week here\nsurveillance_week &lt;- floor_date(surveillance_date,\n                          # round by weeks\n                          unit = \"week\", \n                          # define week to start on Wednesday\n                          week_start = 3)\n\n# define recent (past 14 days) and previous (28 to 14 days prior)\nrecent_period   &lt;- seq(surveillance_week  - 13, surveillance_week, by = 1)\nprevious_period &lt;- seq(surveillance_week  - 27, surveillance_week - 14, by = 1)\n\n# define a text label of date range for the recent period (for table headers)\nrecent_period_labels &lt;- str_c(\n  format(min(recent_period), format = \"%m/%d\"), \n  \"-\", \n  format(max(recent_period), format = \"%m/%d\")\n)\n\n# define text label of date range for previous period (for table headers) \nprevious_period_labels &lt;- str_c(\n  format(min(previous_period), format = \"%m/%d\"), \n  \"-\", \n  format(max(previous_period), format = \"%m/%d\")\n)\n\n\n# define a label for past 28 days (for table captions)\nfull_period_labels &lt;- str_c(\n  format(min(previous_period), format = \"%B %d\"), \n  \"-\", \n  format(surveillance_week, format = \"%B %d, %Y\")\n)\n\n\n##############        CLEAN NAMES     ##############        \n\n# Here we are going to clean the column names of our data set - and store as a new\n# dataset called \"linelist\". \n# \n# It is possible to use the {janitor} package for automated cleaning of variable \n# names - but as there are only a few variables that we want to rename, \n# here we will demonstrate using {dplyr} select() function for manually renaming.\n# \n# Select() can be used either to retain specific columns or to rename them by using\n# the syntax New name = Old name. \n# \n# For more details see: \n# https://epirhandbook.com/cleaning-data-and-core-functions.html#column-names\n\n\n# create a new object called linelist and assign linelist_raw with renamed columns\nlinelist &lt;- linelist_raw %&gt;% \n  # use select() to retain columns and rename them \n     # NEW name = OLD name\n     # aligned for readability\n  select( \n    pid                 = PID,\n    date_report         = reprt_creationdt_FALSE,      \n    date_dob            = case_dob_FALSE,              \n    age                 = case_age,                    \n    gender              = case_gender,\n    race                = case_race,\n    eth                 = case_eth,\n    zip                 = case_zip,\n    # county              = case_county,\n    # district            = case_district,\n    # state               = case_state,\n    contact_id          = Contact_id, \n    date_onset          = sym_startdt_FALSE,\n    sym_fever,\n    sym_subjfever,\n    sym_myalgia,\n    sym_losstastesmell,\n    sym_sorethroat,\n    sym_cough,\n    sym_headache,\n    sym_resolved,\n    date_recovery       = sym_resolveddt_FALSE, \n    contact_hh          = contact_household,\n    hospitalized,  \n    date_hospitalized   = hosp_admidt_FALSE,\n    date_discharge      = hosp_dischdt_FALSE,\n    died,  \n    died_covid,  \n    date_died           = died_dt_FALSE,\n    confirmed_case, \n    covid_dx, \n    date_positive       = pos_sampledt_FALSE,\n    lat                 = latitude_JITT,\n    lon                 = longitude_JITT\n    )\n\n\n##############        CLEAN DATES     ##############        \n\n# Here we are going to clean the date variables \n# \n# The {base} way to convert columns to Date class is with as.Date(). If the\n# current format is YYYY-MM-DD or YYYY/MM/DD then no other arguments are needed. \n# If the format is different, specify it to format= (for more detail see: \n# https://epirhandbook.com/working-with-dates.html#convert-to-date )\n# \n# Below we also introduce using across() from {dplyr}, which allows you to apply a\n# function across multiple specified columns. See\n# https://epirhandbook.com/cleaning-data-and-core-functions.html#clean_across\n\n\nlinelist &lt;- linelist %&gt;% \n  # convert all date columns to date type \n  # note that dates must be formatted correctly - in some cases date parsers from lubridate can be used here\n  mutate(\n    date_report =       as.Date(date_report),\n    date_dob =          as.Date(date_dob),\n    date_onset =        as.Date(date_onset)\n    # date_recovery =     as.Date(date_recovery),\n    # date_hospitalized = as.Date(date_hospitalized),\n    # date_discharge =    as.Date(date_discharge),\n    # date_died =         as.Date(date_died),\n    # date_positive =     as.Date(date_positive)\n  ) %&gt;% \n  \n  # we can do this in a much faster way by by using across()\n  # the apply the as.Date() function to every column with \"date\" in the name\n  # contains() is a tidyselect function (see the handbook for details)\n  # the top mutate can be deleted now!\n  mutate(across(\n    .cols = contains(\"date\"),\n    .fns = ~as.Date(.x)\n  )) %&gt;%\n  \n  # remove onset dates prior to 2020\n  mutate(across(\n    .cols = c(date_report, date_onset, date_hospitalized, date_discharge, date_died),\n    .fns  = ~replace(.x, .x &lt; as.Date(\"2020-01-01\"), NA)\n    )) %&gt;% \n\n  # remove dates after the surveillance_date (for this report) from all date columns\n  mutate(across(\n    .cols = contains(\"date\"),\n    .fns  =  ~replace(.x, .x &gt; surveillance_date, NA)\n    )) %&gt;%\n     \n  # create an \"epiweek\" column from the report date \n  # floor_date() rounds down to the closest week\n  mutate(epiweek = floor_date(date_report,\n                          # round by weeks\n                          unit = \"week\", \n                          # define week to start on Wednesday\n                          week_start = 3)\n  )\n\n\n##############        CLEAN NUMERICS     ##############        \n\n# Here we are going to clean all numeric variables, as well as create some new \n# variables based on difference between dates. \n# \n# First we will ensure that age is numeric and then fix those with incorrectly \n# entered dates (notice that one individual was -20 years old). \n# \n# Then we show how to create new numeric variables for the number of days between \n# two dates. \n# \n# For more details see: \n# https://epirhandbook.com/cleaning-data-and-core-functions.html#num_cats\n# https://epirhandbook.com/cleaning-data-and-core-functions.html#clean_case_when\n# \n# Note the use of if_else() from {dplyr}, which is faster than {base}'s ifelse()\n# and handles dates better.  \n\n# Age \n############\n\nlinelist &lt;- linelist %&gt;%\n  mutate(\n    # ensure that age is a numeric variable\n    age = as.numeric(age),\n    # set those with negative ages and missing DOB to missing \n    # otherwise just leave the age value as is\n          # nb. NA_real_ just ensures the variable class is not changed\n    age = if_else(age &lt; 0 & is.na(date_dob), NA_real_, age)\n  )\n\n \n    \n# Calculating time differences \n##############################\n\nlinelist &lt;- linelist %&gt;%\n     \n  # delay from onset to hospitalization\n  mutate(\n    # calculate time differences\n    days_onset_hosp = as.numeric(date_hospitalized - date_onset),\n    # set those under 0 or over 30 to missing\n    days_onset_hosp = replace(days_onset_hosp, days_onset_hosp &lt; 0, NA),\n    days_onset_hosp = replace(days_onset_hosp, days_onset_hosp &gt; 30, NA)\n  ) %&gt;%\n     \n  # length of hospitalization\n  mutate(\n    # create outcome date based on whether died or was discharged\n    date_outcome = coalesce(date_died, date_discharge),\n    # calculate time difference\n    days_hosp = as.numeric(date_outcome - date_hospitalized),\n    # set those under 0 or over 60 to missing\n    days_hosp = replace(days_hosp, days_hosp &lt; 0, NA),\n    days_hosp = replace(days_hosp, days_hosp &gt; 60, NA)\n  )\n\n## it's a good habit to make sure the variables you're generating seem realistic\n# (are you calculating them correctly?)\n# summary(linelist$days_hosp)\n\n\n##############        CLEAN CATEGORIES     ##############        \n\n\n# create age groups based on the age variable using \n# the age_categories() function from {epikit}. It is also possible to create \n# age groups using the {dplyr} case_when() function - but is more involved. \n# \n# For more details see: \n# https://epirhandbook.com/cleaning-data-and-core-functions.html#column-creation-and-transformation\n# https://epirhandbook.com/cleaning-data-and-core-functions.html#re-code-values\n# https://epirhandbook.com/characters-and-strings.html?q=regex#regular-expressions-regex\n\nlinelist &lt;- linelist %&gt;% \n     \n     # create age group variable\n     mutate(\n       age_group = age_categories(age,\n        # define break points\n        c(0, 10, 20, 30, 40, 50, 60, 70),\n        # whether last break should be highest category\n        ceiling = FALSE\n     )) %&gt;% \n     \n     # recode one value and leave the rest as they are \n     mutate(\n       died_covid = if_else(died_covid == \"Under Review\",\n                            \"Unknown\", died_covid), \n       confirmed_case = if_else(confirmed_case == \"Pending\", \n                                \"Unknown\", confirmed_case), \n     \n        # force categorical variables to use consistent cases (this can be done for others) \n        sym_myalgia = str_to_title(sym_myalgia),\n      ) %&gt;% \n     \n     #replace one value and leave the rest, across multiple variables \n     # mutate(across(\n     #   .cols = c(contact_hh, contains(\"sym_\")),\n     #   .funs = ~if_else(.x == \"Unk\", \"Unknown\", .x)\n     # )) %&gt;% \n\n     # create a composite category from race and ethnicitiy  \n          #  (nb. this sets those that are non-specified in eth to non-hispanic)\n     mutate(eth_race = case_when(\n       # we evaluate if ethnicity is HISPANIC/LATINO **FIRST**\n       # case_when() evaluates in order (if, else if, else if, ... else)\n          eth  == \"HISPANIC/LATINO\"                           ~ \"Hispanic, all races\", \n          race == \"ASIAN\"                                     ~ \"Asian, NH\", \n          race == \"BLACK\"                                     ~ \"Black, NH\",\n          race == \"WHITE\"                                     ~ \"White, NH\",\n      # find all instances of NATIVE (covers AMERICAN INDIAN/ALASKA NATIVE **AND** NATIVE HAWAIIAN/PACIFIC ISLANDER)\n          str_detect(race, \"NATIVE\")                          ~ \"Other, NH\",\n          race == \"OTHER\"                                     ~ \"Other, NH\", \n          TRUE                                                ~ \"Unknown\"\n     )) %&gt;% \n     \n     ## change from upper-case to lower case (with leading capital)\n     # mutate(across(\n     #   .cols = c(county, state),\n     #   .fns = str_to_title\n     # )) %&gt;% \n     # \n     \n     # recode with searching for string patterns\n     # (from \"No-Asymptomatic\"/\"Yes-Symptomatic\"/\"Unknown\")\n     mutate(contact_id = case_when(\n       str_detect(contact_id, \"Yes\")     ~ \"Yes\", \n       str_detect(contact_id, \"No\")      ~ \"No\", \n       str_detect(contact_id, \"Unknown\") ~ \"Unknown\", \n       TRUE                              ~ \"Unknown\"\n     )) %&gt;% \n  \n     # # this section does the same as above, but takes advantage of the way the data is formatted\n     # # data is formatted as \"Yes/No-A/Symptomatic\"\n     # # remove text from a string (everything after the dash) - this uses regular expressions (regex)\n     # # see handbook section on regex for understanding how this works\n     # mutate(contact_id = str_remove(linelist$contact_id, \"-.*\")) %&gt;% \n\n     # recode with searching for string patterns \n     mutate(sym_resolved = case_when(\n          str_detect(sym_resolved, \"Yes\")     ~ \"Yes\", \n          str_detect(sym_resolved, \"No\")      ~ \"No\", \n          str_detect(sym_resolved, \"Unknown\") ~ \"Unknown\", \n          TRUE                                ~ \"Unknown\"\n     )) %&gt;% \n     \n     \n     # create a factor from a default numeric class\n     mutate(zip = as_factor(zip)) %&gt;% \n     \n  \n     # replace missing with \"Unknown\" where relevant \n     mutate(across(\n       .cols = c(gender, race, eth, zip,\n                 contact_id, contact_hh, \n                 hospitalized, died, died_covid, confirmed_case,\n                 contains(\"sym_\"), age_group),\n       .fns  = ~fct_explicit_na(.x, na_level = \"Unknown\")\n     )) %&gt;% \n    \n     # set levels of a factor (define order)\n     mutate(gender      = fct_relevel(gender, \"Female\", \"Male\", \"Unknown\"), \n            eth_race    = fct_relevel(eth_race, \n                                   \"Asian, NH\", \"Black, NH\", \"White, NH\", \n                                   \"Hispanic, all races\", \"Other, NH\", \"Unknown\")\n     ) %&gt;% \n     \n     # set levels of all factors that are yes/no/unknown \n     mutate(across(\n          .cols = c(contact_id, contact_hh, hospitalized, died, died_covid,\n                    confirmed_case, contains(\"sym_\")), \n          .fns = ~fct_relevel(.x, \"Yes\", \"No\", \"Unknown\")\n     ))\n\n##############       REMOVE DUPLICATES     ##############        \n\n\n# Here we remove the duplicates based on having the same pid, gender and date of \n# birth. \n# Note that this might exclude those which are legitimately reported twice - i.e. \n# those who recovered and were reinfected. To deal with these you could create a \n# composite variable of the identifiers of interest, flag the duplicates there and \n# then add an additional argument for having a report date within six months. \n# \n# For more details see: \n# https://epirhandbook.com/de-duplication.html \n\n\n# get a data frame of all the duplicates \n     # this is mostly to inspect manually, but can be used for analysing those dropped\nduplicates &lt;- linelist %&gt;% \n     get_dupes(pid, gender, date_dob)\n\nlinelist &lt;- linelist %&gt;% \n  ## find duplicates based on unique ID, gender and date of birth \n  ## only keep the first occurrence \n  distinct(pid, gender, date_dob, .keep_all = TRUE)\n\n\n##############       FILTER     ##############        \n\n\n# Here we are going to filter our data set to only keep relevant cases for analysis. \n# We keep those that are reported before our surveillance cut-off date and those \n# that are entered as a confirmed case. \n# \n# For more details see: \n# https://epirhandbook.com/cleaning-data-and-core-functions.html#filter-rows\n\n# store those which do not meet our filter criteria \ndropped &lt;- linelist %&gt;% \n     filter(confirmed_case != \"Yes\" |\n              date_report &gt; surveillance_date & \n                !is.na(date_report))\n\n\n# drop the cases that dont meet the criteria \nlinelist &lt;- linelist %&gt;% \n     filter(confirmed_case == \"Yes\" & \n              date_report &lt;= surveillance_date & \n                 !is.na(date_report))\n\n\n\nPlease, continue the case study by clicking in the tab above named: “Descriptive analysis”"
  },
  {
    "objectID": "fulton-en.html#step-4-start-the-report-with-a-summary-of-the-findings",
    "href": "fulton-en.html#step-4-start-the-report-with-a-summary-of-the-findings",
    "title": "2  Fulton (EN)",
    "section": "Step 4: Start the report with a summary of the findings",
    "text": "Step 4: Start the report with a summary of the findings\n\nWrite in rmarkdown three bullet points summarising the data we imported, showing the number of cases by the date of analysis, the number of hospitalisations and the number of deaths.\nWrite it in a dynamic way, so that the dates and numbers are updated automatically if you get a new updated dataset\n\n\n\nClick to see a solution (try it yourself first!)\n\n\nThis is an example of how the code should look like in your rmarkdown file:"
  },
  {
    "objectID": "fulton-en.html#step-5.-analysis-by-time",
    "href": "fulton-en.html#step-5.-analysis-by-time",
    "title": "2  Fulton (EN)",
    "section": "Step 5. Analysis by time",
    "text": "Step 5. Analysis by time\n\nCreate a table with the number of cases per reporting week to see how the epidemic evolved by time in Fulton County\nCreate an epicurve by reporting week, with the colour of the bins based on whether the cases were hospitalised or not\n\n\nQuestion 5.1: During which week do we observe the peak in cases by date of reporting?\n\n The week starting on March 02, 2021 The week starting on December 16, 2020 The week starting on January 13, 2021 The week starting on December 30, 2020\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n############ CREATE EPIWEEK TABLE ###################  \n\n# Here we use the {janitor} tabyl() function to get case counts by calendar week \n# (as well as the percentage these contribute to the overall). \n# \n# We then create use {flextable} to produce a clean output table. \n# \n# For more details see: \n# https://epirhandbook.com/descriptive-tables.html\n# https://epirhandbook.com/tables-for-presentation.html\n# https://epirhandbook.com/descriptive-tables.html#tbl_janitor\n\n# save a quick descriptive table of number of cases reported by week\nepiweek_table &lt;- linelist %&gt;% \n  # get counts and percentages \n  tabyl(epiweek) %&gt;% \n  # add the overall counts as a row\n  adorn_totals() %&gt;%  \n  # change from proportions to percentages (do not add a % sign)\n  adorn_pct_formatting(affix_sign = FALSE) \n\n# transform it into flextable for better visualisation\nepiweek_flextable &lt;- epiweek_table %&gt;% \n     qflextable()\n\n############ CREATE EPICURVE ###################  \n# Here we demonstrate how to plot epicurves using the {ggplot2} package.\n# \n# For more details see: \n# https://epirhandbook.com/epidemic-curves.html\n\n     # we first define the dataset to be used, the x axis which will be reporting week and the colour (fill) of the bins which will depend on hospitalisation outcome\nggplot(\n     data = linelist,\n     mapping = aes(\n          x = epiweek,\n          fill = hospitalized\n     )) + \n     \n     geom_histogram() + \n     \n     # we define that we want breaks by month and formated with scales::label_date_short()\n     scale_x_date(\n          date_breaks = \"month\",\n          labels = label_date_short()\n     ) +\n     \n     # we change the name of the different elements of the graph\n     labs(\n          x = \"\",\n          y = \"Weekly number of cases\",\n          fill = \"Hospitalised\",\n          caption = paste0(\"Data as of \", format(surveillance_date, \"%d %b %Y\"))\n          \n     ) + \n     \n     # we apply one of the predefined themes\n     theme_bw()"
  },
  {
    "objectID": "fulton-en.html#step-6.-analysis-by-person",
    "href": "fulton-en.html#step-6.-analysis-by-person",
    "title": "2  Fulton (EN)",
    "section": "Step 6. Analysis by person",
    "text": "Step 6. Analysis by person\n\nCreate a table summarising, with counts and percentages, the total cumulative number of cases and deaths, as well the cases and deaths notified in the last 28 days by demographic characteristics: sex, age and race.\nCreate an age pyramid with the percentage of cases by age group and sex.\nCreate a scatter plot showing the relation between age and duration of hospital stay. Colour the points based on whether cases died or not.\nCreate a bar stacked bar plot showing the absolute number of cases by race and vital status\n\n\nQuestion 6.1: In which age group do we observe the largest proportion of cumulative cases?\n\n 0-9 30-39 20-29 70+\n\nQuestion 6.2: In which race do we observe the largest proportion of deaths in the last 28 days?\n\n Black White Asian Hispanic\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n#################### A) TABLE WITH DEMOGRAPHIC CHARACTERISTICS ####################\n\n# Here we use {purrr} to iterate over demographics variables (defined in the \n# vector_vars code chunk) - to produce tables of counts and percentages for cases\n# and deaths. \n# \n# We use {dplyr} bind_rows() and bind_cols() to combine the various smaller dataframes\n# of counts in to one large table. \n# \n# And then we colour in our {flextable} with different criteria for each of the \n# demographic variables of interest. \n# \n# For more details see: \n# https://epirhandbook.com/tables-for-presentation.html\n# https://epirhandbook.com/iteration-loops-and-lists.html\n\n\n# get counts tables for measures of interest \n############################################\n\n# we generate 3 summary tables and bind them together\n# summary demographic table for gender\ndem_gender &lt;- linelist %&gt;% \n  tabyl(gender) %&gt;% \n  select(Characteristic = gender, n, percent)\n\n# summary demographic table for age\ndem_age &lt;- linelist %&gt;% \n  tabyl(age_group) %&gt;% \n  select(Characteristic = age_group, n, percent)\n\n# summary demographic table for ethnicity and race\ndem_eth_race &lt;- linelist %&gt;% \n  tabyl(eth_race) %&gt;% \n  select(Characteristic = eth_race, n, percent)\n\n# bind all tables together\ntotal_cases &lt;- bind_rows(list(dem_gender, dem_age, dem_eth_race))\n\n# type out the variables of interest\ndemographic_vars &lt;- c(\"gender\", \"age_group\", \"eth_race\")\n\n# the above can also be done iteratively (we are repeating code)\n# this uses the {purrr} package to iterate over each variable\n# counts of total cases \ntotal_cases &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars,\n  # create a table  \n  .f = ~tabyl(linelist, .x) %&gt;%\n        # only keep variables of interest and rename the variable column \n        # this is so that they are all the same for row binding \n        select(\"Characteristic\" = .x,\n               n_cases_total = n,\n               perc_cases_total = percent)\n  ) %&gt;% \n  # combine rows in to one dataframe\n  bind_rows()\n\n\n# counts of new cases (last 28 days) \nrecent_cases &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter the linelist for dates on or after 28 days ago\n  .f = ~filter(linelist, \n          date_report &gt;= (surveillance_date - 28)) %&gt;% \n        # get counts based on filtered data\n        tabyl(.x) %&gt;% \n        # nb we dont keep the characteristic column because it would be duplicated\n        select(n_cases_recent = n,\n               perc_cases_recent = percent)\n  ) %&gt;%\n  bind_rows()\n\n# counts of total deaths \ntotal_deaths &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter for those who died \n  .f = ~filter(linelist, \n          died_covid == \"Yes\") %&gt;% \n        # get counts based on filtered data \n        tabyl(.x, show_na = TRUE) %&gt;%\n        select(n_deaths_total = n, perc_deaths_total = percent)\n  ) %&gt;% \n  bind_rows()\n\n# counts of new deaths (last 28 days)\nrecent_deaths &lt;- purrr::map(\n  # for each variable listed\n  .x = demographic_vars, \n  # filter to those who died in the last 28 days\n  .f = ~filter(linelist, \n          died_covid == \"Yes\" & \n          date_died &gt;= (surveillance_date - 28)) %&gt;% \n        # get counts based on filtered data\n        tabyl(.x) %&gt;% \n        select(n_deaths_recent = n, perc_deaths_recent = percent) %&gt;% \n        # add in a variable column (used for colouring later) \n        mutate(variable = .x)\n  ) %&gt;% \n  bind_rows()\n\n\n# total counts for all of the above measures (not by demographic)\noverall &lt;- linelist %&gt;% \n  summarise(\n    # add in row label \n    Characteristic = \"Total\",\n    # counts of total cases \n    n_cases_total = n(),\n    # leave all percentages empty (would just be 100)\n    perc_cases_total  = NA, \n    # counts of new cases (last 28 days) \n    n_cases_recent = sum(date_report &gt;= (surveillance_date - 28)), \n    perc_cases_recent  = NA, \n    # counts of total deaths \n    n_deaths_total = sum(died_covid == \"Yes\"), \n    perc_deaths_total = NA, \n    # counts of new deaths (last 28 days)\n    n_deaths_recent = sum(died_covid == \"Yes\" & \n                          date_died &gt;= (surveillance_date - 28)),\n    perc_deaths_recent = NA, \n    # add in a variable column (used for colouring later) \n    variable = \"Overall\"\n  )\n\n\n\n# merge tables together \n#######################\n\n# combine all the demographic tables - side by side\ndemographics_counts &lt;- bind_cols(total_cases, recent_cases, total_deaths, recent_deaths) %&gt;% \n  # mutate each of the proportion columns to be percentages\n  mutate(across(\n    .cols = contains(\"perc\"),\n    .fns = ~round(.x * 100, digits = 1)\n    )) \n\n# add in the totals row at the top of the merged demographics table\ndemographics_counts &lt;- bind_rows(overall, demographics_counts)\n\n\n\n# define colour scheme \n######################\n\n# get the column numbers that are percentages (based on the name) \npercentage_cols &lt;- names(demographics_counts) %&gt;% \n  str_detect(\"perc\") %&gt;% \n  which()\n\n# define colour cut-offs for gender column \ngender_colours &lt;- scales::col_bin(\n  # choose colours \n  palette = c(\"#91CF60\", \"#FC8D59\"), \n  # choose min and max (range)\n  domain  = c(0, 100),\n  # choose how to split (in this case above and below 50)\n  bins    = 2\n)\n\n# define colour cut-offs for age column \nage_colours &lt;- scales::col_bin(\n  # choose colours\n  palette = c(\"#91CF60\",\"#FFFFBF\", \"#FC8D59\"),\n  # choose min and max (range)\n  domain  = c(0, 100), \n  # choose cut-off categories \n  bins    = c(0, 5, 20, 100)\n)\n\n# define colour cut-offs for ethnicity column \neth_colours &lt;- scales::col_bin(\n  palette = c(\"#91CF60\",\"#FFFFBF\", \"#FC8D59\"),\n  domain  = c(0, 100), \n  bins    = c(0, 10, 40, 100)\n)\n\n\n# create styled table  \n######################\n\ndemographics_counts %&gt;%\n  # initiate flextable to produce styled output table\n  flextable(\n    # retain variable column for formatting but do not display it\n    col_keys = names(demographics_counts)[-10]\n  ) %&gt;%\n  # redefine column names based on original names\n  set_header_labels(\n    \"n_cases_total\"       = \"Total Confirmed Cases\",\n    \"perc_cases_total\" = \"% of Total Cases\",\n    \"n_cases_recent\"       = \"Confirmed Cases past 28 days\",\n    \"perc_cases_recent\" = \"% of Confirmed Cases past 28 days\",\n    \"n_deaths_total\"       = \"Total Confirmed Deaths\",\n    \"perc_deaths_total\" = \"% of Total Deaths\",\n    \"n_deaths_recent\"       = \"Confirmed Deaths past 28 days\",\n    \"perc_deaths_recent\" = \"% of Confirmed Deaths past 28 days\"\n  ) %&gt;%\n  # move the header text to the centre\n  align(align = \"center\", part = \"header\") %&gt;%\n  # make header text bold\n  bold(part = \"header\") %&gt;%\n  # make the totals row bold (i.e. first row)\n  bold(i = 1, part = \"body\") %&gt;%\n  # fill in the cells\n  # choose the rows with gender counts\n  bg(i = ~variable == \"gender\",\n     # choose the columns with percentages in them\n     j = percentage_cols,\n     # fill in based on previous defined cut-offs\n     bg = gender_colours) %&gt;%\n  bg(i = ~variable == \"age_group\",\n     j = percentage_cols, bg = age_colours) %&gt;%\n  bg(i = ~variable == \"eth_race\",\n     j = percentage_cols, bg = eth_colours) %&gt;%\n  # add horizontal lines after the cells with totals and unknowns\n    # (short-cut to find row ending of each demographic variable)\n  hline(i = ~Characteristic %in% c(\"Total\", \"Unknown\")) %&gt;%\n  # add in footnotes for rows counting unknowns (reference in first column)\n  footnote(i = ~Characteristic == \"Unknown\", j = 1, part = \"body\", ref_symbols = c(\"a\"),\n           value = as_paragraph(\"Unknown includes cases not yet interviewed\")) %&gt;%\n  # add in footnote for deaths counts (ref in the header)\n  footnote(i = 1, j = c(6, 8), part = \"header\", ref_symbols = c(\"b\"),\n           value = as_paragraph(\"Deaths refer to all persons who had a positive PCR test result\n                                for Covid-19 and there is evidence that COVID-19 was the cause of\n                                death or a significant contributor to their death.\")) %&gt;%\n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\") %&gt;% \n  # decrease the fontsize in the header and body for aesthetic purposes in the document\n  fontsize(part = \"all\", size = 8)\n\n\n#################### B) AGE PYRAMID ####################\n\n# Here we demonstrate how to plot age pyramids using the {apyramid} package and edit\n# it with {ggplot2]. \n# \n# For more details see: \n# https://epirhandbook.com/demographic-pyramids-and-likert-scales.html\n\n# prepare dataset\n\n# start a new dataframe (as dont want to overwrite the original)\nlinelist_2g &lt;- linelist %&gt;% \n  # update the gender and age_group columns\n  mutate(across(.cols = c(gender, age_group), \n                .fns = ~{\n                  # replace \"Unknown\" with NA\n                  .x = na_if(.x, \"Unknown\") \n                  # drop \"Unknown\" from the factor levels \n                  .x = fct_drop(.x)\n                }))\n\n# plot age pyramid \nage_pyramid(\n  data = linelist_2g,\n  age_group = \"age_group\",\n  split_by = \"gender\",\n  # Show as percentages of total cases\n  proportional = TRUE,\n  # remove guide line for mid-point\n  show_midpoint = FALSE) +\n  # set theme to basic \n  theme_minimal() +\n  # add labels \n  labs(\n    title = \"\",\n    subtitle = ,\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = \"Gender\",\n    # use str_glue to set dynamic captions \n    # {missing} is defined in the second argument below\n    caption = str_glue(\n      \"{missing} cases missing either age or gender are not shown. \\n Fictional COVID-19 data\",\n      missing = linelist_2g %&gt;%\n        filter(is.na(gender) | is.na(age_group)) %&gt;%\n        nrow()\n      )\n    )\n\n#################### C) SCATTER PLOT ####################\n\n# Here we demonstrate how to plot points with {ggplot2}. \n# \n# For more details see: \n# https://epirhandbook.com/ggplot-basics.html#geoms\n\n# open a plot with the linelist data\nggplot(data = linelist) +\n  # add points \n  geom_point(\n    mapping = aes(\n      # plot age on the x and days hospitalised on the y axis \n      x = age,\n      y = days_hosp,\n      # color points by outcome\n      color = died),  \n    # all points 3x size\n    size = 3, \n    # opacity of 30% (i.e. relatively see-through)\n    alpha = 0.3) +      \n  # make the x and y axes start at the origin \n  scale_y_continuous(expand = c(0, 0)) + \n  scale_x_continuous(expand = c(0, 0)) + \n  # add in labels \n  labs(\n    x = \"Age (years)\",\n    y = \"Duration (days)\",\n    caption = \"Fulton COVID-19 data\",\n    color = \"Deceased\"\n    ) + \n     theme_bw()\n\n#################### D) BAR PLOT BY RACE ####################\n\n# Here we demonstrate how to plot bar charts with {ggplot2}. \n# \n# For more details see: \n# https://epirhandbook.com/ggplot-basics.html#geoms\n# https://epirhandbook.com/ggplot-tips.html\n\n# open a plot with the linelist data\nggplot(linelist) +\n  # add bars \n  geom_bar(\n    mapping = aes(\n      # plot the number of cases by ethnicity (ordered in reverse frequency)\n      x = fct_rev(fct_infreq(eth_race)),\n      # stack bars and colour by died (ordered in reverse frequency)\n      fill = fct_rev(fct_infreq(died))\n    )\n  ) +\n  # flip the x and y axes \n  coord_flip() +\n  # make the x axes start at the origin (nb axes flipped)\n  scale_y_continuous(expand = c(0, 0), \n                     # define where to label xaxis (nb axes flipped )\n                     breaks = seq(from = 0,\n                                  to = 35000,\n                                  by = 5000)) + \n  # add in labels \n  labs(\n    # set the axes titles (nb axes flipped)\n    x = \"Race and Ethnicity\",\n    y = \"Cases (n)\",\n    caption = \"Fictional COVID-19 data\",\n    fill = \"Deceased\"\n    ) + \n  # apply a defined theme\n     theme_bw()"
  },
  {
    "objectID": "fulton-en.html#step-7.-analysis-by-place",
    "href": "fulton-en.html#step-7.-analysis-by-place",
    "title": "2  Fulton (EN)",
    "section": "Step 7. Analysis by place",
    "text": "Step 7. Analysis by place\nCreate a table by zip code in which you show the incidence in the most recent 14 days period, the incidence in the previous 14 days period and the percentage change in incidence between these periods.\n\nQuestion 7.1: What is the change in incidence observed between periods in the zip code number 30337?\n\n +20% +36% -62.5% -25%\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n################### TABLE BY ZIP CODE\n\n# /// zip_counts \\\\\\\n# \n# # Here we use {dplyr} functions to get case counts based on ZIP Code and the \n# time periods created in the define_reporting_periods code chunk above. \n# We store as an object called zip_counts so that it can be merged with population\n# in the chunks below. \n# \n# For more details see: \n# https://epirhandbook.com/descriptive-tables.html#dplyr-package\n\nzip_counts &lt;- linelist %&gt;% \n  group_by(zip) %&gt;% \n  # count cases in the appropriate period \n  summarise(\n    recent   = sum(date_report %in% recent_period),\n    previous = sum(date_report %in% previous_period)\n  ) %&gt;% \n  adorn_totals() %&gt;% \n  # a percentage change column and round the digits\n  mutate(\n    perc_change = round((recent - previous) / previous * 100, digits = 1)\n    )\n\n\n# /// zip_join \\\\\\\n# \n# Here, use {dplyr} functions to extract the population counts from our shapefile, \n# and then merge these with our zip_counts from above. \n# N.b. the left_join() functions preserves all the rows from the first dataset \n# provided and only merges the rows from the second that match. \n# We then calculate incidence per 10,000 population. \n# \n# For more details see: \n# https://epirhandbook.com/descriptive-tables.html#dplyr-package\n# https://epirhandbook.com/joining-data.html\n\n# extract population counts for each zip from the shapefile\nzip_pop &lt;- shapefile %&gt;% \n  # change to tibble (otherwise geo-data gets pulled with)\n  as_tibble() %&gt;% \n  # only keep zip code and population counts\n  select(ZipCode, Population) %&gt;% \n  # add a row with overall counts\n  adorn_totals()\n  \n# merge case counts and population counts\n# zip (or ZipCode in the shapefile) variable is the unique identifier\nzip_counts &lt;- left_join(zip_counts, \n                        zip_pop, \n                        by = c(\"zip\" = \"ZipCode\")\n                        ) %&gt;% \n  # calculate the incidence \n  mutate(across(\n      # for each period (recent and previous)\n      .cols = c(recent, previous), \n      # divide each variable by population (and round the outcome)\n      .fns = ~round(.x / Population * 10000, digits = 1), \n      # for each period create a new variable with _inc on the end\n      .names = \"{.col}_inc\"), \n    \n    # replace NAs in incidence with 0\n    across(\n      .cols = contains(\"inc\"),\n      .fns = ~replace_na(.x, 0)),\n    \n    perc_change = case_when(\n      # fix the outliers: set missing to 0 and infinity (divided by 0) to 100\n      is.na(perc_change)       ~ 0,\n      is.infinite(perc_change) ~ 100, \n      TRUE                     ~ perc_change\n    ))\n\n# /// zip_table \\\\\\\n# \n# Here we use {flextable} to produce a publication-ready table. We also demonstrate\n# how to colour cells based on their values, defining the cut-offs in advance using\n# {dplyr} case_when(). Colours are called here using HEX-codes but can also be \n# referred to by name. \n# \n# For more details see: \n# https://epirhandbook.com/tables-for-presentation.html\n# https://colorbrewer2.org/#type=sequential&scheme=Reds&n=3\n\n# pick colours (uncomment next to lines)\n# RColorBrewer::brewer.pal(3, \"RdYlGn\") %&gt;% \n#   scales::show_col()\n\n# choose colours to fill in cells  \nrow_colour &lt;- case_when(\n  # those less than zero will be green (decreasing cases)\n  zip_counts$perc_change &lt; 0 ~ \"#91CF60\", \n  # over zero red (increasing)\n  zip_counts$perc_change &gt; 0 ~ \"#FC8D59\", \n  # missing or zero orange\n  TRUE                       ~ \"#FFFFBF\")\n\n\nzip_counts %&gt;% \n  # keep the columns of interest and define order\n  select(zip, recent, recent_inc, previous, previous_inc, perc_change) %&gt;% \n  # initiate {flextable} to produce styled output table\n  flextable() %&gt;% \n  # fill in cells - choose the column and then pass our colour-scheme defined above\n  bg(j = \"perc_change\", \n     bg = row_colour\n     ) %&gt;% \n  # add in a header for labeling counts and incidence by period \n    # note the empty columns (\"\") to fit to the original table headers\n  add_header_row(\n    values = c(\"\", \n               str_c(\"Recent 14-day reporting period\\n\", recent_period_labels), \n               \"\", \n               str_c(\"Previous 14-day reporting period\\n\", previous_period_labels), \n               \"\", \n               \"Change between reporting periods\"\n               )) %&gt;% \n  # redefine column names based on original names\n    # note the different syntax to dplyr::select, here it is old_name = new_name\n  set_header_labels(\n    zip          = \"Zip Code\", \n    recent       = \"n\", \n    recent_inc   = \"Incidence\", \n    previous     = \"n\", \n    previous_inc = \"Incidence\", \n    perc_change  = \"%\"\n  ) %&gt;% \n  # combine the headers cells for the appropriate periods \n  # (i defines rows, j defines columns)\n  merge_at(i = 1, j = 2:3, part = \"header\") %&gt;% \n  merge_at(i = 1, j = 4:5, part = \"header\") %&gt;% \n  # move the header text to the centre\n  align(align = \"center\", part = \"header\") %&gt;% \n  # make header text bold \n  bold(part = \"header\") %&gt;% \n  # make the row with totals in it bold (i.e. the last row in the dataframe)\n  bold(i = nrow(zip_counts), part = \"body\") %&gt;% \n  # add in footnotes for variables (referencing the header cells)\n  footnote(j = c(3, 5), part = \"header\", ref_symbols = c(\"a\"),\n           value = as_paragraph(\"Incidence calculated as cases per 10,000 population by zip code\")) %&gt;% \n  footnote(j = 6, part = \"header\", ref_symbols = c(\"b\"),\n           value = as_paragraph(\"These reflect the percentage increase or decrease of new diagnoses \n                                between the 14 days preceding the past 7 days and the 14 days\n                                preceding that.\")) %&gt;% \n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\")\n\n\n\nPlease, continue the case study by clicking in the tab above named: “Analysis of mortality”"
  },
  {
    "objectID": "fulton-en.html#step-8.-analysis-of-risk-factors-for-mortality",
    "href": "fulton-en.html#step-8.-analysis-of-risk-factors-for-mortality",
    "title": "2  Fulton (EN)",
    "section": "Step 8. Analysis of risk factors for mortality",
    "text": "Step 8. Analysis of risk factors for mortality\n\nCreate a table in which you assess, with the appropriate statistical tests, whether the demographic characteristics of those dying from Covid-19 are significantly different from cases who did not die from it.\nFor each of the variables used in the table that you just created, carry out univariate regression using each demographic variable as the independent variable and the outcome (dead, not dead) as the dependent variables. Create a table with the estimates -alongside 95% CI - of the estimates.\n\n\nQuestion 8.1: According to the results of the univariate analysis, how was having a sore throat associated with mortality from Covid-19\n\n It was a risk factor for mortality It was a protective factor for mortality It was not associated with mortality Impossible to know\n\n\n\n\nClick to see a solution (try it yourself first!)\n\n\n\n################### A) TABLE WITH DEMOGRAPHIC DIFFERENCES BY VITAL STATUS #################\n\n# /// rf_unknowns \\\\\\\n# \n# Here we need to define our variables of interest to investigate as risk factors. \n# We then need to swap factor levels so that the appropriate levels are selected \n# as the exposure level in regression. \n# We then need to keep only complete cases (i.e. that don't have any missings\n# for any of the variables of interest). \n# Finally, we  use the {labelled} package to assign text for each variable name to appear \n# in output tables. \n# \n# For more details see: \n# https://epirhandbook.com/univariate-and-multivariable-regression.html#store-explanatory-variables\n# https://epirhandbook.com/cleaning-data-and-core-functions.html#re-code-values\n# http://larmarange.github.io/labelled/\n\n# define a list of variables for looping over later\nsymptom_vars &lt;- linelist %&gt;% \n     # choose all columns that contain \"sym_\" in the name but exclude \"sym_resolved\"\n     select(c(contains(\"sym_\"), -sym_resolved)) %&gt;% \n     # pull the names out \n     names()\n\n# define variables of interest (save typing them out later) \ndescriptive_vars &lt;- c(\"gender\", \n                      \"age_group\",\n                      \"eth_race\",\n                      symptom_vars,\n                      \"hospitalized\",\n                      \"days_hosp\")\n\n# filter dataset  \nrf_data &lt;- linelist %&gt;% \n  # only keep variables of interest\n  select(died_covid, age, all_of(descriptive_vars)) %&gt;% \n  # set unknown back to NA for all factor variables\n  mutate(across(\n    .cols = where(is.factor),\n    .fns = ~fct_recode(.x, NULL = \"Unknown\"))) %&gt;% \n  # flip factor levels (so that the reference values are correct)\n  mutate(eth_race = fct_infreq(eth_race)) %&gt;% \n  mutate(gender = fct_relevel(gender, \"Female\", \"Male\")) %&gt;% \n  mutate(across(all_of(c(\"died_covid\", symptom_vars, \"hospitalized\")), \n                ~fct_relevel(.x, \"No\", \"Yes\")\n                )) %&gt;% \n  # only keep rows with complete data for all variables of interest\n  # note that this will drop rows where **ANY** of the listed variables are NA\n  drop_na(any_of(c(\"died_covid\", \"age\", descriptive_vars)))\n\n\n# define variable labels to show in output tables \nrf_data &lt;- rf_data %&gt;%\n  set_variable_labels(\n    died_covid = \"Died\",\n    age = \"Age (years)\",\n    gender = \"Gender\",\n    age_group = \"Age group (years)\",\n    eth_race = \"Ethnicity\",\n    sym_fever = \"Fever\",\n    sym_subjfever = \"Subjective fever\",\n    sym_myalgia = \"Myalgia\",\n    sym_losstastesmell = \"Loss taste/smell\",\n    sym_sorethroat = \"Sore throat\",\n    sym_cough = \"Cough\",\n    sym_headache = \"Headache\",\n    hospitalized = \"Hospitalized\",\n    days_hosp = \"Days in hospital\"\n  )\n\n\n# &lt;!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# /// simple_stats \\\\\\\n# --------------------------------------------------------------------------------\n# \n# Here we demonstrate how to do simple statistical tests using the {gtsummary} \n# package. We can define which tests to run for which variables and then modify the \n# table format afterwards, also using {gtsummary}. The syntax for formatting is \n# similar to {flextable} and as this needs to be in {flextable} for MS word anyway, \n# you could also do all the formatting using {flextable}.  \n# \n# For more details see: \n# https://epirhandbook.com/simple-statistical-tests.html#stats_gt\n# https://epirhandbook.com/tables-for-presentation.html\n\nrf_data %&gt;%\n  # keep variables of interest\n  select(died_covid, gender, eth_race, age, days_hosp) %&gt;%\n  # produce summary table and specify grouping variable\n  tbl_summary(\n    by = died_covid\n  ) %&gt;%\n  # specify what test to perform\n  add_p(\n    list(\n      all_continuous() ~ \"kruskal.test\",\n      eth_race ~ \"kruskal.test\",\n      all_dichotomous() ~ \"chisq.test\"\n    )\n  ) %&gt;%\n  # edit what the column headers say (using {gtsummary})\n  # nb. {n} automatically shows the number in that group and \\n is a linebreak\n  modify_header(update = list(\n    stat_1 ~ \"**Dead**\\n (N={n})\",\n    stat_2 ~ \"**Alive**\\n (N={n})\"\n  )) %&gt;%\n  # edit what it says in the footnote (using {gtsummary})\n  modify_footnote(update = list(\n    all_stat_cols() ~ \"n (%) for categorical;\\n median (IQR) for continuous\",\n    p.value ~ \"Pearson's Chi-squared test for dichotomous;\\n Kruskal-Wallis rank sum test for continuous and categorical\"\n  )) %&gt;%\n  # change to flextable format\n  as_flex_table() %&gt;%\n  # make header text bold (using {flextable})\n  bold(part = \"header\")\n\n###################### B) UNIVARIATE REGRESSION ANALYSIS ####################################\n\n# /// regression \\\\\\\n# \n# Here we demonstrate how to do univariate regression to produce odds ratios with \n# {gtsummary}. We first create a regression table, then a counts table and then \n# finally merge the two and format the output. \n# Note that a cox regression taking into account observation time might be a \n# more appropriate analysis given the question on mortality - you could do this \n# using {gtsummary} but take a look at the epiRhandbook page on survival analysis.\n# \n# For more details see: \n# https://epirhandbook.com/univariate-and-multivariable-regression.html\n# https://epirhandbook.com/survival-analysis.html\n# https://epirhandbook.com/tables-for-presentation.html\n\n# produce table with regression estimates\nregress_tab &lt;- rf_data %&gt;%\n  # drop variables not interested in \n  select(-age_group) %&gt;%\n  # produce univariate table\n  tbl_uvregression(\n    # define outcome variable\n    y = died_covid, \n    # define regression want to run (generalised linear model)\n    method = glm, \n    # define what type of glm want to run (logistic)\n    method.args = list(family = binomial), \n    # exponentiate to produce odds ratios (rather than log odds)\n    exponentiate = TRUE, \n    # do not show the overall counts (this is done in cross_tab below)\n    hide_n = TRUE,\n    ## uncomment this line if you want to not show reference rows\n    # show_single_row = c(symptom_vars, gender, hospitalized),\n    ## note: NULL at the end allows you to have a comma before a commented out row\n    NULL\n  )\n\n# produce table with counts by outcome (using the data fed to the regression above)\ncross_tab &lt;- regress_tab$inputs$data %&gt;%\n  tbl_summary(\n    # group by outcome \n    by = died_covid,\n    ## uncomment this line if you only want to show the \"Male\" row for gender\n    ## this would be run if you also uncommented the single_row in regression above\n    # value = list(gender ~\"Male\"),\n    ## show all levels (otherwise only shows the \"Yes\" level)\n    type = list(all_dichotomous() ~ \"categorical\"),\n    ## note: NULL at the end allows you to have a comma before a commented out row\n    NULL\n  )\n\n# combine tables \ntbl_merge(list(cross_tab, regress_tab)) %&gt;%\n  # edit what it says in the grouping headers \n  modify_spanning_header(update = list(\n    c(\"stat_1_1\",\"stat_2_1\") ~ \"Died\",\n    c(\"estimate_2\", \"ci_2\", \"p.value_2\") ~ \"Univariate regression\")\n    ) %&gt;% \n  # edit what it says in the footnote (using {gtsummary})\n  modify_footnote(update = list(\n    all_stat_cols() ~ \"n (%) for categorical;\\n median (IQR) for continuous\")\n    ) %&gt;% \n  # change to flextable format\n  as_flex_table() %&gt;%\n  # make header text bold (using {flextable})\n  bold(part = \"header\") %&gt;% \n  # make your table fit to the maximum width of the word document\n  set_table_properties(layout = \"autofit\")"
  }
]